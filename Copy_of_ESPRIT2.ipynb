{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ESPRIT2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/opooladz/ESPRIT-Autoencoder-Anomaly-Detection/blob/master/Copy_of_ESPRIT2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ctjGCWel6JV5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install nvidia-cuda-toolkit\n",
        "!pip3 install numba\n",
        "\n",
        "import os\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/lib/nvidia-cuda-toolkit/libdevice\"\n",
        "os.environ['NUMBAPRO_NVVM'] = \"/usr/lib/x86_64-linux-gnu/libnvvm.so\"\n",
        "\n",
        "from numba import cuda\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "@cuda.jit\n",
        "def hello(data):\n",
        "    data[cuda.blockIdx.x, cuda.threadIdx.x] = cuda.blockIdx.x\n",
        "\n",
        "numBlocks = 5\n",
        "threadsPerBlock = 10\n",
        "\n",
        "data = np.ones((numBlocks, threadsPerBlock), dtype=np.uint8)\n",
        "\n",
        "hello[numBlocks, threadsPerBlock](data)\n",
        "\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ls_UG_Iv50o5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "6b1d0bb1-fb1b-4c54-b587-57bde9266cc1"
      },
      "cell_type": "code",
      "source": [
        "!pip install numba"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numba\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/89/6f1755892d60ddd528090dc313349e7cc491170d6737f6b3a7a5b317ef81/numba-0.39.0-cp36-cp36m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.9MB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from numba) (1.14.5)\n",
            "Collecting llvmlite>=0.24.0dev0 (from numba)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/05/c1b933d6b3dd6a234b681605e4154c44d21ee22cbef315c4eb9d64e6ab6a/llvmlite-0.24.0-cp36-cp36m-manylinux1_x86_64.whl (15.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 15.9MB 2.5MB/s \n",
            "\u001b[?25hInstalling collected packages: llvmlite, numba\n",
            "Successfully installed llvmlite-0.24.0 numba-0.39.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "32BPXqrHfNrs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5d2af99-b50d-430c-cb90-63b0d579678e"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import toeplitz\n",
        "from numpy import linalg as lg\n",
        "from time import time\n",
        "from typing import Tuple\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import regularizers\n",
        "from numba import jit\n",
        "\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "\n",
        "@jit\n",
        "def compute_autocovariance(x: np.ndarray, M: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    This function compute the auto-covariance matrix of a numpy signal.\n",
        "    The auto-covariance is computed as follows\n",
        "    .. math:: \\textbf{R}=\\frac{1}{N}\\sum_{M-1}^{N-1}\\textbf{x}_{m}\\textbf{x}_{m}^{H}\n",
        "    where :math:`\\textbf{x}_{m}^{T}=[x[m],x[m-1],x[m-M+1]]`.\n",
        "    :param x: 1-D vector of size N\n",
        "    :param M:  int, optional. Size of signal block.\n",
        "    :returns: NxN ndarray\n",
        "    \"\"\"\n",
        "\n",
        "    # Create covariance matrix for psd estimation\n",
        "    # length of the vector x\n",
        "    x = np.asarray(x).squeeze()\n",
        "    assert x.ndim == 1, '1-D only'\n",
        "    N = x.size\n",
        "\n",
        "    # Create column vector (Nx1) from row array\n",
        "    x_vect = x[None, :].T\n",
        "\n",
        "    # init covariance matrix\n",
        "    yn = x_vect[M-1::-1]  # reverse order from M-1 to 0\n",
        "\n",
        "    R = yn @ yn.conj().T  # zeroth lag\n",
        "    # about 5-8% of computation time\n",
        "    for i in range(1, N-M):  # no zero because we just computed it\n",
        "        # extract the column vector\n",
        "        yn = x_vect[M-1+i:i-1:-1]\n",
        "\n",
        "        R = R + yn @ yn.conj().T\n",
        "\n",
        "    return R / N\n",
        "@jit\n",
        "def wrapper(x):\n",
        "  return np.convolve(x,xc,mode=\"valid\")\n",
        "\n",
        "@jit\n",
        "def esprit1(x: np.ndarray, L: int, M: int=None, fs: int=1,\n",
        "           verbose: bool=False) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    This function estimate the frequency components based on the ESPRIT algorithm [ROY89]_\n",
        "    The frequencies are related to the roots as :math:`z=e^{-2j\\pi f/Fe}`.\n",
        "    See [STO97]_ section 4.7 for more information about the implementation.\n",
        "    :param x: ndarray, Nsamples\n",
        "    :param L: int. Number of components to be extracted.\n",
        "    :param M:  int, optional. Size of signal block.\n",
        "    :param Fs: float. Sampling Frequency.\n",
        "    :returns: ndarray ndarray containing the L frequencies\n",
        "    >>> import numpy as np\n",
        "    >>> import spectral_analysis.spectral_analysis as sa\n",
        "    >>> Fe=500\n",
        "    >>> t=1.*np.arange(100)/Fe\n",
        "    >>> x=np.exp(2j*np.pi*55.2*t)\n",
        "    >>> f=sa.Esprit(x,1,None,Fe)\n",
        "    >>> print(f)\n",
        "    \"\"\"\n",
        "\n",
        "    x = np.asarray(x).squeeze()\n",
        "    assert x.ndim in (1, 2)\n",
        "    # length of the vector x\n",
        "    if x.ndim == 1:\n",
        "        N = x.size\n",
        "    else:\n",
        "        N = x.shape[1]\n",
        "\n",
        "    if M is None:\n",
        "        M = N // 2\n",
        "# %% extract signal subspace  99.9 % of computation time\n",
        "    tic = time()\n",
        "    if x.ndim == 1 and isinstance(M, int):\n",
        "        R = compute_autocovariance(x, M)  # 75% of computation time        \n",
        "    else:\n",
        "        # the random phase of transmit/receive/target actually helps--need at least 5-6 observations to make useful\n",
        "        R = np.cov(x, rowvar=False)\n",
        "    if verbose:\n",
        "        print('autocov sec.', time()-tic)\n",
        "    # R = subspace.corrmtx(x.astype(complex128),M).astype(float) #f2py fortran\n",
        "\n",
        "    tic = time()\n",
        "    #U, S, V = lg.svd(R)  # 25% of computation time\n",
        "    w, v = lg.eig(R)    \n",
        "    idx = w.argsort()[::-1]   \n",
        "    w = w[idx]\n",
        "    v = v[:,idx]    \n",
        "    if verbose:\n",
        "        print('svd sec.', time()-tic)\n",
        "# %% take eigenvalues and determine sinusoid frequencies\n",
        "    # Remove last row\n",
        "    S1 = v[:-1, :L]\n",
        "    # Remove first row\n",
        "    S2 = v[1:, :L]\n",
        "\n",
        "    # Compute matrix Phi (Stoica 4.7.12)  <0.1 % of computation time\n",
        "    Phi = lg.inv(S1.conj().T @ S1) @ S1.conj().T @ S2\n",
        "\n",
        "    # Perform eigenvalue decomposition <0.1 % of computation time\n",
        "    V, U = lg.eig(Phi)\n",
        "\n",
        "    # extract frequencies ((note that there a minus sign since Yn are defined as [y(n), y(n-1),y(n-2),..].T))\n",
        "    ang = -np.angle(V)\n",
        "\n",
        "    # frequency normalisation\n",
        "    f = fs*ang / (2.*np.pi)\n",
        "    t = np.arange(0, 0.01, 1/fs)\n",
        "    \n",
        "    x2 = np.exp(-1j*2*np.pi*t[::-1])[:,np.newaxis]**f\n",
        "    #display(xc.shape)\n",
        "    #ampCisoid = np.apply_along_axis(lambda q: np.convolve(q,xc,mode=\"valid\"),axis = 0,arr=x2)\n",
        "    ampCisoid = np.apply_along_axis(wrapper,axis = 0,arr=x2)\n",
        "    return f, np.abs(w[:L]), np.abs(ampCisoid)*1./480., np.angle(ampCisoid)\n",
        "  \n",
        "\n",
        "def esprit2(x: np.ndarray, L: int, M: int=None, fs: int=1,\n",
        "           verbose: bool=False) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    This function estimate the frequency components based on the ESPRIT algorithm [ROY89]_\n",
        "    The frequencies are related to the roots as :math:`z=e^{-2j\\pi f/Fe}`.\n",
        "    See [STO97]_ section 4.7 for more information about the implementation.\n",
        "    :param x: ndarray, Nsamples\n",
        "    :param L: int. Number of components to be extracted.\n",
        "    :param M:  int, optional. Size of signal block.\n",
        "    :param Fs: float. Sampling Frequency.\n",
        "    :returns: ndarray ndarray containing the L frequencies\n",
        "    >>> import numpy as np\n",
        "    >>> import spectral_analysis.spectral_analysis as sa\n",
        "    >>> Fe=500\n",
        "    >>> t=1.*np.arange(100)/Fe\n",
        "    >>> x=np.exp(2j*np.pi*55.2*t)\n",
        "    >>> f=sa.Esprit(x,1,None,Fe)\n",
        "    >>> print(f)\n",
        "    \"\"\"\n",
        "\n",
        "    x = np.asarray(x).squeeze()\n",
        "    assert x.ndim in (1, 2)\n",
        "    # length of the vector x\n",
        "    if x.ndim == 1:\n",
        "        N = x.size\n",
        "    else:\n",
        "        N = x.shape[1]\n",
        "\n",
        "    if M is None:\n",
        "        M = N // 2\n",
        "# %% extract signal subspace  99.9 % of computation time\n",
        "    tic = time()\n",
        "    if x.ndim == 1 and isinstance(M, int):\n",
        "        R = compute_autocovariance(x, M)  # 75% of computation time\n",
        "    else:\n",
        "        # the random phase of transmit/receive/target actually helps--need at least 5-6 observations to make useful\n",
        "        R = np.cov(x, rowvar=False)\n",
        "    if verbose:\n",
        "        print('autocov sec.', time()-tic)\n",
        "    # R = subspace.corrmtx(x.astype(complex128),M).astype(float) #f2py fortran\n",
        "\n",
        "    tic = time()\n",
        "    U, S, V = lg.svd(R)  # 25% of computation time\n",
        "    #w, v = lg.eig(R)    \n",
        "    #idx = w.argsort()[::-1]   \n",
        "    #w = w[idx]\n",
        "    #v = v[:,idx]    \n",
        "    if verbose:\n",
        "        print('svd sec.', time()-tic)\n",
        "# %% take eigenvalues and determine sinusoid frequencies\n",
        "    # Remove last row\n",
        "    S1 = U[:-1, :L]\n",
        "    # Remove first row\n",
        "    S2 = U[1:, :L]\n",
        "\n",
        "    # Compute matrix Phi (Stoica 4.7.12)  <0.1 % of computation time\n",
        "    Phi = lg.inv(S1.conj().T @ S1) @ S1.conj().T @ S2\n",
        "\n",
        "    # Perform eigenvalue decomposition <0.1 % of computation time\n",
        "    V, U = lg.eig(Phi)\n",
        "\n",
        "    # extract frequencies ((note that there a minus sign since Yn are defined as [y(n), y(n-1),y(n-2),..].T))\n",
        "    ang = -np.angle(V)\n",
        "\n",
        "    # frequency normalisation\n",
        "    f = fs*ang / (2.*np.pi)\n",
        "\n",
        "    return f, S[:L]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "vpUQO1epmo5v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "260087ef-5ee4-4e7a-9331-88b3389c2df8"
      },
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "\n",
        "# Bool: Needs to be set by user \n",
        "full_anom = 0\n",
        "anom_samples = 0\n",
        "\n",
        "x = np.random.randn(4096).astype(np.complex128)\n",
        "F = 12345.6\n",
        "\n",
        "f0 = 12345.6\n",
        "f1 = 1000.6\n",
        "f2 = 726.6\n",
        "f3 = 57.3\n",
        "\n",
        "f0=np.random.uniform(low=0.,high = 10000.)\n",
        "f1=np.random.uniform(low=0.,high = 10000.)\n",
        "f2=np.random.uniform(low=0.,high = 10000.)\n",
        "f3 = np.random.uniform(low=0.,high = 10000.)\n",
        "\n",
        "\n",
        "c0 = 15.\n",
        "c1 = 7.\n",
        "c2 = 10.\n",
        "c0= np.random.uniform(low=3.,high = 100.)\n",
        "c1= np.random.uniform(low=3.,high = 100.)\n",
        "c2= np.random.uniform(low=3.,high = 100.)\n",
        "c3 = np.random.uniform(low=3.,high = 100.)\n",
        "\n",
        "fs = 48e3\n",
        "snr = 20.  # dB\n",
        "Ntone = 6\n",
        "\n",
        "t = np.arange(0, 0.01, 1/fs)\n",
        "\n",
        "nvar = 10**(-snr/10.)\n",
        "\n",
        "\n",
        "\n",
        "M = [100] * 300  # iterating over block length\n",
        "\n",
        "py = DataFrame(index=M, columns=['err', 'sigma','cisoidAmp','cisoidAngle'])\n",
        "fortreal = DataFrame(index=M, columns=['err', 'sigma','cisoidAmp','cisoidAngle'])\n",
        "fortcmpl = DataFrame(index=M, columns=['err', 'sigma','cisoidAmp','cisoidAngle'])\n",
        "fest = []\n",
        "fest2 = []\n",
        "cisoidAmp = []\n",
        "cisoidAmp2 = []\n",
        "i = 0\n",
        "for m in M:\n",
        "    i = i + 1\n",
        "    # Generate fist tripplet of cisoid  \n",
        "    # Train data start\n",
        "    xc = c0*np.exp(1j*2*np.pi*f0*t)+c1*np.exp(1j*2*np.pi*f1*t) +c2*np.exp(1j*2*np.pi*f2*t)\n",
        "    xc1 = xc + np.sqrt(nvar)*(np.random.randn(t.size) + 1j*np.random.randn(t.size))\n",
        "  \n",
        "    tmpFest, sigma,tmpAmp,cisoidAngle = esprit1(xc1, Ntone//2, M=m, fs=fs, verbose=False)\n",
        "    fest.append(tmpFest)\n",
        "    tmpAmp = tmpAmp[0]\n",
        "    cisoidAmp.append(tmpAmp)\n",
        "    # Train data end \n",
        "    \n",
        "    # Test section start\n",
        "    \n",
        "    # Inject Anomaly\n",
        "    if not(full_anom or i%40):\n",
        "      display(i)\n",
        "      for j in np.arange(anom_samples):\n",
        "        display(i)\n",
        "        xc2 = c0*np.exp(1j*2*np.pi*f0*t)+c1*np.exp(1j*2*np.pi*f1*t) +c3*np.exp(1j*2*np.pi*f3*t)+ np.sqrt(nvar)*(np.random.randn(t.size) + 1j*np.random.randn(t.size))\n",
        "        tmpFest, sigma,tmpAmp,cisoidAngle = esprit1(xc2, Ntone//2, M=m, fs=fs, verbose=False)\n",
        "        fest2.append(tmpFest)\n",
        "        tmpAmp = tmpAmp[0]\n",
        "        cisoidAmp2.append(tmpAmp) \n",
        "    # When not Anomaly use xc as baseline signal and add AWGN - Run through esprit\n",
        "    xc2 = xc +  np.sqrt(nvar)*(np.random.randn(t.size) + 1j*np.random.randn(t.size))\n",
        "    if full_anom:\n",
        "      xc2 = c0*np.exp(1j*2*np.pi*f0*t)+c1*np.exp(1j*2*np.pi*f1*t) +c3*np.exp(1j*2*np.pi*f3*t)+ np.sqrt(nvar)*(np.random.randn(t.size) + 1j*np.random.randn(t.size))\n",
        "    tmpFest, sigma,tmpAmp,cisoidAngle = esprit1(xc2, Ntone//2, M=m, fs=fs, verbose=False)\n",
        "    fest2.append(tmpFest)\n",
        "    tmpAmp = tmpAmp[0]\n",
        "    cisoidAmp2.append(tmpAmp)  \n",
        "    # Test section end \n",
        "\n",
        "# Create train and test set     \n",
        "x_train = np.hstack((cisoidAmp,fest))    \n",
        "x_test = np.hstack((cisoidAmp2,fest2))\n",
        "    "
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "240"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "280"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "u0i86OadtTfo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "481fe2be-dfda-4dc0-db27-6d0856cad56d"
      },
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "metadata": {
        "id": "FKHmRNFTldag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "f76f5e3b-d385-4fd3-8d62-c3acf382fd0d"
      },
      "cell_type": "code",
      "source": [
        "full_anom = 0\n",
        "anom_samples = 1\n",
        "fest2 = []\n",
        "cisoidAmp2 = []\n",
        "i = 0\n",
        "for m in M:\n",
        "    i = i + 1\n",
        "    \n",
        "    # Test section start\n",
        "    \n",
        "    # Inject Anomaly\n",
        "    if not(full_anom or i%20):\n",
        "      display(i)\n",
        "      for j in np.arange(anom_samples):\n",
        "        display(i)\n",
        "        xc2 = c0*np.exp(1j*2*np.pi*f0*t)+c1*np.exp(1j*2*np.pi*f1*t) +c2*np.exp(1j*2*np.pi*f3*t)+ np.sqrt(nvar)*(np.random.randn(t.size) + 1j*np.random.randn(t.size))\n",
        "        tmpFest, sigma,tmpAmp,cisoidAngle = esprit1(xc2, Ntone//2, M=m, fs=fs, verbose=False)\n",
        "        fest2.append(tmpFest)\n",
        "        tmpAmp = tmpAmp[0]\n",
        "        cisoidAmp2.append(tmpAmp) \n",
        "    # When not Anomaly use xc as baseline signal and add AWGN - Run through esprit\n",
        "    xc2 = xc +  np.sqrt(nvar)*(np.random.randn(t.size) + 1j*np.random.randn(t.size))\n",
        "    if full_anom:\n",
        "      xc2 = c0*np.exp(1j*2*np.pi*f0*t)+c1*np.exp(1j*2*np.pi*f1*t) +c2*np.exp(1j*2*np.pi*f3*t)+ np.sqrt(nvar)*(np.random.randn(t.size) + 1j*np.random.randn(t.size))\n",
        "    tmpFest, sigma,tmpAmp,cisoidAngle = esprit1(xc2, Ntone//2, M=m, fs=fs, verbose=False)\n",
        "    fest2.append(tmpFest)\n",
        "    tmpAmp = tmpAmp[0]\n",
        "    cisoidAmp2.append(tmpAmp)  \n",
        "    # Test section end \n",
        "\n",
        "# Create train and test set     \n",
        "x_test = np.hstack((cisoidAmp2,fest2))"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ri27AZRJdco4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7137
        },
        "outputId": "157ea5e9-0ef4-4be9-8e5b-9713e5b25d94"
      },
      "cell_type": "code",
      "source": [
        "display(cisoidAmp2)\n",
        "display(cisoidAmp)\n",
        "\n"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[array([93.00542398, 68.47235078,  9.18655282]),\n",
              " array([93.00543023, 68.47235094,  9.18527796]),\n",
              " array([93.00545337, 68.47235109,  9.18466791]),\n",
              " array([93.00544724, 68.47235073,  9.18694677]),\n",
              " array([93.00544428, 68.47235109,  9.18504655]),\n",
              " array([93.00542367, 68.47235106,  9.18476745]),\n",
              " array([93.00544329, 68.47235048,  9.18740015]),\n",
              " array([93.00545165, 68.47235099,  9.18517441]),\n",
              " array([93.00542956, 68.47235104,  9.1876641 ]),\n",
              " array([93.00545083, 68.47235108,  9.18556481]),\n",
              " array([93.00543306, 68.47235103,  9.18655683]),\n",
              " array([93.0054376 , 68.47235109,  9.18438757]),\n",
              " array([93.00543856, 68.47235107,  9.18627001]),\n",
              " array([93.00543117, 68.47235094,  9.18627307]),\n",
              " array([93.00542879, 68.47235068,  9.18682128]),\n",
              " array([93.00544571, 68.47235108,  9.1871391 ]),\n",
              " array([93.00542213, 68.47235097,  9.18695734]),\n",
              " array([93.0054344 , 68.47235083,  9.18656433]),\n",
              " array([93.00542734, 68.47235097,  9.18853224]),\n",
              " array([93.00543287,  0.71454789,  9.18535378]),\n",
              " array([93.00542979, 68.47235088,  9.18449268]),\n",
              " array([93.0054581 , 68.47235102,  9.18656461]),\n",
              " array([93.00542105, 68.47235095,  9.18714196]),\n",
              " array([93.00544155, 68.47235086,  9.18351568]),\n",
              " array([93.00544167, 68.47235094,  9.18548603]),\n",
              " array([93.00542886, 68.47235102,  9.18537936]),\n",
              " array([93.00544362, 68.47235109,  9.18615436]),\n",
              " array([93.00543928, 68.47235109,  9.18740181]),\n",
              " array([93.00543353, 68.47235102,  9.18537053]),\n",
              " array([93.00542792, 68.47235099,  9.18469119]),\n",
              " array([93.00542026, 68.47235067,  9.18537264]),\n",
              " array([93.00543503, 68.47235001,  9.18781632]),\n",
              " array([93.00542746, 68.47234963,  9.18835716]),\n",
              " array([93.00543543, 68.47235101,  9.18570324]),\n",
              " array([93.00544356, 68.47235109,  9.18543818]),\n",
              " array([93.00542027, 68.47235071,  9.1856682 ]),\n",
              " array([93.00542843, 68.47235106,  9.1878912 ]),\n",
              " array([93.00543064, 68.47235108,  9.18585415]),\n",
              " array([93.00542633, 68.47235108,  9.18893926]),\n",
              " array([93.00542828, 68.47235078,  9.18417431]),\n",
              " array([93.00543984,  0.71880723,  9.18568723]),\n",
              " array([93.00543714, 68.47235108,  9.18620624]),\n",
              " array([93.00543622, 68.47235101,  9.18793571]),\n",
              " array([93.00544642, 68.47235109,  9.1876558 ]),\n",
              " array([93.00542823, 68.47235073,  9.18671946]),\n",
              " array([93.00542812, 68.47235069,  9.1866206 ]),\n",
              " array([93.00542865, 68.47235109,  9.18901176]),\n",
              " array([93.00543229, 68.47235106,  9.1870357 ]),\n",
              " array([93.00542341, 68.47235093,  9.18710381]),\n",
              " array([93.00543599, 68.47235109,  9.18641403]),\n",
              " array([93.00544328, 68.47235108,  9.18811239]),\n",
              " array([93.00543239, 68.47235099,  9.1844147 ]),\n",
              " array([93.00543265, 68.47235082,  9.18730261]),\n",
              " array([93.0054382 , 68.47235062,  9.1857963 ]),\n",
              " array([93.00544467, 68.47235105,  9.18592681]),\n",
              " array([93.0054224 , 68.47235073,  9.18500359]),\n",
              " array([93.00543344, 68.47235109,  9.18614994]),\n",
              " array([93.00544968, 68.47235107,  9.18803594]),\n",
              " array([93.00543135, 68.472351  ,  9.1852103 ]),\n",
              " array([93.00542748, 68.472351  ,  9.18581941]),\n",
              " array([93.00543404, 68.47235077,  9.18506331]),\n",
              " array([93.00544977,  0.7153496 ,  9.18650674]),\n",
              " array([93.00544007, 68.47235072,  9.18709405]),\n",
              " array([93.00543082, 68.47235095,  9.18700866]),\n",
              " array([93.00545117, 68.47235086,  9.18658722]),\n",
              " array([93.00543898, 68.47235109,  9.1866329 ]),\n",
              " array([93.00544244, 68.47235097,  9.18403234]),\n",
              " array([93.00544062, 68.47235077,  9.18669257]),\n",
              " array([93.00543525, 68.4723504 ,  9.18683267]),\n",
              " array([93.00542479, 68.47235069,  9.18742383]),\n",
              " array([93.00544405, 68.47235001,  9.18432687]),\n",
              " array([93.0054465 , 68.4723504 ,  9.18503814]),\n",
              " array([93.00544317, 68.47235101,  9.184663  ]),\n",
              " array([93.00543151, 68.47235104,  9.18495202]),\n",
              " array([93.00543858, 68.47235108,  9.18630606]),\n",
              " array([93.00542163, 68.472351  ,  9.18701283]),\n",
              " array([93.00543204, 68.47235092,  9.18508795]),\n",
              " array([93.005439  , 68.47235015,  9.18470163]),\n",
              " array([93.00544081, 68.47235096,  9.18548289]),\n",
              " array([93.00543914, 68.47235001,  9.18458624]),\n",
              " array([93.0054288 , 68.47235094,  9.18824954]),\n",
              " array([93.00542546, 68.4723508 ,  9.18794499]),\n",
              " array([93.0054339 ,  0.72039679,  9.18646705]),\n",
              " array([93.00543778, 68.47235104,  9.18205522]),\n",
              " array([93.00543137, 68.47235054,  9.18893545]),\n",
              " array([93.00544323, 68.4723509 ,  9.18890536]),\n",
              " array([93.00543428, 68.47235096,  9.18679449]),\n",
              " array([93.0054445 , 68.47235098,  9.18660656]),\n",
              " array([93.00545654, 68.47235097,  9.18866265]),\n",
              " array([93.00542123, 68.4723507 ,  9.18677762]),\n",
              " array([93.00544079, 68.47235109,  9.18700167]),\n",
              " array([93.00542606, 68.4723509 ,  9.18831792]),\n",
              " array([93.0054455 , 68.47235104,  9.1863046 ]),\n",
              " array([93.00544066, 68.47235109,  9.184825  ]),\n",
              " array([93.00543865, 68.47235088,  9.18609108]),\n",
              " array([93.00544856, 68.47235086,  9.18578662]),\n",
              " array([93.0054436 , 68.47235095,  9.18280316]),\n",
              " array([93.00544307, 68.47235082,  9.18615603]),\n",
              " array([93.00544049, 68.47235103,  9.1836865 ]),\n",
              " array([93.00542488, 68.47235109,  9.18420173]),\n",
              " array([93.00544062, 68.47235058,  9.18646526]),\n",
              " array([93.0054304 , 68.47235068,  9.18696204]),\n",
              " array([93.00543528, 68.47235065,  9.1849148 ]),\n",
              " array([93.00543952,  0.72192902,  9.18441845]),\n",
              " array([93.00544531, 68.4723507 ,  9.18936639]),\n",
              " array([93.00543844, 68.47235108,  9.18631562]),\n",
              " array([93.00543296, 68.47235104,  9.18603092]),\n",
              " array([93.00542333, 68.47235082,  9.18636251]),\n",
              " array([93.00542694, 68.47235085,  9.18305383]),\n",
              " array([93.00543931, 68.47235092,  9.18490258]),\n",
              " array([93.00544004, 68.47235096,  9.18536157]),\n",
              " array([93.00544418, 68.47235103,  9.18570884]),\n",
              " array([93.00541961, 68.472351  ,  9.18746603]),\n",
              " array([93.00544169, 68.47235068,  9.18757067]),\n",
              " array([93.00544609, 68.47235079,  9.18480778]),\n",
              " array([93.00543974, 68.47235083,  9.18776791]),\n",
              " array([93.0054424 , 68.47235104,  9.18598992]),\n",
              " array([93.00543619, 68.47235105,  9.18520465]),\n",
              " array([93.00544323, 68.47235091,  9.18615872]),\n",
              " array([93.00542409, 68.47235109,  9.18843972]),\n",
              " array([93.0054404 , 68.47235094,  9.18714463]),\n",
              " array([93.00545481, 68.47235089,  9.18496083]),\n",
              " array([93.00544926, 68.47235108,  9.18513642]),\n",
              " array([93.00543536, 68.47235102,  9.18443466]),\n",
              " array([93.00543707,  0.71722933,  9.18525698]),\n",
              " array([93.00539747, 68.47235106,  9.18964708]),\n",
              " array([93.00543504, 68.47235074,  9.18665206]),\n",
              " array([93.00543777, 68.47235075,  9.18549782]),\n",
              " array([93.00544699, 68.47235105,  9.18872195]),\n",
              " array([93.00543297, 68.47235066,  9.1847207 ]),\n",
              " array([93.00543786, 68.47235093,  9.18672907]),\n",
              " array([93.00544944, 68.47235098,  9.18330429]),\n",
              " array([93.00542769, 68.47235106,  9.18562325]),\n",
              " array([93.00543138, 68.47235106,  9.18629126]),\n",
              " array([93.00542796, 68.47235089,  9.18797052]),\n",
              " array([93.00544178, 68.47235103,  9.1861693 ]),\n",
              " array([93.00544123, 68.47235104,  9.18789274]),\n",
              " array([93.00543378, 68.4723509 ,  9.18776336]),\n",
              " array([93.0054282 , 68.47235108,  9.18636924]),\n",
              " array([93.00544522, 68.47235105,  9.18553115]),\n",
              " array([93.00544742, 68.47235055,  9.18497176]),\n",
              " array([93.00543122, 68.47235104,  9.18522914]),\n",
              " array([93.00543574, 68.47235109,  9.18629674]),\n",
              " array([93.00543001, 68.47235071,  9.18384277]),\n",
              " array([93.00544675, 68.47235107,  9.18565648]),\n",
              " array([93.00544175,  0.7177462 ,  9.18613261]),\n",
              " array([93.00543691, 68.47235109,  9.1857821 ]),\n",
              " array([93.00543344, 68.47235102,  9.18481865]),\n",
              " array([93.0054374 , 68.47235093,  9.18589589]),\n",
              " array([93.00543787, 68.47235024,  9.18378411]),\n",
              " array([93.00544204, 68.47235044,  9.19000192]),\n",
              " array([93.00544393, 68.47235106,  9.18538881]),\n",
              " array([93.00544039, 68.47235109,  9.18760199]),\n",
              " array([93.00546779, 68.47235108,  9.18636402]),\n",
              " array([93.0054332 , 68.47235027,  9.18588664]),\n",
              " array([93.00544259, 68.47235109,  9.1872021 ]),\n",
              " array([93.00544351, 68.47235042,  9.1887179 ]),\n",
              " array([93.00544775, 68.47235106,  9.1845799 ]),\n",
              " array([93.00545578, 68.47235108,  9.18739766]),\n",
              " array([93.00542763, 68.47235025,  9.18793591]),\n",
              " array([93.00542725, 68.47235104,  9.18553822]),\n",
              " array([93.005443  , 68.47235109,  9.18740097]),\n",
              " array([93.00543988, 68.47235085,  9.18295669]),\n",
              " array([93.00543604, 68.4723509 ,  9.18743146]),\n",
              " array([93.00546187, 68.47235041,  9.18480516]),\n",
              " array([93.00543989, 68.47235105,  9.18595362]),\n",
              " array([93.00543609,  0.71578886,  9.18621788]),\n",
              " array([93.00542433, 68.47235098,  9.18654161]),\n",
              " array([93.00544491, 68.47235071,  9.18606551]),\n",
              " array([93.005425  , 68.47235108,  9.1867356 ]),\n",
              " array([93.00541998, 68.47235041,  9.18599452]),\n",
              " array([93.00542801, 68.47235061,  9.1849859 ]),\n",
              " array([93.0054573 , 68.47235098,  9.18549223]),\n",
              " array([93.0054312 , 68.4723504 ,  9.18800073]),\n",
              " array([93.00544611, 68.47235044,  9.18639154]),\n",
              " array([93.00543598, 68.472351  ,  9.18418067]),\n",
              " array([93.00543262, 68.47235076,  9.1828981 ]),\n",
              " array([93.00542745, 68.47235073,  9.18445406]),\n",
              " array([93.00544002, 68.47235101,  9.18814078]),\n",
              " array([93.00544988, 68.47235108,  9.1862424 ]),\n",
              " array([93.00542814, 68.4723508 ,  9.18673294]),\n",
              " array([93.00543607, 68.47235001,  9.18699564]),\n",
              " array([93.00543009, 68.47235106,  9.18587635]),\n",
              " array([93.00545441, 68.47235108,  9.18501656]),\n",
              " array([93.00541695, 68.47235073,  9.18403194]),\n",
              " array([93.00543593, 68.472351  ,  9.18510328]),\n",
              " array([93.00544298, 68.4723508 ,  9.18487128]),\n",
              " array([93.0054503 ,  0.71711212,  9.18565323]),\n",
              " array([93.00545228, 68.47235088,  9.18831543]),\n",
              " array([93.00544111, 68.47235109,  9.18392976]),\n",
              " array([93.00543457, 68.47235026,  9.18650589]),\n",
              " array([93.00542695, 68.47234945,  9.18555551]),\n",
              " array([93.00543184, 68.47235109,  9.18658554]),\n",
              " array([93.0054525 , 68.47235108,  9.18679746]),\n",
              " array([93.00542204, 68.47235107,  9.18656483]),\n",
              " array([93.00544581, 68.47235019,  9.18736362]),\n",
              " array([93.00543127, 68.47235109,  9.18535983]),\n",
              " array([93.00542267, 68.47235103,  9.18602994]),\n",
              " array([93.0054114 , 68.47235092,  9.18777211]),\n",
              " array([93.005441  , 68.47235109,  9.1869032 ]),\n",
              " array([93.00544206, 68.47235109,  9.18486128]),\n",
              " array([93.00542865, 68.47235102,  9.18558067]),\n",
              " array([93.00544595, 68.47235073,  9.18444185]),\n",
              " array([93.0054228 , 68.47235097,  9.18628214]),\n",
              " array([93.00542635, 68.47235108,  9.18494788]),\n",
              " array([93.00543554, 68.47235107,  9.18602574]),\n",
              " array([93.00542053, 68.47235068,  9.18669738]),\n",
              " array([93.00540442, 68.47235109,  9.18548544]),\n",
              " array([93.00544798,  0.71332692,  9.18733507]),\n",
              " array([93.00544171, 68.47235109,  9.1859276 ])]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[array([93.00544826, 68.47235071,  9.18382735]),\n",
              " array([93.00544046, 68.47235107,  9.1852524 ]),\n",
              " array([93.00542699, 68.47235071,  9.18516183]),\n",
              " array([93.00543024, 68.47235027,  9.18525339]),\n",
              " array([93.00542015, 68.47235096,  9.18518695]),\n",
              " array([93.00544385, 68.47235108,  9.18429215]),\n",
              " array([93.00544764, 68.4723507 ,  9.18658561]),\n",
              " array([93.00542074, 68.47235077,  9.1885925 ]),\n",
              " array([93.00542092, 68.47235108,  9.18651842]),\n",
              " array([93.00544275, 68.47235083,  9.18374881]),\n",
              " array([93.00543151, 68.47235098,  9.18749926]),\n",
              " array([93.00545047, 68.47235089,  9.18494787]),\n",
              " array([93.00543821, 68.47235087,  9.18587203]),\n",
              " array([93.00544978, 68.47235094,  9.18580337]),\n",
              " array([93.00545341, 68.47235103,  9.1858805 ]),\n",
              " array([93.00544423, 68.47235045,  9.18540527]),\n",
              " array([93.00544968, 68.47235106,  9.18846549]),\n",
              " array([93.0054327 , 68.47235109,  9.18698757]),\n",
              " array([93.0054339 , 68.47235098,  9.18554322]),\n",
              " array([93.00543667, 68.47235106,  9.18846946]),\n",
              " array([93.00543408, 68.47235105,  9.18643519]),\n",
              " array([93.00545154, 68.47235102,  9.18591125]),\n",
              " array([93.0054293 , 68.47235109,  9.18451353]),\n",
              " array([93.00544006, 68.47235053,  9.18713902]),\n",
              " array([93.0054366 , 68.47235108,  9.18830967]),\n",
              " array([93.00544953, 68.47235062,  9.18584275]),\n",
              " array([93.00543081, 68.47235107,  9.18485124]),\n",
              " array([93.00542585, 68.47235106,  9.18739453]),\n",
              " array([93.00542328, 68.47235108,  9.18478588]),\n",
              " array([93.00544011, 68.47235095,  9.18480095]),\n",
              " array([93.00543415, 68.47235101,  9.18963047]),\n",
              " array([93.00545125, 68.47235068,  9.18315723]),\n",
              " array([93.00544791, 68.4723509 ,  9.18366379]),\n",
              " array([93.00543586, 68.47235013,  9.18647663]),\n",
              " array([93.00543468, 68.47235096,  9.18608396]),\n",
              " array([93.00543294, 68.47235062,  9.19066681]),\n",
              " array([93.00545985, 68.47235098,  9.18644256]),\n",
              " array([93.00544159, 68.47234988,  9.18949727]),\n",
              " array([93.0054287 , 68.47235069,  9.18606931]),\n",
              " array([93.00543695, 68.47235097,  9.18488113]),\n",
              " array([93.00543798, 68.47235062,  9.1888235 ]),\n",
              " array([93.00543668, 68.4723505 ,  9.18507425]),\n",
              " array([93.00542421, 68.47235109,  9.18522966]),\n",
              " array([93.00543398, 68.47235032,  9.1855647 ]),\n",
              " array([93.00543538, 68.47235094,  9.18397188]),\n",
              " array([93.00543072, 68.47235105,  9.1896582 ]),\n",
              " array([93.00543496, 68.47235108,  9.18616634]),\n",
              " array([93.00542764, 68.47235097,  9.18759861]),\n",
              " array([93.0054412 , 68.47235083,  9.18553471]),\n",
              " array([93.00544534, 68.47235108,  9.18638993]),\n",
              " array([93.00543414, 68.47235104,  9.18423175]),\n",
              " array([93.00543621, 68.47235109,  9.18476523]),\n",
              " array([93.00542993, 68.47235099,  9.18476798]),\n",
              " array([93.00542228, 68.47235041,  9.18706474]),\n",
              " array([93.00544215, 68.47235104,  9.18647967]),\n",
              " array([93.00544815, 68.47234972,  9.18871967]),\n",
              " array([93.0054314 , 68.47234993,  9.1861858 ]),\n",
              " array([93.00541997, 68.47235105,  9.18534054]),\n",
              " array([93.00543937, 68.47235109,  9.18797609]),\n",
              " array([93.00544754, 68.47235107,  9.1884871 ]),\n",
              " array([93.00543234, 68.47235091,  9.18552284]),\n",
              " array([93.00543536, 68.47235103,  9.18625877]),\n",
              " array([93.00543973, 68.47235108,  9.18459078]),\n",
              " array([93.00544881, 68.472351  ,  9.18612575]),\n",
              " array([93.00544458, 68.47235096,  9.18459456]),\n",
              " array([93.00545243, 68.47235107,  9.18593256]),\n",
              " array([93.0054326 , 68.47235109,  9.18706096]),\n",
              " array([93.0054278 , 68.47235086,  9.18697279]),\n",
              " array([93.00544236, 68.47235066,  9.18483291]),\n",
              " array([93.00544833, 68.47234948,  9.18725703]),\n",
              " array([93.00544782, 68.472351  ,  9.18369634]),\n",
              " array([93.00543212, 68.47234998,  9.18743043]),\n",
              " array([93.00543759, 68.47235096,  9.1866167 ]),\n",
              " array([93.0054354 , 68.47235097,  9.18649955]),\n",
              " array([93.00544937, 68.47235099,  9.18687069]),\n",
              " array([93.00544254, 68.47235041,  9.18455337]),\n",
              " array([93.00544322, 68.47235109,  9.18564239]),\n",
              " array([93.00543918, 68.47235109,  9.18890834]),\n",
              " array([93.00543061, 68.47235042,  9.18508697]),\n",
              " array([93.00543112, 68.472351  ,  9.18695105]),\n",
              " array([93.00544887, 68.47235105,  9.18740217]),\n",
              " array([93.00543101, 68.47235099,  9.18765672]),\n",
              " array([93.00544615, 68.47235064,  9.1865754 ]),\n",
              " array([93.00544668, 68.47235082,  9.1870424 ]),\n",
              " array([93.00543417, 68.47235107,  9.18850621]),\n",
              " array([93.00542909, 68.47235108,  9.18614416]),\n",
              " array([93.00544494, 68.47235107,  9.18223906]),\n",
              " array([93.00542601, 68.47235109,  9.18841504]),\n",
              " array([93.00544334, 68.47235109,  9.18549205]),\n",
              " array([93.00543973, 68.47235075,  9.18741515]),\n",
              " array([93.00542073, 68.47235106,  9.18262099]),\n",
              " array([93.00544098, 68.47235109,  9.1863789 ]),\n",
              " array([93.0054447 , 68.47235088,  9.18754808]),\n",
              " array([93.00544839, 68.47235048,  9.18904927]),\n",
              " array([93.00543529, 68.47235059,  9.18580631]),\n",
              " array([93.00544117, 68.47235071,  9.18509117]),\n",
              " array([93.00542543, 68.47235103,  9.18523187]),\n",
              " array([93.00542032, 68.47235107,  9.18579802]),\n",
              " array([93.00542956, 68.47235046,  9.18514704]),\n",
              " array([93.0054266 , 68.47235109,  9.18564502]),\n",
              " array([93.00542869, 68.47235094,  9.18642732]),\n",
              " array([93.00543226, 68.47235108,  9.18956064]),\n",
              " array([93.00543972, 68.47235079,  9.18721569]),\n",
              " array([93.00543942, 68.47235103,  9.18494011]),\n",
              " array([93.00544198, 68.47235069,  9.18601538]),\n",
              " array([93.00542302, 68.47235083,  9.18571166]),\n",
              " array([93.00542758, 68.47235109,  9.18267604]),\n",
              " array([93.00542002, 68.47235033,  9.18792438]),\n",
              " array([93.00545259, 68.47235098,  9.1863157 ]),\n",
              " array([93.00543262, 68.47235074,  9.18572197]),\n",
              " array([93.00543375, 68.47235089,  9.18662358]),\n",
              " array([93.0054237 , 68.47235092,  9.18618145]),\n",
              " array([93.00542703, 68.47235108,  9.19011815]),\n",
              " array([93.00543914, 68.47235071,  9.18892056]),\n",
              " array([93.00544745, 68.47235106,  9.18405328]),\n",
              " array([93.00544447, 68.47235078,  9.18634312]),\n",
              " array([93.00543653, 68.47235102,  9.18636628]),\n",
              " array([93.00543631, 68.47235087,  9.18417499]),\n",
              " array([93.00544615, 68.47235101,  9.18839189]),\n",
              " array([93.00544633, 68.47235109,  9.1862611 ]),\n",
              " array([93.00543687, 68.47235109,  9.18756441]),\n",
              " array([93.00542723, 68.47235109,  9.18555018]),\n",
              " array([93.00543396, 68.4723509 ,  9.18845315]),\n",
              " array([93.00545475, 68.47235083,  9.18577808]),\n",
              " array([93.00542835, 68.47235107,  9.18491242]),\n",
              " array([93.00544997, 68.47235102,  9.18523973]),\n",
              " array([93.00542908, 68.47235047,  9.18537603]),\n",
              " array([93.00542276, 68.47235109,  9.18567825]),\n",
              " array([93.00544429, 68.47235108,  9.18610655]),\n",
              " array([93.00542426, 68.47235042,  9.18883405]),\n",
              " array([93.00543384, 68.47235045,  9.18466556]),\n",
              " array([93.00543999, 68.47235003,  9.18244234]),\n",
              " array([93.00544562, 68.47235046,  9.18699889]),\n",
              " array([93.00543045, 68.47235082,  9.18667098]),\n",
              " array([93.005439  , 68.47235082,  9.18449258]),\n",
              " array([93.00544735, 68.47235096,  9.18598382]),\n",
              " array([93.0054306 , 68.47235097,  9.18673424]),\n",
              " array([93.0054391 , 68.47235103,  9.18628248]),\n",
              " array([93.00544417, 68.47235107,  9.18666268]),\n",
              " array([93.00544125, 68.472351  ,  9.1837269 ]),\n",
              " array([93.00542235, 68.47235105,  9.18806189]),\n",
              " array([93.00545665, 68.47235109,  9.18658172]),\n",
              " array([93.00542675, 68.47235093,  9.18689143]),\n",
              " array([93.00543264, 68.4723507 ,  9.18563838]),\n",
              " array([93.00542965, 68.47235016,  9.18493829]),\n",
              " array([93.0054484 , 68.47235094,  9.18864184]),\n",
              " array([93.00545774, 68.47235085,  9.18685824]),\n",
              " array([93.00542686, 68.4723509 ,  9.18641023]),\n",
              " array([93.0054191 , 68.472351  ,  9.18680269]),\n",
              " array([93.00543369, 68.47235027,  9.18444203]),\n",
              " array([93.00543276, 68.47235031,  9.18547437]),\n",
              " array([93.00543216, 68.47235079,  9.18631099]),\n",
              " array([93.0054318 , 68.47235109,  9.18813104]),\n",
              " array([93.00544766, 68.47235105,  9.18564528]),\n",
              " array([93.00543555, 68.47235109,  9.18433976]),\n",
              " array([93.00544337, 68.47235109,  9.18625822]),\n",
              " array([93.00543507, 68.47235107,  9.18622406]),\n",
              " array([93.00543001, 68.47235108,  9.18796678]),\n",
              " array([93.00545232, 68.4723509 ,  9.18456356]),\n",
              " array([93.00543455, 68.47235073,  9.18756989]),\n",
              " array([93.00544411, 68.47235085,  9.18795264]),\n",
              " array([93.005435  , 68.47235046,  9.18432185]),\n",
              " array([93.00542784, 68.47235082,  9.18600936]),\n",
              " array([93.00544665, 68.47235109,  9.1849456 ]),\n",
              " array([93.00544302, 68.47235103,  9.18546308]),\n",
              " array([93.00545278, 68.47234971,  9.18743185]),\n",
              " array([93.00543766, 68.47235108,  9.18790236]),\n",
              " array([93.00544625, 68.47235106,  9.18559145]),\n",
              " array([93.00543116, 68.47235105,  9.18487573]),\n",
              " array([93.0054314 , 68.47235104,  9.18515415]),\n",
              " array([93.00543303, 68.47235109,  9.18556969]),\n",
              " array([93.00542253, 68.47235056,  9.18312867]),\n",
              " array([93.00542145, 68.47235097,  9.18523455]),\n",
              " array([93.0054484 , 68.47235033,  9.18620415]),\n",
              " array([93.00543748, 68.47235081,  9.18580617]),\n",
              " array([93.00543552, 68.47235042,  9.18672682]),\n",
              " array([93.00542856, 68.47235109,  9.18766472]),\n",
              " array([93.00544487, 68.47235105,  9.18584896]),\n",
              " array([93.00544081, 68.47235101,  9.18694867]),\n",
              " array([93.00543369, 68.47235109,  9.18759633]),\n",
              " array([93.00543206, 68.47235106,  9.1850566 ]),\n",
              " array([93.00544267, 68.47235073,  9.18650041]),\n",
              " array([93.00544347, 68.47235093,  9.18681756]),\n",
              " array([93.00545943, 68.47235081,  9.18535539]),\n",
              " array([93.00544267, 68.47235109,  9.18314386]),\n",
              " array([93.00544166, 68.47235085,  9.18518674]),\n",
              " array([93.00543771, 68.47235107,  9.18441994]),\n",
              " array([93.00543286, 68.47235101,  9.18760988]),\n",
              " array([93.00542982, 68.47235087,  9.19016215]),\n",
              " array([93.00542183, 68.47235109,  9.18669804]),\n",
              " array([93.00542288, 68.47235107,  9.18514604]),\n",
              " array([93.00542354, 68.47235095,  9.18608594]),\n",
              " array([93.00543731, 68.47235103,  9.18733514]),\n",
              " array([93.00544874, 68.47235109,  9.18401789]),\n",
              " array([93.00541907, 68.47235093,  9.18470706]),\n",
              " array([93.00543705, 68.47235108,  9.18538928]),\n",
              " array([93.00544714, 68.47235098,  9.18832542]),\n",
              " array([93.00545876, 68.47235011,  9.18650722]),\n",
              " array([93.00544549, 68.47235107,  9.18898664]),\n",
              " array([93.00542875, 68.47235088,  9.18620471])]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UE4XLjKyNYB1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6964
        },
        "outputId": "c005affa-15a2-4f77-8e08-243a64dc442b"
      },
      "cell_type": "code",
      "source": [
        "display(fest2)\n",
        "display(fest)\n",
        "\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[array([2520.24601186, 6518.75541612, 5539.51346662]),\n",
              " array([2520.24082735, 6518.75611803, 5539.48113757]),\n",
              " array([2520.24404723, 6518.76260246, 5539.4891568 ]),\n",
              " array([2520.24776107, 6518.75218071, 5539.51915847]),\n",
              " array([2520.24187595, 6518.75417206, 5539.50322696]),\n",
              " array([2520.24262793, 6518.75941024, 5539.5336541 ]),\n",
              " array([2520.2371879 , 6518.75880462, 5539.48806348]),\n",
              " array([2520.24333602, 6518.75399104, 5539.55758521]),\n",
              " array([2520.24603343, 6518.75308744, 5539.50149856]),\n",
              " array([2520.24636987, 6518.7621706 , 5539.56075229]),\n",
              " array([2520.24179651, 6518.7579379 , 5539.42204218]),\n",
              " array([2520.25104699, 6518.75558791, 5539.49075416]),\n",
              " array([2520.24387559, 6518.75885616, 5539.50815474]),\n",
              " array([2520.24293999, 6518.7570123 , 5539.55807999]),\n",
              " array([2520.24548104, 6518.75312361, 5539.5309619 ]),\n",
              " array([2520.24812994, 6518.75516011, 5539.50841978]),\n",
              " array([2520.24610148, 6518.75977128, 5539.56489617]),\n",
              " array([2520.24617791, 6518.75742377, 5539.52893209]),\n",
              " array([2520.2460039 , 6518.75301124, 5539.52882296]),\n",
              " array([2520.23811173, 6518.75022442, 5539.5146987 ]),\n",
              " array([2520.24963296, 6518.75770679, 5539.41249941]),\n",
              " array([2520.244912  , 6518.75538126, 5539.51651005]),\n",
              " array([2520.24737404, 6518.75673495, 5539.46083657]),\n",
              " array([2520.25191001, 6518.76166292, 5539.48753256]),\n",
              " array([2520.23995952, 6518.75213344, 5539.52136913]),\n",
              " array([2520.24454156, 6518.75877376, 5539.47694848]),\n",
              " array([2520.24720823, 6518.76157921, 5539.46148278]),\n",
              " array([2520.23937598, 6518.761538  , 5539.52046007]),\n",
              " array([2520.24568318, 6518.75524145, 5539.47889502]),\n",
              " array([2520.24412565, 6518.75865353, 5539.47569304]),\n",
              " array([2520.244525  , 6518.75567329, 5539.49511427]),\n",
              " array([2520.24489915, 6518.76166919, 5539.52369778]),\n",
              " array([2520.24776176, 6518.74942582, 5539.53566322]),\n",
              " array([2520.24600977, 6518.75727201, 5539.47559825]),\n",
              " array([2520.24920391, 6518.75526229, 5539.50701281]),\n",
              " array([2520.24473802, 6518.75683604, 5539.50690408]),\n",
              " array([2520.2471602 , 6518.7576076 , 5539.50370114]),\n",
              " array([2520.25055102, 6518.75446962, 5539.5365843 ]),\n",
              " array([2520.24424487, 6518.7577719 , 5539.4503813 ]),\n",
              " array([2520.245259  , 6518.76151912, 5539.52052716]),\n",
              " array([2520.24632423, 6518.75337541, 5539.50632653]),\n",
              " array([2520.24417025, 6518.75676292, 5539.53047981]),\n",
              " array([2520.24315292, 6518.74811499, 5539.51666681]),\n",
              " array([2520.24342674, 6518.75363481, 5539.4966809 ]),\n",
              " array([2520.24755317, 6518.7502627 , 5539.5253028 ]),\n",
              " array([2520.24935101, 6518.75362779, 5539.56535088]),\n",
              " array([2520.24683513, 6518.75438458, 5539.4945668 ]),\n",
              " array([2520.24381287, 6518.75309234, 5539.4941838 ]),\n",
              " array([2520.24392144, 6518.75742629, 5539.42715926]),\n",
              " array([2520.24408582, 6518.76138304, 5539.47536471]),\n",
              " array([2520.24083086, 6518.75725167, 5539.48634973]),\n",
              " array([2520.24531868, 6518.75890516, 5539.46440746]),\n",
              " array([2520.24193839, 6518.75477523, 5539.51652953]),\n",
              " array([2520.24798806, 6518.75723426, 5539.51035162]),\n",
              " array([2520.25174031, 6518.7565756 , 5539.52233979]),\n",
              " array([2520.24524511, 6518.75505038, 5539.49384197]),\n",
              " array([2520.24603238, 6518.75975872, 5539.53473878]),\n",
              " array([2520.24147423, 6518.75921072, 5539.5546923 ]),\n",
              " array([2520.24945493, 6518.75806929, 5539.55311292]),\n",
              " array([2520.24377345, 6518.75652052, 5539.55355951]),\n",
              " array([2520.24194682, 6518.76005741, 5539.45864535]),\n",
              " array([2520.24757543, 6518.75542184, 5539.49865713]),\n",
              " array([2520.24389757, 6518.76186654, 5539.49636202]),\n",
              " array([2520.24416041, 6518.75353053, 5539.58479502]),\n",
              " array([2520.24591734, 6518.75882134, 5539.51138615]),\n",
              " array([2520.25020933, 6518.74721405, 5539.50605918]),\n",
              " array([2520.24623023, 6518.75224161, 5539.46676564]),\n",
              " array([2520.2478529 , 6518.75229419, 5539.45379589]),\n",
              " array([2520.23984268, 6518.75289703, 5539.52237386]),\n",
              " array([2520.24165766, 6518.7543971 , 5539.49647473]),\n",
              " array([2520.24504157, 6518.75408499, 5539.51245234]),\n",
              " array([2520.2390805 , 6518.75457904, 5539.50302824]),\n",
              " array([2520.24364968, 6518.75860856, 5539.50915815]),\n",
              " array([2520.24651312, 6518.75221585, 5539.51895732]),\n",
              " array([2520.24492763, 6518.75497541, 5539.48199424]),\n",
              " array([2520.2500913 , 6518.75812719, 5539.57502454]),\n",
              " array([2520.24439815, 6518.75478377, 5539.52393995]),\n",
              " array([2520.24920861, 6518.75929636, 5539.47087323]),\n",
              " array([2520.24088754, 6518.75162503, 5539.51945226]),\n",
              " array([2520.24280546, 6518.75622188, 5539.50641409]),\n",
              " array([2520.2447126 , 6518.75501587, 5539.49584105]),\n",
              " array([2520.24827216, 6518.75626173, 5539.47446268]),\n",
              " array([2520.24569312, 6518.75478803, 5539.54520248]),\n",
              " array([2520.24291102, 6518.7616783 , 5539.45215097]),\n",
              " array([2520.24208083, 6518.75044803, 5539.43921612]),\n",
              " array([2520.24934108, 6518.75758915, 5539.53585088]),\n",
              " array([2520.24475732, 6518.75532691, 5539.5058805 ]),\n",
              " array([2520.24736288, 6518.75142545, 5539.53514016]),\n",
              " array([2520.24614764, 6518.75316591, 5539.53243616]),\n",
              " array([2520.24043266, 6518.7600663 , 5539.54438484]),\n",
              " array([2520.2457437 , 6518.75287355, 5539.56164987]),\n",
              " array([2520.24648191, 6518.75167271, 5539.54396909]),\n",
              " array([2520.24375021, 6518.75386599, 5539.53047896]),\n",
              " array([2520.24329301, 6518.75587962, 5539.51784388]),\n",
              " array([2520.24343854, 6518.76404941, 5539.51769306]),\n",
              " array([2520.24581734, 6518.75475711, 5539.50451782]),\n",
              " array([2520.24254048, 6518.756363  , 5539.55710794]),\n",
              " array([2520.24436317, 6518.75916585, 5539.54256538]),\n",
              " array([2520.25089129, 6518.75948319, 5539.51961356]),\n",
              " array([2520.24464849, 6518.75397508, 5539.51180209]),\n",
              " array([2520.24281928, 6518.75611908, 5539.46880239]),\n",
              " array([2520.24390241, 6518.75626591, 5539.50761702]),\n",
              " array([2520.25298873, 6518.75737349, 5539.50953017]),\n",
              " array([2520.2480781 , 6518.75265726, 5539.51052014]),\n",
              " array([2520.25135297, 6518.75063519, 5539.58040158]),\n",
              " array([2520.25444389, 6518.74483909, 5539.54777084]),\n",
              " array([2520.24552682, 6518.75343447, 5539.52235102]),\n",
              " array([2520.24525496, 6518.75945675, 5539.49208952]),\n",
              " array([2520.24176935, 6518.75632126, 5539.49311657]),\n",
              " array([2520.24716573, 6518.7544157 , 5539.49580664]),\n",
              " array([2520.24488298, 6518.75922841, 5539.52783378]),\n",
              " array([2520.24426905, 6518.75619791, 5539.49264239]),\n",
              " array([2520.24750734, 6518.75726056, 5539.47786395]),\n",
              " array([2520.24270333, 6518.74718065, 5539.50231301]),\n",
              " array([2520.24508513, 6518.75856588, 5539.51997197]),\n",
              " array([2520.24301943, 6518.75232114, 5539.46933452]),\n",
              " array([2520.24781782, 6518.75594488, 5539.48202572]),\n",
              " array([2520.25232979, 6518.75685476, 5539.47311973]),\n",
              " array([2520.24562807, 6518.75708244, 5539.51919044]),\n",
              " array([2520.24097171, 6518.75204684, 5539.57632157]),\n",
              " array([2520.24683928, 6518.7530517 , 5539.51404506]),\n",
              " array([2520.24312726, 6518.74933246, 5539.52341472]),\n",
              " array([2520.24715789, 6518.75265576, 5539.51290336]),\n",
              " array([2520.24219823, 6518.75374389, 5539.53943087]),\n",
              " array([2520.25057545, 6518.76640808, 5539.52369476]),\n",
              " array([2520.24339815, 6518.75807854, 5539.4714077 ]),\n",
              " array([2520.2483743 , 6518.75632214, 5539.5301202 ]),\n",
              " array([2520.24326683, 6518.75796985, 5539.52109002]),\n",
              " array([2520.24958169, 6518.75409843, 5539.5213049 ]),\n",
              " array([2520.24005907, 6518.76170771, 5539.45425656]),\n",
              " array([2520.24789621, 6518.75067908, 5539.51888654]),\n",
              " array([2520.24289946, 6518.76118896, 5539.51463367]),\n",
              " array([2520.24876572, 6518.74987682, 5539.50015914]),\n",
              " array([2520.24941658, 6518.75841798, 5539.51599514]),\n",
              " array([2520.24327303, 6518.75676694, 5539.53627142]),\n",
              " array([2520.24257453, 6518.75416974, 5539.53285724]),\n",
              " array([2520.24822373, 6518.75167369, 5539.45415372]),\n",
              " array([2520.24189797, 6518.75902925, 5539.49360206]),\n",
              " array([2520.24971381, 6518.75515054, 5539.45761042]),\n",
              " array([2520.24472087, 6518.76288733, 5539.49338926]),\n",
              " array([2520.2499194 , 6518.75695877, 5539.50130041]),\n",
              " array([2520.24279983, 6518.75972177, 5539.58458047]),\n",
              " array([2520.24392887, 6518.75769587, 5539.51434495]),\n",
              " array([2520.24378518, 6518.75637918, 5539.50766974]),\n",
              " array([2520.24769655, 6518.75887768, 5539.54293297]),\n",
              " array([2520.25152266, 6518.75981462, 5539.47447547]),\n",
              " array([2520.24118566, 6518.75343044, 5539.44614815]),\n",
              " array([2520.24722662, 6518.75304569, 5539.50487612]),\n",
              " array([2520.24526602, 6518.7546014 , 5539.51811377]),\n",
              " array([2520.24664752, 6518.75245207, 5539.50838518]),\n",
              " array([2520.24197957, 6518.75185853, 5539.49253338]),\n",
              " array([2520.2463589 , 6518.75783272, 5539.54682983]),\n",
              " array([2520.24390918, 6518.75948238, 5539.554851  ]),\n",
              " array([2520.24531999, 6518.75551099, 5539.51484843]),\n",
              " array([2520.24610608, 6518.75715812, 5539.49802089]),\n",
              " array([2520.25118208, 6518.75826964, 5539.56004959]),\n",
              " array([2520.24374826, 6518.75825846, 5539.51120314]),\n",
              " array([2520.24396845, 6518.74857589, 5539.53696122]),\n",
              " array([2520.24420009, 6518.7526745 , 5539.53707038]),\n",
              " array([2520.24674093, 6518.75938769, 5539.511464  ]),\n",
              " array([2520.24984792, 6518.76309354, 5539.52760957]),\n",
              " array([2520.24696683, 6518.75384854, 5539.52481226]),\n",
              " array([2520.2367705 , 6518.75806183, 5539.5414799 ]),\n",
              " array([2520.24651816, 6518.75282539, 5539.51687138]),\n",
              " array([2520.24679834, 6518.75552479, 5539.50538043]),\n",
              " array([2520.24736153, 6518.76254735, 5539.51381129]),\n",
              " array([2520.24347236, 6518.75609449, 5539.45837663]),\n",
              " array([2520.24452657, 6518.7497505 , 5539.53893533]),\n",
              " array([2520.24325007, 6518.75138979, 5539.46326132]),\n",
              " array([2520.24909054, 6518.75630886, 5539.56622121]),\n",
              " array([2520.25011051, 6518.75823224, 5539.55867731]),\n",
              " array([2520.24297714, 6518.75174528, 5539.38834282]),\n",
              " array([2520.24658592, 6518.75889676, 5539.47702237]),\n",
              " array([2520.23969951, 6518.75490088, 5539.44587079]),\n",
              " array([2520.25013921, 6518.76091687, 5539.53494625]),\n",
              " array([2520.24869126, 6518.75676345, 5539.58227574]),\n",
              " array([2520.24733461, 6518.75173659, 5539.48846664]),\n",
              " array([2520.24499196, 6518.75828562, 5539.49424593]),\n",
              " array([2520.250244  , 6518.75019895, 5539.48254969]),\n",
              " array([2520.24624649, 6518.75500249, 5539.52337434]),\n",
              " array([2520.24767949, 6518.75295894, 5539.58002147]),\n",
              " array([2520.24416167, 6518.75673326, 5539.47353795]),\n",
              " array([2520.24729777, 6518.75302622, 5539.55556541]),\n",
              " array([2520.24129006, 6518.7606264 , 5539.55516313]),\n",
              " array([2520.24443183, 6518.75604575, 5539.46653616]),\n",
              " array([2520.23847407, 6518.75146168, 5539.57421088]),\n",
              " array([2520.24349805, 6518.75576795, 5539.52266005]),\n",
              " array([2520.24733313, 6518.75817361, 5539.59217792]),\n",
              " array([2520.25203736, 6518.75018432, 5539.52949829]),\n",
              " array([2520.24836946, 6518.75053462, 5539.45810427]),\n",
              " array([2520.25300845, 6518.75754226, 5539.58049042]),\n",
              " array([2520.24459949, 6518.76296476, 5539.47878935]),\n",
              " array([2520.24546443, 6518.75231832, 5539.44969525]),\n",
              " array([2520.24537012, 6518.7574652 , 5539.55787692]),\n",
              " array([2520.24956143, 6518.75258838, 5539.54007944]),\n",
              " array([2520.24858335, 6518.74737287, 5539.46022157]),\n",
              " array([2520.25155519, 6518.7593197 , 5539.50055398]),\n",
              " array([2520.24648816, 6518.75516499, 5539.46048276]),\n",
              " array([2520.24519744, 6518.75547099, 5539.55054776]),\n",
              " array([2520.25423833, 6518.7497072 , 5539.49800876])]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[array([9845.70281756, 6518.75732165, 5539.50301356]),\n",
              " array([9845.69144295, 6518.75507602, 5539.43380359]),\n",
              " array([9845.6989237 , 6518.75576413, 5539.55252133]),\n",
              " array([9845.70088568, 6518.7522811 , 5539.52781744]),\n",
              " array([9845.70578037, 6518.75562625, 5539.44009269]),\n",
              " array([9845.70297198, 6518.75587981, 5539.49594468]),\n",
              " array([9845.70045592, 6518.75333391, 5539.4929031 ]),\n",
              " array([9845.69209239, 6518.75911709, 5539.53820247]),\n",
              " array([9845.70049923, 6518.75963723, 5539.53495941]),\n",
              " array([9845.69813442, 6518.75071615, 5539.51981172]),\n",
              " array([9845.69672108, 6518.75325087, 5539.45620974]),\n",
              " array([9845.69986759, 6518.75957905, 5539.53631913]),\n",
              " array([9845.69538331, 6518.75358893, 5539.56192167]),\n",
              " array([9845.69696635, 6518.75960941, 5539.50665045]),\n",
              " array([9845.70169909, 6518.7638564 , 5539.53438418]),\n",
              " array([9845.70387831, 6518.75638105, 5539.54426849]),\n",
              " array([9845.69928589, 6518.75315094, 5539.52835173]),\n",
              " array([9845.69895024, 6518.75353206, 5539.51141595]),\n",
              " array([9845.69396976, 6518.757827  , 5539.49898417]),\n",
              " array([9845.69486224, 6518.75845932, 5539.515373  ]),\n",
              " array([9845.70031921, 6518.75741028, 5539.53799353]),\n",
              " array([9845.69555624, 6518.75121278, 5539.51887905]),\n",
              " array([9845.69535201, 6518.75794876, 5539.49610915]),\n",
              " array([9845.69821476, 6518.75372345, 5539.57864106]),\n",
              " array([9845.69320569, 6518.7594409 , 5539.51113897]),\n",
              " array([9845.70505526, 6518.75344241, 5539.51767574]),\n",
              " array([9845.70401145, 6518.75107134, 5539.49619331]),\n",
              " array([9845.69109009, 6518.75604773, 5539.54699754]),\n",
              " array([9845.69343604, 6518.75407167, 5539.58060845]),\n",
              " array([9845.70452776, 6518.75882803, 5539.50578122]),\n",
              " array([9845.69652785, 6518.75118475, 5539.50132736]),\n",
              " array([9845.69822478, 6518.75917277, 5539.53657237]),\n",
              " array([9845.70262338, 6518.75417649, 5539.5439103 ]),\n",
              " array([9845.70122298, 6518.75744647, 5539.47562144]),\n",
              " array([9845.69906205, 6518.75586981, 5539.55149506]),\n",
              " array([9845.69242333, 6518.75371569, 5539.51872177]),\n",
              " array([9845.6985138 , 6518.75092768, 5539.50268115]),\n",
              " array([9845.70235249, 6518.75989165, 5539.56363051]),\n",
              " array([9845.69558627, 6518.75665482, 5539.50043106]),\n",
              " array([9845.70088853, 6518.75444234, 5539.44294914]),\n",
              " array([9845.69399217, 6518.75630258, 5539.51926895]),\n",
              " array([9845.70190442, 6518.75265372, 5539.45293203]),\n",
              " array([9845.69614002, 6518.75498145, 5539.51008538]),\n",
              " array([9845.69987315, 6518.75732025, 5539.55422816]),\n",
              " array([9845.70170174, 6518.75290624, 5539.48438249]),\n",
              " array([9845.70119656, 6518.75771096, 5539.48116109]),\n",
              " array([9845.69808749, 6518.75361001, 5539.51444853]),\n",
              " array([9845.70372847, 6518.7616413 , 5539.56749244]),\n",
              " array([9845.70002391, 6518.75066727, 5539.53269084]),\n",
              " array([9845.69730718, 6518.75512773, 5539.48718414]),\n",
              " array([9845.69586104, 6518.75097659, 5539.52100564]),\n",
              " array([9845.70222494, 6518.75770182, 5539.49297578]),\n",
              " array([9845.69752772, 6518.7577556 , 5539.52492964]),\n",
              " array([9845.70178578, 6518.75390429, 5539.48016695]),\n",
              " array([9845.69909537, 6518.75300457, 5539.5497325 ]),\n",
              " array([9845.70172541, 6518.75784146, 5539.48646797]),\n",
              " array([9845.70498686, 6518.75522411, 5539.44600465]),\n",
              " array([9845.69749462, 6518.75422455, 5539.50501926]),\n",
              " array([9845.70120057, 6518.75648655, 5539.48716661]),\n",
              " array([9845.70067799, 6518.75222939, 5539.45383743]),\n",
              " array([9845.70335586, 6518.7568359 , 5539.55394271]),\n",
              " array([9845.70047287, 6518.75339088, 5539.44053353]),\n",
              " array([9845.70064324, 6518.75365236, 5539.53463178]),\n",
              " array([9845.69810352, 6518.75338482, 5539.49579319]),\n",
              " array([9845.69876719, 6518.75731645, 5539.53542771]),\n",
              " array([9845.70382575, 6518.75165083, 5539.51262744]),\n",
              " array([9845.69193499, 6518.75329769, 5539.54654679]),\n",
              " array([9845.70188895, 6518.75475092, 5539.53673918]),\n",
              " array([9845.69877105, 6518.75527731, 5539.53072127]),\n",
              " array([9845.69668595, 6518.75881408, 5539.51742026]),\n",
              " array([9845.69845099, 6518.75319008, 5539.52409861]),\n",
              " array([9845.69913558, 6518.75632135, 5539.49239423]),\n",
              " array([9845.69643377, 6518.76086967, 5539.47491313]),\n",
              " array([9845.70138112, 6518.75847219, 5539.54317233]),\n",
              " array([9845.6951564 , 6518.75176944, 5539.54201127]),\n",
              " array([9845.69301809, 6518.75932194, 5539.5195009 ]),\n",
              " array([9845.70430942, 6518.7515264 , 5539.52049654]),\n",
              " array([9845.69903725, 6518.7540013 , 5539.53791992]),\n",
              " array([9845.69285322, 6518.75568586, 5539.5070364 ]),\n",
              " array([9845.70541188, 6518.75458287, 5539.52564162]),\n",
              " array([9845.69415983, 6518.75565558, 5539.53464446]),\n",
              " array([9845.70231383, 6518.75620208, 5539.50526753]),\n",
              " array([9845.6979418 , 6518.7609123 , 5539.59001033]),\n",
              " array([9845.69204768, 6518.75432948, 5539.55176669]),\n",
              " array([9845.70261968, 6518.75712031, 5539.52814142]),\n",
              " array([9845.69672552, 6518.75364495, 5539.47532186]),\n",
              " array([9845.7026555 , 6518.75460933, 5539.55198301]),\n",
              " array([9845.7030531 , 6518.75497961, 5539.48542653]),\n",
              " array([9845.69771605, 6518.75433377, 5539.54662889]),\n",
              " array([9845.69839286, 6518.75449529, 5539.53263095]),\n",
              " array([9845.69943559, 6518.75424506, 5539.52752342]),\n",
              " array([9845.69886205, 6518.75839442, 5539.54663973]),\n",
              " array([9845.70483027, 6518.75598436, 5539.50978909]),\n",
              " array([9845.69812975, 6518.75359735, 5539.51246038]),\n",
              " array([9845.69852561, 6518.75382399, 5539.52318364]),\n",
              " array([9845.7008659 , 6518.76198711, 5539.49142891]),\n",
              " array([9845.6983574, 6518.750806 , 5539.4404508]),\n",
              " array([9845.70184835, 6518.75528798, 5539.54637642]),\n",
              " array([9845.69672002, 6518.75599029, 5539.53549158]),\n",
              " array([9845.69851421, 6518.75833749, 5539.52633315]),\n",
              " array([9845.69738659, 6518.75421793, 5539.5697664 ]),\n",
              " array([9845.70131453, 6518.75453467, 5539.54821246]),\n",
              " array([9845.69876469, 6518.75248161, 5539.48263458]),\n",
              " array([9845.70109662, 6518.75142659, 5539.54140343]),\n",
              " array([9845.69919798, 6518.7500847 , 5539.50067421]),\n",
              " array([9845.69809675, 6518.75853675, 5539.52093568]),\n",
              " array([9845.6969483 , 6518.75674076, 5539.55337311]),\n",
              " array([9845.7031002 , 6518.75316946, 5539.54161199]),\n",
              " array([9845.70098816, 6518.75366286, 5539.46946943]),\n",
              " array([9845.69371903, 6518.75788667, 5539.54872544]),\n",
              " array([9845.69759458, 6518.75453786, 5539.49561774]),\n",
              " array([9845.70060924, 6518.75091786, 5539.54225193]),\n",
              " array([9845.69604697, 6518.75977692, 5539.49891073]),\n",
              " array([9845.69791953, 6518.75234603, 5539.54210688]),\n",
              " array([9845.7000149 , 6518.7510646 , 5539.53728215]),\n",
              " array([9845.69858574, 6518.76382626, 5539.56678087]),\n",
              " array([9845.69756232, 6518.75544135, 5539.50504581]),\n",
              " array([9845.70107415, 6518.75448142, 5539.56026652]),\n",
              " array([9845.70219127, 6518.75479405, 5539.49050739]),\n",
              " array([9845.69626281, 6518.76041574, 5539.52582254]),\n",
              " array([9845.69802645, 6518.74935688, 5539.54574931]),\n",
              " array([9845.69882   , 6518.75456822, 5539.52026586]),\n",
              " array([9845.70164642, 6518.75436219, 5539.47465292]),\n",
              " array([9845.70027377, 6518.75260413, 5539.54559874]),\n",
              " array([9845.69473455, 6518.76035834, 5539.46743105]),\n",
              " array([9845.69387778, 6518.75126304, 5539.50653344]),\n",
              " array([9845.69498272, 6518.75215096, 5539.50759086]),\n",
              " array([9845.69537633, 6518.7542459 , 5539.53293582]),\n",
              " array([9845.7013533 , 6518.75233336, 5539.5180557 ]),\n",
              " array([9845.69940959, 6518.75159897, 5539.51335988]),\n",
              " array([9845.70139673, 6518.75347635, 5539.49506487]),\n",
              " array([9845.69849231, 6518.74974105, 5539.51356153]),\n",
              " array([9845.69723489, 6518.75161624, 5539.52929004]),\n",
              " array([9845.69893672, 6518.75511778, 5539.48243612]),\n",
              " array([9845.69662887, 6518.75410111, 5539.4953305 ]),\n",
              " array([9845.69139369, 6518.75990066, 5539.48991672]),\n",
              " array([9845.69213227, 6518.74851796, 5539.52776759]),\n",
              " array([9845.70061478, 6518.75679151, 5539.53326351]),\n",
              " array([9845.70138906, 6518.75453044, 5539.52386715]),\n",
              " array([9845.70460179, 6518.75397212, 5539.59135259]),\n",
              " array([9845.69288805, 6518.74471027, 5539.54826534]),\n",
              " array([9845.69758838, 6518.75435344, 5539.47454034]),\n",
              " array([9845.69956104, 6518.75458109, 5539.55331455]),\n",
              " array([9845.69358024, 6518.75170787, 5539.46903134]),\n",
              " array([9845.6943581 , 6518.75429587, 5539.55408129]),\n",
              " array([9845.70184132, 6518.75605457, 5539.52584197]),\n",
              " array([9845.69886892, 6518.75456548, 5539.56821355]),\n",
              " array([9845.70156398, 6518.75854477, 5539.4511729 ]),\n",
              " array([9845.69539981, 6518.75469675, 5539.53558625]),\n",
              " array([9845.69560418, 6518.75378562, 5539.54688181]),\n",
              " array([9845.70094251, 6518.75189871, 5539.61834374]),\n",
              " array([9845.69118804, 6518.7548069 , 5539.47316455]),\n",
              " array([9845.69771157, 6518.75206056, 5539.52831679]),\n",
              " array([9845.69315509, 6518.75417405, 5539.44539881]),\n",
              " array([9845.69708174, 6518.75596077, 5539.50527821]),\n",
              " array([9845.69683877, 6518.74973757, 5539.44771675]),\n",
              " array([9845.69874685, 6518.75210127, 5539.48272414]),\n",
              " array([9845.69379317, 6518.75198635, 5539.54332206]),\n",
              " array([9845.69370876, 6518.75969062, 5539.47716337]),\n",
              " array([9845.6995107 , 6518.75751069, 5539.50043452]),\n",
              " array([9845.70077909, 6518.76087299, 5539.52245952]),\n",
              " array([9845.70181906, 6518.75445615, 5539.50266509]),\n",
              " array([9845.69989486, 6518.75216965, 5539.46653411]),\n",
              " array([9845.69795086, 6518.75511734, 5539.47775829]),\n",
              " array([9845.69370506, 6518.75306562, 5539.52204943]),\n",
              " array([9845.70950608, 6518.74973588, 5539.52873988]),\n",
              " array([9845.70421376, 6518.75415376, 5539.51298234]),\n",
              " array([9845.70234097, 6518.75193998, 5539.52731026]),\n",
              " array([9845.69763981, 6518.75799501, 5539.55708997]),\n",
              " array([9845.70804318, 6518.75733537, 5539.54734509]),\n",
              " array([9845.69426944, 6518.75415594, 5539.41653524]),\n",
              " array([9845.70113948, 6518.75679078, 5539.48177703]),\n",
              " array([9845.69653898, 6518.75126393, 5539.53058667]),\n",
              " array([9845.70100761, 6518.75031317, 5539.55869186]),\n",
              " array([9845.69547804, 6518.75734355, 5539.50048918]),\n",
              " array([9845.70223624, 6518.75600425, 5539.47238079]),\n",
              " array([9845.698246  , 6518.7532141 , 5539.48774614]),\n",
              " array([9845.69800317, 6518.76316501, 5539.48893185]),\n",
              " array([9845.70260364, 6518.75924035, 5539.49190624]),\n",
              " array([9845.69804385, 6518.75696185, 5539.48449179]),\n",
              " array([9845.69652927, 6518.75699405, 5539.50834976]),\n",
              " array([9845.69963861, 6518.75795854, 5539.55774603]),\n",
              " array([9845.69794321, 6518.7551948 , 5539.48568182]),\n",
              " array([9845.70151136, 6518.75678361, 5539.5415225 ]),\n",
              " array([9845.70150636, 6518.75379122, 5539.56258885]),\n",
              " array([9845.69946941, 6518.75716441, 5539.56882173]),\n",
              " array([9845.69791004, 6518.75253702, 5539.46607646]),\n",
              " array([9845.6999037 , 6518.75470822, 5539.52991143]),\n",
              " array([9845.69686752, 6518.76077976, 5539.51804326]),\n",
              " array([9845.70110382, 6518.75751695, 5539.47578665]),\n",
              " array([9845.69556731, 6518.75172116, 5539.47517075]),\n",
              " array([9845.69844577, 6518.759088  , 5539.50700325]),\n",
              " array([9845.70390216, 6518.7556422 , 5539.46532331]),\n",
              " array([9845.69616927, 6518.75213193, 5539.47140733]),\n",
              " array([9845.69840823, 6518.7585632 , 5539.47386514]),\n",
              " array([9845.69842181, 6518.75462144, 5539.5414941 ]),\n",
              " array([9845.6979784 , 6518.75577161, 5539.57657025]),\n",
              " array([9845.69893321, 6518.75446545, 5539.49502176]),\n",
              " array([9845.70118713, 6518.75587335, 5539.51839588]),\n",
              " array([9845.69874099, 6518.75213074, 5539.49074224])]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "shU2I4Khmord",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "5bc4e16d-97fa-4698-cc72-e75de5645272"
      },
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Make sure to run this after each new generation of data\n",
        "# zero mean and unit var\n",
        "x_train2 = StandardScaler().fit_transform(x_train)\n",
        "x_test2 = StandardScaler().fit_transform(x_test)\n",
        "#x_train2 = x_train2[:,:,np.newaxis]\n",
        "#x_test2 = x_test2[:,:,np.newaxis]\n",
        "\n",
        "#x_train2 = x_train2.astype('float32') / 255.\n",
        "#x_test2 = x_test2.astype('float32') / 255.\n",
        "\n",
        "display(x_train2.shape)\n",
        "\n",
        "input_dim = x_train.shape[1]\n",
        "\n",
        "# set size of autoencoder \n",
        "encoding_dim = 6\n",
        "\n",
        "# use elu because it is leaky tried both net and l1 and l2 : net and l1 worked the best \n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "encoder = Dense(encoding_dim, activation=\"elu\",kernel_initializer= 'he_normal', activity_regularizer=regularizers.l1_l2(l1=10e-5, l2=10e-4))(input_layer)\n",
        "#encoder = Dense(encoding_dim, activation=\"elu\",activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "encoder = Dense(int(encoding_dim / 2), activation=\"elu\",kernel_initializer= 'he_normal')(encoder)\n",
        "decoder = Dense(int(encoding_dim / 2), activation='elu',kernel_initializer= 'he_normal')(encoder)\n",
        "decoder = Dense(input_dim, activation='elu',kernel_initializer= 'he_normal')(decoder)\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "\n",
        "autoencoder.summary()  \n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(200, 6)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 3)                 21        \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 6)                 24        \n",
            "=================================================================\n",
            "Total params: 99\n",
            "Trainable params: 99\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0b0rnWT13v-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 28587
        },
        "outputId": "29a729c5-2c9d-4b26-9c87-61d7ceae1176"
      },
      "cell_type": "code",
      "source": [
        "#Results with no anomily \n",
        "# Loss and Val Loss are very close + Accuracy and Val Accuracy are very close \n",
        "# Depending on the params of the net it can hit Accuracy of  1\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "full_anom = 0\n",
        "anom_samples = 0\n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    #loss = 'binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy_with_masking', factor=0.2,\n",
        "                              patience=5,verbose = 1)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "                    validation_split=.1,\n",
        "                    verbose=1,callbacks=[reduce_lr])\n",
        "score = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 180 samples, validate on 20 samples\n",
            "Epoch 1/800\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.5229 - acc: 0.6167 - val_loss: 0.6079 - val_acc: 0.7500\n",
            "Epoch 2/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.5127 - acc: 0.6278 - val_loss: 0.5990 - val_acc: 0.7500\n",
            "Epoch 3/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5022 - acc: 0.6333 - val_loss: 0.5901 - val_acc: 0.7500\n",
            "Epoch 4/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.4927 - acc: 0.6333 - val_loss: 0.5807 - val_acc: 0.7000\n",
            "Epoch 5/800\n",
            " 32/180 [====>.........................] - ETA: 0s - loss: 0.4667 - acc: 0.7500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:972: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_accuracy_with_masking` which is not available. Available metrics are: val_loss,val_acc,loss,acc,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "180/180 [==============================] - 0s 320us/step - loss: 0.4829 - acc: 0.6389 - val_loss: 0.5705 - val_acc: 0.7000\n",
            "Epoch 6/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.4734 - acc: 0.6333 - val_loss: 0.5620 - val_acc: 0.6500\n",
            "Epoch 7/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.4632 - acc: 0.6556 - val_loss: 0.5519 - val_acc: 0.6500\n",
            "Epoch 8/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4528 - acc: 0.6611 - val_loss: 0.5431 - val_acc: 0.6500\n",
            "Epoch 9/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.4432 - acc: 0.6667 - val_loss: 0.5324 - val_acc: 0.6500\n",
            "Epoch 10/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.4334 - acc: 0.6833 - val_loss: 0.5234 - val_acc: 0.6500\n",
            "Epoch 11/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.4246 - acc: 0.7000 - val_loss: 0.5132 - val_acc: 0.7000\n",
            "Epoch 12/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.4155 - acc: 0.7111 - val_loss: 0.5044 - val_acc: 0.7000\n",
            "Epoch 13/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.4059 - acc: 0.7000 - val_loss: 0.4959 - val_acc: 0.7000\n",
            "Epoch 14/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.3971 - acc: 0.7278 - val_loss: 0.4865 - val_acc: 0.7000\n",
            "Epoch 15/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.3878 - acc: 0.7333 - val_loss: 0.4760 - val_acc: 0.7000\n",
            "Epoch 16/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.3799 - acc: 0.7222 - val_loss: 0.4676 - val_acc: 0.7000\n",
            "Epoch 17/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.3712 - acc: 0.7444 - val_loss: 0.4601 - val_acc: 0.7000\n",
            "Epoch 18/800\n",
            "180/180 [==============================] - 0s 335us/step - loss: 0.3631 - acc: 0.7500 - val_loss: 0.4527 - val_acc: 0.7000\n",
            "Epoch 19/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.3552 - acc: 0.7167 - val_loss: 0.4430 - val_acc: 0.7000\n",
            "Epoch 20/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.3472 - acc: 0.7444 - val_loss: 0.4360 - val_acc: 0.7000\n",
            "Epoch 21/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.3397 - acc: 0.7500 - val_loss: 0.4262 - val_acc: 0.7000\n",
            "Epoch 22/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.3327 - acc: 0.7444 - val_loss: 0.4212 - val_acc: 0.7000\n",
            "Epoch 23/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.3249 - acc: 0.7556 - val_loss: 0.4114 - val_acc: 0.7000\n",
            "Epoch 24/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.3184 - acc: 0.7556 - val_loss: 0.4045 - val_acc: 0.7000\n",
            "Epoch 25/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.3118 - acc: 0.7667 - val_loss: 0.3978 - val_acc: 0.7000\n",
            "Epoch 26/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.3056 - acc: 0.7667 - val_loss: 0.3903 - val_acc: 0.7000\n",
            "Epoch 27/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.2995 - acc: 0.7667 - val_loss: 0.3841 - val_acc: 0.7000\n",
            "Epoch 28/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.2931 - acc: 0.7778 - val_loss: 0.3774 - val_acc: 0.7000\n",
            "Epoch 29/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.2876 - acc: 0.7833 - val_loss: 0.3709 - val_acc: 0.7000\n",
            "Epoch 30/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.2823 - acc: 0.7833 - val_loss: 0.3651 - val_acc: 0.7000\n",
            "Epoch 31/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.2768 - acc: 0.7833 - val_loss: 0.3584 - val_acc: 0.7000\n",
            "Epoch 32/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.2711 - acc: 0.7833 - val_loss: 0.3528 - val_acc: 0.7500\n",
            "Epoch 33/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.2665 - acc: 0.7833 - val_loss: 0.3466 - val_acc: 0.7500\n",
            "Epoch 34/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.2609 - acc: 0.7889 - val_loss: 0.3418 - val_acc: 0.7500\n",
            "Epoch 35/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.2564 - acc: 0.7722 - val_loss: 0.3354 - val_acc: 0.8000\n",
            "Epoch 36/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.2518 - acc: 0.7778 - val_loss: 0.3301 - val_acc: 0.8000\n",
            "Epoch 37/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.2472 - acc: 0.7778 - val_loss: 0.3243 - val_acc: 0.8000\n",
            "Epoch 38/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.2427 - acc: 0.7778 - val_loss: 0.3206 - val_acc: 0.8000\n",
            "Epoch 39/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.2386 - acc: 0.7833 - val_loss: 0.3143 - val_acc: 0.8000\n",
            "Epoch 40/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.2341 - acc: 0.7889 - val_loss: 0.3105 - val_acc: 0.8000\n",
            "Epoch 41/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.2307 - acc: 0.7778 - val_loss: 0.3053 - val_acc: 0.8000\n",
            "Epoch 42/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.2266 - acc: 0.7833 - val_loss: 0.2998 - val_acc: 0.8000\n",
            "Epoch 43/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.2232 - acc: 0.7889 - val_loss: 0.2952 - val_acc: 0.8000\n",
            "Epoch 44/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.2193 - acc: 0.7833 - val_loss: 0.2920 - val_acc: 0.8000\n",
            "Epoch 45/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.2158 - acc: 0.7944 - val_loss: 0.2884 - val_acc: 0.8000\n",
            "Epoch 46/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.2119 - acc: 0.7833 - val_loss: 0.2831 - val_acc: 0.8000\n",
            "Epoch 47/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.2087 - acc: 0.7833 - val_loss: 0.2794 - val_acc: 0.8500\n",
            "Epoch 48/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.2056 - acc: 0.7889 - val_loss: 0.2760 - val_acc: 0.8500\n",
            "Epoch 49/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.2028 - acc: 0.7889 - val_loss: 0.2743 - val_acc: 0.8500\n",
            "Epoch 50/800\n",
            "180/180 [==============================] - 0s 408us/step - loss: 0.1997 - acc: 0.7833 - val_loss: 0.2686 - val_acc: 0.8500\n",
            "Epoch 51/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1969 - acc: 0.7944 - val_loss: 0.2654 - val_acc: 0.8500\n",
            "Epoch 52/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1937 - acc: 0.7889 - val_loss: 0.2626 - val_acc: 0.8500\n",
            "Epoch 53/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1913 - acc: 0.8111 - val_loss: 0.2598 - val_acc: 0.9000\n",
            "Epoch 54/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1885 - acc: 0.7944 - val_loss: 0.2563 - val_acc: 0.8500\n",
            "Epoch 55/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1863 - acc: 0.8222 - val_loss: 0.2548 - val_acc: 0.8500\n",
            "Epoch 56/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1842 - acc: 0.8111 - val_loss: 0.2506 - val_acc: 0.8500\n",
            "Epoch 57/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1819 - acc: 0.8167 - val_loss: 0.2487 - val_acc: 0.8500\n",
            "Epoch 58/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1795 - acc: 0.8167 - val_loss: 0.2459 - val_acc: 0.8500\n",
            "Epoch 59/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1774 - acc: 0.8111 - val_loss: 0.2441 - val_acc: 0.8500\n",
            "Epoch 60/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1756 - acc: 0.8167 - val_loss: 0.2421 - val_acc: 0.8500\n",
            "Epoch 61/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1743 - acc: 0.8222 - val_loss: 0.2392 - val_acc: 0.8500\n",
            "Epoch 62/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1716 - acc: 0.8278 - val_loss: 0.2384 - val_acc: 0.8500\n",
            "Epoch 63/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1703 - acc: 0.8333 - val_loss: 0.2355 - val_acc: 0.8500\n",
            "Epoch 64/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1686 - acc: 0.8333 - val_loss: 0.2335 - val_acc: 0.8500\n",
            "Epoch 65/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1670 - acc: 0.8333 - val_loss: 0.2320 - val_acc: 0.8500\n",
            "Epoch 66/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1656 - acc: 0.8278 - val_loss: 0.2303 - val_acc: 0.9500\n",
            "Epoch 67/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1647 - acc: 0.8278 - val_loss: 0.2298 - val_acc: 0.9000\n",
            "Epoch 68/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1624 - acc: 0.8278 - val_loss: 0.2262 - val_acc: 0.9500\n",
            "Epoch 69/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1615 - acc: 0.8278 - val_loss: 0.2282 - val_acc: 0.9000\n",
            "Epoch 70/800\n",
            "180/180 [==============================] - 0s 409us/step - loss: 0.1609 - acc: 0.8278 - val_loss: 0.2269 - val_acc: 0.9000\n",
            "Epoch 71/800\n",
            "180/180 [==============================] - 0s 329us/step - loss: 0.1588 - acc: 0.8333 - val_loss: 0.2225 - val_acc: 0.9500\n",
            "Epoch 72/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1578 - acc: 0.8444 - val_loss: 0.2208 - val_acc: 0.9500\n",
            "Epoch 73/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1568 - acc: 0.8333 - val_loss: 0.2208 - val_acc: 0.9000\n",
            "Epoch 74/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1554 - acc: 0.8333 - val_loss: 0.2211 - val_acc: 0.9500\n",
            "Epoch 75/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1547 - acc: 0.8444 - val_loss: 0.2186 - val_acc: 0.8500\n",
            "Epoch 76/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1536 - acc: 0.8500 - val_loss: 0.2176 - val_acc: 0.9500\n",
            "Epoch 77/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1529 - acc: 0.8389 - val_loss: 0.2157 - val_acc: 0.9500\n",
            "Epoch 78/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1515 - acc: 0.8389 - val_loss: 0.2149 - val_acc: 0.9000\n",
            "Epoch 79/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1506 - acc: 0.8444 - val_loss: 0.2130 - val_acc: 0.9000\n",
            "Epoch 80/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1499 - acc: 0.8222 - val_loss: 0.2123 - val_acc: 0.8500\n",
            "Epoch 81/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1489 - acc: 0.8333 - val_loss: 0.2118 - val_acc: 0.9000\n",
            "Epoch 82/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1481 - acc: 0.8333 - val_loss: 0.2119 - val_acc: 0.9000\n",
            "Epoch 83/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1472 - acc: 0.8333 - val_loss: 0.2106 - val_acc: 0.8000\n",
            "Epoch 84/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1463 - acc: 0.8389 - val_loss: 0.2105 - val_acc: 0.9000\n",
            "Epoch 85/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1456 - acc: 0.8389 - val_loss: 0.2086 - val_acc: 0.8000\n",
            "Epoch 86/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1447 - acc: 0.8389 - val_loss: 0.2085 - val_acc: 0.9000\n",
            "Epoch 87/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1448 - acc: 0.8333 - val_loss: 0.2059 - val_acc: 0.8500\n",
            "Epoch 88/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1434 - acc: 0.8278 - val_loss: 0.2093 - val_acc: 0.9000\n",
            "Epoch 89/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1434 - acc: 0.8278 - val_loss: 0.2069 - val_acc: 0.9000\n",
            "Epoch 90/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1422 - acc: 0.8333 - val_loss: 0.2049 - val_acc: 0.8500\n",
            "Epoch 91/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1418 - acc: 0.8222 - val_loss: 0.2074 - val_acc: 0.8000\n",
            "Epoch 92/800\n",
            "180/180 [==============================] - 0s 336us/step - loss: 0.1415 - acc: 0.8222 - val_loss: 0.2044 - val_acc: 0.8000\n",
            "Epoch 93/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1405 - acc: 0.8333 - val_loss: 0.2039 - val_acc: 0.8000\n",
            "Epoch 94/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1400 - acc: 0.8278 - val_loss: 0.2023 - val_acc: 0.8000\n",
            "Epoch 95/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1393 - acc: 0.8333 - val_loss: 0.2024 - val_acc: 0.8500\n",
            "Epoch 96/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1392 - acc: 0.8333 - val_loss: 0.2022 - val_acc: 0.8500\n",
            "Epoch 97/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1385 - acc: 0.8278 - val_loss: 0.2010 - val_acc: 0.8000\n",
            "Epoch 98/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.1384 - acc: 0.8389 - val_loss: 0.2004 - val_acc: 0.8000\n",
            "Epoch 99/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1373 - acc: 0.8333 - val_loss: 0.1992 - val_acc: 0.8500\n",
            "Epoch 100/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1366 - acc: 0.8222 - val_loss: 0.1989 - val_acc: 0.8500\n",
            "Epoch 101/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1362 - acc: 0.8333 - val_loss: 0.1977 - val_acc: 0.8000\n",
            "Epoch 102/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1360 - acc: 0.8278 - val_loss: 0.1984 - val_acc: 0.8000\n",
            "Epoch 103/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1357 - acc: 0.8278 - val_loss: 0.1980 - val_acc: 0.9000\n",
            "Epoch 104/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1349 - acc: 0.8333 - val_loss: 0.1984 - val_acc: 0.8500\n",
            "Epoch 105/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1346 - acc: 0.8333 - val_loss: 0.1955 - val_acc: 0.8500\n",
            "Epoch 106/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1339 - acc: 0.8389 - val_loss: 0.1954 - val_acc: 0.8500\n",
            "Epoch 107/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1336 - acc: 0.8444 - val_loss: 0.1952 - val_acc: 0.8500\n",
            "Epoch 108/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1333 - acc: 0.8333 - val_loss: 0.1949 - val_acc: 0.8000\n",
            "Epoch 109/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1326 - acc: 0.8278 - val_loss: 0.1952 - val_acc: 0.9000\n",
            "Epoch 110/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1330 - acc: 0.8278 - val_loss: 0.1939 - val_acc: 0.8000\n",
            "Epoch 111/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1327 - acc: 0.8278 - val_loss: 0.1926 - val_acc: 0.8000\n",
            "Epoch 112/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1317 - acc: 0.8389 - val_loss: 0.1937 - val_acc: 0.8000\n",
            "Epoch 113/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.1317 - acc: 0.8333 - val_loss: 0.1933 - val_acc: 0.8000\n",
            "Epoch 114/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1307 - acc: 0.8333 - val_loss: 0.1931 - val_acc: 0.9000\n",
            "Epoch 115/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1316 - acc: 0.8333 - val_loss: 0.1916 - val_acc: 0.8500\n",
            "Epoch 116/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1306 - acc: 0.8278 - val_loss: 0.1910 - val_acc: 0.8500\n",
            "Epoch 117/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1303 - acc: 0.8444 - val_loss: 0.1904 - val_acc: 0.9000\n",
            "Epoch 118/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1298 - acc: 0.8444 - val_loss: 0.1908 - val_acc: 0.8000\n",
            "Epoch 119/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1288 - acc: 0.8500 - val_loss: 0.1897 - val_acc: 0.8000\n",
            "Epoch 120/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1288 - acc: 0.8444 - val_loss: 0.1911 - val_acc: 0.8000\n",
            "Epoch 121/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1284 - acc: 0.8333 - val_loss: 0.1896 - val_acc: 0.8500\n",
            "Epoch 122/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1280 - acc: 0.8444 - val_loss: 0.1895 - val_acc: 0.9000\n",
            "Epoch 123/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1277 - acc: 0.8278 - val_loss: 0.1877 - val_acc: 0.9000\n",
            "Epoch 124/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1277 - acc: 0.8389 - val_loss: 0.1891 - val_acc: 0.9000\n",
            "Epoch 125/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1269 - acc: 0.8333 - val_loss: 0.1877 - val_acc: 0.9000\n",
            "Epoch 126/800\n",
            "180/180 [==============================] - 0s 334us/step - loss: 0.1276 - acc: 0.8278 - val_loss: 0.1862 - val_acc: 0.9000\n",
            "Epoch 127/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1268 - acc: 0.8389 - val_loss: 0.1870 - val_acc: 0.8500\n",
            "Epoch 128/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1265 - acc: 0.8444 - val_loss: 0.1896 - val_acc: 0.8500\n",
            "Epoch 129/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1258 - acc: 0.8333 - val_loss: 0.1863 - val_acc: 0.9500\n",
            "Epoch 130/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1261 - acc: 0.8389 - val_loss: 0.1877 - val_acc: 0.8500\n",
            "Epoch 131/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1256 - acc: 0.8167 - val_loss: 0.1868 - val_acc: 0.8500\n",
            "Epoch 132/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1258 - acc: 0.8500 - val_loss: 0.1861 - val_acc: 0.9500\n",
            "Epoch 133/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.1252 - acc: 0.8333 - val_loss: 0.1855 - val_acc: 0.9000\n",
            "Epoch 134/800\n",
            "180/180 [==============================] - 0s 324us/step - loss: 0.1247 - acc: 0.8389 - val_loss: 0.1867 - val_acc: 0.9000\n",
            "Epoch 135/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1246 - acc: 0.8333 - val_loss: 0.1849 - val_acc: 0.9000\n",
            "Epoch 136/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1244 - acc: 0.8333 - val_loss: 0.1869 - val_acc: 0.8500\n",
            "Epoch 137/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1241 - acc: 0.8278 - val_loss: 0.1870 - val_acc: 0.9000\n",
            "Epoch 138/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1237 - acc: 0.8389 - val_loss: 0.1831 - val_acc: 0.9000\n",
            "Epoch 139/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1236 - acc: 0.8389 - val_loss: 0.1873 - val_acc: 0.9000\n",
            "Epoch 140/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1237 - acc: 0.8222 - val_loss: 0.1839 - val_acc: 0.8500\n",
            "Epoch 141/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1227 - acc: 0.8389 - val_loss: 0.1848 - val_acc: 0.9000\n",
            "Epoch 142/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1232 - acc: 0.8333 - val_loss: 0.1840 - val_acc: 0.8500\n",
            "Epoch 143/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1224 - acc: 0.8333 - val_loss: 0.1860 - val_acc: 0.9000\n",
            "Epoch 144/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1226 - acc: 0.8444 - val_loss: 0.1836 - val_acc: 0.9000\n",
            "Epoch 145/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1226 - acc: 0.8444 - val_loss: 0.1832 - val_acc: 0.9500\n",
            "Epoch 146/800\n",
            "180/180 [==============================] - 0s 328us/step - loss: 0.1220 - acc: 0.8333 - val_loss: 0.1820 - val_acc: 0.9000\n",
            "Epoch 147/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1225 - acc: 0.8167 - val_loss: 0.1828 - val_acc: 0.8500\n",
            "Epoch 148/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1214 - acc: 0.8278 - val_loss: 0.1807 - val_acc: 0.9500\n",
            "Epoch 149/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1214 - acc: 0.8389 - val_loss: 0.1821 - val_acc: 0.9000\n",
            "Epoch 150/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1216 - acc: 0.8333 - val_loss: 0.1809 - val_acc: 0.8500\n",
            "Epoch 151/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1206 - acc: 0.8278 - val_loss: 0.1837 - val_acc: 0.8500\n",
            "Epoch 152/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1211 - acc: 0.8389 - val_loss: 0.1813 - val_acc: 0.9000\n",
            "Epoch 153/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1208 - acc: 0.8444 - val_loss: 0.1804 - val_acc: 0.9000\n",
            "Epoch 154/800\n",
            "180/180 [==============================] - 0s 409us/step - loss: 0.1201 - acc: 0.8389 - val_loss: 0.1819 - val_acc: 0.9500\n",
            "Epoch 155/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1205 - acc: 0.8333 - val_loss: 0.1805 - val_acc: 0.8500\n",
            "Epoch 156/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.1200 - acc: 0.8333 - val_loss: 0.1807 - val_acc: 0.9000\n",
            "Epoch 157/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1197 - acc: 0.8500 - val_loss: 0.1831 - val_acc: 0.8000\n",
            "Epoch 158/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1202 - acc: 0.8278 - val_loss: 0.1808 - val_acc: 0.9000\n",
            "Epoch 159/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1198 - acc: 0.8500 - val_loss: 0.1806 - val_acc: 0.9000\n",
            "Epoch 160/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1190 - acc: 0.8389 - val_loss: 0.1785 - val_acc: 0.9500\n",
            "Epoch 161/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1198 - acc: 0.8500 - val_loss: 0.1799 - val_acc: 0.9000\n",
            "Epoch 162/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1195 - acc: 0.8500 - val_loss: 0.1793 - val_acc: 0.9500\n",
            "Epoch 163/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1189 - acc: 0.8500 - val_loss: 0.1815 - val_acc: 0.9500\n",
            "Epoch 164/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1188 - acc: 0.8444 - val_loss: 0.1790 - val_acc: 0.8000\n",
            "Epoch 165/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1192 - acc: 0.8389 - val_loss: 0.1780 - val_acc: 0.9000\n",
            "Epoch 166/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1190 - acc: 0.8444 - val_loss: 0.1783 - val_acc: 0.9000\n",
            "Epoch 167/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1183 - acc: 0.8500 - val_loss: 0.1787 - val_acc: 0.9500\n",
            "Epoch 168/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1181 - acc: 0.8278 - val_loss: 0.1805 - val_acc: 0.8000\n",
            "Epoch 169/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.1182 - acc: 0.8222 - val_loss: 0.1790 - val_acc: 0.9500\n",
            "Epoch 170/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1183 - acc: 0.8389 - val_loss: 0.1782 - val_acc: 0.9000\n",
            "Epoch 171/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1179 - acc: 0.8444 - val_loss: 0.1769 - val_acc: 0.9500\n",
            "Epoch 172/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1176 - acc: 0.8389 - val_loss: 0.1789 - val_acc: 0.9500\n",
            "Epoch 173/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1175 - acc: 0.8444 - val_loss: 0.1769 - val_acc: 0.9500\n",
            "Epoch 174/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1173 - acc: 0.8444 - val_loss: 0.1777 - val_acc: 0.9000\n",
            "Epoch 175/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1174 - acc: 0.8333 - val_loss: 0.1770 - val_acc: 0.8500\n",
            "Epoch 176/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1170 - acc: 0.8389 - val_loss: 0.1786 - val_acc: 0.8000\n",
            "Epoch 177/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1169 - acc: 0.8278 - val_loss: 0.1783 - val_acc: 0.8000\n",
            "Epoch 178/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.1163 - acc: 0.8333 - val_loss: 0.1768 - val_acc: 0.9000\n",
            "Epoch 179/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1169 - acc: 0.8500 - val_loss: 0.1774 - val_acc: 0.8500\n",
            "Epoch 180/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1164 - acc: 0.8333 - val_loss: 0.1761 - val_acc: 0.9000\n",
            "Epoch 181/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1162 - acc: 0.8556 - val_loss: 0.1754 - val_acc: 0.8000\n",
            "Epoch 182/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1162 - acc: 0.8333 - val_loss: 0.1769 - val_acc: 0.8000\n",
            "Epoch 183/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1160 - acc: 0.8500 - val_loss: 0.1781 - val_acc: 0.8000\n",
            "Epoch 184/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1164 - acc: 0.8444 - val_loss: 0.1767 - val_acc: 0.8000\n",
            "Epoch 185/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1158 - acc: 0.8333 - val_loss: 0.1759 - val_acc: 0.9500\n",
            "Epoch 186/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1155 - acc: 0.8444 - val_loss: 0.1770 - val_acc: 0.9000\n",
            "Epoch 187/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1160 - acc: 0.8444 - val_loss: 0.1760 - val_acc: 0.9000\n",
            "Epoch 188/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1152 - acc: 0.8333 - val_loss: 0.1761 - val_acc: 0.8000\n",
            "Epoch 189/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1152 - acc: 0.8389 - val_loss: 0.1761 - val_acc: 0.8000\n",
            "Epoch 190/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1153 - acc: 0.8444 - val_loss: 0.1746 - val_acc: 0.8500\n",
            "Epoch 191/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1153 - acc: 0.8500 - val_loss: 0.1761 - val_acc: 0.9000\n",
            "Epoch 192/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1153 - acc: 0.8389 - val_loss: 0.1743 - val_acc: 0.9500\n",
            "Epoch 193/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1150 - acc: 0.8278 - val_loss: 0.1756 - val_acc: 0.8500\n",
            "Epoch 194/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1158 - acc: 0.8389 - val_loss: 0.1751 - val_acc: 0.8500\n",
            "Epoch 195/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1146 - acc: 0.8500 - val_loss: 0.1756 - val_acc: 0.8000\n",
            "Epoch 196/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1146 - acc: 0.8333 - val_loss: 0.1752 - val_acc: 0.8000\n",
            "Epoch 197/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1146 - acc: 0.8500 - val_loss: 0.1746 - val_acc: 0.8500\n",
            "Epoch 198/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1144 - acc: 0.8333 - val_loss: 0.1750 - val_acc: 0.8000\n",
            "Epoch 199/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1141 - acc: 0.8389 - val_loss: 0.1766 - val_acc: 0.8000\n",
            "Epoch 200/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1145 - acc: 0.8278 - val_loss: 0.1759 - val_acc: 0.8000\n",
            "Epoch 201/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1142 - acc: 0.8333 - val_loss: 0.1744 - val_acc: 0.8000\n",
            "Epoch 202/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1139 - acc: 0.8444 - val_loss: 0.1731 - val_acc: 0.8500\n",
            "Epoch 203/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1134 - acc: 0.8500 - val_loss: 0.1768 - val_acc: 0.8000\n",
            "Epoch 204/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1137 - acc: 0.8278 - val_loss: 0.1720 - val_acc: 0.9000\n",
            "Epoch 205/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1136 - acc: 0.8333 - val_loss: 0.1741 - val_acc: 0.8000\n",
            "Epoch 206/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1138 - acc: 0.8500 - val_loss: 0.1723 - val_acc: 0.8500\n",
            "Epoch 207/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1132 - acc: 0.8389 - val_loss: 0.1722 - val_acc: 0.8500\n",
            "Epoch 208/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1129 - acc: 0.8389 - val_loss: 0.1734 - val_acc: 0.9000\n",
            "Epoch 209/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1136 - acc: 0.8389 - val_loss: 0.1751 - val_acc: 0.8500\n",
            "Epoch 210/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1136 - acc: 0.8444 - val_loss: 0.1730 - val_acc: 0.9000\n",
            "Epoch 211/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1131 - acc: 0.8500 - val_loss: 0.1751 - val_acc: 0.8500\n",
            "Epoch 212/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.1132 - acc: 0.8333 - val_loss: 0.1736 - val_acc: 0.8500\n",
            "Epoch 213/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1128 - acc: 0.8556 - val_loss: 0.1745 - val_acc: 0.8000\n",
            "Epoch 214/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1126 - acc: 0.8389 - val_loss: 0.1740 - val_acc: 0.8000\n",
            "Epoch 215/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1130 - acc: 0.8333 - val_loss: 0.1724 - val_acc: 0.8500\n",
            "Epoch 216/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.1128 - acc: 0.8500 - val_loss: 0.1726 - val_acc: 0.8000\n",
            "Epoch 217/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1126 - acc: 0.8222 - val_loss: 0.1721 - val_acc: 0.9000\n",
            "Epoch 218/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1123 - acc: 0.8389 - val_loss: 0.1735 - val_acc: 0.8500\n",
            "Epoch 219/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1132 - acc: 0.8333 - val_loss: 0.1734 - val_acc: 0.8000\n",
            "Epoch 220/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1120 - acc: 0.8389 - val_loss: 0.1742 - val_acc: 0.8000\n",
            "Epoch 221/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1125 - acc: 0.8444 - val_loss: 0.1705 - val_acc: 0.9000\n",
            "Epoch 222/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1124 - acc: 0.8389 - val_loss: 0.1723 - val_acc: 0.9500\n",
            "Epoch 223/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1124 - acc: 0.8444 - val_loss: 0.1714 - val_acc: 0.9000\n",
            "Epoch 224/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1114 - acc: 0.8389 - val_loss: 0.1746 - val_acc: 0.8000\n",
            "Epoch 225/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1117 - acc: 0.8500 - val_loss: 0.1728 - val_acc: 0.8500\n",
            "Epoch 226/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1119 - acc: 0.8333 - val_loss: 0.1716 - val_acc: 0.8000\n",
            "Epoch 227/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1116 - acc: 0.8444 - val_loss: 0.1738 - val_acc: 0.8000\n",
            "Epoch 228/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1118 - acc: 0.8278 - val_loss: 0.1718 - val_acc: 0.8000\n",
            "Epoch 229/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1118 - acc: 0.8444 - val_loss: 0.1718 - val_acc: 0.9000\n",
            "Epoch 230/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1110 - acc: 0.8278 - val_loss: 0.1728 - val_acc: 0.8500\n",
            "Epoch 231/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1113 - acc: 0.8667 - val_loss: 0.1710 - val_acc: 0.8500\n",
            "Epoch 232/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1111 - acc: 0.8444 - val_loss: 0.1716 - val_acc: 0.8000\n",
            "Epoch 233/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1111 - acc: 0.8278 - val_loss: 0.1718 - val_acc: 0.8000\n",
            "Epoch 234/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1109 - acc: 0.8333 - val_loss: 0.1718 - val_acc: 0.8500\n",
            "Epoch 235/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1107 - acc: 0.8333 - val_loss: 0.1714 - val_acc: 0.8500\n",
            "Epoch 236/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.1113 - acc: 0.8333 - val_loss: 0.1707 - val_acc: 0.8500\n",
            "Epoch 237/800\n",
            "180/180 [==============================] - 0s 400us/step - loss: 0.1103 - acc: 0.8500 - val_loss: 0.1704 - val_acc: 0.9500\n",
            "Epoch 238/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1104 - acc: 0.8389 - val_loss: 0.1703 - val_acc: 0.8000\n",
            "Epoch 239/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1103 - acc: 0.8389 - val_loss: 0.1696 - val_acc: 0.9000\n",
            "Epoch 240/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1103 - acc: 0.8278 - val_loss: 0.1717 - val_acc: 0.8000\n",
            "Epoch 241/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1107 - acc: 0.8611 - val_loss: 0.1706 - val_acc: 0.9000\n",
            "Epoch 242/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1112 - acc: 0.8389 - val_loss: 0.1708 - val_acc: 0.9000\n",
            "Epoch 243/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1105 - acc: 0.8444 - val_loss: 0.1703 - val_acc: 0.8000\n",
            "Epoch 244/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1114 - acc: 0.8556 - val_loss: 0.1705 - val_acc: 0.9000\n",
            "Epoch 245/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1100 - acc: 0.8389 - val_loss: 0.1698 - val_acc: 0.8500\n",
            "Epoch 246/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1099 - acc: 0.8444 - val_loss: 0.1713 - val_acc: 0.9500\n",
            "Epoch 247/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1103 - acc: 0.8556 - val_loss: 0.1709 - val_acc: 0.9000\n",
            "Epoch 248/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1098 - acc: 0.8444 - val_loss: 0.1696 - val_acc: 0.9500\n",
            "Epoch 249/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1099 - acc: 0.8444 - val_loss: 0.1690 - val_acc: 0.9000\n",
            "Epoch 250/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1104 - acc: 0.8444 - val_loss: 0.1692 - val_acc: 0.9500\n",
            "Epoch 251/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1096 - acc: 0.8389 - val_loss: 0.1699 - val_acc: 0.9000\n",
            "Epoch 252/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1097 - acc: 0.8500 - val_loss: 0.1696 - val_acc: 0.9000\n",
            "Epoch 253/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1094 - acc: 0.8389 - val_loss: 0.1697 - val_acc: 0.8000\n",
            "Epoch 254/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1096 - acc: 0.8444 - val_loss: 0.1683 - val_acc: 0.9000\n",
            "Epoch 255/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1093 - acc: 0.8611 - val_loss: 0.1702 - val_acc: 0.9000\n",
            "Epoch 256/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1096 - acc: 0.8556 - val_loss: 0.1696 - val_acc: 0.9000\n",
            "Epoch 257/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1097 - acc: 0.8500 - val_loss: 0.1705 - val_acc: 0.9000\n",
            "Epoch 258/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.1096 - acc: 0.8556 - val_loss: 0.1692 - val_acc: 1.0000\n",
            "Epoch 259/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1092 - acc: 0.8500 - val_loss: 0.1679 - val_acc: 0.8000\n",
            "Epoch 260/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1093 - acc: 0.8500 - val_loss: 0.1689 - val_acc: 0.9500\n",
            "Epoch 261/800\n",
            "180/180 [==============================] - 0s 323us/step - loss: 0.1090 - acc: 0.8500 - val_loss: 0.1692 - val_acc: 0.8500\n",
            "Epoch 262/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1090 - acc: 0.8444 - val_loss: 0.1702 - val_acc: 1.0000\n",
            "Epoch 263/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1091 - acc: 0.8611 - val_loss: 0.1706 - val_acc: 0.8000\n",
            "Epoch 264/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1093 - acc: 0.8500 - val_loss: 0.1687 - val_acc: 0.9000\n",
            "Epoch 265/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1089 - acc: 0.8556 - val_loss: 0.1701 - val_acc: 0.9500\n",
            "Epoch 266/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1087 - acc: 0.8444 - val_loss: 0.1685 - val_acc: 0.9000\n",
            "Epoch 267/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1087 - acc: 0.8389 - val_loss: 0.1679 - val_acc: 0.9000\n",
            "Epoch 268/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1087 - acc: 0.8389 - val_loss: 0.1691 - val_acc: 0.9000\n",
            "Epoch 269/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1085 - acc: 0.8389 - val_loss: 0.1684 - val_acc: 0.9500\n",
            "Epoch 270/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1683 - val_acc: 0.9000\n",
            "Epoch 271/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1090 - acc: 0.8500 - val_loss: 0.1694 - val_acc: 0.9500\n",
            "Epoch 272/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1091 - acc: 0.8278 - val_loss: 0.1666 - val_acc: 0.9000\n",
            "Epoch 273/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1082 - acc: 0.8444 - val_loss: 0.1696 - val_acc: 0.9500\n",
            "Epoch 274/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1080 - acc: 0.8500 - val_loss: 0.1673 - val_acc: 0.9500\n",
            "Epoch 275/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1081 - acc: 0.8444 - val_loss: 0.1679 - val_acc: 0.9000\n",
            "Epoch 276/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1078 - acc: 0.8444 - val_loss: 0.1676 - val_acc: 0.9000\n",
            "Epoch 277/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1080 - acc: 0.8556 - val_loss: 0.1684 - val_acc: 0.9000\n",
            "Epoch 278/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1075 - acc: 0.8333 - val_loss: 0.1678 - val_acc: 0.8500\n",
            "Epoch 279/800\n",
            "180/180 [==============================] - 0s 408us/step - loss: 0.1085 - acc: 0.8222 - val_loss: 0.1682 - val_acc: 0.9500\n",
            "Epoch 280/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1075 - acc: 0.8389 - val_loss: 0.1682 - val_acc: 0.9000\n",
            "Epoch 281/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.1083 - acc: 0.8333 - val_loss: 0.1690 - val_acc: 0.8500\n",
            "Epoch 282/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.1078 - acc: 0.8500 - val_loss: 0.1682 - val_acc: 0.9000\n",
            "Epoch 283/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1073 - acc: 0.8611 - val_loss: 0.1685 - val_acc: 0.8500\n",
            "Epoch 284/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1074 - acc: 0.8500 - val_loss: 0.1673 - val_acc: 0.9000\n",
            "Epoch 285/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1071 - acc: 0.8389 - val_loss: 0.1685 - val_acc: 0.9500\n",
            "Epoch 286/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1076 - acc: 0.8389 - val_loss: 0.1682 - val_acc: 0.9500\n",
            "Epoch 287/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1076 - acc: 0.8444 - val_loss: 0.1694 - val_acc: 0.8500\n",
            "Epoch 288/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1074 - acc: 0.8667 - val_loss: 0.1701 - val_acc: 0.8500\n",
            "Epoch 289/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.1071 - acc: 0.8556 - val_loss: 0.1671 - val_acc: 0.9000\n",
            "Epoch 290/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1070 - acc: 0.8389 - val_loss: 0.1683 - val_acc: 0.8500\n",
            "Epoch 291/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1087 - acc: 0.8500 - val_loss: 0.1682 - val_acc: 0.9000\n",
            "Epoch 292/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1075 - acc: 0.8389 - val_loss: 0.1666 - val_acc: 0.9000\n",
            "Epoch 293/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1070 - acc: 0.8500 - val_loss: 0.1681 - val_acc: 0.9000\n",
            "Epoch 294/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1072 - acc: 0.8667 - val_loss: 0.1676 - val_acc: 0.9000\n",
            "Epoch 295/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.1070 - acc: 0.8333 - val_loss: 0.1672 - val_acc: 0.8000\n",
            "Epoch 296/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1075 - acc: 0.8500 - val_loss: 0.1685 - val_acc: 0.8500\n",
            "Epoch 297/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1071 - acc: 0.8556 - val_loss: 0.1662 - val_acc: 0.9000\n",
            "Epoch 298/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1071 - acc: 0.8444 - val_loss: 0.1675 - val_acc: 0.9500\n",
            "Epoch 299/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1070 - acc: 0.8556 - val_loss: 0.1695 - val_acc: 0.8500\n",
            "Epoch 300/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1071 - acc: 0.8389 - val_loss: 0.1675 - val_acc: 1.0000\n",
            "Epoch 301/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.1066 - acc: 0.8611 - val_loss: 0.1657 - val_acc: 0.9500\n",
            "Epoch 302/800\n",
            "180/180 [==============================] - 0s 323us/step - loss: 0.1072 - acc: 0.8722 - val_loss: 0.1671 - val_acc: 0.9000\n",
            "Epoch 303/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1064 - acc: 0.8444 - val_loss: 0.1662 - val_acc: 1.0000\n",
            "Epoch 304/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1067 - acc: 0.8500 - val_loss: 0.1661 - val_acc: 0.9500\n",
            "Epoch 305/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1066 - acc: 0.8500 - val_loss: 0.1697 - val_acc: 0.9000\n",
            "Epoch 306/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1067 - acc: 0.8556 - val_loss: 0.1667 - val_acc: 0.9000\n",
            "Epoch 307/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1077 - acc: 0.8722 - val_loss: 0.1675 - val_acc: 0.9000\n",
            "Epoch 308/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1064 - acc: 0.8389 - val_loss: 0.1680 - val_acc: 0.9500\n",
            "Epoch 309/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1062 - acc: 0.8444 - val_loss: 0.1657 - val_acc: 0.9500\n",
            "Epoch 310/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1067 - acc: 0.8611 - val_loss: 0.1657 - val_acc: 0.9500\n",
            "Epoch 311/800\n",
            "180/180 [==============================] - 0s 323us/step - loss: 0.1068 - acc: 0.8444 - val_loss: 0.1684 - val_acc: 0.8500\n",
            "Epoch 312/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1066 - acc: 0.8278 - val_loss: 0.1669 - val_acc: 0.9000\n",
            "Epoch 313/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1077 - acc: 0.8556 - val_loss: 0.1689 - val_acc: 0.9000\n",
            "Epoch 314/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1063 - acc: 0.8500 - val_loss: 0.1658 - val_acc: 0.9500\n",
            "Epoch 315/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1061 - acc: 0.8611 - val_loss: 0.1668 - val_acc: 0.9500\n",
            "Epoch 316/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1061 - acc: 0.8611 - val_loss: 0.1698 - val_acc: 0.8500\n",
            "Epoch 317/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1058 - acc: 0.8611 - val_loss: 0.1660 - val_acc: 0.9000\n",
            "Epoch 318/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1059 - acc: 0.8389 - val_loss: 0.1654 - val_acc: 0.9500\n",
            "Epoch 319/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1060 - acc: 0.8722 - val_loss: 0.1678 - val_acc: 0.9500\n",
            "Epoch 320/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1058 - acc: 0.8389 - val_loss: 0.1661 - val_acc: 0.9500\n",
            "Epoch 321/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.1052 - acc: 0.8500 - val_loss: 0.1691 - val_acc: 0.9000\n",
            "Epoch 322/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1064 - acc: 0.8667 - val_loss: 0.1652 - val_acc: 0.9500\n",
            "Epoch 323/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1054 - acc: 0.8444 - val_loss: 0.1654 - val_acc: 0.9000\n",
            "Epoch 324/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1056 - acc: 0.8611 - val_loss: 0.1661 - val_acc: 0.9500\n",
            "Epoch 325/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1054 - acc: 0.8556 - val_loss: 0.1666 - val_acc: 1.0000\n",
            "Epoch 326/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1058 - acc: 0.8556 - val_loss: 0.1651 - val_acc: 0.9500\n",
            "Epoch 327/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1056 - acc: 0.8556 - val_loss: 0.1657 - val_acc: 0.9000\n",
            "Epoch 328/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1059 - acc: 0.8667 - val_loss: 0.1665 - val_acc: 0.9000\n",
            "Epoch 329/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1056 - acc: 0.8389 - val_loss: 0.1667 - val_acc: 0.9500\n",
            "Epoch 330/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1054 - acc: 0.8500 - val_loss: 0.1664 - val_acc: 0.8500\n",
            "Epoch 331/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1052 - acc: 0.8444 - val_loss: 0.1672 - val_acc: 0.9500\n",
            "Epoch 332/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1052 - acc: 0.8444 - val_loss: 0.1660 - val_acc: 0.9500\n",
            "Epoch 333/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1049 - acc: 0.8444 - val_loss: 0.1648 - val_acc: 0.9500\n",
            "Epoch 334/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1048 - acc: 0.8611 - val_loss: 0.1656 - val_acc: 0.8500\n",
            "Epoch 335/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1052 - acc: 0.8556 - val_loss: 0.1672 - val_acc: 0.9000\n",
            "Epoch 336/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1059 - acc: 0.8444 - val_loss: 0.1638 - val_acc: 0.9500\n",
            "Epoch 337/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1049 - acc: 0.8611 - val_loss: 0.1680 - val_acc: 0.8500\n",
            "Epoch 338/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1049 - acc: 0.8500 - val_loss: 0.1668 - val_acc: 0.8500\n",
            "Epoch 339/800\n",
            "180/180 [==============================] - 0s 330us/step - loss: 0.1058 - acc: 0.8667 - val_loss: 0.1644 - val_acc: 0.9500\n",
            "Epoch 340/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1059 - acc: 0.8500 - val_loss: 0.1652 - val_acc: 0.9500\n",
            "Epoch 341/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1052 - acc: 0.8556 - val_loss: 0.1651 - val_acc: 1.0000\n",
            "Epoch 342/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1061 - acc: 0.8667 - val_loss: 0.1675 - val_acc: 0.8500\n",
            "Epoch 343/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1052 - acc: 0.8556 - val_loss: 0.1647 - val_acc: 0.9500\n",
            "Epoch 344/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.1049 - acc: 0.8611 - val_loss: 0.1661 - val_acc: 0.9500\n",
            "Epoch 345/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1053 - acc: 0.8500 - val_loss: 0.1655 - val_acc: 0.9000\n",
            "Epoch 346/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1046 - acc: 0.8556 - val_loss: 0.1660 - val_acc: 0.9500\n",
            "Epoch 347/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1046 - acc: 0.8667 - val_loss: 0.1671 - val_acc: 0.8500\n",
            "Epoch 348/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1048 - acc: 0.8667 - val_loss: 0.1667 - val_acc: 0.9000\n",
            "Epoch 349/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1046 - acc: 0.8556 - val_loss: 0.1664 - val_acc: 0.9500\n",
            "Epoch 350/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1046 - acc: 0.8333 - val_loss: 0.1660 - val_acc: 0.9000\n",
            "Epoch 351/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1047 - acc: 0.8389 - val_loss: 0.1645 - val_acc: 0.9500\n",
            "Epoch 352/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1049 - acc: 0.8611 - val_loss: 0.1642 - val_acc: 0.9500\n",
            "Epoch 353/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1042 - acc: 0.8667 - val_loss: 0.1650 - val_acc: 0.9000\n",
            "Epoch 354/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1043 - acc: 0.8444 - val_loss: 0.1663 - val_acc: 0.8500\n",
            "Epoch 355/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1051 - acc: 0.8444 - val_loss: 0.1655 - val_acc: 0.9000\n",
            "Epoch 356/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1045 - acc: 0.8556 - val_loss: 0.1646 - val_acc: 0.9500\n",
            "Epoch 357/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1045 - acc: 0.8556 - val_loss: 0.1650 - val_acc: 0.9500\n",
            "Epoch 358/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1052 - acc: 0.8667 - val_loss: 0.1657 - val_acc: 0.9500\n",
            "Epoch 359/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1038 - acc: 0.8500 - val_loss: 0.1655 - val_acc: 0.9500\n",
            "Epoch 360/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1043 - acc: 0.8556 - val_loss: 0.1652 - val_acc: 0.9000\n",
            "Epoch 361/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1043 - acc: 0.8500 - val_loss: 0.1681 - val_acc: 0.8500\n",
            "Epoch 362/800\n",
            "180/180 [==============================] - 0s 335us/step - loss: 0.1049 - acc: 0.8611 - val_loss: 0.1661 - val_acc: 0.8500\n",
            "Epoch 363/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1048 - acc: 0.8611 - val_loss: 0.1666 - val_acc: 0.9500\n",
            "Epoch 364/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1054 - acc: 0.8500 - val_loss: 0.1646 - val_acc: 0.8500\n",
            "Epoch 365/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1041 - acc: 0.8611 - val_loss: 0.1641 - val_acc: 1.0000\n",
            "Epoch 366/800\n",
            "180/180 [==============================] - 0s 329us/step - loss: 0.1039 - acc: 0.8389 - val_loss: 0.1640 - val_acc: 0.9500\n",
            "Epoch 367/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1042 - acc: 0.8444 - val_loss: 0.1651 - val_acc: 0.8500\n",
            "Epoch 368/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1036 - acc: 0.8667 - val_loss: 0.1654 - val_acc: 0.9500\n",
            "Epoch 369/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1038 - acc: 0.8500 - val_loss: 0.1644 - val_acc: 0.9500\n",
            "Epoch 370/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1035 - acc: 0.8500 - val_loss: 0.1651 - val_acc: 0.9500\n",
            "Epoch 371/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1038 - acc: 0.8667 - val_loss: 0.1643 - val_acc: 0.9000\n",
            "Epoch 372/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1037 - acc: 0.8444 - val_loss: 0.1641 - val_acc: 1.0000\n",
            "Epoch 373/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1041 - acc: 0.8667 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 374/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1041 - acc: 0.8444 - val_loss: 0.1641 - val_acc: 0.9500\n",
            "Epoch 375/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1033 - acc: 0.8444 - val_loss: 0.1648 - val_acc: 0.9500\n",
            "Epoch 376/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1035 - acc: 0.8389 - val_loss: 0.1643 - val_acc: 0.9500\n",
            "Epoch 377/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1033 - acc: 0.8611 - val_loss: 0.1645 - val_acc: 0.9500\n",
            "Epoch 378/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1037 - acc: 0.8667 - val_loss: 0.1658 - val_acc: 0.9000\n",
            "Epoch 379/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1031 - acc: 0.8444 - val_loss: 0.1664 - val_acc: 0.9000\n",
            "Epoch 380/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1033 - acc: 0.8667 - val_loss: 0.1648 - val_acc: 0.9000\n",
            "Epoch 381/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1044 - acc: 0.8778 - val_loss: 0.1652 - val_acc: 0.9500\n",
            "Epoch 382/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1038 - acc: 0.8500 - val_loss: 0.1639 - val_acc: 0.9500\n",
            "Epoch 383/800\n",
            "180/180 [==============================] - 0s 447us/step - loss: 0.1032 - acc: 0.8556 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 384/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1032 - acc: 0.8611 - val_loss: 0.1636 - val_acc: 0.9500\n",
            "Epoch 385/800\n",
            "180/180 [==============================] - 0s 331us/step - loss: 0.1035 - acc: 0.8556 - val_loss: 0.1672 - val_acc: 0.9000\n",
            "Epoch 386/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1034 - acc: 0.8556 - val_loss: 0.1635 - val_acc: 0.9500\n",
            "Epoch 387/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1033 - acc: 0.8667 - val_loss: 0.1624 - val_acc: 0.9500\n",
            "Epoch 388/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.1032 - acc: 0.8722 - val_loss: 0.1663 - val_acc: 1.0000\n",
            "Epoch 389/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1050 - acc: 0.8722 - val_loss: 0.1651 - val_acc: 0.9500\n",
            "Epoch 390/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1031 - acc: 0.8556 - val_loss: 0.1646 - val_acc: 0.9500\n",
            "Epoch 391/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1037 - acc: 0.8444 - val_loss: 0.1660 - val_acc: 0.9500\n",
            "Epoch 392/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1030 - acc: 0.8667 - val_loss: 0.1645 - val_acc: 0.9000\n",
            "Epoch 393/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1029 - acc: 0.8556 - val_loss: 0.1634 - val_acc: 0.9500\n",
            "Epoch 394/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1027 - acc: 0.8389 - val_loss: 0.1652 - val_acc: 0.9500\n",
            "Epoch 395/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1042 - acc: 0.8778 - val_loss: 0.1645 - val_acc: 0.8500\n",
            "Epoch 396/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1032 - acc: 0.8667 - val_loss: 0.1633 - val_acc: 0.9000\n",
            "Epoch 397/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1027 - acc: 0.8556 - val_loss: 0.1642 - val_acc: 0.8500\n",
            "Epoch 398/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1035 - acc: 0.8444 - val_loss: 0.1660 - val_acc: 0.9500\n",
            "Epoch 399/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1031 - acc: 0.8667 - val_loss: 0.1634 - val_acc: 0.9500\n",
            "Epoch 400/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1027 - acc: 0.8611 - val_loss: 0.1624 - val_acc: 0.9500\n",
            "Epoch 401/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1033 - acc: 0.8500 - val_loss: 0.1644 - val_acc: 1.0000\n",
            "Epoch 402/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1028 - acc: 0.8611 - val_loss: 0.1619 - val_acc: 1.0000\n",
            "Epoch 403/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1031 - acc: 0.8444 - val_loss: 0.1629 - val_acc: 0.9500\n",
            "Epoch 404/800\n",
            "180/180 [==============================] - 0s 427us/step - loss: 0.1027 - acc: 0.8778 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 405/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1027 - acc: 0.8556 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 406/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1029 - acc: 0.8500 - val_loss: 0.1639 - val_acc: 0.9000\n",
            "Epoch 407/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1026 - acc: 0.8611 - val_loss: 0.1650 - val_acc: 0.8500\n",
            "Epoch 408/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1026 - acc: 0.8611 - val_loss: 0.1661 - val_acc: 0.9000\n",
            "Epoch 409/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1030 - acc: 0.8556 - val_loss: 0.1622 - val_acc: 0.9500\n",
            "Epoch 410/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.8667 - val_loss: 0.1635 - val_acc: 0.9000\n",
            "Epoch 411/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1026 - acc: 0.8778 - val_loss: 0.1636 - val_acc: 0.9500\n",
            "Epoch 412/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.8556 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 413/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1026 - acc: 0.8556 - val_loss: 0.1633 - val_acc: 0.9500\n",
            "Epoch 414/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1023 - acc: 0.8722 - val_loss: 0.1621 - val_acc: 0.9500\n",
            "Epoch 415/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1022 - acc: 0.8556 - val_loss: 0.1657 - val_acc: 0.8500\n",
            "Epoch 416/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1033 - acc: 0.8611 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 417/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1032 - acc: 0.8500 - val_loss: 0.1622 - val_acc: 0.9500\n",
            "Epoch 418/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1018 - acc: 0.8722 - val_loss: 0.1654 - val_acc: 0.9000\n",
            "Epoch 419/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1031 - acc: 0.8667 - val_loss: 0.1630 - val_acc: 0.9000\n",
            "Epoch 420/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1025 - acc: 0.8667 - val_loss: 0.1678 - val_acc: 0.8500\n",
            "Epoch 421/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1028 - acc: 0.8389 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 422/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1023 - acc: 0.8556 - val_loss: 0.1641 - val_acc: 1.0000\n",
            "Epoch 423/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1032 - acc: 0.8556 - val_loss: 0.1622 - val_acc: 0.9500\n",
            "Epoch 424/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1019 - acc: 0.8556 - val_loss: 0.1636 - val_acc: 0.9500\n",
            "Epoch 425/800\n",
            "180/180 [==============================] - 0s 394us/step - loss: 0.1025 - acc: 0.8500 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 426/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1019 - acc: 0.8611 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 427/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.8556 - val_loss: 0.1639 - val_acc: 0.8500\n",
            "Epoch 428/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1019 - acc: 0.8556 - val_loss: 0.1629 - val_acc: 0.9500\n",
            "Epoch 429/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1019 - acc: 0.8611 - val_loss: 0.1637 - val_acc: 0.8500\n",
            "Epoch 430/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1022 - acc: 0.8611 - val_loss: 0.1650 - val_acc: 0.9500\n",
            "Epoch 431/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1023 - acc: 0.8556 - val_loss: 0.1648 - val_acc: 0.9500\n",
            "Epoch 432/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1031 - acc: 0.8667 - val_loss: 0.1643 - val_acc: 1.0000\n",
            "Epoch 433/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1021 - acc: 0.8722 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 434/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1021 - acc: 0.8667 - val_loss: 0.1624 - val_acc: 0.9500\n",
            "Epoch 435/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1026 - acc: 0.8389 - val_loss: 0.1626 - val_acc: 0.9500\n",
            "Epoch 436/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1016 - acc: 0.8722 - val_loss: 0.1617 - val_acc: 0.9500\n",
            "Epoch 437/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1048 - acc: 0.8500 - val_loss: 0.1653 - val_acc: 0.9500\n",
            "Epoch 438/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1027 - acc: 0.8444 - val_loss: 0.1647 - val_acc: 0.9500\n",
            "Epoch 439/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1023 - acc: 0.8722 - val_loss: 0.1626 - val_acc: 1.0000\n",
            "Epoch 440/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1023 - acc: 0.8722 - val_loss: 0.1621 - val_acc: 0.9500\n",
            "Epoch 441/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1029 - acc: 0.8722 - val_loss: 0.1649 - val_acc: 0.9500\n",
            "Epoch 442/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1024 - acc: 0.8611 - val_loss: 0.1621 - val_acc: 0.9500\n",
            "Epoch 443/800\n",
            "180/180 [==============================] - 0s 329us/step - loss: 0.1016 - acc: 0.8778 - val_loss: 0.1649 - val_acc: 0.9000\n",
            "Epoch 444/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1019 - acc: 0.8500 - val_loss: 0.1609 - val_acc: 0.9500\n",
            "Epoch 445/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1021 - acc: 0.8778 - val_loss: 0.1640 - val_acc: 0.8500\n",
            "Epoch 446/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.1017 - acc: 0.8556 - val_loss: 0.1639 - val_acc: 0.9500\n",
            "Epoch 447/800\n",
            "180/180 [==============================] - 0s 329us/step - loss: 0.1022 - acc: 0.8778 - val_loss: 0.1648 - val_acc: 0.9500\n",
            "Epoch 448/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1030 - acc: 0.8667 - val_loss: 0.1609 - val_acc: 0.9500\n",
            "Epoch 449/800\n",
            "180/180 [==============================] - 0s 324us/step - loss: 0.1018 - acc: 0.8611 - val_loss: 0.1632 - val_acc: 0.9000\n",
            "Epoch 450/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1019 - acc: 0.8611 - val_loss: 0.1624 - val_acc: 0.9500\n",
            "Epoch 451/800\n",
            "180/180 [==============================] - 0s 324us/step - loss: 0.1018 - acc: 0.8722 - val_loss: 0.1618 - val_acc: 0.9500\n",
            "Epoch 452/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.8556 - val_loss: 0.1638 - val_acc: 0.9500\n",
            "Epoch 453/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1029 - acc: 0.8889 - val_loss: 0.1649 - val_acc: 0.9500\n",
            "Epoch 454/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1016 - acc: 0.8722 - val_loss: 0.1631 - val_acc: 0.9000\n",
            "Epoch 455/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1022 - acc: 0.8667 - val_loss: 0.1637 - val_acc: 0.9500\n",
            "Epoch 456/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1012 - acc: 0.8667 - val_loss: 0.1628 - val_acc: 0.9500\n",
            "Epoch 457/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1019 - acc: 0.8611 - val_loss: 0.1638 - val_acc: 0.9500\n",
            "Epoch 458/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.1017 - acc: 0.8611 - val_loss: 0.1636 - val_acc: 0.9500\n",
            "Epoch 459/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1039 - acc: 0.8556 - val_loss: 0.1615 - val_acc: 0.9500\n",
            "Epoch 460/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1012 - acc: 0.8611 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 461/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1016 - acc: 0.8722 - val_loss: 0.1624 - val_acc: 0.9500\n",
            "Epoch 462/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1017 - acc: 0.8556 - val_loss: 0.1628 - val_acc: 1.0000\n",
            "Epoch 463/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1015 - acc: 0.8778 - val_loss: 0.1629 - val_acc: 0.9500\n",
            "Epoch 464/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1012 - acc: 0.8611 - val_loss: 0.1611 - val_acc: 1.0000\n",
            "Epoch 465/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1013 - acc: 0.8667 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 466/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1011 - acc: 0.8611 - val_loss: 0.1615 - val_acc: 0.9500\n",
            "Epoch 467/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1016 - acc: 0.8611 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 468/800\n",
            "180/180 [==============================] - 0s 324us/step - loss: 0.1033 - acc: 0.8611 - val_loss: 0.1655 - val_acc: 0.9500\n",
            "Epoch 469/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1038 - acc: 0.8611 - val_loss: 0.1642 - val_acc: 0.9500\n",
            "Epoch 470/800\n",
            "180/180 [==============================] - 0s 328us/step - loss: 0.1018 - acc: 0.8778 - val_loss: 0.1638 - val_acc: 0.9500\n",
            "Epoch 471/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1008 - acc: 0.8667 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 472/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1021 - acc: 0.8833 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 473/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1014 - acc: 0.8667 - val_loss: 0.1615 - val_acc: 0.9500\n",
            "Epoch 474/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1012 - acc: 0.8611 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 475/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1011 - acc: 0.8667 - val_loss: 0.1629 - val_acc: 0.9500\n",
            "Epoch 476/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1009 - acc: 0.8722 - val_loss: 0.1617 - val_acc: 0.9500\n",
            "Epoch 477/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1016 - acc: 0.8722 - val_loss: 0.1617 - val_acc: 0.9500\n",
            "Epoch 478/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1012 - acc: 0.8444 - val_loss: 0.1626 - val_acc: 1.0000\n",
            "Epoch 479/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1019 - acc: 0.8667 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 480/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1014 - acc: 0.8556 - val_loss: 0.1619 - val_acc: 0.9500\n",
            "Epoch 481/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1009 - acc: 0.8500 - val_loss: 0.1606 - val_acc: 0.9500\n",
            "Epoch 482/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1010 - acc: 0.8667 - val_loss: 0.1610 - val_acc: 1.0000\n",
            "Epoch 483/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1022 - acc: 0.8667 - val_loss: 0.1633 - val_acc: 0.9500\n",
            "Epoch 484/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1010 - acc: 0.8667 - val_loss: 0.1616 - val_acc: 0.9500\n",
            "Epoch 485/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1006 - acc: 0.8722 - val_loss: 0.1616 - val_acc: 0.9500\n",
            "Epoch 486/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.1009 - acc: 0.8611 - val_loss: 0.1636 - val_acc: 0.9500\n",
            "Epoch 487/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1014 - acc: 0.8556 - val_loss: 0.1608 - val_acc: 0.9500\n",
            "Epoch 488/800\n",
            "180/180 [==============================] - 0s 335us/step - loss: 0.1010 - acc: 0.8611 - val_loss: 0.1604 - val_acc: 1.0000\n",
            "Epoch 489/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1011 - acc: 0.8556 - val_loss: 0.1618 - val_acc: 0.9500\n",
            "Epoch 490/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1008 - acc: 0.8778 - val_loss: 0.1605 - val_acc: 0.9500\n",
            "Epoch 491/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1005 - acc: 0.8556 - val_loss: 0.1619 - val_acc: 0.9500\n",
            "Epoch 492/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1012 - acc: 0.8556 - val_loss: 0.1620 - val_acc: 0.9500\n",
            "Epoch 493/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1008 - acc: 0.8722 - val_loss: 0.1626 - val_acc: 0.9500\n",
            "Epoch 494/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1006 - acc: 0.8611 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 495/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1010 - acc: 0.8667 - val_loss: 0.1633 - val_acc: 0.9500\n",
            "Epoch 496/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.1012 - acc: 0.8722 - val_loss: 0.1643 - val_acc: 1.0000\n",
            "Epoch 497/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1006 - acc: 0.8444 - val_loss: 0.1608 - val_acc: 0.9500\n",
            "Epoch 498/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1001 - acc: 0.8611 - val_loss: 0.1618 - val_acc: 0.9500\n",
            "Epoch 499/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1024 - acc: 0.8722 - val_loss: 0.1610 - val_acc: 0.9500\n",
            "Epoch 500/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1010 - acc: 0.8667 - val_loss: 0.1626 - val_acc: 0.9500\n",
            "Epoch 501/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1009 - acc: 0.8667 - val_loss: 0.1605 - val_acc: 0.9500\n",
            "Epoch 502/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1003 - acc: 0.8611 - val_loss: 0.1611 - val_acc: 0.9500\n",
            "Epoch 503/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1008 - acc: 0.8722 - val_loss: 0.1681 - val_acc: 0.8500\n",
            "Epoch 504/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1013 - acc: 0.8556 - val_loss: 0.1614 - val_acc: 0.9500\n",
            "Epoch 505/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1005 - acc: 0.8611 - val_loss: 0.1616 - val_acc: 0.9500\n",
            "Epoch 506/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1006 - acc: 0.8722 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 507/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1002 - acc: 0.8556 - val_loss: 0.1613 - val_acc: 1.0000\n",
            "Epoch 508/800\n",
            "180/180 [==============================] - 0s 427us/step - loss: 0.1007 - acc: 0.8667 - val_loss: 0.1603 - val_acc: 0.9500\n",
            "Epoch 509/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1003 - acc: 0.8611 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 510/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1007 - acc: 0.8667 - val_loss: 0.1629 - val_acc: 0.9500\n",
            "Epoch 511/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.1009 - acc: 0.8556 - val_loss: 0.1615 - val_acc: 0.9500\n",
            "Epoch 512/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1006 - acc: 0.8778 - val_loss: 0.1622 - val_acc: 0.9500\n",
            "Epoch 513/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1001 - acc: 0.8444 - val_loss: 0.1612 - val_acc: 1.0000\n",
            "Epoch 514/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1003 - acc: 0.8889 - val_loss: 0.1620 - val_acc: 1.0000\n",
            "Epoch 515/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1004 - acc: 0.8722 - val_loss: 0.1619 - val_acc: 0.9500\n",
            "Epoch 516/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1009 - acc: 0.8500 - val_loss: 0.1618 - val_acc: 0.9500\n",
            "Epoch 517/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1003 - acc: 0.8722 - val_loss: 0.1627 - val_acc: 0.9000\n",
            "Epoch 518/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1011 - acc: 0.8667 - val_loss: 0.1622 - val_acc: 0.9500\n",
            "Epoch 519/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1003 - acc: 0.8611 - val_loss: 0.1616 - val_acc: 0.9500\n",
            "Epoch 520/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1006 - acc: 0.8667 - val_loss: 0.1607 - val_acc: 0.9500\n",
            "Epoch 521/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.0999 - acc: 0.8778 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 522/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0999 - acc: 0.8667 - val_loss: 0.1647 - val_acc: 0.8500\n",
            "Epoch 523/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1010 - acc: 0.8556 - val_loss: 0.1617 - val_acc: 1.0000\n",
            "Epoch 524/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1004 - acc: 0.8500 - val_loss: 0.1603 - val_acc: 0.9500\n",
            "Epoch 525/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1003 - acc: 0.8667 - val_loss: 0.1659 - val_acc: 0.8000\n",
            "Epoch 526/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1008 - acc: 0.8667 - val_loss: 0.1610 - val_acc: 0.9500\n",
            "Epoch 527/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1000 - acc: 0.8611 - val_loss: 0.1616 - val_acc: 0.9500\n",
            "Epoch 528/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1001 - acc: 0.8778 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 529/800\n",
            "180/180 [==============================] - 0s 432us/step - loss: 0.1003 - acc: 0.8722 - val_loss: 0.1619 - val_acc: 0.9500\n",
            "Epoch 530/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1002 - acc: 0.8778 - val_loss: 0.1615 - val_acc: 0.9500\n",
            "Epoch 531/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1001 - acc: 0.8556 - val_loss: 0.1610 - val_acc: 0.9500\n",
            "Epoch 532/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1000 - acc: 0.8611 - val_loss: 0.1604 - val_acc: 0.9500\n",
            "Epoch 533/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.0995 - acc: 0.8611 - val_loss: 0.1604 - val_acc: 0.9500\n",
            "Epoch 534/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1013 - acc: 0.8444 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 535/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1008 - acc: 0.8667 - val_loss: 0.1626 - val_acc: 0.9000\n",
            "Epoch 536/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1002 - acc: 0.8611 - val_loss: 0.1608 - val_acc: 1.0000\n",
            "Epoch 537/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.0999 - acc: 0.8722 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 538/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.0998 - acc: 0.8556 - val_loss: 0.1622 - val_acc: 0.9500\n",
            "Epoch 539/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1006 - acc: 0.8778 - val_loss: 0.1640 - val_acc: 0.8500\n",
            "Epoch 540/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1000 - acc: 0.8389 - val_loss: 0.1601 - val_acc: 1.0000\n",
            "Epoch 541/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1002 - acc: 0.8611 - val_loss: 0.1605 - val_acc: 0.9500\n",
            "Epoch 542/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0998 - acc: 0.8667 - val_loss: 0.1614 - val_acc: 0.9500\n",
            "Epoch 543/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.0997 - acc: 0.8722 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 544/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.0998 - acc: 0.8611 - val_loss: 0.1602 - val_acc: 1.0000\n",
            "Epoch 545/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.0997 - acc: 0.8722 - val_loss: 0.1664 - val_acc: 0.9000\n",
            "Epoch 546/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1010 - acc: 0.8500 - val_loss: 0.1672 - val_acc: 0.9500\n",
            "Epoch 547/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1012 - acc: 0.8611 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 548/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0999 - acc: 0.8778 - val_loss: 0.1624 - val_acc: 1.0000\n",
            "Epoch 549/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1008 - acc: 0.8667 - val_loss: 0.1624 - val_acc: 1.0000\n",
            "Epoch 550/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1002 - acc: 0.8611 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 551/800\n",
            "180/180 [==============================] - 0s 331us/step - loss: 0.0999 - acc: 0.8889 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 552/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.0995 - acc: 0.8722 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 553/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.0994 - acc: 0.8778 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 554/800\n",
            "180/180 [==============================] - 0s 330us/step - loss: 0.1004 - acc: 0.8444 - val_loss: 0.1623 - val_acc: 1.0000\n",
            "Epoch 555/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1005 - acc: 0.8556 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 556/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1006 - acc: 0.8778 - val_loss: 0.1607 - val_acc: 0.9500\n",
            "Epoch 557/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1025 - acc: 0.8611 - val_loss: 0.1628 - val_acc: 0.9500\n",
            "Epoch 558/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1003 - acc: 0.8722 - val_loss: 0.1605 - val_acc: 1.0000\n",
            "Epoch 559/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1000 - acc: 0.8667 - val_loss: 0.1608 - val_acc: 0.9000\n",
            "Epoch 560/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.0993 - acc: 0.8722 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 561/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0998 - acc: 0.8667 - val_loss: 0.1607 - val_acc: 1.0000\n",
            "Epoch 562/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1002 - acc: 0.8667 - val_loss: 0.1631 - val_acc: 0.9500\n",
            "Epoch 563/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1004 - acc: 0.8500 - val_loss: 0.1597 - val_acc: 1.0000\n",
            "Epoch 564/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.0994 - acc: 0.8611 - val_loss: 0.1643 - val_acc: 0.9000\n",
            "Epoch 565/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1020 - acc: 0.8611 - val_loss: 0.1624 - val_acc: 0.9500\n",
            "Epoch 566/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1000 - acc: 0.8667 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 567/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1010 - acc: 0.8833 - val_loss: 0.1604 - val_acc: 0.9500\n",
            "Epoch 568/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.0995 - acc: 0.8500 - val_loss: 0.1600 - val_acc: 1.0000\n",
            "Epoch 569/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.0998 - acc: 0.8833 - val_loss: 0.1605 - val_acc: 0.9500\n",
            "Epoch 570/800\n",
            "180/180 [==============================] - 0s 337us/step - loss: 0.0995 - acc: 0.8667 - val_loss: 0.1602 - val_acc: 0.9500\n",
            "Epoch 571/800\n",
            "180/180 [==============================] - 0s 403us/step - loss: 0.0997 - acc: 0.8778 - val_loss: 0.1604 - val_acc: 0.9500\n",
            "Epoch 572/800\n",
            "180/180 [==============================] - 0s 329us/step - loss: 0.1002 - acc: 0.8667 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 573/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1000 - acc: 0.8722 - val_loss: 0.1611 - val_acc: 1.0000\n",
            "Epoch 574/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1002 - acc: 0.8778 - val_loss: 0.1624 - val_acc: 1.0000\n",
            "Epoch 575/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1000 - acc: 0.8556 - val_loss: 0.1646 - val_acc: 0.9500\n",
            "Epoch 576/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1004 - acc: 0.8611 - val_loss: 0.1594 - val_acc: 1.0000\n",
            "Epoch 577/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0992 - acc: 0.8778 - val_loss: 0.1632 - val_acc: 0.9000\n",
            "Epoch 578/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.0998 - acc: 0.8722 - val_loss: 0.1610 - val_acc: 0.9500\n",
            "Epoch 579/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1000 - acc: 0.8667 - val_loss: 0.1653 - val_acc: 0.8000\n",
            "Epoch 580/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1004 - acc: 0.8500 - val_loss: 0.1619 - val_acc: 0.9500\n",
            "Epoch 581/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0999 - acc: 0.8611 - val_loss: 0.1592 - val_acc: 0.9500\n",
            "Epoch 582/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.0992 - acc: 0.8722 - val_loss: 0.1617 - val_acc: 0.9000\n",
            "Epoch 583/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.0992 - acc: 0.8556 - val_loss: 0.1604 - val_acc: 0.9500\n",
            "Epoch 584/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.0994 - acc: 0.8556 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 585/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0994 - acc: 0.8722 - val_loss: 0.1605 - val_acc: 0.9500\n",
            "Epoch 586/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0996 - acc: 0.8889 - val_loss: 0.1619 - val_acc: 0.9500\n",
            "Epoch 587/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.0992 - acc: 0.8667 - val_loss: 0.1594 - val_acc: 0.9500\n",
            "Epoch 588/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.0990 - acc: 0.8611 - val_loss: 0.1619 - val_acc: 0.9500\n",
            "Epoch 589/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.0999 - acc: 0.8556 - val_loss: 0.1618 - val_acc: 0.9500\n",
            "Epoch 590/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.0992 - acc: 0.8778 - val_loss: 0.1619 - val_acc: 0.9000\n",
            "Epoch 591/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.0992 - acc: 0.8444 - val_loss: 0.1606 - val_acc: 0.9500\n",
            "Epoch 592/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.0995 - acc: 0.8722 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 593/800\n",
            "180/180 [==============================] - 0s 329us/step - loss: 0.0993 - acc: 0.8778 - val_loss: 0.1631 - val_acc: 0.9000\n",
            "Epoch 594/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.0992 - acc: 0.8611 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 595/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.0995 - acc: 0.8833 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 596/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0996 - acc: 0.8778 - val_loss: 0.1614 - val_acc: 0.9500\n",
            "Epoch 597/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.0994 - acc: 0.8778 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 598/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.0993 - acc: 0.8556 - val_loss: 0.1617 - val_acc: 1.0000\n",
            "Epoch 599/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1003 - acc: 0.8500 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 600/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.0991 - acc: 0.8722 - val_loss: 0.1613 - val_acc: 0.9500\n",
            "Epoch 601/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.0994 - acc: 0.8722 - val_loss: 0.1602 - val_acc: 0.9000\n",
            "Epoch 602/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.0989 - acc: 0.8611 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 603/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.0997 - acc: 0.8444 - val_loss: 0.1603 - val_acc: 1.0000\n",
            "Epoch 604/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.0990 - acc: 0.8722 - val_loss: 0.1613 - val_acc: 0.9000\n",
            "Epoch 605/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0992 - acc: 0.8556 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 606/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.0990 - acc: 0.8556 - val_loss: 0.1590 - val_acc: 0.9500\n",
            "Epoch 607/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.0998 - acc: 0.8611 - val_loss: 0.1606 - val_acc: 0.9500\n",
            "Epoch 608/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.0991 - acc: 0.8889 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 609/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0997 - acc: 0.8778 - val_loss: 0.1641 - val_acc: 0.9000\n",
            "Epoch 610/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.0994 - acc: 0.8556 - val_loss: 0.1597 - val_acc: 0.9500\n",
            "Epoch 611/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.0988 - acc: 0.8667 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 612/800\n",
            "180/180 [==============================] - 0s 469us/step - loss: 0.0988 - acc: 0.8611 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 613/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.0991 - acc: 0.8722 - val_loss: 0.1605 - val_acc: 0.9500\n",
            "Epoch 614/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0993 - acc: 0.8778 - val_loss: 0.1600 - val_acc: 1.0000\n",
            "Epoch 615/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1002 - acc: 0.8833 - val_loss: 0.1616 - val_acc: 0.9500\n",
            "Epoch 616/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0991 - acc: 0.8667 - val_loss: 0.1608 - val_acc: 1.0000\n",
            "Epoch 617/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.0988 - acc: 0.8667 - val_loss: 0.1608 - val_acc: 0.9500\n",
            "Epoch 618/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0996 - acc: 0.8444 - val_loss: 0.1590 - val_acc: 0.9500\n",
            "Epoch 619/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.0992 - acc: 0.8556 - val_loss: 0.1621 - val_acc: 0.9000\n",
            "Epoch 620/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.0988 - acc: 0.8722 - val_loss: 0.1599 - val_acc: 0.9500\n",
            "Epoch 621/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.0986 - acc: 0.8722 - val_loss: 0.1592 - val_acc: 1.0000\n",
            "Epoch 622/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1002 - acc: 0.8556 - val_loss: 0.1647 - val_acc: 0.9500\n",
            "Epoch 623/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1000 - acc: 0.8722 - val_loss: 0.1639 - val_acc: 0.8500\n",
            "Epoch 624/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.0989 - acc: 0.8611 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 625/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.0989 - acc: 0.8778 - val_loss: 0.1596 - val_acc: 0.9500\n",
            "Epoch 626/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.0988 - acc: 0.8833 - val_loss: 0.1603 - val_acc: 0.9500\n",
            "Epoch 627/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.0991 - acc: 0.8667 - val_loss: 0.1599 - val_acc: 0.9500\n",
            "Epoch 628/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.0987 - acc: 0.8722 - val_loss: 0.1633 - val_acc: 0.9000\n",
            "Epoch 629/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.0991 - acc: 0.8611 - val_loss: 0.1594 - val_acc: 1.0000\n",
            "Epoch 630/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.0993 - acc: 0.8778 - val_loss: 0.1598 - val_acc: 1.0000\n",
            "Epoch 631/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.0985 - acc: 0.8667 - val_loss: 0.1601 - val_acc: 1.0000\n",
            "Epoch 632/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0987 - acc: 0.8611 - val_loss: 0.1588 - val_acc: 0.9500\n",
            "Epoch 633/800\n",
            "180/180 [==============================] - 0s 394us/step - loss: 0.0992 - acc: 0.8667 - val_loss: 0.1595 - val_acc: 1.0000\n",
            "Epoch 634/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.0990 - acc: 0.8722 - val_loss: 0.1592 - val_acc: 1.0000\n",
            "Epoch 635/800\n",
            "180/180 [==============================] - 0s 333us/step - loss: 0.0991 - acc: 0.8667 - val_loss: 0.1589 - val_acc: 0.9500\n",
            "Epoch 636/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.0993 - acc: 0.8667 - val_loss: 0.1626 - val_acc: 0.9500\n",
            "Epoch 637/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1008 - acc: 0.8500 - val_loss: 0.1616 - val_acc: 0.9500\n",
            "Epoch 638/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.0989 - acc: 0.8833 - val_loss: 0.1599 - val_acc: 1.0000\n",
            "Epoch 639/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.0993 - acc: 0.8722 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 640/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.0988 - acc: 0.8722 - val_loss: 0.1629 - val_acc: 0.9000\n",
            "Epoch 641/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0996 - acc: 0.8778 - val_loss: 0.1605 - val_acc: 0.9000\n",
            "Epoch 642/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.0990 - acc: 0.8722 - val_loss: 0.1635 - val_acc: 0.9000\n",
            "Epoch 643/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.0997 - acc: 0.8833 - val_loss: 0.1597 - val_acc: 0.9500\n",
            "Epoch 644/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0997 - acc: 0.8722 - val_loss: 0.1620 - val_acc: 0.9500\n",
            "Epoch 645/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.0987 - acc: 0.8778 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 646/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.0991 - acc: 0.8722 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 647/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.0994 - acc: 0.8833 - val_loss: 0.1611 - val_acc: 0.9500\n",
            "Epoch 648/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.0998 - acc: 0.8722 - val_loss: 0.1596 - val_acc: 0.9500\n",
            "Epoch 649/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.0990 - acc: 0.8667 - val_loss: 0.1592 - val_acc: 0.9500\n",
            "Epoch 650/800\n",
            "180/180 [==============================] - 0s 337us/step - loss: 0.0994 - acc: 0.8778 - val_loss: 0.1594 - val_acc: 0.9500\n",
            "Epoch 651/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0986 - acc: 0.8667 - val_loss: 0.1599 - val_acc: 0.9500\n",
            "Epoch 652/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.0990 - acc: 0.8778 - val_loss: 0.1596 - val_acc: 0.9500\n",
            "Epoch 653/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0988 - acc: 0.8889 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 654/800\n",
            "180/180 [==============================] - 0s 485us/step - loss: 0.0995 - acc: 0.8889 - val_loss: 0.1597 - val_acc: 0.9500\n",
            "Epoch 655/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.0986 - acc: 0.8722 - val_loss: 0.1600 - val_acc: 0.9000\n",
            "Epoch 656/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.0988 - acc: 0.8611 - val_loss: 0.1606 - val_acc: 0.9500\n",
            "Epoch 657/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.0987 - acc: 0.8722 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 658/800\n",
            "180/180 [==============================] - 0s 323us/step - loss: 0.0996 - acc: 0.8611 - val_loss: 0.1638 - val_acc: 0.9500\n",
            "Epoch 659/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0991 - acc: 0.8889 - val_loss: 0.1628 - val_acc: 1.0000\n",
            "Epoch 660/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.0992 - acc: 0.8778 - val_loss: 0.1593 - val_acc: 0.9500\n",
            "Epoch 661/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.0990 - acc: 0.8778 - val_loss: 0.1602 - val_acc: 0.9500\n",
            "Epoch 662/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.0993 - acc: 0.8556 - val_loss: 0.1593 - val_acc: 1.0000\n",
            "Epoch 663/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.0987 - acc: 0.8778 - val_loss: 0.1599 - val_acc: 0.9500\n",
            "Epoch 664/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0985 - acc: 0.8778 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 665/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.0986 - acc: 0.8833 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 666/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.0991 - acc: 0.8667 - val_loss: 0.1608 - val_acc: 0.9500\n",
            "Epoch 667/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.0992 - acc: 0.8722 - val_loss: 0.1595 - val_acc: 1.0000\n",
            "Epoch 668/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.0985 - acc: 0.8556 - val_loss: 0.1609 - val_acc: 0.9500\n",
            "Epoch 669/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0991 - acc: 0.8500 - val_loss: 0.1599 - val_acc: 0.9500\n",
            "Epoch 670/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0988 - acc: 0.8611 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 671/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.0984 - acc: 0.8611 - val_loss: 0.1593 - val_acc: 0.9500\n",
            "Epoch 672/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.0983 - acc: 0.8556 - val_loss: 0.1595 - val_acc: 1.0000\n",
            "Epoch 673/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.0981 - acc: 0.8722 - val_loss: 0.1601 - val_acc: 0.9000\n",
            "Epoch 674/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.0987 - acc: 0.8778 - val_loss: 0.1585 - val_acc: 0.9500\n",
            "Epoch 675/800\n",
            "180/180 [==============================] - 0s 420us/step - loss: 0.0985 - acc: 0.8722 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 676/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.0988 - acc: 0.8722 - val_loss: 0.1588 - val_acc: 1.0000\n",
            "Epoch 677/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.0987 - acc: 0.8556 - val_loss: 0.1604 - val_acc: 0.9500\n",
            "Epoch 678/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0992 - acc: 0.8667 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 679/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0989 - acc: 0.8556 - val_loss: 0.1592 - val_acc: 0.9500\n",
            "Epoch 680/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0983 - acc: 0.8778 - val_loss: 0.1589 - val_acc: 0.9500\n",
            "Epoch 681/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.0989 - acc: 0.8722 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 682/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.0988 - acc: 0.8778 - val_loss: 0.1602 - val_acc: 1.0000\n",
            "Epoch 683/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.0990 - acc: 0.8833 - val_loss: 0.1602 - val_acc: 0.9500\n",
            "Epoch 684/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.0982 - acc: 0.8556 - val_loss: 0.1603 - val_acc: 0.9500\n",
            "Epoch 685/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.0981 - acc: 0.8722 - val_loss: 0.1620 - val_acc: 0.9500\n",
            "Epoch 686/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.0985 - acc: 0.8833 - val_loss: 0.1599 - val_acc: 0.9500\n",
            "Epoch 687/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.0984 - acc: 0.8611 - val_loss: 0.1597 - val_acc: 0.9500\n",
            "Epoch 688/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1005 - acc: 0.8611 - val_loss: 0.1602 - val_acc: 1.0000\n",
            "Epoch 689/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0982 - acc: 0.8667 - val_loss: 0.1592 - val_acc: 0.9500\n",
            "Epoch 690/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0982 - acc: 0.8722 - val_loss: 0.1589 - val_acc: 0.9500\n",
            "Epoch 691/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0983 - acc: 0.8833 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 692/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0984 - acc: 0.8556 - val_loss: 0.1626 - val_acc: 0.9500\n",
            "Epoch 693/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0989 - acc: 0.8611 - val_loss: 0.1597 - val_acc: 0.9500\n",
            "Epoch 694/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.0984 - acc: 0.8722 - val_loss: 0.1608 - val_acc: 0.9500\n",
            "Epoch 695/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.0983 - acc: 0.8722 - val_loss: 0.1599 - val_acc: 1.0000\n",
            "Epoch 696/800\n",
            "180/180 [==============================] - 0s 397us/step - loss: 0.0983 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 0.9500\n",
            "Epoch 697/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0980 - acc: 0.8889 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 698/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.0983 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 0.9500\n",
            "Epoch 699/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.0982 - acc: 0.8833 - val_loss: 0.1602 - val_acc: 0.9500\n",
            "Epoch 700/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.0989 - acc: 0.8778 - val_loss: 0.1602 - val_acc: 1.0000\n",
            "Epoch 701/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0987 - acc: 0.8778 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 702/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0985 - acc: 0.8833 - val_loss: 0.1592 - val_acc: 0.9500\n",
            "Epoch 703/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0986 - acc: 0.8833 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 704/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.0982 - acc: 0.8667 - val_loss: 0.1588 - val_acc: 0.9500\n",
            "Epoch 705/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.0981 - acc: 0.8889 - val_loss: 0.1589 - val_acc: 1.0000\n",
            "Epoch 706/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0984 - acc: 0.8722 - val_loss: 0.1616 - val_acc: 0.9000\n",
            "Epoch 707/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0984 - acc: 0.8833 - val_loss: 0.1598 - val_acc: 1.0000\n",
            "Epoch 708/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.0984 - acc: 0.8611 - val_loss: 0.1598 - val_acc: 1.0000\n",
            "Epoch 709/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0982 - acc: 0.8611 - val_loss: 0.1590 - val_acc: 0.9500\n",
            "Epoch 710/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.0983 - acc: 0.8722 - val_loss: 0.1627 - val_acc: 0.9000\n",
            "Epoch 711/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.0997 - acc: 0.8833 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 712/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.0990 - acc: 0.8778 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 713/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.0986 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 1.0000\n",
            "Epoch 714/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0983 - acc: 0.8778 - val_loss: 0.1587 - val_acc: 1.0000\n",
            "Epoch 715/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.0989 - acc: 0.8722 - val_loss: 0.1596 - val_acc: 0.9500\n",
            "Epoch 716/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0983 - acc: 0.8833 - val_loss: 0.1601 - val_acc: 1.0000\n",
            "Epoch 717/800\n",
            "180/180 [==============================] - 0s 404us/step - loss: 0.0990 - acc: 0.8778 - val_loss: 0.1614 - val_acc: 0.9000\n",
            "Epoch 718/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.0984 - acc: 0.8611 - val_loss: 0.1606 - val_acc: 0.9500\n",
            "Epoch 719/800\n",
            "180/180 [==============================] - 0s 331us/step - loss: 0.0984 - acc: 0.8667 - val_loss: 0.1587 - val_acc: 1.0000\n",
            "Epoch 720/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.0979 - acc: 0.8667 - val_loss: 0.1589 - val_acc: 0.9500\n",
            "Epoch 721/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.0986 - acc: 0.8778 - val_loss: 0.1588 - val_acc: 1.0000\n",
            "Epoch 722/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.0982 - acc: 0.8778 - val_loss: 0.1586 - val_acc: 1.0000\n",
            "Epoch 723/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.0985 - acc: 0.8833 - val_loss: 0.1605 - val_acc: 1.0000\n",
            "Epoch 724/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.0989 - acc: 0.8556 - val_loss: 0.1603 - val_acc: 0.9500\n",
            "Epoch 725/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0992 - acc: 0.8778 - val_loss: 0.1603 - val_acc: 0.9500\n",
            "Epoch 726/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.0984 - acc: 0.8611 - val_loss: 0.1597 - val_acc: 0.9500\n",
            "Epoch 727/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.0983 - acc: 0.8611 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 728/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.0982 - acc: 0.8556 - val_loss: 0.1594 - val_acc: 1.0000\n",
            "Epoch 729/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.0977 - acc: 0.8778 - val_loss: 0.1593 - val_acc: 0.9500\n",
            "Epoch 730/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.0981 - acc: 0.8778 - val_loss: 0.1593 - val_acc: 1.0000\n",
            "Epoch 731/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.0983 - acc: 0.8889 - val_loss: 0.1622 - val_acc: 1.0000\n",
            "Epoch 732/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.0984 - acc: 0.8722 - val_loss: 0.1587 - val_acc: 0.9500\n",
            "Epoch 733/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0986 - acc: 0.8778 - val_loss: 0.1590 - val_acc: 1.0000\n",
            "Epoch 734/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.0982 - acc: 0.8833 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 735/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0979 - acc: 0.8778 - val_loss: 0.1602 - val_acc: 0.9500\n",
            "Epoch 736/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.0979 - acc: 0.8778 - val_loss: 0.1599 - val_acc: 0.9000\n",
            "Epoch 737/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.0983 - acc: 0.8667 - val_loss: 0.1650 - val_acc: 0.9500\n",
            "Epoch 738/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.1006 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 1.0000\n",
            "Epoch 739/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.0987 - acc: 0.8611 - val_loss: 0.1588 - val_acc: 0.9500\n",
            "Epoch 740/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.0979 - acc: 0.8778 - val_loss: 0.1587 - val_acc: 0.9500\n",
            "Epoch 741/800\n",
            "180/180 [==============================] - 0s 330us/step - loss: 0.0983 - acc: 0.8833 - val_loss: 0.1617 - val_acc: 0.9500\n",
            "Epoch 742/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.0990 - acc: 0.8722 - val_loss: 0.1592 - val_acc: 0.9500\n",
            "Epoch 743/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.0983 - acc: 0.8667 - val_loss: 0.1620 - val_acc: 1.0000\n",
            "Epoch 744/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.0984 - acc: 0.8778 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 745/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.0981 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.9500\n",
            "Epoch 746/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.0994 - acc: 0.8722 - val_loss: 0.1592 - val_acc: 0.9500\n",
            "Epoch 747/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.0989 - acc: 0.8722 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 748/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.0982 - acc: 0.8722 - val_loss: 0.1610 - val_acc: 1.0000\n",
            "Epoch 749/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.0985 - acc: 0.8778 - val_loss: 0.1587 - val_acc: 0.9500\n",
            "Epoch 750/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.0977 - acc: 0.8611 - val_loss: 0.1587 - val_acc: 0.9500\n",
            "Epoch 751/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0979 - acc: 0.8722 - val_loss: 0.1588 - val_acc: 0.9500\n",
            "Epoch 752/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.0976 - acc: 0.8722 - val_loss: 0.1610 - val_acc: 0.9500\n",
            "Epoch 753/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0978 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 1.0000\n",
            "Epoch 754/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.0977 - acc: 0.8611 - val_loss: 0.1627 - val_acc: 0.9000\n",
            "Epoch 755/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.0982 - acc: 0.8778 - val_loss: 0.1593 - val_acc: 0.9500\n",
            "Epoch 756/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0983 - acc: 0.8722 - val_loss: 0.1584 - val_acc: 1.0000\n",
            "Epoch 757/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0976 - acc: 0.8722 - val_loss: 0.1589 - val_acc: 0.9500\n",
            "Epoch 758/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.0982 - acc: 0.8778 - val_loss: 0.1615 - val_acc: 1.0000\n",
            "Epoch 759/800\n",
            "180/180 [==============================] - 0s 416us/step - loss: 0.0983 - acc: 0.8833 - val_loss: 0.1585 - val_acc: 1.0000\n",
            "Epoch 760/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.0980 - acc: 0.8722 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 761/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0976 - acc: 0.8833 - val_loss: 0.1589 - val_acc: 0.9500\n",
            "Epoch 762/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0978 - acc: 0.8611 - val_loss: 0.1580 - val_acc: 1.0000\n",
            "Epoch 763/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.0982 - acc: 0.8667 - val_loss: 0.1596 - val_acc: 1.0000\n",
            "Epoch 764/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0981 - acc: 0.8611 - val_loss: 0.1591 - val_acc: 1.0000\n",
            "Epoch 765/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0980 - acc: 0.8889 - val_loss: 0.1586 - val_acc: 0.9500\n",
            "Epoch 766/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0979 - acc: 0.8889 - val_loss: 0.1584 - val_acc: 0.9500\n",
            "Epoch 767/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.0977 - acc: 0.8667 - val_loss: 0.1625 - val_acc: 0.9000\n",
            "Epoch 768/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.0979 - acc: 0.8722 - val_loss: 0.1585 - val_acc: 0.9500\n",
            "Epoch 769/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.0979 - acc: 0.8722 - val_loss: 0.1615 - val_acc: 0.9500\n",
            "Epoch 770/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.0980 - acc: 0.8833 - val_loss: 0.1604 - val_acc: 0.9500\n",
            "Epoch 771/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0976 - acc: 0.8944 - val_loss: 0.1590 - val_acc: 0.9500\n",
            "Epoch 772/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.0981 - acc: 0.8944 - val_loss: 0.1600 - val_acc: 1.0000\n",
            "Epoch 773/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.0979 - acc: 0.8722 - val_loss: 0.1590 - val_acc: 0.9500\n",
            "Epoch 774/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.0982 - acc: 0.8667 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 775/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.0977 - acc: 0.8722 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 776/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.0973 - acc: 0.8667 - val_loss: 0.1579 - val_acc: 0.9500\n",
            "Epoch 777/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.0983 - acc: 0.8778 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 778/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.0984 - acc: 0.8778 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 779/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.0981 - acc: 0.8722 - val_loss: 0.1587 - val_acc: 0.9500\n",
            "Epoch 780/800\n",
            "180/180 [==============================] - 0s 395us/step - loss: 0.0976 - acc: 0.8778 - val_loss: 0.1622 - val_acc: 0.9000\n",
            "Epoch 781/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0990 - acc: 0.8778 - val_loss: 0.1619 - val_acc: 0.9000\n",
            "Epoch 782/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.0982 - acc: 0.8556 - val_loss: 0.1617 - val_acc: 0.9500\n",
            "Epoch 783/800\n",
            "180/180 [==============================] - 0s 335us/step - loss: 0.0982 - acc: 0.8667 - val_loss: 0.1594 - val_acc: 1.0000\n",
            "Epoch 784/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0976 - acc: 0.8722 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 785/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.0975 - acc: 0.8667 - val_loss: 0.1596 - val_acc: 1.0000\n",
            "Epoch 786/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.0977 - acc: 0.8611 - val_loss: 0.1591 - val_acc: 1.0000\n",
            "Epoch 787/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.0975 - acc: 0.8833 - val_loss: 0.1590 - val_acc: 0.9500\n",
            "Epoch 788/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0987 - acc: 0.8500 - val_loss: 0.1586 - val_acc: 1.0000\n",
            "Epoch 789/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0983 - acc: 0.8722 - val_loss: 0.1585 - val_acc: 1.0000\n",
            "Epoch 790/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.0980 - acc: 0.8722 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 791/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0976 - acc: 0.8667 - val_loss: 0.1611 - val_acc: 0.9000\n",
            "Epoch 792/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.0988 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 0.9500\n",
            "Epoch 793/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0977 - acc: 0.8667 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 794/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.0980 - acc: 0.8833 - val_loss: 0.1603 - val_acc: 0.9000\n",
            "Epoch 795/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.0984 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.9500\n",
            "Epoch 796/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0975 - acc: 0.8778 - val_loss: 0.1589 - val_acc: 0.9500\n",
            "Epoch 797/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.0974 - acc: 0.8778 - val_loss: 0.1599 - val_acc: 0.9500\n",
            "Epoch 798/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.0988 - acc: 0.8556 - val_loss: 0.1583 - val_acc: 0.9500\n",
            "Epoch 799/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.0974 - acc: 0.8833 - val_loss: 0.1581 - val_acc: 0.9500\n",
            "Epoch 800/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.0974 - acc: 0.8833 - val_loss: 0.1594 - val_acc: 0.9500\n",
            "200/200 [==============================] - 0s 99us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0.11783276438713074, 0.945]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "0HjRmdZ2FXk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "6c8a68ba-97ab-4fd7-930e-a140b912dc3e"
      },
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Make sure to run this after each new generation of data\n",
        "# zero mean and unit var\n",
        "x_train2 = StandardScaler().fit_transform(x_train)\n",
        "x_test2 = StandardScaler().fit_transform(x_test)\n",
        "#x_train2 = x_train2[:,:,np.newaxis]\n",
        "#x_test2 = x_test2[:,:,np.newaxis]\n",
        "\n",
        "#x_train2 = x_train2.astype('float32') \n",
        "#x_test2 = x_test2.astype('float32')\n",
        "\n",
        "display(x_train2.shape)\n",
        "\n",
        "input_dim = x_train.shape[1]\n",
        "\n",
        "# set size of autoencoder \n",
        "encoding_dim = 5\n",
        "elu = keras.layers.ELU(alpha=1.2)\n",
        "lrlu= keras.layers.LeakyReLU(alpha=0.3)\n",
        "\n",
        "\n",
        "# use elu because it is leaky tried both net and l1 and l2 : net and l1 worked the best \n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "encoder = Dense(encoding_dim,kernel_initializer= 'he_normal', activity_regularizer=regularizers.l1_l2(l1=10e-5, l2=75.10e-5))(input_layer)\n",
        "encoder = keras.layers.LeakyReLU(alpha=0.011)(encoder)\n",
        "#encoder = Dense(encoding_dim, activation=\"elu\",activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "encoder = Dense(int(encoding_dim / 2),kernel_initializer= 'he_normal')(encoder)\n",
        "encoder = keras.layers.LeakyReLU(alpha=0.011)(encoder)\n",
        "decoder = Dense(int(encoding_dim / 2),kernel_initializer= 'he_normal')(encoder)\n",
        "decoder = keras.layers.LeakyReLU(alpha=0.011)(decoder)\n",
        "decoder = Dense(input_dim,kernel_initializer= 'he_normal')(decoder)\n",
        "decoder = keras.layers.LeakyReLU(alpha=0.011)(decoder)\n",
        "autoencoder2 = Model(inputs=input_layer, outputs=decoder)\n",
        "\n",
        "autoencoder2.summary()  \n"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(300, 6)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_21 (InputLayer)        (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 5)                 35        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_82 (LeakyReLU)   (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 2)                 12        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_83 (LeakyReLU)   (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_83 (Dense)             (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_84 (LeakyReLU)   (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 6)                 18        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_85 (LeakyReLU)   (None, 6)                 0         \n",
            "=================================================================\n",
            "Total params: 71\n",
            "Trainable params: 71\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TGa_7-W3FSLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27353
        },
        "outputId": "c575da05-1a0f-4183-cc77-65616e3c8614"
      },
      "cell_type": "code",
      "source": [
        "#Results with no anomily \n",
        "# Loss and Val Loss are very close + Accuracy and Val Accuracy are very close \n",
        "# Depending on the params of the net it can hit Accuracy of  1\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "full_anom = 0\n",
        "anom_samples = 0\n",
        "batch_size = 32\n",
        "import keras\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "nadam =keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
        "\n",
        "autoencoder2.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    #loss = 'binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
        "                              patience=300,verbose = 1)\n",
        "history = autoencoder2.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "                    validation_split=.1,\n",
        "                    verbose=1,callbacks=[reduce_lr])\n",
        "score = autoencoder2.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 180 samples, validate on 20 samples\n",
            "Epoch 1/800\n",
            "180/180 [==============================] - 7s 38ms/step - loss: 0.6340 - acc: 0.5222 - val_loss: 0.6486 - val_acc: 0.4000\n",
            "Epoch 2/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.6323 - acc: 0.5167 - val_loss: 0.6465 - val_acc: 0.4000\n",
            "Epoch 3/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.6305 - acc: 0.5333 - val_loss: 0.6434 - val_acc: 0.4000\n",
            "Epoch 4/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.6292 - acc: 0.5389 - val_loss: 0.6430 - val_acc: 0.4000\n",
            "Epoch 5/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.6275 - acc: 0.5611 - val_loss: 0.6400 - val_acc: 0.4000\n",
            "Epoch 6/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.6262 - acc: 0.5778 - val_loss: 0.6392 - val_acc: 0.4500\n",
            "Epoch 7/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.6250 - acc: 0.6111 - val_loss: 0.6368 - val_acc: 0.5000\n",
            "Epoch 8/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.6230 - acc: 0.6278 - val_loss: 0.6366 - val_acc: 0.4500\n",
            "Epoch 9/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.6219 - acc: 0.6056 - val_loss: 0.6333 - val_acc: 0.3500\n",
            "Epoch 10/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.6211 - acc: 0.6056 - val_loss: 0.6322 - val_acc: 0.3500\n",
            "Epoch 11/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.6195 - acc: 0.5722 - val_loss: 0.6297 - val_acc: 0.4000\n",
            "Epoch 12/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.6186 - acc: 0.5889 - val_loss: 0.6267 - val_acc: 0.4000\n",
            "Epoch 13/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.6171 - acc: 0.6167 - val_loss: 0.6242 - val_acc: 0.4000\n",
            "Epoch 14/800\n",
            "180/180 [==============================] - 0s 414us/step - loss: 0.6153 - acc: 0.6111 - val_loss: 0.6235 - val_acc: 0.5000\n",
            "Epoch 15/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.6140 - acc: 0.6444 - val_loss: 0.6222 - val_acc: 0.4500\n",
            "Epoch 16/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.6126 - acc: 0.6389 - val_loss: 0.6198 - val_acc: 0.5500\n",
            "Epoch 17/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.6111 - acc: 0.6500 - val_loss: 0.6177 - val_acc: 0.5500\n",
            "Epoch 18/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.6092 - acc: 0.6500 - val_loss: 0.6170 - val_acc: 0.6500\n",
            "Epoch 19/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.6072 - acc: 0.6389 - val_loss: 0.6154 - val_acc: 0.6500\n",
            "Epoch 20/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.6052 - acc: 0.6333 - val_loss: 0.6140 - val_acc: 0.5500\n",
            "Epoch 21/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.6033 - acc: 0.6278 - val_loss: 0.6128 - val_acc: 0.6000\n",
            "Epoch 22/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.6017 - acc: 0.6667 - val_loss: 0.6102 - val_acc: 0.6000\n",
            "Epoch 23/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.5993 - acc: 0.6667 - val_loss: 0.6077 - val_acc: 0.6000\n",
            "Epoch 24/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.5972 - acc: 0.6833 - val_loss: 0.6046 - val_acc: 0.6500\n",
            "Epoch 25/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.5953 - acc: 0.6889 - val_loss: 0.6004 - val_acc: 0.6500\n",
            "Epoch 26/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.5931 - acc: 0.6833 - val_loss: 0.5985 - val_acc: 0.7000\n",
            "Epoch 27/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.5908 - acc: 0.6944 - val_loss: 0.5950 - val_acc: 0.7000\n",
            "Epoch 28/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.5895 - acc: 0.6833 - val_loss: 0.5942 - val_acc: 0.6500\n",
            "Epoch 29/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.5871 - acc: 0.6889 - val_loss: 0.5890 - val_acc: 0.7000\n",
            "Epoch 30/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.5850 - acc: 0.6778 - val_loss: 0.5875 - val_acc: 0.6500\n",
            "Epoch 31/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.5829 - acc: 0.6833 - val_loss: 0.5843 - val_acc: 0.6500\n",
            "Epoch 32/800\n",
            "180/180 [==============================] - 0s 480us/step - loss: 0.5812 - acc: 0.6889 - val_loss: 0.5801 - val_acc: 0.7000\n",
            "Epoch 33/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.5805 - acc: 0.7056 - val_loss: 0.5771 - val_acc: 0.7000\n",
            "Epoch 34/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.5776 - acc: 0.7000 - val_loss: 0.5727 - val_acc: 0.7000\n",
            "Epoch 35/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.5755 - acc: 0.6889 - val_loss: 0.5697 - val_acc: 0.7000\n",
            "Epoch 36/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.5731 - acc: 0.6833 - val_loss: 0.5663 - val_acc: 0.7000\n",
            "Epoch 37/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.5715 - acc: 0.6889 - val_loss: 0.5633 - val_acc: 0.7000\n",
            "Epoch 38/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.5700 - acc: 0.6833 - val_loss: 0.5601 - val_acc: 0.7000\n",
            "Epoch 39/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.5677 - acc: 0.6833 - val_loss: 0.5567 - val_acc: 0.7000\n",
            "Epoch 40/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.5655 - acc: 0.6889 - val_loss: 0.5524 - val_acc: 0.7000\n",
            "Epoch 41/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.5638 - acc: 0.7056 - val_loss: 0.5492 - val_acc: 0.7000\n",
            "Epoch 42/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.5618 - acc: 0.7000 - val_loss: 0.5439 - val_acc: 0.7500\n",
            "Epoch 43/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.5589 - acc: 0.7000 - val_loss: 0.5411 - val_acc: 0.8000\n",
            "Epoch 44/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.5569 - acc: 0.7056 - val_loss: 0.5370 - val_acc: 0.8000\n",
            "Epoch 45/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.5540 - acc: 0.7222 - val_loss: 0.5328 - val_acc: 0.9000\n",
            "Epoch 46/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.5525 - acc: 0.7389 - val_loss: 0.5278 - val_acc: 0.8500\n",
            "Epoch 47/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.5489 - acc: 0.7556 - val_loss: 0.5248 - val_acc: 0.8500\n",
            "Epoch 48/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.5458 - acc: 0.7556 - val_loss: 0.5214 - val_acc: 0.9000\n",
            "Epoch 49/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.5435 - acc: 0.7556 - val_loss: 0.5185 - val_acc: 0.9000\n",
            "Epoch 50/800\n",
            "180/180 [==============================] - 0s 455us/step - loss: 0.5420 - acc: 0.7722 - val_loss: 0.5159 - val_acc: 0.9000\n",
            "Epoch 51/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.5393 - acc: 0.7611 - val_loss: 0.5138 - val_acc: 0.9000\n",
            "Epoch 52/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.5374 - acc: 0.7722 - val_loss: 0.5100 - val_acc: 0.9500\n",
            "Epoch 53/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.5352 - acc: 0.7778 - val_loss: 0.5079 - val_acc: 0.9000\n",
            "Epoch 54/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.5332 - acc: 0.7833 - val_loss: 0.5053 - val_acc: 0.9500\n",
            "Epoch 55/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.5321 - acc: 0.7889 - val_loss: 0.5032 - val_acc: 0.9500\n",
            "Epoch 56/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.5296 - acc: 0.7944 - val_loss: 0.5013 - val_acc: 0.9500\n",
            "Epoch 57/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.5277 - acc: 0.7944 - val_loss: 0.4986 - val_acc: 0.9000\n",
            "Epoch 58/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.5262 - acc: 0.7889 - val_loss: 0.4976 - val_acc: 0.9500\n",
            "Epoch 59/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.5247 - acc: 0.7944 - val_loss: 0.4949 - val_acc: 0.9500\n",
            "Epoch 60/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.5232 - acc: 0.8000 - val_loss: 0.4935 - val_acc: 0.9500\n",
            "Epoch 61/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.5216 - acc: 0.8000 - val_loss: 0.4921 - val_acc: 0.9500\n",
            "Epoch 62/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.5204 - acc: 0.7944 - val_loss: 0.4904 - val_acc: 0.9500\n",
            "Epoch 63/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.5193 - acc: 0.8000 - val_loss: 0.4896 - val_acc: 0.9000\n",
            "Epoch 64/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.5181 - acc: 0.7889 - val_loss: 0.4879 - val_acc: 0.9000\n",
            "Epoch 65/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.5173 - acc: 0.7944 - val_loss: 0.4866 - val_acc: 0.8500\n",
            "Epoch 66/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.5161 - acc: 0.7778 - val_loss: 0.4862 - val_acc: 0.9000\n",
            "Epoch 67/800\n",
            "180/180 [==============================] - 0s 475us/step - loss: 0.5147 - acc: 0.7944 - val_loss: 0.4857 - val_acc: 0.8000\n",
            "Epoch 68/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.5142 - acc: 0.7722 - val_loss: 0.4836 - val_acc: 0.8500\n",
            "Epoch 69/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.5134 - acc: 0.7889 - val_loss: 0.4833 - val_acc: 0.8500\n",
            "Epoch 70/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.5120 - acc: 0.7833 - val_loss: 0.4820 - val_acc: 0.8500\n",
            "Epoch 71/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.5107 - acc: 0.8056 - val_loss: 0.4831 - val_acc: 0.8000\n",
            "Epoch 72/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.5102 - acc: 0.8056 - val_loss: 0.4805 - val_acc: 0.8000\n",
            "Epoch 73/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.5089 - acc: 0.8056 - val_loss: 0.4802 - val_acc: 0.8000\n",
            "Epoch 74/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.5075 - acc: 0.8056 - val_loss: 0.4795 - val_acc: 0.8000\n",
            "Epoch 75/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.5066 - acc: 0.8167 - val_loss: 0.4788 - val_acc: 0.8500\n",
            "Epoch 76/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.5058 - acc: 0.7889 - val_loss: 0.4787 - val_acc: 0.8000\n",
            "Epoch 77/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.5047 - acc: 0.7944 - val_loss: 0.4784 - val_acc: 0.8000\n",
            "Epoch 78/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.5035 - acc: 0.8111 - val_loss: 0.4775 - val_acc: 0.8500\n",
            "Epoch 79/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.5031 - acc: 0.8000 - val_loss: 0.4763 - val_acc: 0.8000\n",
            "Epoch 80/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.5016 - acc: 0.8056 - val_loss: 0.4760 - val_acc: 0.8500\n",
            "Epoch 81/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.5007 - acc: 0.8167 - val_loss: 0.4756 - val_acc: 0.8000\n",
            "Epoch 82/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.5000 - acc: 0.8167 - val_loss: 0.4754 - val_acc: 0.8500\n",
            "Epoch 83/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.4990 - acc: 0.8167 - val_loss: 0.4749 - val_acc: 0.8000\n",
            "Epoch 84/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.4984 - acc: 0.8222 - val_loss: 0.4742 - val_acc: 0.8000\n",
            "Epoch 85/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.4980 - acc: 0.8167 - val_loss: 0.4742 - val_acc: 0.8000\n",
            "Epoch 86/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4970 - acc: 0.8111 - val_loss: 0.4739 - val_acc: 0.8500\n",
            "Epoch 87/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4963 - acc: 0.8056 - val_loss: 0.4734 - val_acc: 0.8500\n",
            "Epoch 88/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4961 - acc: 0.8167 - val_loss: 0.4731 - val_acc: 0.8500\n",
            "Epoch 89/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4953 - acc: 0.8222 - val_loss: 0.4728 - val_acc: 0.8000\n",
            "Epoch 90/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4949 - acc: 0.8222 - val_loss: 0.4727 - val_acc: 0.8500\n",
            "Epoch 91/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4941 - acc: 0.8056 - val_loss: 0.4726 - val_acc: 0.8000\n",
            "Epoch 92/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4936 - acc: 0.8111 - val_loss: 0.4720 - val_acc: 0.8500\n",
            "Epoch 93/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4931 - acc: 0.8278 - val_loss: 0.4711 - val_acc: 0.8000\n",
            "Epoch 94/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4926 - acc: 0.8278 - val_loss: 0.4709 - val_acc: 0.8500\n",
            "Epoch 95/800\n",
            "180/180 [==============================] - 0s 399us/step - loss: 0.4923 - acc: 0.8111 - val_loss: 0.4707 - val_acc: 0.8000\n",
            "Epoch 96/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4916 - acc: 0.8167 - val_loss: 0.4703 - val_acc: 0.8500\n",
            "Epoch 97/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4914 - acc: 0.8167 - val_loss: 0.4696 - val_acc: 0.8500\n",
            "Epoch 98/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4913 - acc: 0.8389 - val_loss: 0.4696 - val_acc: 0.8500\n",
            "Epoch 99/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4906 - acc: 0.8333 - val_loss: 0.4695 - val_acc: 0.8500\n",
            "Epoch 100/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4905 - acc: 0.8111 - val_loss: 0.4687 - val_acc: 0.8500\n",
            "Epoch 101/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4899 - acc: 0.8111 - val_loss: 0.4688 - val_acc: 0.8000\n",
            "Epoch 102/800\n",
            "180/180 [==============================] - 0s 497us/step - loss: 0.4895 - acc: 0.8222 - val_loss: 0.4685 - val_acc: 0.8500\n",
            "Epoch 103/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4893 - acc: 0.8333 - val_loss: 0.4686 - val_acc: 0.8000\n",
            "Epoch 104/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4889 - acc: 0.8278 - val_loss: 0.4685 - val_acc: 0.8500\n",
            "Epoch 105/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4887 - acc: 0.8167 - val_loss: 0.4679 - val_acc: 0.8500\n",
            "Epoch 106/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4883 - acc: 0.8111 - val_loss: 0.4682 - val_acc: 0.8500\n",
            "Epoch 107/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4881 - acc: 0.8167 - val_loss: 0.4690 - val_acc: 0.8500\n",
            "Epoch 108/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.4879 - acc: 0.8444 - val_loss: 0.4680 - val_acc: 0.8500\n",
            "Epoch 109/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4876 - acc: 0.8167 - val_loss: 0.4677 - val_acc: 0.8000\n",
            "Epoch 110/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4872 - acc: 0.8444 - val_loss: 0.4679 - val_acc: 0.8000\n",
            "Epoch 111/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4871 - acc: 0.8222 - val_loss: 0.4681 - val_acc: 0.8500\n",
            "Epoch 112/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4869 - acc: 0.8389 - val_loss: 0.4674 - val_acc: 0.9000\n",
            "Epoch 113/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4866 - acc: 0.8500 - val_loss: 0.4676 - val_acc: 0.9500\n",
            "Epoch 114/800\n",
            "180/180 [==============================] - 0s 401us/step - loss: 0.4863 - acc: 0.8389 - val_loss: 0.4670 - val_acc: 0.9500\n",
            "Epoch 115/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4862 - acc: 0.8778 - val_loss: 0.4673 - val_acc: 1.0000\n",
            "Epoch 116/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4859 - acc: 0.8722 - val_loss: 0.4674 - val_acc: 1.0000\n",
            "Epoch 117/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4859 - acc: 0.9056 - val_loss: 0.4668 - val_acc: 0.9500\n",
            "Epoch 118/800\n",
            "180/180 [==============================] - 0s 393us/step - loss: 0.4856 - acc: 0.8944 - val_loss: 0.4670 - val_acc: 1.0000\n",
            "Epoch 119/800\n",
            "180/180 [==============================] - 0s 472us/step - loss: 0.4854 - acc: 0.9000 - val_loss: 0.4665 - val_acc: 1.0000\n",
            "Epoch 120/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4852 - acc: 0.9222 - val_loss: 0.4666 - val_acc: 1.0000\n",
            "Epoch 121/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4850 - acc: 0.9000 - val_loss: 0.4665 - val_acc: 1.0000\n",
            "Epoch 122/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4849 - acc: 0.9222 - val_loss: 0.4666 - val_acc: 1.0000\n",
            "Epoch 123/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.4850 - acc: 0.9278 - val_loss: 0.4665 - val_acc: 1.0000\n",
            "Epoch 124/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.4846 - acc: 0.9389 - val_loss: 0.4664 - val_acc: 1.0000\n",
            "Epoch 125/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4846 - acc: 0.9222 - val_loss: 0.4660 - val_acc: 1.0000\n",
            "Epoch 126/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.4842 - acc: 0.9389 - val_loss: 0.4663 - val_acc: 1.0000\n",
            "Epoch 127/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.4840 - acc: 0.9056 - val_loss: 0.4665 - val_acc: 1.0000\n",
            "Epoch 128/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.4840 - acc: 0.9389 - val_loss: 0.4665 - val_acc: 1.0000\n",
            "Epoch 129/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4838 - acc: 0.9444 - val_loss: 0.4667 - val_acc: 1.0000\n",
            "Epoch 130/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.4841 - acc: 0.9389 - val_loss: 0.4657 - val_acc: 1.0000\n",
            "Epoch 131/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4838 - acc: 0.9278 - val_loss: 0.4664 - val_acc: 1.0000\n",
            "Epoch 132/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4834 - acc: 0.9222 - val_loss: 0.4658 - val_acc: 1.0000\n",
            "Epoch 133/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4833 - acc: 0.9389 - val_loss: 0.4661 - val_acc: 1.0000\n",
            "Epoch 134/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4832 - acc: 0.9444 - val_loss: 0.4656 - val_acc: 1.0000\n",
            "Epoch 135/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4830 - acc: 0.8667 - val_loss: 0.4657 - val_acc: 1.0000\n",
            "Epoch 136/800\n",
            "180/180 [==============================] - 0s 431us/step - loss: 0.4832 - acc: 0.8778 - val_loss: 0.4658 - val_acc: 1.0000\n",
            "Epoch 137/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.4827 - acc: 0.9167 - val_loss: 0.4659 - val_acc: 0.9500\n",
            "Epoch 138/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.4829 - acc: 0.9167 - val_loss: 0.4651 - val_acc: 1.0000\n",
            "Epoch 139/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4824 - acc: 0.9111 - val_loss: 0.4668 - val_acc: 1.0000\n",
            "Epoch 140/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4825 - acc: 0.9222 - val_loss: 0.4654 - val_acc: 1.0000\n",
            "Epoch 141/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4830 - acc: 0.9056 - val_loss: 0.4657 - val_acc: 1.0000\n",
            "Epoch 142/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4821 - acc: 0.9056 - val_loss: 0.4649 - val_acc: 1.0000\n",
            "Epoch 143/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4827 - acc: 0.9222 - val_loss: 0.4656 - val_acc: 1.0000\n",
            "Epoch 144/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4821 - acc: 0.9278 - val_loss: 0.4649 - val_acc: 1.0000\n",
            "Epoch 145/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.4823 - acc: 0.9222 - val_loss: 0.4660 - val_acc: 1.0000\n",
            "Epoch 146/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4818 - acc: 0.9333 - val_loss: 0.4650 - val_acc: 1.0000\n",
            "Epoch 147/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4816 - acc: 0.9167 - val_loss: 0.4648 - val_acc: 1.0000\n",
            "Epoch 148/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4819 - acc: 0.9278 - val_loss: 0.4653 - val_acc: 1.0000\n",
            "Epoch 149/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4817 - acc: 0.9222 - val_loss: 0.4644 - val_acc: 1.0000\n",
            "Epoch 150/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4815 - acc: 0.9333 - val_loss: 0.4643 - val_acc: 1.0000\n",
            "Epoch 151/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4812 - acc: 0.9222 - val_loss: 0.4641 - val_acc: 1.0000\n",
            "Epoch 152/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4813 - acc: 0.9222 - val_loss: 0.4648 - val_acc: 1.0000\n",
            "Epoch 153/800\n",
            "180/180 [==============================] - 0s 398us/step - loss: 0.4813 - acc: 0.9444 - val_loss: 0.4647 - val_acc: 1.0000\n",
            "Epoch 154/800\n",
            "180/180 [==============================] - 0s 399us/step - loss: 0.4812 - acc: 0.9278 - val_loss: 0.4642 - val_acc: 1.0000\n",
            "Epoch 155/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4811 - acc: 0.9444 - val_loss: 0.4647 - val_acc: 1.0000\n",
            "Epoch 156/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4809 - acc: 0.9278 - val_loss: 0.4651 - val_acc: 1.0000\n",
            "Epoch 157/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4817 - acc: 0.9167 - val_loss: 0.4644 - val_acc: 1.0000\n",
            "Epoch 158/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4807 - acc: 0.9389 - val_loss: 0.4641 - val_acc: 1.0000\n",
            "Epoch 159/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4806 - acc: 0.9444 - val_loss: 0.4637 - val_acc: 1.0000\n",
            "Epoch 160/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4806 - acc: 0.9056 - val_loss: 0.4636 - val_acc: 1.0000\n",
            "Epoch 161/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4803 - acc: 0.9333 - val_loss: 0.4639 - val_acc: 1.0000\n",
            "Epoch 162/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4804 - acc: 0.9111 - val_loss: 0.4637 - val_acc: 0.9500\n",
            "Epoch 163/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4807 - acc: 0.9111 - val_loss: 0.4641 - val_acc: 1.0000\n",
            "Epoch 164/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4804 - acc: 0.8889 - val_loss: 0.4640 - val_acc: 1.0000\n",
            "Epoch 165/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4800 - acc: 0.9111 - val_loss: 0.4652 - val_acc: 1.0000\n",
            "Epoch 166/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4814 - acc: 0.9000 - val_loss: 0.4635 - val_acc: 1.0000\n",
            "Epoch 167/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4803 - acc: 0.9333 - val_loss: 0.4636 - val_acc: 1.0000\n",
            "Epoch 168/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4801 - acc: 0.9111 - val_loss: 0.4641 - val_acc: 1.0000\n",
            "Epoch 169/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4799 - acc: 0.9333 - val_loss: 0.4638 - val_acc: 1.0000\n",
            "Epoch 170/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.4797 - acc: 0.9167 - val_loss: 0.4638 - val_acc: 1.0000\n",
            "Epoch 171/800\n",
            "180/180 [==============================] - 0s 412us/step - loss: 0.4798 - acc: 0.9278 - val_loss: 0.4630 - val_acc: 1.0000\n",
            "Epoch 172/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4798 - acc: 0.9167 - val_loss: 0.4636 - val_acc: 1.0000\n",
            "Epoch 173/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4795 - acc: 0.9333 - val_loss: 0.4639 - val_acc: 1.0000\n",
            "Epoch 174/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.4795 - acc: 0.9389 - val_loss: 0.4631 - val_acc: 1.0000\n",
            "Epoch 175/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4796 - acc: 0.9222 - val_loss: 0.4631 - val_acc: 1.0000\n",
            "Epoch 176/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4795 - acc: 0.9333 - val_loss: 0.4634 - val_acc: 1.0000\n",
            "Epoch 177/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4792 - acc: 0.9111 - val_loss: 0.4634 - val_acc: 1.0000\n",
            "Epoch 178/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4792 - acc: 0.9222 - val_loss: 0.4633 - val_acc: 1.0000\n",
            "Epoch 179/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4792 - acc: 0.9278 - val_loss: 0.4629 - val_acc: 1.0000\n",
            "Epoch 180/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4790 - acc: 0.9333 - val_loss: 0.4634 - val_acc: 1.0000\n",
            "Epoch 181/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4791 - acc: 0.9278 - val_loss: 0.4643 - val_acc: 1.0000\n",
            "Epoch 182/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4792 - acc: 0.9333 - val_loss: 0.4670 - val_acc: 1.0000\n",
            "Epoch 183/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.4797 - acc: 0.9111 - val_loss: 0.4637 - val_acc: 1.0000\n",
            "Epoch 184/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4787 - acc: 0.9389 - val_loss: 0.4631 - val_acc: 1.0000\n",
            "Epoch 185/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.4785 - acc: 0.9389 - val_loss: 0.4640 - val_acc: 1.0000\n",
            "Epoch 186/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.4786 - acc: 0.9556 - val_loss: 0.4638 - val_acc: 1.0000\n",
            "Epoch 187/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4787 - acc: 0.9056 - val_loss: 0.4632 - val_acc: 1.0000\n",
            "Epoch 188/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.4786 - acc: 0.9222 - val_loss: 0.4647 - val_acc: 1.0000\n",
            "Epoch 189/800\n",
            "180/180 [==============================] - 0s 443us/step - loss: 0.4790 - acc: 0.9444 - val_loss: 0.4637 - val_acc: 1.0000\n",
            "Epoch 190/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4783 - acc: 0.9167 - val_loss: 0.4626 - val_acc: 1.0000\n",
            "Epoch 191/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4782 - acc: 0.9333 - val_loss: 0.4631 - val_acc: 1.0000\n",
            "Epoch 192/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4785 - acc: 0.9444 - val_loss: 0.4628 - val_acc: 1.0000\n",
            "Epoch 193/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4781 - acc: 0.9333 - val_loss: 0.4633 - val_acc: 1.0000\n",
            "Epoch 194/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4782 - acc: 0.9167 - val_loss: 0.4631 - val_acc: 1.0000\n",
            "Epoch 195/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4779 - acc: 0.9389 - val_loss: 0.4642 - val_acc: 1.0000\n",
            "Epoch 196/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.4798 - acc: 0.9222 - val_loss: 0.4625 - val_acc: 1.0000\n",
            "Epoch 197/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.4779 - acc: 0.9444 - val_loss: 0.4624 - val_acc: 1.0000\n",
            "Epoch 198/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4780 - acc: 0.9333 - val_loss: 0.4627 - val_acc: 1.0000\n",
            "Epoch 199/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4782 - acc: 0.9389 - val_loss: 0.4622 - val_acc: 1.0000\n",
            "Epoch 200/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4775 - acc: 0.9333 - val_loss: 0.4629 - val_acc: 1.0000\n",
            "Epoch 201/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4775 - acc: 0.9167 - val_loss: 0.4618 - val_acc: 1.0000\n",
            "Epoch 202/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4773 - acc: 0.9167 - val_loss: 0.4617 - val_acc: 1.0000\n",
            "Epoch 203/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4772 - acc: 0.9333 - val_loss: 0.4621 - val_acc: 1.0000\n",
            "Epoch 204/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4773 - acc: 0.9222 - val_loss: 0.4620 - val_acc: 1.0000\n",
            "Epoch 205/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4778 - acc: 0.9222 - val_loss: 0.4630 - val_acc: 1.0000\n",
            "Epoch 206/800\n",
            "180/180 [==============================] - 0s 393us/step - loss: 0.4772 - acc: 0.9389 - val_loss: 0.4616 - val_acc: 1.0000\n",
            "Epoch 207/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4773 - acc: 0.9500 - val_loss: 0.4621 - val_acc: 0.9500\n",
            "Epoch 208/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4770 - acc: 0.9222 - val_loss: 0.4620 - val_acc: 1.0000\n",
            "Epoch 209/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4770 - acc: 0.9167 - val_loss: 0.4617 - val_acc: 1.0000\n",
            "Epoch 210/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4768 - acc: 0.9222 - val_loss: 0.4610 - val_acc: 1.0000\n",
            "Epoch 211/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4774 - acc: 0.9278 - val_loss: 0.4616 - val_acc: 1.0000\n",
            "Epoch 212/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4765 - acc: 0.9278 - val_loss: 0.4612 - val_acc: 1.0000\n",
            "Epoch 213/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4767 - acc: 0.9222 - val_loss: 0.4615 - val_acc: 1.0000\n",
            "Epoch 214/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.4769 - acc: 0.9333 - val_loss: 0.4611 - val_acc: 1.0000\n",
            "Epoch 215/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4767 - acc: 0.9111 - val_loss: 0.4608 - val_acc: 1.0000\n",
            "Epoch 216/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4767 - acc: 0.9056 - val_loss: 0.4611 - val_acc: 0.9500\n",
            "Epoch 217/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4763 - acc: 0.9389 - val_loss: 0.4612 - val_acc: 1.0000\n",
            "Epoch 218/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4770 - acc: 0.9333 - val_loss: 0.4606 - val_acc: 1.0000\n",
            "Epoch 219/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4760 - acc: 0.9333 - val_loss: 0.4605 - val_acc: 1.0000\n",
            "Epoch 220/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.4760 - acc: 0.9389 - val_loss: 0.4608 - val_acc: 1.0000\n",
            "Epoch 221/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4761 - acc: 0.9222 - val_loss: 0.4611 - val_acc: 1.0000\n",
            "Epoch 222/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.4759 - acc: 0.9278 - val_loss: 0.4601 - val_acc: 1.0000\n",
            "Epoch 223/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4761 - acc: 0.9056 - val_loss: 0.4610 - val_acc: 1.0000\n",
            "Epoch 224/800\n",
            "180/180 [==============================] - 0s 456us/step - loss: 0.4760 - acc: 0.9389 - val_loss: 0.4602 - val_acc: 1.0000\n",
            "Epoch 225/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4756 - acc: 0.9111 - val_loss: 0.4602 - val_acc: 1.0000\n",
            "Epoch 226/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4758 - acc: 0.9278 - val_loss: 0.4598 - val_acc: 1.0000\n",
            "Epoch 227/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4753 - acc: 0.9167 - val_loss: 0.4598 - val_acc: 1.0000\n",
            "Epoch 228/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4756 - acc: 0.9333 - val_loss: 0.4605 - val_acc: 1.0000\n",
            "Epoch 229/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4764 - acc: 0.9111 - val_loss: 0.4597 - val_acc: 1.0000\n",
            "Epoch 230/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4752 - acc: 0.9500 - val_loss: 0.4600 - val_acc: 1.0000\n",
            "Epoch 231/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4781 - acc: 0.9167 - val_loss: 0.4609 - val_acc: 1.0000\n",
            "Epoch 232/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4763 - acc: 0.9222 - val_loss: 0.4607 - val_acc: 0.9500\n",
            "Epoch 233/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4754 - acc: 0.9222 - val_loss: 0.4590 - val_acc: 1.0000\n",
            "Epoch 234/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4749 - acc: 0.9389 - val_loss: 0.4592 - val_acc: 1.0000\n",
            "Epoch 235/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4749 - acc: 0.9222 - val_loss: 0.4614 - val_acc: 0.9500\n",
            "Epoch 236/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4754 - acc: 0.9278 - val_loss: 0.4590 - val_acc: 1.0000\n",
            "Epoch 237/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4743 - acc: 0.9333 - val_loss: 0.4589 - val_acc: 1.0000\n",
            "Epoch 238/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.4748 - acc: 0.9500 - val_loss: 0.4586 - val_acc: 1.0000\n",
            "Epoch 239/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4742 - acc: 0.9444 - val_loss: 0.4587 - val_acc: 1.0000\n",
            "Epoch 240/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4741 - acc: 0.9111 - val_loss: 0.4581 - val_acc: 1.0000\n",
            "Epoch 241/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.4740 - acc: 0.9333 - val_loss: 0.4581 - val_acc: 1.0000\n",
            "Epoch 242/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4740 - acc: 0.9444 - val_loss: 0.4581 - val_acc: 1.0000\n",
            "Epoch 243/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4736 - acc: 0.9222 - val_loss: 0.4583 - val_acc: 0.9500\n",
            "Epoch 244/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4737 - acc: 0.9278 - val_loss: 0.4582 - val_acc: 1.0000\n",
            "Epoch 245/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4743 - acc: 0.9333 - val_loss: 0.4591 - val_acc: 1.0000\n",
            "Epoch 246/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4742 - acc: 0.9167 - val_loss: 0.4580 - val_acc: 0.9500\n",
            "Epoch 247/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4734 - acc: 0.9222 - val_loss: 0.4574 - val_acc: 1.0000\n",
            "Epoch 248/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4735 - acc: 0.9222 - val_loss: 0.4579 - val_acc: 1.0000\n",
            "Epoch 249/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4732 - acc: 0.9444 - val_loss: 0.4573 - val_acc: 1.0000\n",
            "Epoch 250/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4736 - acc: 0.9111 - val_loss: 0.4576 - val_acc: 1.0000\n",
            "Epoch 251/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4732 - acc: 0.9333 - val_loss: 0.4570 - val_acc: 1.0000\n",
            "Epoch 252/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.4728 - acc: 0.9278 - val_loss: 0.4576 - val_acc: 1.0000\n",
            "Epoch 253/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4729 - acc: 0.9278 - val_loss: 0.4574 - val_acc: 1.0000\n",
            "Epoch 254/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4735 - acc: 0.8667 - val_loss: 0.4567 - val_acc: 0.9500\n",
            "Epoch 255/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4727 - acc: 0.9222 - val_loss: 0.4566 - val_acc: 1.0000\n",
            "Epoch 256/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4721 - acc: 0.9056 - val_loss: 0.4564 - val_acc: 1.0000\n",
            "Epoch 257/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4723 - acc: 0.9222 - val_loss: 0.4566 - val_acc: 1.0000\n",
            "Epoch 258/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.4720 - acc: 0.9333 - val_loss: 0.4567 - val_acc: 1.0000\n",
            "Epoch 259/800\n",
            "180/180 [==============================] - 0s 501us/step - loss: 0.4718 - acc: 0.9278 - val_loss: 0.4572 - val_acc: 1.0000\n",
            "Epoch 260/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.4730 - acc: 0.9222 - val_loss: 0.4565 - val_acc: 1.0000\n",
            "Epoch 261/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4723 - acc: 0.9167 - val_loss: 0.4564 - val_acc: 1.0000\n",
            "Epoch 262/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.4728 - acc: 0.9167 - val_loss: 0.4567 - val_acc: 1.0000\n",
            "Epoch 263/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4717 - acc: 0.8944 - val_loss: 0.4573 - val_acc: 1.0000\n",
            "Epoch 264/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4715 - acc: 0.8722 - val_loss: 0.4552 - val_acc: 1.0000\n",
            "Epoch 265/800\n",
            "180/180 [==============================] - 0s 398us/step - loss: 0.4714 - acc: 0.9222 - val_loss: 0.4558 - val_acc: 1.0000\n",
            "Epoch 266/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4714 - acc: 0.9111 - val_loss: 0.4548 - val_acc: 0.9500\n",
            "Epoch 267/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4712 - acc: 0.9278 - val_loss: 0.4553 - val_acc: 1.0000\n",
            "Epoch 268/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4708 - acc: 0.9389 - val_loss: 0.4556 - val_acc: 1.0000\n",
            "Epoch 269/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4706 - acc: 0.9111 - val_loss: 0.4555 - val_acc: 0.9500\n",
            "Epoch 270/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4717 - acc: 0.8944 - val_loss: 0.4558 - val_acc: 0.9500\n",
            "Epoch 271/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.4726 - acc: 0.9056 - val_loss: 0.4552 - val_acc: 0.9500\n",
            "Epoch 272/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4702 - acc: 0.9278 - val_loss: 0.4540 - val_acc: 1.0000\n",
            "Epoch 273/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4698 - acc: 0.9389 - val_loss: 0.4545 - val_acc: 0.9500\n",
            "Epoch 274/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4701 - acc: 0.9278 - val_loss: 0.4542 - val_acc: 0.9500\n",
            "Epoch 275/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4706 - acc: 0.8667 - val_loss: 0.4555 - val_acc: 1.0000\n",
            "Epoch 276/800\n",
            "180/180 [==============================] - 0s 484us/step - loss: 0.4718 - acc: 0.8722 - val_loss: 0.4528 - val_acc: 1.0000\n",
            "Epoch 277/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4702 - acc: 0.9056 - val_loss: 0.4539 - val_acc: 0.9500\n",
            "Epoch 278/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4693 - acc: 0.9111 - val_loss: 0.4528 - val_acc: 0.9500\n",
            "Epoch 279/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4689 - acc: 0.9111 - val_loss: 0.4523 - val_acc: 1.0000\n",
            "Epoch 280/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.4689 - acc: 0.9111 - val_loss: 0.4524 - val_acc: 1.0000\n",
            "Epoch 281/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4684 - acc: 0.9167 - val_loss: 0.4522 - val_acc: 1.0000\n",
            "Epoch 282/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.4683 - acc: 0.9056 - val_loss: 0.4528 - val_acc: 0.9500\n",
            "Epoch 283/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4692 - acc: 0.9444 - val_loss: 0.4531 - val_acc: 1.0000\n",
            "Epoch 284/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.4681 - acc: 0.9333 - val_loss: 0.4531 - val_acc: 1.0000\n",
            "Epoch 285/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4680 - acc: 0.9222 - val_loss: 0.4516 - val_acc: 1.0000\n",
            "Epoch 286/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.4677 - acc: 0.9167 - val_loss: 0.4521 - val_acc: 0.9500\n",
            "Epoch 287/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4679 - acc: 0.9111 - val_loss: 0.4510 - val_acc: 1.0000\n",
            "Epoch 288/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4667 - acc: 0.9278 - val_loss: 0.4504 - val_acc: 0.9500\n",
            "Epoch 289/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4667 - acc: 0.9222 - val_loss: 0.4519 - val_acc: 0.9500\n",
            "Epoch 290/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4672 - acc: 0.9000 - val_loss: 0.4506 - val_acc: 0.9500\n",
            "Epoch 291/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4669 - acc: 0.9333 - val_loss: 0.4498 - val_acc: 0.9500\n",
            "Epoch 292/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4661 - acc: 0.9389 - val_loss: 0.4509 - val_acc: 0.9500\n",
            "Epoch 293/800\n",
            "180/180 [==============================] - 0s 495us/step - loss: 0.4664 - acc: 0.9000 - val_loss: 0.4496 - val_acc: 1.0000\n",
            "Epoch 294/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4660 - acc: 0.9333 - val_loss: 0.4494 - val_acc: 1.0000\n",
            "Epoch 295/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4655 - acc: 0.9333 - val_loss: 0.4489 - val_acc: 0.9500\n",
            "Epoch 296/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4654 - acc: 0.9167 - val_loss: 0.4495 - val_acc: 0.9500\n",
            "Epoch 297/800\n",
            "180/180 [==============================] - 0s 395us/step - loss: 0.4658 - acc: 0.9000 - val_loss: 0.4482 - val_acc: 1.0000\n",
            "Epoch 298/800\n",
            "180/180 [==============================] - 0s 408us/step - loss: 0.4644 - acc: 0.9278 - val_loss: 0.4476 - val_acc: 1.0000\n",
            "Epoch 299/800\n",
            "180/180 [==============================] - 0s 394us/step - loss: 0.4656 - acc: 0.9056 - val_loss: 0.4482 - val_acc: 0.9500\n",
            "Epoch 300/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4646 - acc: 0.9111 - val_loss: 0.4475 - val_acc: 1.0000\n",
            "Epoch 301/800\n",
            "180/180 [==============================] - 0s 400us/step - loss: 0.4643 - acc: 0.9056 - val_loss: 0.4471 - val_acc: 0.9000\n",
            "Epoch 302/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.4638 - acc: 0.9389 - val_loss: 0.4485 - val_acc: 1.0000\n",
            "Epoch 303/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4636 - acc: 0.8889 - val_loss: 0.4471 - val_acc: 0.9500\n",
            "Epoch 304/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.4632 - acc: 0.9056 - val_loss: 0.4458 - val_acc: 1.0000\n",
            "Epoch 305/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4622 - acc: 0.9222 - val_loss: 0.4451 - val_acc: 1.0000\n",
            "Epoch 306/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4622 - acc: 0.9056 - val_loss: 0.4477 - val_acc: 0.9500\n",
            "Epoch 307/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4626 - acc: 0.9000 - val_loss: 0.4461 - val_acc: 0.9500\n",
            "Epoch 308/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4615 - acc: 0.9444 - val_loss: 0.4450 - val_acc: 0.9500\n",
            "Epoch 309/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4625 - acc: 0.9167 - val_loss: 0.4466 - val_acc: 1.0000\n",
            "Epoch 310/800\n",
            "180/180 [==============================] - 0s 495us/step - loss: 0.4719 - acc: 0.8444 - val_loss: 0.4438 - val_acc: 0.9500\n",
            "Epoch 311/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4603 - acc: 0.9056 - val_loss: 0.4437 - val_acc: 1.0000\n",
            "Epoch 312/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4613 - acc: 0.9111 - val_loss: 0.4439 - val_acc: 0.9500\n",
            "Epoch 313/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4605 - acc: 0.8889 - val_loss: 0.4435 - val_acc: 0.9500\n",
            "Epoch 314/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4596 - acc: 0.9278 - val_loss: 0.4417 - val_acc: 1.0000\n",
            "Epoch 315/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4589 - acc: 0.9056 - val_loss: 0.4424 - val_acc: 0.9500\n",
            "Epoch 316/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4592 - acc: 0.9056 - val_loss: 0.4415 - val_acc: 0.9500\n",
            "Epoch 317/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4580 - acc: 0.9000 - val_loss: 0.4407 - val_acc: 0.9500\n",
            "Epoch 318/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4598 - acc: 0.9000 - val_loss: 0.4405 - val_acc: 1.0000\n",
            "Epoch 319/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4587 - acc: 0.9056 - val_loss: 0.4405 - val_acc: 0.9000\n",
            "Epoch 320/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4570 - acc: 0.9056 - val_loss: 0.4423 - val_acc: 1.0000\n",
            "Epoch 321/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4570 - acc: 0.9056 - val_loss: 0.4413 - val_acc: 0.9500\n",
            "Epoch 322/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.4576 - acc: 0.8944 - val_loss: 0.4391 - val_acc: 0.9500\n",
            "Epoch 323/800\n",
            "180/180 [==============================] - 0s 394us/step - loss: 0.4569 - acc: 0.8944 - val_loss: 0.4395 - val_acc: 0.8500\n",
            "Epoch 324/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4555 - acc: 0.9278 - val_loss: 0.4378 - val_acc: 0.9500\n",
            "Epoch 325/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4571 - acc: 0.8833 - val_loss: 0.4384 - val_acc: 1.0000\n",
            "Epoch 326/800\n",
            "180/180 [==============================] - 0s 395us/step - loss: 0.4555 - acc: 0.9056 - val_loss: 0.4371 - val_acc: 1.0000\n",
            "Epoch 327/800\n",
            "180/180 [==============================] - 0s 479us/step - loss: 0.4553 - acc: 0.8889 - val_loss: 0.4386 - val_acc: 0.9500\n",
            "Epoch 328/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4570 - acc: 0.8833 - val_loss: 0.4356 - val_acc: 0.9500\n",
            "Epoch 329/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4533 - acc: 0.9167 - val_loss: 0.4345 - val_acc: 1.0000\n",
            "Epoch 330/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4533 - acc: 0.9167 - val_loss: 0.4351 - val_acc: 0.9500\n",
            "Epoch 331/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4521 - acc: 0.9000 - val_loss: 0.4359 - val_acc: 0.9500\n",
            "Epoch 332/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4520 - acc: 0.8889 - val_loss: 0.4342 - val_acc: 0.9500\n",
            "Epoch 333/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4511 - acc: 0.9167 - val_loss: 0.4329 - val_acc: 0.9500\n",
            "Epoch 334/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4502 - acc: 0.9056 - val_loss: 0.4333 - val_acc: 0.9000\n",
            "Epoch 335/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4541 - acc: 0.8889 - val_loss: 0.4355 - val_acc: 0.9500\n",
            "Epoch 336/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4512 - acc: 0.8722 - val_loss: 0.4328 - val_acc: 0.9500\n",
            "Epoch 337/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4490 - acc: 0.8889 - val_loss: 0.4303 - val_acc: 1.0000\n",
            "Epoch 338/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4484 - acc: 0.8889 - val_loss: 0.4309 - val_acc: 1.0000\n",
            "Epoch 339/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4496 - acc: 0.9056 - val_loss: 0.4310 - val_acc: 1.0000\n",
            "Epoch 340/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.4487 - acc: 0.9222 - val_loss: 0.4297 - val_acc: 0.9000\n",
            "Epoch 341/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4481 - acc: 0.9056 - val_loss: 0.4286 - val_acc: 0.9500\n",
            "Epoch 342/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4473 - acc: 0.8833 - val_loss: 0.4282 - val_acc: 1.0000\n",
            "Epoch 343/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4463 - acc: 0.9000 - val_loss: 0.4272 - val_acc: 0.9500\n",
            "Epoch 344/800\n",
            "180/180 [==============================] - 0s 417us/step - loss: 0.4468 - acc: 0.9000 - val_loss: 0.4276 - val_acc: 0.9500\n",
            "Epoch 345/800\n",
            "180/180 [==============================] - 0s 399us/step - loss: 0.4452 - acc: 0.8833 - val_loss: 0.4273 - val_acc: 0.9500\n",
            "Epoch 346/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4510 - acc: 0.8667 - val_loss: 0.4265 - val_acc: 1.0000\n",
            "Epoch 347/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4478 - acc: 0.9000 - val_loss: 0.4271 - val_acc: 0.9500\n",
            "Epoch 348/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4457 - acc: 0.8667 - val_loss: 0.4270 - val_acc: 0.9000\n",
            "Epoch 349/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4445 - acc: 0.9111 - val_loss: 0.4252 - val_acc: 0.9500\n",
            "Epoch 350/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4429 - acc: 0.9056 - val_loss: 0.4245 - val_acc: 1.0000\n",
            "Epoch 351/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4429 - acc: 0.8944 - val_loss: 0.4249 - val_acc: 0.9500\n",
            "Epoch 352/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4420 - acc: 0.8944 - val_loss: 0.4245 - val_acc: 0.9500\n",
            "Epoch 353/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.4418 - acc: 0.9000 - val_loss: 0.4230 - val_acc: 0.9500\n",
            "Epoch 354/800\n",
            "180/180 [==============================] - 0s 403us/step - loss: 0.4417 - acc: 0.8778 - val_loss: 0.4220 - val_acc: 0.9500\n",
            "Epoch 355/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4406 - acc: 0.8778 - val_loss: 0.4215 - val_acc: 1.0000\n",
            "Epoch 356/800\n",
            "180/180 [==============================] - 0s 392us/step - loss: 0.4400 - acc: 0.9056 - val_loss: 0.4214 - val_acc: 0.9500\n",
            "Epoch 357/800\n",
            "180/180 [==============================] - 0s 396us/step - loss: 0.4405 - acc: 0.8889 - val_loss: 0.4215 - val_acc: 1.0000\n",
            "Epoch 358/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4403 - acc: 0.8889 - val_loss: 0.4216 - val_acc: 0.9000\n",
            "Epoch 359/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4398 - acc: 0.8722 - val_loss: 0.4207 - val_acc: 0.9500\n",
            "Epoch 360/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4390 - acc: 0.8889 - val_loss: 0.4202 - val_acc: 0.9500\n",
            "Epoch 361/800\n",
            "180/180 [==============================] - 0s 499us/step - loss: 0.4383 - acc: 0.8833 - val_loss: 0.4185 - val_acc: 0.9500\n",
            "Epoch 362/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4384 - acc: 0.9167 - val_loss: 0.4188 - val_acc: 0.9000\n",
            "Epoch 363/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4375 - acc: 0.9056 - val_loss: 0.4173 - val_acc: 1.0000\n",
            "Epoch 364/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.4368 - acc: 0.8833 - val_loss: 0.4166 - val_acc: 1.0000\n",
            "Epoch 365/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4364 - acc: 0.9000 - val_loss: 0.4182 - val_acc: 0.9000\n",
            "Epoch 366/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4369 - acc: 0.8944 - val_loss: 0.4156 - val_acc: 0.9500\n",
            "Epoch 367/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4364 - acc: 0.8889 - val_loss: 0.4150 - val_acc: 1.0000\n",
            "Epoch 368/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4361 - acc: 0.8944 - val_loss: 0.4181 - val_acc: 0.9500\n",
            "Epoch 369/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4364 - acc: 0.8611 - val_loss: 0.4144 - val_acc: 1.0000\n",
            "Epoch 370/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4351 - acc: 0.8944 - val_loss: 0.4149 - val_acc: 1.0000\n",
            "Epoch 371/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4344 - acc: 0.8778 - val_loss: 0.4140 - val_acc: 0.9000\n",
            "Epoch 372/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4341 - acc: 0.8944 - val_loss: 0.4129 - val_acc: 1.0000\n",
            "Epoch 373/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.4337 - acc: 0.8944 - val_loss: 0.4129 - val_acc: 1.0000\n",
            "Epoch 374/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4338 - acc: 0.8944 - val_loss: 0.4128 - val_acc: 1.0000\n",
            "Epoch 375/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4336 - acc: 0.8889 - val_loss: 0.4125 - val_acc: 1.0000\n",
            "Epoch 376/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4349 - acc: 0.8833 - val_loss: 0.4129 - val_acc: 1.0000\n",
            "Epoch 377/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4329 - acc: 0.9000 - val_loss: 0.4117 - val_acc: 1.0000\n",
            "Epoch 378/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4330 - acc: 0.9167 - val_loss: 0.4122 - val_acc: 0.9500\n",
            "Epoch 379/800\n",
            "180/180 [==============================] - 0s 498us/step - loss: 0.4335 - acc: 0.9000 - val_loss: 0.4104 - val_acc: 1.0000\n",
            "Epoch 380/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4319 - acc: 0.8833 - val_loss: 0.4103 - val_acc: 0.9500\n",
            "Epoch 381/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4318 - acc: 0.9167 - val_loss: 0.4092 - val_acc: 1.0000\n",
            "Epoch 382/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.4310 - acc: 0.8833 - val_loss: 0.4092 - val_acc: 1.0000\n",
            "Epoch 383/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4309 - acc: 0.9056 - val_loss: 0.4104 - val_acc: 0.9500\n",
            "Epoch 384/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4319 - acc: 0.8778 - val_loss: 0.4121 - val_acc: 1.0000\n",
            "Epoch 385/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.4339 - acc: 0.8889 - val_loss: 0.4082 - val_acc: 0.9500\n",
            "Epoch 386/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4303 - acc: 0.9056 - val_loss: 0.4075 - val_acc: 1.0000\n",
            "Epoch 387/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.4294 - acc: 0.9000 - val_loss: 0.4071 - val_acc: 1.0000\n",
            "Epoch 388/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4282 - acc: 0.8833 - val_loss: 0.4059 - val_acc: 1.0000\n",
            "Epoch 389/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4285 - acc: 0.9111 - val_loss: 0.4062 - val_acc: 0.9500\n",
            "Epoch 390/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4278 - acc: 0.8889 - val_loss: 0.4078 - val_acc: 0.9500\n",
            "Epoch 391/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4299 - acc: 0.8944 - val_loss: 0.4054 - val_acc: 1.0000\n",
            "Epoch 392/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4275 - acc: 0.9056 - val_loss: 0.4117 - val_acc: 1.0000\n",
            "Epoch 393/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4339 - acc: 0.8556 - val_loss: 0.4068 - val_acc: 1.0000\n",
            "Epoch 394/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4283 - acc: 0.8944 - val_loss: 0.4048 - val_acc: 0.9500\n",
            "Epoch 395/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4270 - acc: 0.9278 - val_loss: 0.4043 - val_acc: 1.0000\n",
            "Epoch 396/800\n",
            "180/180 [==============================] - 0s 465us/step - loss: 0.4262 - acc: 0.9000 - val_loss: 0.4048 - val_acc: 1.0000\n",
            "Epoch 397/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4285 - acc: 0.9056 - val_loss: 0.4056 - val_acc: 1.0000\n",
            "Epoch 398/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4270 - acc: 0.9167 - val_loss: 0.4049 - val_acc: 1.0000\n",
            "Epoch 399/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4262 - acc: 0.8833 - val_loss: 0.4031 - val_acc: 1.0000\n",
            "Epoch 400/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4273 - acc: 0.8722 - val_loss: 0.4028 - val_acc: 1.0000\n",
            "Epoch 401/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4254 - acc: 0.9167 - val_loss: 0.4029 - val_acc: 1.0000\n",
            "Epoch 402/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4262 - acc: 0.9056 - val_loss: 0.4023 - val_acc: 1.0000\n",
            "Epoch 403/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4277 - acc: 0.9111 - val_loss: 0.4044 - val_acc: 1.0000\n",
            "Epoch 404/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4265 - acc: 0.8889 - val_loss: 0.4021 - val_acc: 0.9500\n",
            "Epoch 405/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.4252 - acc: 0.9167 - val_loss: 0.4026 - val_acc: 0.9500\n",
            "Epoch 406/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.4247 - acc: 0.9000 - val_loss: 0.4009 - val_acc: 1.0000\n",
            "Epoch 407/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4243 - acc: 0.8833 - val_loss: 0.4022 - val_acc: 1.0000\n",
            "Epoch 408/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4241 - acc: 0.8944 - val_loss: 0.4009 - val_acc: 0.9500\n",
            "Epoch 409/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4235 - acc: 0.9167 - val_loss: 0.4023 - val_acc: 1.0000\n",
            "Epoch 410/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4243 - acc: 0.8778 - val_loss: 0.4012 - val_acc: 1.0000\n",
            "Epoch 411/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4233 - acc: 0.8833 - val_loss: 0.4007 - val_acc: 0.9500\n",
            "Epoch 412/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4233 - acc: 0.9056 - val_loss: 0.4003 - val_acc: 1.0000\n",
            "Epoch 413/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4232 - acc: 0.9000 - val_loss: 0.3996 - val_acc: 1.0000\n",
            "Epoch 414/800\n",
            "180/180 [==============================] - 0s 437us/step - loss: 0.4233 - acc: 0.8833 - val_loss: 0.3993 - val_acc: 0.9500\n",
            "Epoch 415/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4225 - acc: 0.9000 - val_loss: 0.3994 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00415: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 416/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4221 - acc: 0.9000 - val_loss: 0.3991 - val_acc: 1.0000\n",
            "Epoch 417/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4218 - acc: 0.9111 - val_loss: 0.3991 - val_acc: 1.0000\n",
            "Epoch 418/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.4221 - acc: 0.9056 - val_loss: 0.3990 - val_acc: 1.0000\n",
            "Epoch 419/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4219 - acc: 0.9111 - val_loss: 0.3990 - val_acc: 1.0000\n",
            "Epoch 420/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4219 - acc: 0.9000 - val_loss: 0.3989 - val_acc: 1.0000\n",
            "Epoch 421/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4218 - acc: 0.8667 - val_loss: 0.3989 - val_acc: 1.0000\n",
            "Epoch 422/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4218 - acc: 0.8722 - val_loss: 0.3989 - val_acc: 1.0000\n",
            "Epoch 423/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4218 - acc: 0.8944 - val_loss: 0.3988 - val_acc: 1.0000\n",
            "Epoch 424/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.4219 - acc: 0.9167 - val_loss: 0.3987 - val_acc: 1.0000\n",
            "Epoch 425/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.4215 - acc: 0.9222 - val_loss: 0.3987 - val_acc: 1.0000\n",
            "Epoch 426/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4213 - acc: 0.9167 - val_loss: 0.3987 - val_acc: 1.0000\n",
            "Epoch 427/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4214 - acc: 0.9167 - val_loss: 0.3986 - val_acc: 1.0000\n",
            "Epoch 428/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4215 - acc: 0.9111 - val_loss: 0.3986 - val_acc: 1.0000\n",
            "Epoch 429/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.4215 - acc: 0.8889 - val_loss: 0.3986 - val_acc: 1.0000\n",
            "Epoch 430/800\n",
            "180/180 [==============================] - 0s 464us/step - loss: 0.4216 - acc: 0.8667 - val_loss: 0.3985 - val_acc: 1.0000\n",
            "Epoch 431/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4217 - acc: 0.8778 - val_loss: 0.3984 - val_acc: 1.0000\n",
            "Epoch 432/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4213 - acc: 0.8778 - val_loss: 0.3984 - val_acc: 1.0000\n",
            "Epoch 433/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4212 - acc: 0.8833 - val_loss: 0.3984 - val_acc: 1.0000\n",
            "Epoch 434/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4211 - acc: 0.9167 - val_loss: 0.3983 - val_acc: 1.0000\n",
            "Epoch 435/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.4215 - acc: 0.9222 - val_loss: 0.3983 - val_acc: 1.0000\n",
            "Epoch 436/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4212 - acc: 0.9056 - val_loss: 0.3983 - val_acc: 1.0000\n",
            "Epoch 437/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4212 - acc: 0.9056 - val_loss: 0.3983 - val_acc: 1.0000\n",
            "Epoch 438/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.4213 - acc: 0.9056 - val_loss: 0.3983 - val_acc: 1.0000\n",
            "Epoch 439/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.4206 - acc: 0.9056 - val_loss: 0.3982 - val_acc: 1.0000\n",
            "Epoch 440/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4209 - acc: 0.9167 - val_loss: 0.3981 - val_acc: 1.0000\n",
            "Epoch 441/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4209 - acc: 0.9111 - val_loss: 0.3981 - val_acc: 1.0000\n",
            "Epoch 442/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4212 - acc: 0.9167 - val_loss: 0.3980 - val_acc: 1.0000\n",
            "Epoch 443/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4211 - acc: 0.9167 - val_loss: 0.3980 - val_acc: 1.0000\n",
            "Epoch 444/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4210 - acc: 0.9111 - val_loss: 0.3979 - val_acc: 1.0000\n",
            "Epoch 445/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4206 - acc: 0.9222 - val_loss: 0.3979 - val_acc: 1.0000\n",
            "Epoch 446/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4206 - acc: 0.9000 - val_loss: 0.3979 - val_acc: 1.0000\n",
            "Epoch 447/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4208 - acc: 0.9111 - val_loss: 0.3978 - val_acc: 1.0000\n",
            "Epoch 448/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4205 - acc: 0.9167 - val_loss: 0.3978 - val_acc: 1.0000\n",
            "Epoch 449/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4209 - acc: 0.9167 - val_loss: 0.3978 - val_acc: 1.0000\n",
            "Epoch 450/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4206 - acc: 0.9111 - val_loss: 0.3978 - val_acc: 1.0000\n",
            "Epoch 451/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4206 - acc: 0.9167 - val_loss: 0.3978 - val_acc: 1.0000\n",
            "Epoch 452/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.4205 - acc: 0.9167 - val_loss: 0.3977 - val_acc: 1.0000\n",
            "Epoch 453/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4203 - acc: 0.9111 - val_loss: 0.3976 - val_acc: 1.0000\n",
            "Epoch 454/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4204 - acc: 0.9056 - val_loss: 0.3976 - val_acc: 1.0000\n",
            "Epoch 455/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.4206 - acc: 0.9111 - val_loss: 0.3975 - val_acc: 1.0000\n",
            "Epoch 456/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4206 - acc: 0.9111 - val_loss: 0.3974 - val_acc: 1.0000\n",
            "Epoch 457/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4204 - acc: 0.9167 - val_loss: 0.3974 - val_acc: 1.0000\n",
            "Epoch 458/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4203 - acc: 0.9167 - val_loss: 0.3974 - val_acc: 1.0000\n",
            "Epoch 459/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4203 - acc: 0.9167 - val_loss: 0.3974 - val_acc: 1.0000\n",
            "Epoch 460/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4203 - acc: 0.9222 - val_loss: 0.3974 - val_acc: 1.0000\n",
            "Epoch 461/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4203 - acc: 0.9111 - val_loss: 0.3973 - val_acc: 1.0000\n",
            "Epoch 462/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4204 - acc: 0.9111 - val_loss: 0.3973 - val_acc: 1.0000\n",
            "Epoch 463/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4199 - acc: 0.9167 - val_loss: 0.3972 - val_acc: 1.0000\n",
            "Epoch 464/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4203 - acc: 0.9167 - val_loss: 0.3972 - val_acc: 1.0000\n",
            "Epoch 465/800\n",
            "180/180 [==============================] - 0s 469us/step - loss: 0.4200 - acc: 0.9056 - val_loss: 0.3972 - val_acc: 1.0000\n",
            "Epoch 466/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4202 - acc: 0.8667 - val_loss: 0.3972 - val_acc: 1.0000\n",
            "Epoch 467/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4202 - acc: 0.8833 - val_loss: 0.3971 - val_acc: 1.0000\n",
            "Epoch 468/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4200 - acc: 0.8889 - val_loss: 0.3971 - val_acc: 1.0000\n",
            "Epoch 469/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4200 - acc: 0.9111 - val_loss: 0.3971 - val_acc: 1.0000\n",
            "Epoch 470/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4201 - acc: 0.9333 - val_loss: 0.3970 - val_acc: 1.0000\n",
            "Epoch 471/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.4199 - acc: 0.9333 - val_loss: 0.3969 - val_acc: 1.0000\n",
            "Epoch 472/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4201 - acc: 0.9167 - val_loss: 0.3969 - val_acc: 1.0000\n",
            "Epoch 473/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4195 - acc: 0.9111 - val_loss: 0.3969 - val_acc: 1.0000\n",
            "Epoch 474/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.4198 - acc: 0.9222 - val_loss: 0.3968 - val_acc: 1.0000\n",
            "Epoch 475/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4197 - acc: 0.9000 - val_loss: 0.3968 - val_acc: 1.0000\n",
            "Epoch 476/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4197 - acc: 0.8778 - val_loss: 0.3969 - val_acc: 1.0000\n",
            "Epoch 477/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4198 - acc: 0.8889 - val_loss: 0.3968 - val_acc: 1.0000\n",
            "Epoch 478/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4196 - acc: 0.9111 - val_loss: 0.3967 - val_acc: 1.0000\n",
            "Epoch 479/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4199 - acc: 0.9056 - val_loss: 0.3967 - val_acc: 1.0000\n",
            "Epoch 480/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4194 - acc: 0.9111 - val_loss: 0.3967 - val_acc: 1.0000\n",
            "Epoch 481/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4193 - acc: 0.9111 - val_loss: 0.3966 - val_acc: 1.0000\n",
            "Epoch 482/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4196 - acc: 0.9167 - val_loss: 0.3966 - val_acc: 1.0000\n",
            "Epoch 483/800\n",
            "180/180 [==============================] - 0s 417us/step - loss: 0.4198 - acc: 0.9167 - val_loss: 0.3966 - val_acc: 1.0000\n",
            "Epoch 484/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4193 - acc: 0.9167 - val_loss: 0.3966 - val_acc: 1.0000\n",
            "Epoch 485/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4194 - acc: 0.9167 - val_loss: 0.3965 - val_acc: 1.0000\n",
            "Epoch 486/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.4197 - acc: 0.9167 - val_loss: 0.3965 - val_acc: 1.0000\n",
            "Epoch 487/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4194 - acc: 0.9222 - val_loss: 0.3964 - val_acc: 1.0000\n",
            "Epoch 488/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4192 - acc: 0.9111 - val_loss: 0.3964 - val_acc: 1.0000\n",
            "Epoch 489/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4191 - acc: 0.9222 - val_loss: 0.3965 - val_acc: 1.0000\n",
            "Epoch 490/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4193 - acc: 0.9167 - val_loss: 0.3964 - val_acc: 1.0000\n",
            "Epoch 491/800\n",
            "180/180 [==============================] - 0s 392us/step - loss: 0.4193 - acc: 0.9222 - val_loss: 0.3964 - val_acc: 1.0000\n",
            "Epoch 492/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4194 - acc: 0.9167 - val_loss: 0.3963 - val_acc: 1.0000\n",
            "Epoch 493/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4191 - acc: 0.9167 - val_loss: 0.3963 - val_acc: 1.0000\n",
            "Epoch 494/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4189 - acc: 0.9222 - val_loss: 0.3963 - val_acc: 1.0000\n",
            "Epoch 495/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4193 - acc: 0.8944 - val_loss: 0.3962 - val_acc: 1.0000\n",
            "Epoch 496/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4191 - acc: 0.8667 - val_loss: 0.3962 - val_acc: 1.0000\n",
            "Epoch 497/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4191 - acc: 0.8833 - val_loss: 0.3962 - val_acc: 1.0000\n",
            "Epoch 498/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4192 - acc: 0.9000 - val_loss: 0.3961 - val_acc: 1.0000\n",
            "Epoch 499/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4190 - acc: 0.9056 - val_loss: 0.3960 - val_acc: 1.0000\n",
            "Epoch 500/800\n",
            "180/180 [==============================] - 0s 519us/step - loss: 0.4191 - acc: 0.9167 - val_loss: 0.3960 - val_acc: 1.0000\n",
            "Epoch 501/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4191 - acc: 0.9222 - val_loss: 0.3960 - val_acc: 1.0000\n",
            "Epoch 502/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4190 - acc: 0.9222 - val_loss: 0.3959 - val_acc: 1.0000\n",
            "Epoch 503/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4188 - acc: 0.9111 - val_loss: 0.3960 - val_acc: 1.0000\n",
            "Epoch 504/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4186 - acc: 0.9222 - val_loss: 0.3958 - val_acc: 1.0000\n",
            "Epoch 505/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4189 - acc: 0.9111 - val_loss: 0.3959 - val_acc: 1.0000\n",
            "Epoch 506/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4190 - acc: 0.9167 - val_loss: 0.3958 - val_acc: 1.0000\n",
            "Epoch 507/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4189 - acc: 0.9222 - val_loss: 0.3958 - val_acc: 1.0000\n",
            "Epoch 508/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4189 - acc: 0.9222 - val_loss: 0.3958 - val_acc: 1.0000\n",
            "Epoch 509/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4188 - acc: 0.9278 - val_loss: 0.3957 - val_acc: 1.0000\n",
            "Epoch 510/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.4184 - acc: 0.9111 - val_loss: 0.3958 - val_acc: 1.0000\n",
            "Epoch 511/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.4186 - acc: 0.9222 - val_loss: 0.3957 - val_acc: 1.0000\n",
            "Epoch 512/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4186 - acc: 0.9222 - val_loss: 0.3957 - val_acc: 1.0000\n",
            "Epoch 513/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4185 - acc: 0.9167 - val_loss: 0.3956 - val_acc: 1.0000\n",
            "Epoch 514/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4182 - acc: 0.9111 - val_loss: 0.3956 - val_acc: 1.0000\n",
            "Epoch 515/800\n",
            "180/180 [==============================] - 0s 409us/step - loss: 0.4186 - acc: 0.8778 - val_loss: 0.3955 - val_acc: 1.0000\n",
            "Epoch 516/800\n",
            "180/180 [==============================] - 0s 392us/step - loss: 0.4182 - acc: 0.8944 - val_loss: 0.3955 - val_acc: 1.0000\n",
            "Epoch 517/800\n",
            "180/180 [==============================] - 0s 505us/step - loss: 0.4185 - acc: 0.9222 - val_loss: 0.3955 - val_acc: 1.0000\n",
            "Epoch 518/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4184 - acc: 0.9222 - val_loss: 0.3954 - val_acc: 1.0000\n",
            "Epoch 519/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4186 - acc: 0.9333 - val_loss: 0.3955 - val_acc: 1.0000\n",
            "Epoch 520/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4182 - acc: 0.9167 - val_loss: 0.3954 - val_acc: 1.0000\n",
            "Epoch 521/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4184 - acc: 0.9167 - val_loss: 0.3954 - val_acc: 1.0000\n",
            "Epoch 522/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4183 - acc: 0.9111 - val_loss: 0.3953 - val_acc: 1.0000\n",
            "Epoch 523/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.4183 - acc: 0.9167 - val_loss: 0.3953 - val_acc: 1.0000\n",
            "Epoch 524/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.4180 - acc: 0.9167 - val_loss: 0.3953 - val_acc: 1.0000\n",
            "Epoch 525/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4183 - acc: 0.9167 - val_loss: 0.3952 - val_acc: 1.0000\n",
            "Epoch 526/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4182 - acc: 0.9111 - val_loss: 0.3952 - val_acc: 1.0000\n",
            "Epoch 527/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4182 - acc: 0.9111 - val_loss: 0.3951 - val_acc: 1.0000\n",
            "Epoch 528/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4181 - acc: 0.9111 - val_loss: 0.3951 - val_acc: 1.0000\n",
            "Epoch 529/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4180 - acc: 0.9222 - val_loss: 0.3951 - val_acc: 1.0000\n",
            "Epoch 530/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4180 - acc: 0.9056 - val_loss: 0.3950 - val_acc: 1.0000\n",
            "Epoch 531/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4181 - acc: 0.9000 - val_loss: 0.3950 - val_acc: 1.0000\n",
            "Epoch 532/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4180 - acc: 0.9111 - val_loss: 0.3950 - val_acc: 1.0000\n",
            "Epoch 533/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4179 - acc: 0.9222 - val_loss: 0.3949 - val_acc: 1.0000\n",
            "Epoch 534/800\n",
            "180/180 [==============================] - 0s 459us/step - loss: 0.4180 - acc: 0.9111 - val_loss: 0.3949 - val_acc: 1.0000\n",
            "Epoch 535/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.4179 - acc: 0.9167 - val_loss: 0.3949 - val_acc: 1.0000\n",
            "Epoch 536/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4180 - acc: 0.9056 - val_loss: 0.3949 - val_acc: 1.0000\n",
            "Epoch 537/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.4178 - acc: 0.9056 - val_loss: 0.3949 - val_acc: 1.0000\n",
            "Epoch 538/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4178 - acc: 0.9056 - val_loss: 0.3948 - val_acc: 1.0000\n",
            "Epoch 539/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4177 - acc: 0.9167 - val_loss: 0.3948 - val_acc: 1.0000\n",
            "Epoch 540/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4180 - acc: 0.9222 - val_loss: 0.3948 - val_acc: 1.0000\n",
            "Epoch 541/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4176 - acc: 0.9111 - val_loss: 0.3948 - val_acc: 1.0000\n",
            "Epoch 542/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4176 - acc: 0.9056 - val_loss: 0.3947 - val_acc: 1.0000\n",
            "Epoch 543/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4173 - acc: 0.9222 - val_loss: 0.3947 - val_acc: 1.0000\n",
            "Epoch 544/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4177 - acc: 0.9167 - val_loss: 0.3946 - val_acc: 1.0000\n",
            "Epoch 545/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4176 - acc: 0.9222 - val_loss: 0.3947 - val_acc: 1.0000\n",
            "Epoch 546/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4173 - acc: 0.9056 - val_loss: 0.3945 - val_acc: 1.0000\n",
            "Epoch 547/800\n",
            "180/180 [==============================] - 0s 411us/step - loss: 0.4175 - acc: 0.9111 - val_loss: 0.3946 - val_acc: 1.0000\n",
            "Epoch 548/800\n",
            "180/180 [==============================] - 0s 396us/step - loss: 0.4171 - acc: 0.9111 - val_loss: 0.3946 - val_acc: 1.0000\n",
            "Epoch 549/800\n",
            "180/180 [==============================] - 0s 402us/step - loss: 0.4173 - acc: 0.9111 - val_loss: 0.3945 - val_acc: 1.0000\n",
            "Epoch 550/800\n",
            "180/180 [==============================] - 0s 411us/step - loss: 0.4174 - acc: 0.9167 - val_loss: 0.3944 - val_acc: 1.0000\n",
            "Epoch 551/800\n",
            "180/180 [==============================] - 0s 493us/step - loss: 0.4174 - acc: 0.9222 - val_loss: 0.3944 - val_acc: 1.0000\n",
            "Epoch 552/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4174 - acc: 0.9111 - val_loss: 0.3944 - val_acc: 1.0000\n",
            "Epoch 553/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4174 - acc: 0.9111 - val_loss: 0.3943 - val_acc: 1.0000\n",
            "Epoch 554/800\n",
            "180/180 [==============================] - 0s 395us/step - loss: 0.4172 - acc: 0.9111 - val_loss: 0.3943 - val_acc: 1.0000\n",
            "Epoch 555/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4174 - acc: 0.9056 - val_loss: 0.3943 - val_acc: 1.0000\n",
            "Epoch 556/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4172 - acc: 0.9056 - val_loss: 0.3943 - val_acc: 1.0000\n",
            "Epoch 557/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4169 - acc: 0.9056 - val_loss: 0.3942 - val_acc: 1.0000\n",
            "Epoch 558/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4172 - acc: 0.9111 - val_loss: 0.3942 - val_acc: 1.0000\n",
            "Epoch 559/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4170 - acc: 0.9111 - val_loss: 0.3942 - val_acc: 1.0000\n",
            "Epoch 560/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4169 - acc: 0.9222 - val_loss: 0.3942 - val_acc: 1.0000\n",
            "Epoch 561/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4171 - acc: 0.9167 - val_loss: 0.3942 - val_acc: 1.0000\n",
            "Epoch 562/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4172 - acc: 0.9167 - val_loss: 0.3940 - val_acc: 1.0000\n",
            "Epoch 563/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4170 - acc: 0.9111 - val_loss: 0.3940 - val_acc: 1.0000\n",
            "Epoch 564/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4167 - acc: 0.9000 - val_loss: 0.3940 - val_acc: 1.0000\n",
            "Epoch 565/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4170 - acc: 0.9056 - val_loss: 0.3940 - val_acc: 1.0000\n",
            "Epoch 566/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4171 - acc: 0.9111 - val_loss: 0.3940 - val_acc: 1.0000\n",
            "Epoch 567/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4172 - acc: 0.9111 - val_loss: 0.3940 - val_acc: 1.0000\n",
            "Epoch 568/800\n",
            "180/180 [==============================] - 0s 473us/step - loss: 0.4169 - acc: 0.9167 - val_loss: 0.3938 - val_acc: 1.0000\n",
            "Epoch 569/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4167 - acc: 0.9056 - val_loss: 0.3938 - val_acc: 1.0000\n",
            "Epoch 570/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4169 - acc: 0.9111 - val_loss: 0.3939 - val_acc: 1.0000\n",
            "Epoch 571/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4167 - acc: 0.9111 - val_loss: 0.3939 - val_acc: 1.0000\n",
            "Epoch 572/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4166 - acc: 0.9167 - val_loss: 0.3939 - val_acc: 1.0000\n",
            "Epoch 573/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4165 - acc: 0.9000 - val_loss: 0.3937 - val_acc: 1.0000\n",
            "Epoch 574/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4167 - acc: 0.8722 - val_loss: 0.3937 - val_acc: 1.0000\n",
            "Epoch 575/800\n",
            "180/180 [==============================] - 0s 392us/step - loss: 0.4165 - acc: 0.8722 - val_loss: 0.3937 - val_acc: 1.0000\n",
            "Epoch 576/800\n",
            "180/180 [==============================] - 0s 432us/step - loss: 0.4166 - acc: 0.9167 - val_loss: 0.3937 - val_acc: 1.0000\n",
            "Epoch 577/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4168 - acc: 0.9222 - val_loss: 0.3937 - val_acc: 1.0000\n",
            "Epoch 578/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4165 - acc: 0.9389 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 579/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4164 - acc: 0.9333 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 580/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4164 - acc: 0.9278 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 581/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4164 - acc: 0.9222 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 582/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4165 - acc: 0.9167 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 583/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4166 - acc: 0.9056 - val_loss: 0.3934 - val_acc: 1.0000\n",
            "Epoch 584/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4165 - acc: 0.9167 - val_loss: 0.3933 - val_acc: 1.0000\n",
            "Epoch 585/800\n",
            "180/180 [==============================] - 0s 529us/step - loss: 0.4165 - acc: 0.9167 - val_loss: 0.3934 - val_acc: 1.0000\n",
            "Epoch 586/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.4162 - acc: 0.9167 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 587/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.4161 - acc: 0.9167 - val_loss: 0.3935 - val_acc: 1.0000\n",
            "Epoch 588/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.4163 - acc: 0.9111 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 589/800\n",
            "180/180 [==============================] - 0s 389us/step - loss: 0.4163 - acc: 0.9111 - val_loss: 0.3935 - val_acc: 1.0000\n",
            "Epoch 590/800\n",
            "180/180 [==============================] - 0s 394us/step - loss: 0.4160 - acc: 0.9167 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 591/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.4161 - acc: 0.9056 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 592/800\n",
            "180/180 [==============================] - 0s 400us/step - loss: 0.4159 - acc: 0.9111 - val_loss: 0.3935 - val_acc: 1.0000\n",
            "Epoch 593/800\n",
            "180/180 [==============================] - 0s 393us/step - loss: 0.4160 - acc: 0.9056 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 594/800\n",
            "180/180 [==============================] - 0s 401us/step - loss: 0.4162 - acc: 0.9167 - val_loss: 0.3935 - val_acc: 1.0000\n",
            "Epoch 595/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4161 - acc: 0.9056 - val_loss: 0.3935 - val_acc: 1.0000\n",
            "Epoch 596/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4158 - acc: 0.9056 - val_loss: 0.3934 - val_acc: 1.0000\n",
            "Epoch 597/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4159 - acc: 0.9056 - val_loss: 0.3934 - val_acc: 1.0000\n",
            "Epoch 598/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4158 - acc: 0.8889 - val_loss: 0.3933 - val_acc: 1.0000\n",
            "Epoch 599/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4158 - acc: 0.8722 - val_loss: 0.3933 - val_acc: 1.0000\n",
            "Epoch 600/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4160 - acc: 0.8944 - val_loss: 0.3932 - val_acc: 1.0000\n",
            "Epoch 601/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4157 - acc: 0.9167 - val_loss: 0.3933 - val_acc: 1.0000\n",
            "Epoch 602/800\n",
            "180/180 [==============================] - 0s 483us/step - loss: 0.4157 - acc: 0.9167 - val_loss: 0.3933 - val_acc: 1.0000\n",
            "Epoch 603/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4157 - acc: 0.9167 - val_loss: 0.3932 - val_acc: 1.0000\n",
            "Epoch 604/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.4155 - acc: 0.9167 - val_loss: 0.3933 - val_acc: 1.0000\n",
            "Epoch 605/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4156 - acc: 0.9000 - val_loss: 0.3931 - val_acc: 1.0000\n",
            "Epoch 606/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4156 - acc: 0.8833 - val_loss: 0.3930 - val_acc: 1.0000\n",
            "Epoch 607/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4154 - acc: 0.8833 - val_loss: 0.3930 - val_acc: 1.0000\n",
            "Epoch 608/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4155 - acc: 0.8944 - val_loss: 0.3930 - val_acc: 1.0000\n",
            "Epoch 609/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.4155 - acc: 0.9167 - val_loss: 0.3930 - val_acc: 1.0000\n",
            "Epoch 610/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4154 - acc: 0.9111 - val_loss: 0.3929 - val_acc: 1.0000\n",
            "Epoch 611/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4154 - acc: 0.9111 - val_loss: 0.3929 - val_acc: 1.0000\n",
            "Epoch 612/800\n",
            "180/180 [==============================] - 0s 470us/step - loss: 0.4155 - acc: 0.8944 - val_loss: 0.3930 - val_acc: 1.0000\n",
            "Epoch 613/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.4154 - acc: 0.9056 - val_loss: 0.3929 - val_acc: 1.0000\n",
            "Epoch 614/800\n",
            "180/180 [==============================] - 0s 407us/step - loss: 0.4152 - acc: 0.8833 - val_loss: 0.3929 - val_acc: 1.0000\n",
            "Epoch 615/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4154 - acc: 0.8889 - val_loss: 0.3929 - val_acc: 1.0000\n",
            "Epoch 616/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.4154 - acc: 0.8833 - val_loss: 0.3927 - val_acc: 1.0000\n",
            "Epoch 617/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4152 - acc: 0.9000 - val_loss: 0.3926 - val_acc: 1.0000\n",
            "Epoch 618/800\n",
            "180/180 [==============================] - 0s 497us/step - loss: 0.4155 - acc: 0.9111 - val_loss: 0.3928 - val_acc: 1.0000\n",
            "Epoch 619/800\n",
            "180/180 [==============================] - 0s 398us/step - loss: 0.4152 - acc: 0.9111 - val_loss: 0.3926 - val_acc: 1.0000\n",
            "Epoch 620/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4151 - acc: 0.9000 - val_loss: 0.3927 - val_acc: 1.0000\n",
            "Epoch 621/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4153 - acc: 0.9000 - val_loss: 0.3926 - val_acc: 1.0000\n",
            "Epoch 622/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4148 - acc: 0.9167 - val_loss: 0.3926 - val_acc: 1.0000\n",
            "Epoch 623/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4152 - acc: 0.9111 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 624/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4152 - acc: 0.9167 - val_loss: 0.3924 - val_acc: 1.0000\n",
            "Epoch 625/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4150 - acc: 0.9167 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 626/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4150 - acc: 0.9167 - val_loss: 0.3926 - val_acc: 1.0000\n",
            "Epoch 627/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4149 - acc: 0.9167 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 628/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4151 - acc: 0.9167 - val_loss: 0.3926 - val_acc: 1.0000\n",
            "Epoch 629/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4148 - acc: 0.9222 - val_loss: 0.3924 - val_acc: 1.0000\n",
            "Epoch 630/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.4150 - acc: 0.9167 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 631/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4150 - acc: 0.9167 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 632/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4147 - acc: 0.9111 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 633/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4149 - acc: 0.9222 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 634/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4146 - acc: 0.9278 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 635/800\n",
            "180/180 [==============================] - 0s 467us/step - loss: 0.4148 - acc: 0.9111 - val_loss: 0.3923 - val_acc: 1.0000\n",
            "Epoch 636/800\n",
            "180/180 [==============================] - 0s 405us/step - loss: 0.4149 - acc: 0.9278 - val_loss: 0.3923 - val_acc: 1.0000\n",
            "Epoch 637/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4148 - acc: 0.9333 - val_loss: 0.3923 - val_acc: 1.0000\n",
            "Epoch 638/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4149 - acc: 0.9278 - val_loss: 0.3921 - val_acc: 1.0000\n",
            "Epoch 639/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4146 - acc: 0.9222 - val_loss: 0.3923 - val_acc: 1.0000\n",
            "Epoch 640/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4145 - acc: 0.9111 - val_loss: 0.3923 - val_acc: 1.0000\n",
            "Epoch 641/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4146 - acc: 0.8889 - val_loss: 0.3922 - val_acc: 1.0000\n",
            "Epoch 642/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4144 - acc: 0.8833 - val_loss: 0.3921 - val_acc: 1.0000\n",
            "Epoch 643/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4145 - acc: 0.8889 - val_loss: 0.3922 - val_acc: 1.0000\n",
            "Epoch 644/800\n",
            "180/180 [==============================] - 0s 411us/step - loss: 0.4145 - acc: 0.9167 - val_loss: 0.3922 - val_acc: 1.0000\n",
            "Epoch 645/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.4144 - acc: 0.9222 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 646/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4145 - acc: 0.9167 - val_loss: 0.3921 - val_acc: 1.0000\n",
            "Epoch 647/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4144 - acc: 0.9111 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 648/800\n",
            "180/180 [==============================] - 0s 409us/step - loss: 0.4145 - acc: 0.9278 - val_loss: 0.3920 - val_acc: 1.0000\n",
            "Epoch 649/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4145 - acc: 0.9389 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 650/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4146 - acc: 0.9222 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 651/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4143 - acc: 0.9222 - val_loss: 0.3918 - val_acc: 1.0000\n",
            "Epoch 652/800\n",
            "180/180 [==============================] - 0s 478us/step - loss: 0.4143 - acc: 0.9167 - val_loss: 0.3918 - val_acc: 1.0000\n",
            "Epoch 653/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4144 - acc: 0.9278 - val_loss: 0.3918 - val_acc: 1.0000\n",
            "Epoch 654/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4143 - acc: 0.9167 - val_loss: 0.3918 - val_acc: 1.0000\n",
            "Epoch 655/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4145 - acc: 0.9167 - val_loss: 0.3918 - val_acc: 1.0000\n",
            "Epoch 656/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.4145 - acc: 0.9222 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 657/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4142 - acc: 0.9278 - val_loss: 0.3920 - val_acc: 1.0000\n",
            "Epoch 658/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4141 - acc: 0.9278 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 659/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.4141 - acc: 0.9167 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 660/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.4142 - acc: 0.9167 - val_loss: 0.3917 - val_acc: 1.0000\n",
            "Epoch 661/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4144 - acc: 0.9167 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 662/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4140 - acc: 0.9167 - val_loss: 0.3917 - val_acc: 1.0000\n",
            "Epoch 663/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4141 - acc: 0.9167 - val_loss: 0.3917 - val_acc: 1.0000\n",
            "Epoch 664/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4141 - acc: 0.9111 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 665/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4140 - acc: 0.9111 - val_loss: 0.3917 - val_acc: 1.0000\n",
            "Epoch 666/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4140 - acc: 0.9056 - val_loss: 0.3915 - val_acc: 1.0000\n",
            "Epoch 667/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4141 - acc: 0.9056 - val_loss: 0.3915 - val_acc: 1.0000\n",
            "Epoch 668/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.4140 - acc: 0.9111 - val_loss: 0.3916 - val_acc: 1.0000\n",
            "Epoch 669/800\n",
            "180/180 [==============================] - 0s 487us/step - loss: 0.4140 - acc: 0.9111 - val_loss: 0.3916 - val_acc: 1.0000\n",
            "Epoch 670/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.4138 - acc: 0.9333 - val_loss: 0.3916 - val_acc: 1.0000\n",
            "Epoch 671/800\n",
            "180/180 [==============================] - 0s 393us/step - loss: 0.4139 - acc: 0.9222 - val_loss: 0.3915 - val_acc: 1.0000\n",
            "Epoch 672/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4138 - acc: 0.9111 - val_loss: 0.3916 - val_acc: 1.0000\n",
            "Epoch 673/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4139 - acc: 0.9056 - val_loss: 0.3914 - val_acc: 1.0000\n",
            "Epoch 674/800\n",
            "180/180 [==============================] - 0s 412us/step - loss: 0.4139 - acc: 0.9167 - val_loss: 0.3914 - val_acc: 1.0000\n",
            "Epoch 675/800\n",
            "180/180 [==============================] - 0s 404us/step - loss: 0.4140 - acc: 0.9056 - val_loss: 0.3912 - val_acc: 1.0000\n",
            "Epoch 676/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4139 - acc: 0.9056 - val_loss: 0.3913 - val_acc: 1.0000\n",
            "Epoch 677/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4140 - acc: 0.9278 - val_loss: 0.3912 - val_acc: 1.0000\n",
            "Epoch 678/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4139 - acc: 0.9167 - val_loss: 0.3915 - val_acc: 1.0000\n",
            "Epoch 679/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4137 - acc: 0.9278 - val_loss: 0.3913 - val_acc: 1.0000\n",
            "Epoch 680/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4137 - acc: 0.9278 - val_loss: 0.3913 - val_acc: 1.0000\n",
            "Epoch 681/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4136 - acc: 0.9167 - val_loss: 0.3912 - val_acc: 1.0000\n",
            "Epoch 682/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4136 - acc: 0.9222 - val_loss: 0.3914 - val_acc: 1.0000\n",
            "Epoch 683/800\n",
            "180/180 [==============================] - 0s 395us/step - loss: 0.4136 - acc: 0.9056 - val_loss: 0.3913 - val_acc: 1.0000\n",
            "Epoch 684/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4136 - acc: 0.9056 - val_loss: 0.3912 - val_acc: 1.0000\n",
            "Epoch 685/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4136 - acc: 0.9167 - val_loss: 0.3913 - val_acc: 1.0000\n",
            "Epoch 686/800\n",
            "180/180 [==============================] - 0s 527us/step - loss: 0.4134 - acc: 0.9167 - val_loss: 0.3911 - val_acc: 1.0000\n",
            "Epoch 687/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4134 - acc: 0.9056 - val_loss: 0.3913 - val_acc: 1.0000\n",
            "Epoch 688/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4135 - acc: 0.9111 - val_loss: 0.3911 - val_acc: 1.0000\n",
            "Epoch 689/800\n",
            "180/180 [==============================] - 0s 389us/step - loss: 0.4134 - acc: 0.9056 - val_loss: 0.3911 - val_acc: 1.0000\n",
            "Epoch 690/800\n",
            "180/180 [==============================] - 0s 412us/step - loss: 0.4136 - acc: 0.9111 - val_loss: 0.3910 - val_acc: 1.0000\n",
            "Epoch 691/800\n",
            "180/180 [==============================] - 0s 405us/step - loss: 0.4132 - acc: 0.9111 - val_loss: 0.3912 - val_acc: 1.0000\n",
            "Epoch 692/800\n",
            "180/180 [==============================] - 0s 416us/step - loss: 0.4134 - acc: 0.9056 - val_loss: 0.3909 - val_acc: 1.0000\n",
            "Epoch 693/800\n",
            "180/180 [==============================] - 0s 409us/step - loss: 0.4135 - acc: 0.9167 - val_loss: 0.3910 - val_acc: 1.0000\n",
            "Epoch 694/800\n",
            "180/180 [==============================] - 0s 410us/step - loss: 0.4132 - acc: 0.9222 - val_loss: 0.3909 - val_acc: 1.0000\n",
            "Epoch 695/800\n",
            "180/180 [==============================] - 0s 402us/step - loss: 0.4132 - acc: 0.9111 - val_loss: 0.3910 - val_acc: 1.0000\n",
            "Epoch 696/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.4134 - acc: 0.9111 - val_loss: 0.3909 - val_acc: 1.0000\n",
            "Epoch 697/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4134 - acc: 0.9111 - val_loss: 0.3909 - val_acc: 1.0000\n",
            "Epoch 698/800\n",
            "180/180 [==============================] - 0s 396us/step - loss: 0.4130 - acc: 0.9111 - val_loss: 0.3910 - val_acc: 1.0000\n",
            "Epoch 699/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4131 - acc: 0.9167 - val_loss: 0.3909 - val_acc: 1.0000\n",
            "Epoch 700/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4132 - acc: 0.9111 - val_loss: 0.3907 - val_acc: 1.0000\n",
            "Epoch 701/800\n",
            "180/180 [==============================] - 0s 414us/step - loss: 0.4130 - acc: 0.9111 - val_loss: 0.3909 - val_acc: 1.0000\n",
            "Epoch 702/800\n",
            "180/180 [==============================] - 0s 513us/step - loss: 0.4132 - acc: 0.9111 - val_loss: 0.3908 - val_acc: 1.0000\n",
            "Epoch 703/800\n",
            "180/180 [==============================] - 0s 393us/step - loss: 0.4131 - acc: 0.9111 - val_loss: 0.3908 - val_acc: 1.0000\n",
            "Epoch 704/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4130 - acc: 0.9111 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 705/800\n",
            "180/180 [==============================] - 0s 389us/step - loss: 0.4131 - acc: 0.9056 - val_loss: 0.3909 - val_acc: 1.0000\n",
            "Epoch 706/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4130 - acc: 0.9222 - val_loss: 0.3906 - val_acc: 1.0000\n",
            "Epoch 707/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4130 - acc: 0.9056 - val_loss: 0.3907 - val_acc: 1.0000\n",
            "Epoch 708/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4131 - acc: 0.9167 - val_loss: 0.3906 - val_acc: 1.0000\n",
            "Epoch 709/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4131 - acc: 0.9278 - val_loss: 0.3907 - val_acc: 1.0000\n",
            "Epoch 710/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4131 - acc: 0.9389 - val_loss: 0.3907 - val_acc: 1.0000\n",
            "Epoch 711/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.4128 - acc: 0.9278 - val_loss: 0.3906 - val_acc: 1.0000\n",
            "Epoch 712/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4128 - acc: 0.9333 - val_loss: 0.3906 - val_acc: 1.0000\n",
            "Epoch 713/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4128 - acc: 0.9056 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 714/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4126 - acc: 0.9056 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 715/800\n",
            "180/180 [==============================] - 0s 389us/step - loss: 0.4129 - acc: 0.9056 - val_loss: 0.3906 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00715: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 716/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4128 - acc: 0.9000 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 717/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4129 - acc: 0.9056 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 718/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4126 - acc: 0.9111 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 719/800\n",
            "180/180 [==============================] - 0s 512us/step - loss: 0.4128 - acc: 0.9056 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 720/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4128 - acc: 0.9056 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 721/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4128 - acc: 0.9056 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 722/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4129 - acc: 0.9167 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 723/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.4127 - acc: 0.9167 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 724/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4127 - acc: 0.9167 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 725/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4127 - acc: 0.9167 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 726/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4126 - acc: 0.9222 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 727/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4128 - acc: 0.9167 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 728/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4129 - acc: 0.9222 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 729/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4125 - acc: 0.9222 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 730/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4126 - acc: 0.9222 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 731/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4128 - acc: 0.9222 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 732/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4128 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 733/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.4128 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 734/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4127 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 735/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4129 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 736/800\n",
            "180/180 [==============================] - 0s 491us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 737/800\n",
            "180/180 [==============================] - 0s 336us/step - loss: 0.4128 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 738/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4126 - acc: 0.9333 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 739/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4127 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 740/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4128 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 741/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4129 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 742/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4128 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 743/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4128 - acc: 0.9333 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 744/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4125 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 745/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4127 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 746/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4125 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 747/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4126 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 748/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 749/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4127 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 750/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4126 - acc: 0.9333 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 751/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4126 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 752/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4126 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 753/800\n",
            "180/180 [==============================] - 0s 393us/step - loss: 0.4126 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 754/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4125 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 755/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4128 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 756/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 757/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4125 - acc: 0.9333 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 758/800\n",
            "180/180 [==============================] - 0s 405us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 759/800\n",
            "180/180 [==============================] - 0s 409us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 760/800\n",
            "180/180 [==============================] - 0s 413us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 761/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4127 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 762/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 763/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4123 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 764/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 765/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 766/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 767/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 768/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 769/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 770/800\n",
            "180/180 [==============================] - 0s 522us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 771/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 772/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 773/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4123 - acc: 0.9333 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 774/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4123 - acc: 0.9333 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 775/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 776/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 777/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 778/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 779/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4123 - acc: 0.9333 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 780/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4123 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 781/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 782/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 783/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 784/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4125 - acc: 0.9333 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 785/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 786/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 787/800\n",
            "180/180 [==============================] - 0s 408us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 788/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.4125 - acc: 0.9333 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 789/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 790/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 791/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 792/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4125 - acc: 0.9333 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 793/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 794/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 795/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4122 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 796/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 797/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4123 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 798/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 799/800\n",
            "180/180 [==============================] - 0s 407us/step - loss: 0.4123 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 800/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "200/200 [==============================] - 0s 125us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0.43619103610515597, 0.945]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NpgVvVhsi6_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27977
        },
        "outputId": "08358b2d-e158-4cd1-a0f5-16ec9c7639a0"
      },
      "cell_type": "code",
      "source": [
        "#Results with no anomily \n",
        "# Loss and Val Loss are very close + Accuracy and Val Accuracy are very close \n",
        "# Depending on the params of the net it can hit Accuracy of  1\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "full_anom = 0\n",
        "anom_samples = 0\n",
        "batch_size = 32\n",
        "import keras\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "nadam =keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
        "\n",
        "autoencoder2.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    #loss = 'binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
        "                              patience=200,verbose = 1)\n",
        "history = autoencoder2.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "                    validation_split=.1,\n",
        "                    verbose=1,callbacks=[reduce_lr])\n",
        "score = autoencoder2.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 180 samples, validate on 20 samples\n",
            "Epoch 1/800\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 0.5234 - acc: 0.8222 - val_loss: 0.3367 - val_acc: 0.8500\n",
            "Epoch 2/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5223 - acc: 0.8667 - val_loss: 0.3346 - val_acc: 0.8500\n",
            "Epoch 3/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5219 - acc: 0.8556 - val_loss: 0.3369 - val_acc: 0.8500\n",
            "Epoch 4/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5224 - acc: 0.8556 - val_loss: 0.3338 - val_acc: 0.8500\n",
            "Epoch 5/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5214 - acc: 0.8556 - val_loss: 0.3348 - val_acc: 0.8500\n",
            "Epoch 6/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5219 - acc: 0.8500 - val_loss: 0.3343 - val_acc: 0.8000\n",
            "Epoch 7/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5220 - acc: 0.8556 - val_loss: 0.3337 - val_acc: 0.8500\n",
            "Epoch 8/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5217 - acc: 0.8611 - val_loss: 0.3345 - val_acc: 0.8500\n",
            "Epoch 9/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5217 - acc: 0.8667 - val_loss: 0.3357 - val_acc: 0.8500\n",
            "Epoch 10/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5222 - acc: 0.8611 - val_loss: 0.3337 - val_acc: 0.8500\n",
            "Epoch 11/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5213 - acc: 0.8611 - val_loss: 0.3352 - val_acc: 0.8500\n",
            "Epoch 12/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5215 - acc: 0.8667 - val_loss: 0.3337 - val_acc: 0.8500\n",
            "Epoch 13/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5210 - acc: 0.8500 - val_loss: 0.3338 - val_acc: 0.8500\n",
            "Epoch 14/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5217 - acc: 0.8556 - val_loss: 0.3335 - val_acc: 0.8500\n",
            "Epoch 15/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5214 - acc: 0.8611 - val_loss: 0.3342 - val_acc: 0.8000\n",
            "Epoch 16/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5211 - acc: 0.8389 - val_loss: 0.3345 - val_acc: 0.8500\n",
            "Epoch 17/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5209 - acc: 0.8556 - val_loss: 0.3336 - val_acc: 0.8500\n",
            "Epoch 18/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5214 - acc: 0.8722 - val_loss: 0.3341 - val_acc: 0.8500\n",
            "Epoch 19/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5219 - acc: 0.8667 - val_loss: 0.3335 - val_acc: 0.8500\n",
            "Epoch 20/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5206 - acc: 0.8611 - val_loss: 0.3346 - val_acc: 0.8000\n",
            "Epoch 21/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5215 - acc: 0.8556 - val_loss: 0.3332 - val_acc: 0.8500\n",
            "Epoch 22/800\n",
            "180/180 [==============================] - 0s 432us/step - loss: 0.5209 - acc: 0.8556 - val_loss: 0.3344 - val_acc: 0.8000\n",
            "Epoch 23/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5220 - acc: 0.8444 - val_loss: 0.3341 - val_acc: 0.8500\n",
            "Epoch 24/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5210 - acc: 0.8611 - val_loss: 0.3400 - val_acc: 0.8500\n",
            "Epoch 25/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.5231 - acc: 0.8667 - val_loss: 0.3352 - val_acc: 0.8500\n",
            "Epoch 26/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5207 - acc: 0.8611 - val_loss: 0.3336 - val_acc: 0.8500\n",
            "Epoch 27/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5205 - acc: 0.8500 - val_loss: 0.3337 - val_acc: 0.8000\n",
            "Epoch 28/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5219 - acc: 0.8389 - val_loss: 0.3343 - val_acc: 0.8500\n",
            "Epoch 29/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5204 - acc: 0.8556 - val_loss: 0.3330 - val_acc: 0.8500\n",
            "Epoch 30/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5201 - acc: 0.8500 - val_loss: 0.3337 - val_acc: 0.8500\n",
            "Epoch 31/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5206 - acc: 0.8611 - val_loss: 0.3331 - val_acc: 0.8500\n",
            "Epoch 32/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5206 - acc: 0.8444 - val_loss: 0.3368 - val_acc: 0.8500\n",
            "Epoch 33/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5212 - acc: 0.8611 - val_loss: 0.3337 - val_acc: 0.8500\n",
            "Epoch 34/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5203 - acc: 0.8722 - val_loss: 0.3343 - val_acc: 0.8500\n",
            "Epoch 35/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.5202 - acc: 0.8722 - val_loss: 0.3343 - val_acc: 0.8500\n",
            "Epoch 36/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5202 - acc: 0.8833 - val_loss: 0.3331 - val_acc: 0.8500\n",
            "Epoch 37/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5202 - acc: 0.8778 - val_loss: 0.3342 - val_acc: 0.8500\n",
            "Epoch 38/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5220 - acc: 0.8500 - val_loss: 0.3337 - val_acc: 0.8000\n",
            "Epoch 39/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5202 - acc: 0.8556 - val_loss: 0.3359 - val_acc: 0.8500\n",
            "Epoch 40/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5205 - acc: 0.8444 - val_loss: 0.3338 - val_acc: 0.8500\n",
            "Epoch 41/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5202 - acc: 0.8444 - val_loss: 0.3330 - val_acc: 0.8500\n",
            "Epoch 42/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5198 - acc: 0.8722 - val_loss: 0.3332 - val_acc: 0.8500\n",
            "Epoch 43/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.5206 - acc: 0.8389 - val_loss: 0.3332 - val_acc: 0.8500\n",
            "Epoch 44/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5199 - acc: 0.8667 - val_loss: 0.3326 - val_acc: 0.8500\n",
            "Epoch 45/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.5203 - acc: 0.8889 - val_loss: 0.3329 - val_acc: 0.8000\n",
            "Epoch 46/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5202 - acc: 0.8500 - val_loss: 0.3328 - val_acc: 0.8500\n",
            "Epoch 47/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5199 - acc: 0.8722 - val_loss: 0.3339 - val_acc: 0.8500\n",
            "Epoch 48/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5213 - acc: 0.8389 - val_loss: 0.3342 - val_acc: 0.8500\n",
            "Epoch 49/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5200 - acc: 0.8667 - val_loss: 0.3343 - val_acc: 0.8500\n",
            "Epoch 50/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5199 - acc: 0.8889 - val_loss: 0.3345 - val_acc: 0.8000\n",
            "Epoch 51/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5209 - acc: 0.8722 - val_loss: 0.3330 - val_acc: 0.8500\n",
            "Epoch 52/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5196 - acc: 0.9056 - val_loss: 0.3335 - val_acc: 0.8500\n",
            "Epoch 53/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5205 - acc: 0.8944 - val_loss: 0.3330 - val_acc: 0.8500\n",
            "Epoch 54/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5195 - acc: 0.9278 - val_loss: 0.3346 - val_acc: 0.8500\n",
            "Epoch 55/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.5208 - acc: 0.9000 - val_loss: 0.3331 - val_acc: 0.8500\n",
            "Epoch 56/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5200 - acc: 0.8778 - val_loss: 0.3364 - val_acc: 0.8500\n",
            "Epoch 57/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5203 - acc: 0.8833 - val_loss: 0.3328 - val_acc: 0.8500\n",
            "Epoch 58/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5205 - acc: 0.8556 - val_loss: 0.3338 - val_acc: 0.8000\n",
            "Epoch 59/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5198 - acc: 0.8500 - val_loss: 0.3328 - val_acc: 0.8000\n",
            "Epoch 60/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5196 - acc: 0.9000 - val_loss: 0.3344 - val_acc: 0.8500\n",
            "Epoch 61/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5198 - acc: 0.9000 - val_loss: 0.3328 - val_acc: 0.8500\n",
            "Epoch 62/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5195 - acc: 0.9000 - val_loss: 0.3329 - val_acc: 0.8500\n",
            "Epoch 63/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.5192 - acc: 0.9056 - val_loss: 0.3323 - val_acc: 0.8500\n",
            "Epoch 64/800\n",
            "180/180 [==============================] - 0s 337us/step - loss: 0.5193 - acc: 0.8944 - val_loss: 0.3334 - val_acc: 0.8000\n",
            "Epoch 65/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5215 - acc: 0.8944 - val_loss: 0.3335 - val_acc: 0.8500\n",
            "Epoch 66/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5193 - acc: 0.8833 - val_loss: 0.3336 - val_acc: 0.8500\n",
            "Epoch 67/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5200 - acc: 0.9000 - val_loss: 0.3331 - val_acc: 0.8500\n",
            "Epoch 68/800\n",
            "180/180 [==============================] - 0s 324us/step - loss: 0.5202 - acc: 0.8722 - val_loss: 0.3332 - val_acc: 0.8500\n",
            "Epoch 69/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.5198 - acc: 0.9167 - val_loss: 0.3325 - val_acc: 0.8500\n",
            "Epoch 70/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5194 - acc: 0.8833 - val_loss: 0.3328 - val_acc: 0.8500\n",
            "Epoch 71/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.5191 - acc: 0.9278 - val_loss: 0.3325 - val_acc: 0.8500\n",
            "Epoch 72/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5197 - acc: 0.9389 - val_loss: 0.3327 - val_acc: 0.8500\n",
            "Epoch 73/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5196 - acc: 0.9389 - val_loss: 0.3352 - val_acc: 0.8000\n",
            "Epoch 74/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5217 - acc: 0.9111 - val_loss: 0.3397 - val_acc: 0.8500\n",
            "Epoch 75/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5264 - acc: 0.8889 - val_loss: 0.3325 - val_acc: 0.8000\n",
            "Epoch 76/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5194 - acc: 0.9278 - val_loss: 0.3331 - val_acc: 0.9000\n",
            "Epoch 77/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5191 - acc: 0.9222 - val_loss: 0.3325 - val_acc: 0.9000\n",
            "Epoch 78/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.5189 - acc: 0.9500 - val_loss: 0.3338 - val_acc: 0.8000\n",
            "Epoch 79/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.5192 - acc: 0.9444 - val_loss: 0.3346 - val_acc: 0.8500\n",
            "Epoch 80/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5191 - acc: 0.9278 - val_loss: 0.3341 - val_acc: 0.8500\n",
            "Epoch 81/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5192 - acc: 0.9500 - val_loss: 0.3324 - val_acc: 0.8500\n",
            "Epoch 82/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5192 - acc: 0.9500 - val_loss: 0.3325 - val_acc: 0.8500\n",
            "Epoch 83/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5188 - acc: 0.9278 - val_loss: 0.3337 - val_acc: 0.8000\n",
            "Epoch 84/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5191 - acc: 0.9500 - val_loss: 0.3327 - val_acc: 0.8500\n",
            "Epoch 85/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5194 - acc: 0.9111 - val_loss: 0.3334 - val_acc: 0.8000\n",
            "Epoch 86/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.5188 - acc: 0.9389 - val_loss: 0.3345 - val_acc: 0.8500\n",
            "Epoch 87/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5189 - acc: 0.9333 - val_loss: 0.3328 - val_acc: 0.8500\n",
            "Epoch 88/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5186 - acc: 0.9444 - val_loss: 0.3326 - val_acc: 0.8500\n",
            "Epoch 89/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5189 - acc: 0.9556 - val_loss: 0.3331 - val_acc: 0.8500\n",
            "Epoch 90/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5187 - acc: 0.9389 - val_loss: 0.3345 - val_acc: 0.8000\n",
            "Epoch 91/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.5189 - acc: 0.9222 - val_loss: 0.3343 - val_acc: 0.8500\n",
            "Epoch 92/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5186 - acc: 0.9500 - val_loss: 0.3360 - val_acc: 0.8500\n",
            "Epoch 93/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5190 - acc: 0.9389 - val_loss: 0.3334 - val_acc: 0.8500\n",
            "Epoch 94/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.5186 - acc: 0.9556 - val_loss: 0.3318 - val_acc: 0.8500\n",
            "Epoch 95/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5190 - acc: 0.9444 - val_loss: 0.3363 - val_acc: 0.8500\n",
            "Epoch 96/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5199 - acc: 0.9111 - val_loss: 0.3329 - val_acc: 0.9000\n",
            "Epoch 97/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5184 - acc: 0.9500 - val_loss: 0.3327 - val_acc: 0.9000\n",
            "Epoch 98/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5184 - acc: 0.9389 - val_loss: 0.3333 - val_acc: 0.9000\n",
            "Epoch 99/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5183 - acc: 0.9444 - val_loss: 0.3326 - val_acc: 0.9000\n",
            "Epoch 100/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5188 - acc: 0.9389 - val_loss: 0.3321 - val_acc: 0.9000\n",
            "Epoch 101/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5191 - acc: 0.9333 - val_loss: 0.3327 - val_acc: 0.9000\n",
            "Epoch 102/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5183 - acc: 0.9556 - val_loss: 0.3320 - val_acc: 0.9000\n",
            "Epoch 103/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5184 - acc: 0.9333 - val_loss: 0.3325 - val_acc: 0.9000\n",
            "Epoch 104/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5183 - acc: 0.9444 - val_loss: 0.3330 - val_acc: 0.9000\n",
            "Epoch 105/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5185 - acc: 0.9500 - val_loss: 0.3322 - val_acc: 0.9000\n",
            "Epoch 106/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5183 - acc: 0.9444 - val_loss: 0.3327 - val_acc: 0.8500\n",
            "Epoch 107/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5184 - acc: 0.9389 - val_loss: 0.3322 - val_acc: 0.9000\n",
            "Epoch 108/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.5184 - acc: 0.9333 - val_loss: 0.3341 - val_acc: 0.9000\n",
            "Epoch 109/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5179 - acc: 0.9444 - val_loss: 0.3354 - val_acc: 0.9000\n",
            "Epoch 110/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5190 - acc: 0.9500 - val_loss: 0.3330 - val_acc: 0.9000\n",
            "Epoch 111/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5183 - acc: 0.9500 - val_loss: 0.3343 - val_acc: 0.9000\n",
            "Epoch 112/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5182 - acc: 0.9444 - val_loss: 0.3324 - val_acc: 0.9000\n",
            "Epoch 113/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5184 - acc: 0.9333 - val_loss: 0.3327 - val_acc: 0.9000\n",
            "Epoch 114/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5179 - acc: 0.9389 - val_loss: 0.3319 - val_acc: 0.8500\n",
            "Epoch 115/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5178 - acc: 0.9556 - val_loss: 0.3316 - val_acc: 0.9000\n",
            "Epoch 116/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5179 - acc: 0.9444 - val_loss: 0.3329 - val_acc: 0.8500\n",
            "Epoch 117/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5180 - acc: 0.9500 - val_loss: 0.3329 - val_acc: 0.8500\n",
            "Epoch 118/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5183 - acc: 0.9444 - val_loss: 0.3318 - val_acc: 0.9000\n",
            "Epoch 119/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5181 - acc: 0.9500 - val_loss: 0.3319 - val_acc: 0.9000\n",
            "Epoch 120/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5181 - acc: 0.9389 - val_loss: 0.3334 - val_acc: 0.9000\n",
            "Epoch 121/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5193 - acc: 0.9389 - val_loss: 0.3329 - val_acc: 0.9000\n",
            "Epoch 122/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.5181 - acc: 0.9556 - val_loss: 0.3336 - val_acc: 0.8500\n",
            "Epoch 123/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5181 - acc: 0.9500 - val_loss: 0.3369 - val_acc: 0.9000\n",
            "Epoch 124/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5196 - acc: 0.9389 - val_loss: 0.3326 - val_acc: 0.9000\n",
            "Epoch 125/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5178 - acc: 0.9389 - val_loss: 0.3333 - val_acc: 0.9000\n",
            "Epoch 126/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5179 - acc: 0.9500 - val_loss: 0.3324 - val_acc: 0.9000\n",
            "Epoch 127/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5176 - acc: 0.9389 - val_loss: 0.3316 - val_acc: 0.9000\n",
            "Epoch 128/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5177 - acc: 0.9111 - val_loss: 0.3323 - val_acc: 0.8500\n",
            "Epoch 129/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5184 - acc: 0.9333 - val_loss: 0.3361 - val_acc: 0.9000\n",
            "Epoch 130/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.5204 - acc: 0.9278 - val_loss: 0.3322 - val_acc: 0.9000\n",
            "Epoch 131/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.5176 - acc: 0.9222 - val_loss: 0.3346 - val_acc: 0.9000\n",
            "Epoch 132/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5188 - acc: 0.9389 - val_loss: 0.3339 - val_acc: 0.9000\n",
            "Epoch 133/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5191 - acc: 0.9333 - val_loss: 0.3323 - val_acc: 0.9000\n",
            "Epoch 134/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5175 - acc: 0.9556 - val_loss: 0.3324 - val_acc: 0.9000\n",
            "Epoch 135/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5178 - acc: 0.9444 - val_loss: 0.3318 - val_acc: 0.9000\n",
            "Epoch 136/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5182 - acc: 0.9389 - val_loss: 0.3326 - val_acc: 0.9000\n",
            "Epoch 137/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.5172 - acc: 0.9500 - val_loss: 0.3322 - val_acc: 0.9000\n",
            "Epoch 138/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5181 - acc: 0.9389 - val_loss: 0.3324 - val_acc: 0.9000\n",
            "Epoch 139/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5176 - acc: 0.9444 - val_loss: 0.3316 - val_acc: 0.8500\n",
            "Epoch 140/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5174 - acc: 0.9333 - val_loss: 0.3336 - val_acc: 0.9500\n",
            "Epoch 141/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5175 - acc: 0.9333 - val_loss: 0.3314 - val_acc: 0.9000\n",
            "Epoch 142/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5179 - acc: 0.9444 - val_loss: 0.3332 - val_acc: 0.9000\n",
            "Epoch 143/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5177 - acc: 0.9556 - val_loss: 0.3343 - val_acc: 0.9500\n",
            "Epoch 144/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5174 - acc: 0.9500 - val_loss: 0.3324 - val_acc: 0.8500\n",
            "Epoch 145/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5177 - acc: 0.9556 - val_loss: 0.3326 - val_acc: 0.9500\n",
            "Epoch 146/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5173 - acc: 0.9667 - val_loss: 0.3341 - val_acc: 0.9500\n",
            "Epoch 147/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5175 - acc: 0.9333 - val_loss: 0.3319 - val_acc: 0.9500\n",
            "Epoch 148/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5175 - acc: 0.9556 - val_loss: 0.3326 - val_acc: 0.9000\n",
            "Epoch 149/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.5183 - acc: 0.9278 - val_loss: 0.3333 - val_acc: 0.9500\n",
            "Epoch 150/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5174 - acc: 0.9444 - val_loss: 0.3313 - val_acc: 0.9000\n",
            "Epoch 151/800\n",
            "180/180 [==============================] - 0s 328us/step - loss: 0.5174 - acc: 0.9389 - val_loss: 0.3320 - val_acc: 0.9500\n",
            "Epoch 152/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.5171 - acc: 0.9556 - val_loss: 0.3315 - val_acc: 0.9500\n",
            "Epoch 153/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.5174 - acc: 0.9556 - val_loss: 0.3317 - val_acc: 0.9500\n",
            "Epoch 154/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5177 - acc: 0.9444 - val_loss: 0.3334 - val_acc: 0.9500\n",
            "Epoch 155/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5176 - acc: 0.9389 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 156/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5173 - acc: 0.9500 - val_loss: 0.3315 - val_acc: 0.9000\n",
            "Epoch 157/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5173 - acc: 0.9500 - val_loss: 0.3336 - val_acc: 0.9500\n",
            "Epoch 158/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5174 - acc: 0.9333 - val_loss: 0.3315 - val_acc: 0.9500\n",
            "Epoch 159/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5177 - acc: 0.9500 - val_loss: 0.3314 - val_acc: 0.9500\n",
            "Epoch 160/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5171 - acc: 0.9444 - val_loss: 0.3309 - val_acc: 0.9500\n",
            "Epoch 161/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5180 - acc: 0.9278 - val_loss: 0.3319 - val_acc: 0.9500\n",
            "Epoch 162/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5170 - acc: 0.9500 - val_loss: 0.3329 - val_acc: 0.9500\n",
            "Epoch 163/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5170 - acc: 0.9278 - val_loss: 0.3319 - val_acc: 0.9500\n",
            "Epoch 164/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5177 - acc: 0.9444 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 165/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5168 - acc: 0.9500 - val_loss: 0.3320 - val_acc: 0.9500\n",
            "Epoch 166/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5171 - acc: 0.9500 - val_loss: 0.3335 - val_acc: 0.9500\n",
            "Epoch 167/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5172 - acc: 0.9556 - val_loss: 0.3334 - val_acc: 0.9500\n",
            "Epoch 168/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5174 - acc: 0.9333 - val_loss: 0.3316 - val_acc: 0.9500\n",
            "Epoch 169/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5172 - acc: 0.9333 - val_loss: 0.3322 - val_acc: 0.9500\n",
            "Epoch 170/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5168 - acc: 0.9611 - val_loss: 0.3317 - val_acc: 0.9500\n",
            "Epoch 171/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5170 - acc: 0.9556 - val_loss: 0.3325 - val_acc: 0.9500\n",
            "Epoch 172/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5175 - acc: 0.9444 - val_loss: 0.3367 - val_acc: 0.9500\n",
            "Epoch 173/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.5178 - acc: 0.9556 - val_loss: 0.3331 - val_acc: 0.9500\n",
            "Epoch 174/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5182 - acc: 0.9444 - val_loss: 0.3332 - val_acc: 0.9500\n",
            "Epoch 175/800\n",
            "180/180 [==============================] - 0s 324us/step - loss: 0.5169 - acc: 0.9444 - val_loss: 0.3323 - val_acc: 0.9500\n",
            "Epoch 176/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5172 - acc: 0.9611 - val_loss: 0.3322 - val_acc: 0.9000\n",
            "Epoch 177/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5168 - acc: 0.9556 - val_loss: 0.3333 - val_acc: 0.9000\n",
            "Epoch 178/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5181 - acc: 0.9389 - val_loss: 0.3337 - val_acc: 0.9000\n",
            "Epoch 179/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5177 - acc: 0.9278 - val_loss: 0.3318 - val_acc: 0.9000\n",
            "Epoch 180/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5172 - acc: 0.9444 - val_loss: 0.3327 - val_acc: 0.9500\n",
            "Epoch 181/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5167 - acc: 0.9444 - val_loss: 0.3328 - val_acc: 0.9500\n",
            "Epoch 182/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5175 - acc: 0.9389 - val_loss: 0.3331 - val_acc: 0.9000\n",
            "Epoch 183/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5181 - acc: 0.9333 - val_loss: 0.3334 - val_acc: 0.9500\n",
            "Epoch 184/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5164 - acc: 0.9611 - val_loss: 0.3306 - val_acc: 0.9500\n",
            "Epoch 185/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5169 - acc: 0.9556 - val_loss: 0.3308 - val_acc: 0.9500\n",
            "Epoch 186/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.5165 - acc: 0.9556 - val_loss: 0.3332 - val_acc: 0.9000\n",
            "Epoch 187/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5178 - acc: 0.9222 - val_loss: 0.3309 - val_acc: 0.9500\n",
            "Epoch 188/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5169 - acc: 0.9389 - val_loss: 0.3324 - val_acc: 0.9000\n",
            "Epoch 189/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5173 - acc: 0.9556 - val_loss: 0.3318 - val_acc: 0.9500\n",
            "Epoch 190/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5172 - acc: 0.9556 - val_loss: 0.3312 - val_acc: 0.9500\n",
            "Epoch 191/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5178 - acc: 0.9556 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 192/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5181 - acc: 0.9556 - val_loss: 0.3315 - val_acc: 0.9500\n",
            "Epoch 193/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5162 - acc: 0.9556 - val_loss: 0.3311 - val_acc: 0.9500\n",
            "Epoch 194/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5168 - acc: 0.9500 - val_loss: 0.3325 - val_acc: 0.9500\n",
            "Epoch 195/800\n",
            "180/180 [==============================] - 0s 412us/step - loss: 0.5177 - acc: 0.9389 - val_loss: 0.3377 - val_acc: 0.9000\n",
            "Epoch 196/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5175 - acc: 0.9500 - val_loss: 0.3308 - val_acc: 0.9500\n",
            "Epoch 197/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5168 - acc: 0.9444 - val_loss: 0.3322 - val_acc: 0.9500\n",
            "Epoch 198/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.5165 - acc: 0.9667 - val_loss: 0.3317 - val_acc: 0.9500\n",
            "Epoch 199/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5171 - acc: 0.9500 - val_loss: 0.3322 - val_acc: 0.9500\n",
            "Epoch 200/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5170 - acc: 0.9556 - val_loss: 0.3314 - val_acc: 1.0000\n",
            "Epoch 201/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5165 - acc: 0.9278 - val_loss: 0.3320 - val_acc: 0.9000\n",
            "Epoch 202/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5170 - acc: 0.9500 - val_loss: 0.3309 - val_acc: 0.9000\n",
            "Epoch 203/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5164 - acc: 0.9611 - val_loss: 0.3324 - val_acc: 0.9000\n",
            "Epoch 204/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.5165 - acc: 0.9444 - val_loss: 0.3327 - val_acc: 0.9500\n",
            "Epoch 205/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5161 - acc: 0.9500 - val_loss: 0.3307 - val_acc: 0.9500\n",
            "Epoch 206/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5177 - acc: 0.9333 - val_loss: 0.3365 - val_acc: 0.9500\n",
            "Epoch 207/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5175 - acc: 0.9444 - val_loss: 0.3300 - val_acc: 0.9500\n",
            "Epoch 208/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5164 - acc: 0.9611 - val_loss: 0.3308 - val_acc: 0.9500\n",
            "Epoch 209/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.5162 - acc: 0.9556 - val_loss: 0.3300 - val_acc: 0.9500\n",
            "Epoch 210/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5164 - acc: 0.9556 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 211/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5168 - acc: 0.9444 - val_loss: 0.3327 - val_acc: 0.9000\n",
            "Epoch 212/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5171 - acc: 0.9444 - val_loss: 0.3320 - val_acc: 0.9500\n",
            "Epoch 213/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5162 - acc: 0.9556 - val_loss: 0.3318 - val_acc: 1.0000\n",
            "Epoch 214/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5167 - acc: 0.9500 - val_loss: 0.3346 - val_acc: 0.9000\n",
            "Epoch 215/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5168 - acc: 0.9444 - val_loss: 0.3327 - val_acc: 0.9500\n",
            "Epoch 216/800\n",
            "180/180 [==============================] - 0s 328us/step - loss: 0.5162 - acc: 0.9556 - val_loss: 0.3305 - val_acc: 0.9500\n",
            "Epoch 217/800\n",
            "180/180 [==============================] - 0s 334us/step - loss: 0.5162 - acc: 0.9611 - val_loss: 0.3405 - val_acc: 0.9000\n",
            "Epoch 218/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5191 - acc: 0.9444 - val_loss: 0.3352 - val_acc: 0.9000\n",
            "Epoch 219/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5169 - acc: 0.9500 - val_loss: 0.3307 - val_acc: 0.9500\n",
            "Epoch 220/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5172 - acc: 0.9500 - val_loss: 0.3326 - val_acc: 0.9500\n",
            "Epoch 221/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5169 - acc: 0.9556 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 222/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5162 - acc: 0.9556 - val_loss: 0.3319 - val_acc: 0.9500\n",
            "Epoch 223/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5174 - acc: 0.9556 - val_loss: 0.3303 - val_acc: 0.9000\n",
            "Epoch 224/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5167 - acc: 0.9556 - val_loss: 0.3311 - val_acc: 0.9500\n",
            "Epoch 225/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5159 - acc: 0.9556 - val_loss: 0.3317 - val_acc: 0.9000\n",
            "Epoch 226/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5165 - acc: 0.9556 - val_loss: 0.3318 - val_acc: 0.9000\n",
            "Epoch 227/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5167 - acc: 0.9611 - val_loss: 0.3321 - val_acc: 0.9500\n",
            "Epoch 228/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5161 - acc: 0.9611 - val_loss: 0.3308 - val_acc: 0.9500\n",
            "Epoch 229/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.5155 - acc: 0.9611 - val_loss: 0.3310 - val_acc: 0.9000\n",
            "Epoch 230/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5157 - acc: 0.9500 - val_loss: 0.3298 - val_acc: 0.9500\n",
            "Epoch 231/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5163 - acc: 0.9667 - val_loss: 0.3301 - val_acc: 0.9500\n",
            "Epoch 232/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5167 - acc: 0.9500 - val_loss: 0.3320 - val_acc: 0.9500\n",
            "Epoch 233/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5159 - acc: 0.9611 - val_loss: 0.3303 - val_acc: 0.9500\n",
            "Epoch 234/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5157 - acc: 0.9778 - val_loss: 0.3325 - val_acc: 0.9500\n",
            "Epoch 235/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5163 - acc: 0.9722 - val_loss: 0.3304 - val_acc: 0.9500\n",
            "Epoch 236/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5163 - acc: 0.9611 - val_loss: 0.3304 - val_acc: 0.8500\n",
            "Epoch 237/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5171 - acc: 0.9444 - val_loss: 0.3318 - val_acc: 0.9500\n",
            "Epoch 238/800\n",
            "180/180 [==============================] - 0s 410us/step - loss: 0.5167 - acc: 0.9444 - val_loss: 0.3310 - val_acc: 0.9500\n",
            "Epoch 239/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5157 - acc: 0.9611 - val_loss: 0.3318 - val_acc: 0.9500\n",
            "Epoch 240/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.5165 - acc: 0.9611 - val_loss: 0.3309 - val_acc: 0.9500\n",
            "Epoch 241/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5159 - acc: 0.9500 - val_loss: 0.3298 - val_acc: 0.9000\n",
            "Epoch 242/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5158 - acc: 0.9611 - val_loss: 0.3340 - val_acc: 0.9000\n",
            "Epoch 243/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5158 - acc: 0.9556 - val_loss: 0.3327 - val_acc: 0.9000\n",
            "Epoch 244/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5163 - acc: 0.9500 - val_loss: 0.3303 - val_acc: 0.9500\n",
            "Epoch 245/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5181 - acc: 0.9444 - val_loss: 0.3305 - val_acc: 0.9000\n",
            "Epoch 246/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5161 - acc: 0.9722 - val_loss: 0.3300 - val_acc: 0.9500\n",
            "Epoch 247/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5157 - acc: 0.9500 - val_loss: 0.3306 - val_acc: 1.0000\n",
            "Epoch 248/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5157 - acc: 0.9667 - val_loss: 0.3327 - val_acc: 0.9500\n",
            "Epoch 249/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5189 - acc: 0.9389 - val_loss: 0.3298 - val_acc: 0.9500\n",
            "Epoch 250/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5157 - acc: 0.9611 - val_loss: 0.3307 - val_acc: 0.9500\n",
            "Epoch 251/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5169 - acc: 0.9500 - val_loss: 0.3303 - val_acc: 0.9500\n",
            "Epoch 252/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5156 - acc: 0.9556 - val_loss: 0.3296 - val_acc: 0.9500\n",
            "Epoch 253/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5165 - acc: 0.9667 - val_loss: 0.3296 - val_acc: 0.9500\n",
            "Epoch 254/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5156 - acc: 0.9778 - val_loss: 0.3321 - val_acc: 0.9500\n",
            "Epoch 255/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5162 - acc: 0.9444 - val_loss: 0.3333 - val_acc: 0.9000\n",
            "Epoch 256/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5156 - acc: 0.9556 - val_loss: 0.3327 - val_acc: 0.9000\n",
            "Epoch 257/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5162 - acc: 0.9389 - val_loss: 0.3311 - val_acc: 0.9000\n",
            "Epoch 258/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5158 - acc: 0.9667 - val_loss: 0.3327 - val_acc: 0.9500\n",
            "Epoch 259/800\n",
            "180/180 [==============================] - 0s 335us/step - loss: 0.5151 - acc: 0.9722 - val_loss: 0.3315 - val_acc: 0.9500\n",
            "Epoch 260/800\n",
            "180/180 [==============================] - 0s 337us/step - loss: 0.5158 - acc: 0.9500 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 261/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5157 - acc: 0.9556 - val_loss: 0.3302 - val_acc: 1.0000\n",
            "Epoch 262/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5154 - acc: 0.9500 - val_loss: 0.3301 - val_acc: 0.9500\n",
            "Epoch 263/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5163 - acc: 0.9556 - val_loss: 0.3302 - val_acc: 0.9500\n",
            "Epoch 264/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5154 - acc: 0.9611 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 265/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5152 - acc: 0.9556 - val_loss: 0.3312 - val_acc: 0.9500\n",
            "Epoch 266/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5168 - acc: 0.9500 - val_loss: 0.3372 - val_acc: 0.9000\n",
            "Epoch 267/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.5182 - acc: 0.9222 - val_loss: 0.3305 - val_acc: 0.9500\n",
            "Epoch 268/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5155 - acc: 0.9611 - val_loss: 0.3295 - val_acc: 1.0000\n",
            "Epoch 269/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5153 - acc: 0.9556 - val_loss: 0.3299 - val_acc: 1.0000\n",
            "Epoch 270/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.5148 - acc: 0.9722 - val_loss: 0.3308 - val_acc: 0.9500\n",
            "Epoch 271/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5154 - acc: 0.9389 - val_loss: 0.3316 - val_acc: 0.9000\n",
            "Epoch 272/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5155 - acc: 0.9722 - val_loss: 0.3336 - val_acc: 0.9000\n",
            "Epoch 273/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5155 - acc: 0.9556 - val_loss: 0.3303 - val_acc: 1.0000\n",
            "Epoch 274/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5150 - acc: 0.9722 - val_loss: 0.3305 - val_acc: 0.9500\n",
            "Epoch 275/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5155 - acc: 0.9611 - val_loss: 0.3294 - val_acc: 1.0000\n",
            "Epoch 276/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5154 - acc: 0.9444 - val_loss: 0.3302 - val_acc: 1.0000\n",
            "Epoch 277/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5149 - acc: 0.9611 - val_loss: 0.3302 - val_acc: 0.9500\n",
            "Epoch 278/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5155 - acc: 0.9500 - val_loss: 0.3298 - val_acc: 0.9000\n",
            "Epoch 279/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.5154 - acc: 0.9500 - val_loss: 0.3314 - val_acc: 0.9500\n",
            "Epoch 280/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5152 - acc: 0.9611 - val_loss: 0.3297 - val_acc: 0.9500\n",
            "Epoch 281/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.5158 - acc: 0.9611 - val_loss: 0.3304 - val_acc: 0.9000\n",
            "Epoch 282/800\n",
            "180/180 [==============================] - 0s 323us/step - loss: 0.5154 - acc: 0.9611 - val_loss: 0.3297 - val_acc: 0.9500\n",
            "Epoch 283/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5152 - acc: 0.9722 - val_loss: 0.3302 - val_acc: 0.9500\n",
            "Epoch 284/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5147 - acc: 0.9611 - val_loss: 0.3309 - val_acc: 0.9500\n",
            "Epoch 285/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.5150 - acc: 0.9611 - val_loss: 0.3298 - val_acc: 0.9500\n",
            "Epoch 286/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5149 - acc: 0.9556 - val_loss: 0.3299 - val_acc: 0.9500\n",
            "Epoch 287/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5157 - acc: 0.9667 - val_loss: 0.3317 - val_acc: 0.9000\n",
            "Epoch 288/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5154 - acc: 0.9444 - val_loss: 0.3309 - val_acc: 0.9500\n",
            "Epoch 289/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5154 - acc: 0.9444 - val_loss: 0.3318 - val_acc: 0.9000\n",
            "Epoch 290/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5163 - acc: 0.9444 - val_loss: 0.3303 - val_acc: 0.9500\n",
            "Epoch 291/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5154 - acc: 0.9444 - val_loss: 0.3302 - val_acc: 0.9500\n",
            "Epoch 292/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5148 - acc: 0.9667 - val_loss: 0.3333 - val_acc: 0.9000\n",
            "Epoch 293/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.5153 - acc: 0.9611 - val_loss: 0.3316 - val_acc: 0.9500\n",
            "Epoch 294/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5162 - acc: 0.9722 - val_loss: 0.3319 - val_acc: 0.9500\n",
            "Epoch 295/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5154 - acc: 0.9611 - val_loss: 0.3310 - val_acc: 0.9500\n",
            "Epoch 296/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5149 - acc: 0.9500 - val_loss: 0.3347 - val_acc: 0.9500\n",
            "Epoch 297/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5162 - acc: 0.9444 - val_loss: 0.3299 - val_acc: 0.9000\n",
            "Epoch 298/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5147 - acc: 0.9556 - val_loss: 0.3305 - val_acc: 0.9000\n",
            "Epoch 299/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5151 - acc: 0.9556 - val_loss: 0.3311 - val_acc: 0.9500\n",
            "Epoch 300/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5156 - acc: 0.9667 - val_loss: 0.3311 - val_acc: 0.9500\n",
            "Epoch 301/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.5157 - acc: 0.9278 - val_loss: 0.3322 - val_acc: 0.9500\n",
            "Epoch 302/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.5160 - acc: 0.9500 - val_loss: 0.3306 - val_acc: 0.9500\n",
            "Epoch 303/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.5151 - acc: 0.9611 - val_loss: 0.3288 - val_acc: 0.9500\n",
            "Epoch 304/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.5148 - acc: 0.9611 - val_loss: 0.3285 - val_acc: 0.9500\n",
            "Epoch 305/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5148 - acc: 0.9556 - val_loss: 0.3290 - val_acc: 1.0000\n",
            "Epoch 306/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5148 - acc: 0.9500 - val_loss: 0.3319 - val_acc: 1.0000\n",
            "Epoch 307/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5157 - acc: 0.9556 - val_loss: 0.3303 - val_acc: 0.9500\n",
            "Epoch 308/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5149 - acc: 0.9722 - val_loss: 0.3305 - val_acc: 1.0000\n",
            "Epoch 309/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5146 - acc: 0.9667 - val_loss: 0.3301 - val_acc: 0.9000\n",
            "Epoch 310/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5171 - acc: 0.9611 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 311/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5147 - acc: 0.9389 - val_loss: 0.3299 - val_acc: 0.9500\n",
            "Epoch 312/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5146 - acc: 0.9500 - val_loss: 0.3300 - val_acc: 0.9500\n",
            "Epoch 313/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.5146 - acc: 0.9611 - val_loss: 0.3288 - val_acc: 1.0000\n",
            "Epoch 314/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5145 - acc: 0.9500 - val_loss: 0.3290 - val_acc: 0.9500\n",
            "Epoch 315/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5148 - acc: 0.9500 - val_loss: 0.3294 - val_acc: 1.0000\n",
            "Epoch 316/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5153 - acc: 0.9389 - val_loss: 0.3285 - val_acc: 0.9500\n",
            "Epoch 317/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5143 - acc: 0.9500 - val_loss: 0.3294 - val_acc: 1.0000\n",
            "Epoch 318/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5149 - acc: 0.9667 - val_loss: 0.3304 - val_acc: 0.9500\n",
            "Epoch 319/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5145 - acc: 0.9611 - val_loss: 0.3290 - val_acc: 0.9500\n",
            "Epoch 320/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.5143 - acc: 0.9556 - val_loss: 0.3300 - val_acc: 0.9500\n",
            "Epoch 321/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5151 - acc: 0.9389 - val_loss: 0.3300 - val_acc: 0.9000\n",
            "Epoch 322/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5146 - acc: 0.9556 - val_loss: 0.3294 - val_acc: 0.9500\n",
            "Epoch 323/800\n",
            "180/180 [==============================] - 0s 414us/step - loss: 0.5147 - acc: 0.9667 - val_loss: 0.3287 - val_acc: 1.0000\n",
            "Epoch 324/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.5146 - acc: 0.9611 - val_loss: 0.3294 - val_acc: 0.9000\n",
            "Epoch 325/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5141 - acc: 0.9722 - val_loss: 0.3285 - val_acc: 0.9500\n",
            "Epoch 326/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.5150 - acc: 0.9667 - val_loss: 0.3284 - val_acc: 1.0000\n",
            "Epoch 327/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.5148 - acc: 0.9500 - val_loss: 0.3301 - val_acc: 0.9500\n",
            "Epoch 328/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5147 - acc: 0.9611 - val_loss: 0.3293 - val_acc: 0.9500\n",
            "Epoch 329/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.5139 - acc: 0.9611 - val_loss: 0.3316 - val_acc: 0.9000\n",
            "Epoch 330/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5153 - acc: 0.9611 - val_loss: 0.3306 - val_acc: 0.9500\n",
            "Epoch 331/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5145 - acc: 0.9333 - val_loss: 0.3313 - val_acc: 0.9000\n",
            "Epoch 332/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5149 - acc: 0.9611 - val_loss: 0.3304 - val_acc: 0.9500\n",
            "Epoch 333/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5148 - acc: 0.9722 - val_loss: 0.3320 - val_acc: 0.9500\n",
            "Epoch 334/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5155 - acc: 0.9667 - val_loss: 0.3285 - val_acc: 1.0000\n",
            "Epoch 335/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5142 - acc: 0.9722 - val_loss: 0.3286 - val_acc: 1.0000\n",
            "Epoch 336/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5137 - acc: 0.9667 - val_loss: 0.3281 - val_acc: 0.9500\n",
            "Epoch 337/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5137 - acc: 0.9556 - val_loss: 0.3291 - val_acc: 1.0000\n",
            "Epoch 338/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5147 - acc: 0.9667 - val_loss: 0.3278 - val_acc: 1.0000\n",
            "Epoch 339/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5145 - acc: 0.9556 - val_loss: 0.3290 - val_acc: 0.9500\n",
            "Epoch 340/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5150 - acc: 0.9389 - val_loss: 0.3335 - val_acc: 0.9000\n",
            "Epoch 341/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5145 - acc: 0.9611 - val_loss: 0.3302 - val_acc: 0.9000\n",
            "Epoch 342/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5140 - acc: 0.9333 - val_loss: 0.3301 - val_acc: 0.9500\n",
            "Epoch 343/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5144 - acc: 0.9611 - val_loss: 0.3297 - val_acc: 0.9500\n",
            "Epoch 344/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.5141 - acc: 0.9722 - val_loss: 0.3301 - val_acc: 0.9500\n",
            "Epoch 345/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5142 - acc: 0.9667 - val_loss: 0.3288 - val_acc: 1.0000\n",
            "Epoch 346/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5144 - acc: 0.9500 - val_loss: 0.3285 - val_acc: 1.0000\n",
            "Epoch 347/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5143 - acc: 0.9556 - val_loss: 0.3299 - val_acc: 0.9500\n",
            "Epoch 348/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5140 - acc: 0.9667 - val_loss: 0.3285 - val_acc: 0.9500\n",
            "Epoch 349/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5151 - acc: 0.9556 - val_loss: 0.3285 - val_acc: 1.0000\n",
            "Epoch 350/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5138 - acc: 0.9611 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 351/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5144 - acc: 0.9389 - val_loss: 0.3322 - val_acc: 0.9000\n",
            "Epoch 352/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.5154 - acc: 0.9444 - val_loss: 0.3321 - val_acc: 0.9500\n",
            "Epoch 353/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5152 - acc: 0.9778 - val_loss: 0.3286 - val_acc: 0.9500\n",
            "Epoch 354/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5140 - acc: 0.9556 - val_loss: 0.3310 - val_acc: 0.9500\n",
            "Epoch 355/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5145 - acc: 0.9333 - val_loss: 0.3286 - val_acc: 1.0000\n",
            "Epoch 356/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5143 - acc: 0.9611 - val_loss: 0.3306 - val_acc: 0.9000\n",
            "Epoch 357/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5144 - acc: 0.9444 - val_loss: 0.3291 - val_acc: 0.9500\n",
            "Epoch 358/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5141 - acc: 0.9778 - val_loss: 0.3299 - val_acc: 0.9000\n",
            "Epoch 359/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5142 - acc: 0.9500 - val_loss: 0.3296 - val_acc: 0.9500\n",
            "Epoch 360/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5140 - acc: 0.9500 - val_loss: 0.3293 - val_acc: 1.0000\n",
            "Epoch 361/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5145 - acc: 0.9500 - val_loss: 0.3297 - val_acc: 0.9500\n",
            "Epoch 362/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5134 - acc: 0.9778 - val_loss: 0.3296 - val_acc: 0.9500\n",
            "Epoch 363/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5137 - acc: 0.9722 - val_loss: 0.3279 - val_acc: 1.0000\n",
            "Epoch 364/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5135 - acc: 0.9667 - val_loss: 0.3291 - val_acc: 0.9500\n",
            "Epoch 365/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.5138 - acc: 0.9722 - val_loss: 0.3305 - val_acc: 0.9500\n",
            "Epoch 366/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.5141 - acc: 0.9667 - val_loss: 0.3301 - val_acc: 0.9000\n",
            "Epoch 367/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.5150 - acc: 0.9722 - val_loss: 0.3298 - val_acc: 0.9500\n",
            "Epoch 368/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5138 - acc: 0.9667 - val_loss: 0.3315 - val_acc: 0.9000\n",
            "Epoch 369/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5148 - acc: 0.9556 - val_loss: 0.3276 - val_acc: 0.9500\n",
            "Epoch 370/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5138 - acc: 0.9611 - val_loss: 0.3288 - val_acc: 0.9000\n",
            "Epoch 371/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5136 - acc: 0.9667 - val_loss: 0.3302 - val_acc: 0.9500\n",
            "Epoch 372/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5135 - acc: 0.9556 - val_loss: 0.3286 - val_acc: 0.9500\n",
            "Epoch 373/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5132 - acc: 0.9722 - val_loss: 0.3288 - val_acc: 0.9500\n",
            "Epoch 374/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5132 - acc: 0.9611 - val_loss: 0.3280 - val_acc: 1.0000\n",
            "Epoch 375/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5135 - acc: 0.9778 - val_loss: 0.3286 - val_acc: 0.9000\n",
            "Epoch 376/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5136 - acc: 0.9611 - val_loss: 0.3285 - val_acc: 0.9500\n",
            "Epoch 377/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5151 - acc: 0.9389 - val_loss: 0.3278 - val_acc: 1.0000\n",
            "Epoch 378/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5153 - acc: 0.9389 - val_loss: 0.3294 - val_acc: 1.0000\n",
            "Epoch 379/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5137 - acc: 0.9722 - val_loss: 0.3290 - val_acc: 1.0000\n",
            "Epoch 380/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5133 - acc: 0.9611 - val_loss: 0.3306 - val_acc: 0.9500\n",
            "Epoch 381/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5138 - acc: 0.9556 - val_loss: 0.3289 - val_acc: 1.0000\n",
            "Epoch 382/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5131 - acc: 0.9556 - val_loss: 0.3279 - val_acc: 0.9500\n",
            "Epoch 383/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5126 - acc: 0.9611 - val_loss: 0.3292 - val_acc: 0.9500\n",
            "Epoch 384/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5127 - acc: 0.9500 - val_loss: 0.3284 - val_acc: 1.0000\n",
            "Epoch 385/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5128 - acc: 0.9167 - val_loss: 0.3279 - val_acc: 0.9000\n",
            "Epoch 386/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5131 - acc: 0.9333 - val_loss: 0.3273 - val_acc: 1.0000\n",
            "Epoch 387/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.5124 - acc: 0.9444 - val_loss: 0.3287 - val_acc: 0.9000\n",
            "Epoch 388/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5123 - acc: 0.9556 - val_loss: 0.3300 - val_acc: 0.9500\n",
            "Epoch 389/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5120 - acc: 0.9500 - val_loss: 0.3285 - val_acc: 0.9000\n",
            "Epoch 390/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.5124 - acc: 0.9667 - val_loss: 0.3259 - val_acc: 1.0000\n",
            "Epoch 391/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5121 - acc: 0.9556 - val_loss: 0.3296 - val_acc: 0.9500\n",
            "Epoch 392/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5142 - acc: 0.9278 - val_loss: 0.3263 - val_acc: 1.0000\n",
            "Epoch 393/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5121 - acc: 0.9444 - val_loss: 0.3273 - val_acc: 1.0000\n",
            "Epoch 394/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5119 - acc: 0.9500 - val_loss: 0.3260 - val_acc: 1.0000\n",
            "Epoch 395/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5123 - acc: 0.9500 - val_loss: 0.3371 - val_acc: 0.9000\n",
            "Epoch 396/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5147 - acc: 0.9389 - val_loss: 0.3262 - val_acc: 0.9000\n",
            "Epoch 397/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5119 - acc: 0.9556 - val_loss: 0.3260 - val_acc: 0.9500\n",
            "Epoch 398/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5121 - acc: 0.9278 - val_loss: 0.3262 - val_acc: 0.9500\n",
            "Epoch 399/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5115 - acc: 0.9389 - val_loss: 0.3260 - val_acc: 0.9000\n",
            "Epoch 400/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5116 - acc: 0.9278 - val_loss: 0.3263 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00400: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 401/800\n",
            "180/180 [==============================] - 0s 399us/step - loss: 0.5110 - acc: 0.9444 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 402/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.5106 - acc: 0.9611 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 403/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5105 - acc: 0.9611 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 404/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5105 - acc: 0.9556 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 405/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5105 - acc: 0.9556 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 406/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5105 - acc: 0.9611 - val_loss: 0.3254 - val_acc: 1.0000\n",
            "Epoch 407/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5104 - acc: 0.9556 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 408/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5104 - acc: 0.9667 - val_loss: 0.3254 - val_acc: 1.0000\n",
            "Epoch 409/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5104 - acc: 0.9500 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 410/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5104 - acc: 0.9556 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 411/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5104 - acc: 0.9611 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 412/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5104 - acc: 0.9611 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 413/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5104 - acc: 0.9556 - val_loss: 0.3253 - val_acc: 1.0000\n",
            "Epoch 414/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5103 - acc: 0.9611 - val_loss: 0.3253 - val_acc: 1.0000\n",
            "Epoch 415/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5103 - acc: 0.9500 - val_loss: 0.3251 - val_acc: 0.9500\n",
            "Epoch 416/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5103 - acc: 0.9556 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 417/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5103 - acc: 0.9444 - val_loss: 0.3250 - val_acc: 1.0000\n",
            "Epoch 418/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5103 - acc: 0.9611 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 419/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.5103 - acc: 0.9556 - val_loss: 0.3250 - val_acc: 1.0000\n",
            "Epoch 420/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5103 - acc: 0.9556 - val_loss: 0.3250 - val_acc: 1.0000\n",
            "Epoch 421/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5103 - acc: 0.9611 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 422/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.5103 - acc: 0.9500 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 423/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.5102 - acc: 0.9556 - val_loss: 0.3250 - val_acc: 1.0000\n",
            "Epoch 424/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5102 - acc: 0.9722 - val_loss: 0.3249 - val_acc: 1.0000\n",
            "Epoch 425/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5102 - acc: 0.9667 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 426/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5102 - acc: 0.9667 - val_loss: 0.3250 - val_acc: 1.0000\n",
            "Epoch 427/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5102 - acc: 0.9667 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 428/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.5102 - acc: 0.9611 - val_loss: 0.3250 - val_acc: 1.0000\n",
            "Epoch 429/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.5101 - acc: 0.9667 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 430/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5101 - acc: 0.9611 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 431/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5101 - acc: 0.9667 - val_loss: 0.3250 - val_acc: 1.0000\n",
            "Epoch 432/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5101 - acc: 0.9667 - val_loss: 0.3249 - val_acc: 1.0000\n",
            "Epoch 433/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5100 - acc: 0.9667 - val_loss: 0.3249 - val_acc: 1.0000\n",
            "Epoch 434/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.5101 - acc: 0.9611 - val_loss: 0.3249 - val_acc: 1.0000\n",
            "Epoch 435/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5100 - acc: 0.9667 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 436/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5100 - acc: 0.9667 - val_loss: 0.3249 - val_acc: 1.0000\n",
            "Epoch 437/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5100 - acc: 0.9611 - val_loss: 0.3249 - val_acc: 1.0000\n",
            "Epoch 438/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5100 - acc: 0.9556 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 439/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5100 - acc: 0.9611 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 440/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5100 - acc: 0.9667 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 441/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5100 - acc: 0.9611 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 442/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5099 - acc: 0.9611 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 443/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5100 - acc: 0.9667 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 444/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5099 - acc: 0.9611 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 445/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.5100 - acc: 0.9722 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 446/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.5099 - acc: 0.9611 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 447/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5099 - acc: 0.9667 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 448/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5099 - acc: 0.9611 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 449/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5099 - acc: 0.9667 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 450/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5098 - acc: 0.9667 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 451/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5098 - acc: 0.9556 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 452/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5098 - acc: 0.9611 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 453/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5098 - acc: 0.9611 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 454/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5098 - acc: 0.9667 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 455/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5098 - acc: 0.9667 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 456/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5098 - acc: 0.9556 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 457/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5097 - acc: 0.9667 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 458/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5097 - acc: 0.9611 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 459/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.5097 - acc: 0.9611 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 460/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5097 - acc: 0.9667 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 461/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5097 - acc: 0.9556 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 462/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5097 - acc: 0.9667 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 463/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5097 - acc: 0.9611 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 464/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5096 - acc: 0.9667 - val_loss: 0.3245 - val_acc: 0.9500\n",
            "Epoch 465/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5097 - acc: 0.9667 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 466/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.5097 - acc: 0.9611 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 467/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.5096 - acc: 0.9500 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 468/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.5097 - acc: 0.9667 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 469/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5096 - acc: 0.9611 - val_loss: 0.3244 - val_acc: 1.0000\n",
            "Epoch 470/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5096 - acc: 0.9611 - val_loss: 0.3244 - val_acc: 1.0000\n",
            "Epoch 471/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5095 - acc: 0.9667 - val_loss: 0.3244 - val_acc: 0.9500\n",
            "Epoch 472/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5096 - acc: 0.9667 - val_loss: 0.3244 - val_acc: 0.9500\n",
            "Epoch 473/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5096 - acc: 0.9556 - val_loss: 0.3245 - val_acc: 0.9500\n",
            "Epoch 474/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5095 - acc: 0.9667 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 475/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5096 - acc: 0.9611 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 476/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5095 - acc: 0.9667 - val_loss: 0.3244 - val_acc: 1.0000\n",
            "Epoch 477/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5095 - acc: 0.9611 - val_loss: 0.3244 - val_acc: 0.9500\n",
            "Epoch 478/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5094 - acc: 0.9611 - val_loss: 0.3244 - val_acc: 0.9500\n",
            "Epoch 479/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5095 - acc: 0.9667 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 480/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5095 - acc: 0.9667 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 481/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5095 - acc: 0.9556 - val_loss: 0.3244 - val_acc: 1.0000\n",
            "Epoch 482/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5094 - acc: 0.9611 - val_loss: 0.3243 - val_acc: 0.9500\n",
            "Epoch 483/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5093 - acc: 0.9667 - val_loss: 0.3244 - val_acc: 1.0000\n",
            "Epoch 484/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5094 - acc: 0.9611 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 485/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5094 - acc: 0.9611 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 486/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5094 - acc: 0.9611 - val_loss: 0.3243 - val_acc: 1.0000\n",
            "Epoch 487/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5094 - acc: 0.9611 - val_loss: 0.3243 - val_acc: 0.9500\n",
            "Epoch 488/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5094 - acc: 0.9556 - val_loss: 0.3243 - val_acc: 1.0000\n",
            "Epoch 489/800\n",
            "180/180 [==============================] - 0s 398us/step - loss: 0.5092 - acc: 0.9556 - val_loss: 0.3243 - val_acc: 0.9500\n",
            "Epoch 490/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5093 - acc: 0.9667 - val_loss: 0.3243 - val_acc: 0.9500\n",
            "Epoch 491/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5092 - acc: 0.9611 - val_loss: 0.3244 - val_acc: 1.0000\n",
            "Epoch 492/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.5093 - acc: 0.9611 - val_loss: 0.3243 - val_acc: 1.0000\n",
            "Epoch 493/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5092 - acc: 0.9500 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 494/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5093 - acc: 0.9611 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 495/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5093 - acc: 0.9667 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 496/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5092 - acc: 0.9556 - val_loss: 0.3242 - val_acc: 0.9500\n",
            "Epoch 497/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5092 - acc: 0.9556 - val_loss: 0.3242 - val_acc: 0.9500\n",
            "Epoch 498/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5092 - acc: 0.9667 - val_loss: 0.3242 - val_acc: 0.9500\n",
            "Epoch 499/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5092 - acc: 0.9667 - val_loss: 0.3242 - val_acc: 0.9500\n",
            "Epoch 500/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5092 - acc: 0.9722 - val_loss: 0.3242 - val_acc: 1.0000\n",
            "Epoch 501/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5092 - acc: 0.9611 - val_loss: 0.3242 - val_acc: 0.9500\n",
            "Epoch 502/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5092 - acc: 0.9667 - val_loss: 0.3242 - val_acc: 0.9500\n",
            "Epoch 503/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5091 - acc: 0.9611 - val_loss: 0.3242 - val_acc: 1.0000\n",
            "Epoch 504/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5091 - acc: 0.9611 - val_loss: 0.3241 - val_acc: 0.9500\n",
            "Epoch 505/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5091 - acc: 0.9556 - val_loss: 0.3240 - val_acc: 0.9500\n",
            "Epoch 506/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5091 - acc: 0.9667 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 507/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5091 - acc: 0.9611 - val_loss: 0.3240 - val_acc: 0.9500\n",
            "Epoch 508/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5090 - acc: 0.9611 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 509/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5091 - acc: 0.9611 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 510/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.5091 - acc: 0.9611 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 511/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5091 - acc: 0.9556 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 512/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.5089 - acc: 0.9611 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 513/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5090 - acc: 0.9667 - val_loss: 0.3239 - val_acc: 1.0000\n",
            "Epoch 514/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5090 - acc: 0.9556 - val_loss: 0.3240 - val_acc: 1.0000\n",
            "Epoch 515/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5090 - acc: 0.9500 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 516/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5089 - acc: 0.9611 - val_loss: 0.3240 - val_acc: 1.0000\n",
            "Epoch 517/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5090 - acc: 0.9500 - val_loss: 0.3240 - val_acc: 1.0000\n",
            "Epoch 518/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5089 - acc: 0.9667 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 519/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.5089 - acc: 0.9556 - val_loss: 0.3240 - val_acc: 1.0000\n",
            "Epoch 520/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5089 - acc: 0.9667 - val_loss: 0.3239 - val_acc: 1.0000\n",
            "Epoch 521/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5089 - acc: 0.9611 - val_loss: 0.3240 - val_acc: 1.0000\n",
            "Epoch 522/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.5089 - acc: 0.9667 - val_loss: 0.3239 - val_acc: 1.0000\n",
            "Epoch 523/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5089 - acc: 0.9667 - val_loss: 0.3239 - val_acc: 1.0000\n",
            "Epoch 524/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5089 - acc: 0.9611 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 525/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5088 - acc: 0.9611 - val_loss: 0.3239 - val_acc: 1.0000\n",
            "Epoch 526/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5089 - acc: 0.9556 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 527/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5087 - acc: 0.9556 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 528/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5088 - acc: 0.9611 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 529/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5088 - acc: 0.9556 - val_loss: 0.3239 - val_acc: 1.0000\n",
            "Epoch 530/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5088 - acc: 0.9556 - val_loss: 0.3238 - val_acc: 0.9500\n",
            "Epoch 531/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.5087 - acc: 0.9611 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 532/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.5087 - acc: 0.9500 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 533/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5087 - acc: 0.9611 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 534/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5087 - acc: 0.9667 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 535/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5086 - acc: 0.9611 - val_loss: 0.3239 - val_acc: 1.0000\n",
            "Epoch 536/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5087 - acc: 0.9556 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 537/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.5087 - acc: 0.9556 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 538/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5087 - acc: 0.9611 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 539/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5086 - acc: 0.9667 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 540/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5086 - acc: 0.9556 - val_loss: 0.3236 - val_acc: 0.9500\n",
            "Epoch 541/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.5086 - acc: 0.9667 - val_loss: 0.3238 - val_acc: 0.9500\n",
            "Epoch 542/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5086 - acc: 0.9611 - val_loss: 0.3238 - val_acc: 0.9500\n",
            "Epoch 543/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5085 - acc: 0.9667 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 544/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5086 - acc: 0.9611 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 545/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5086 - acc: 0.9667 - val_loss: 0.3236 - val_acc: 1.0000\n",
            "Epoch 546/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5085 - acc: 0.9556 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 547/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5085 - acc: 0.9611 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 548/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5085 - acc: 0.9556 - val_loss: 0.3236 - val_acc: 1.0000\n",
            "Epoch 549/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5085 - acc: 0.9556 - val_loss: 0.3236 - val_acc: 1.0000\n",
            "Epoch 550/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5084 - acc: 0.9667 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 551/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5084 - acc: 0.9556 - val_loss: 0.3236 - val_acc: 1.0000\n",
            "Epoch 552/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5085 - acc: 0.9556 - val_loss: 0.3235 - val_acc: 1.0000\n",
            "Epoch 553/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.5085 - acc: 0.9556 - val_loss: 0.3235 - val_acc: 1.0000\n",
            "Epoch 554/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5084 - acc: 0.9611 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 555/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5083 - acc: 0.9444 - val_loss: 0.3235 - val_acc: 0.9500\n",
            "Epoch 556/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5084 - acc: 0.9667 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 557/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5084 - acc: 0.9556 - val_loss: 0.3236 - val_acc: 1.0000\n",
            "Epoch 558/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5084 - acc: 0.9444 - val_loss: 0.3235 - val_acc: 1.0000\n",
            "Epoch 559/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5083 - acc: 0.9611 - val_loss: 0.3234 - val_acc: 1.0000\n",
            "Epoch 560/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5083 - acc: 0.9556 - val_loss: 0.3235 - val_acc: 1.0000\n",
            "Epoch 561/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5083 - acc: 0.9556 - val_loss: 0.3236 - val_acc: 1.0000\n",
            "Epoch 562/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5083 - acc: 0.9444 - val_loss: 0.3235 - val_acc: 1.0000\n",
            "Epoch 563/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5083 - acc: 0.9611 - val_loss: 0.3234 - val_acc: 1.0000\n",
            "Epoch 564/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.5082 - acc: 0.9611 - val_loss: 0.3234 - val_acc: 1.0000\n",
            "Epoch 565/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5082 - acc: 0.9556 - val_loss: 0.3233 - val_acc: 1.0000\n",
            "Epoch 566/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5082 - acc: 0.9667 - val_loss: 0.3234 - val_acc: 1.0000\n",
            "Epoch 567/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5082 - acc: 0.9500 - val_loss: 0.3233 - val_acc: 1.0000\n",
            "Epoch 568/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5082 - acc: 0.9556 - val_loss: 0.3233 - val_acc: 0.9500\n",
            "Epoch 569/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5082 - acc: 0.9611 - val_loss: 0.3233 - val_acc: 1.0000\n",
            "Epoch 570/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5082 - acc: 0.9611 - val_loss: 0.3234 - val_acc: 1.0000\n",
            "Epoch 571/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5082 - acc: 0.9611 - val_loss: 0.3234 - val_acc: 1.0000\n",
            "Epoch 572/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5081 - acc: 0.9611 - val_loss: 0.3233 - val_acc: 1.0000\n",
            "Epoch 573/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5081 - acc: 0.9667 - val_loss: 0.3233 - val_acc: 1.0000\n",
            "Epoch 574/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.5082 - acc: 0.9667 - val_loss: 0.3234 - val_acc: 1.0000\n",
            "Epoch 575/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.5081 - acc: 0.9500 - val_loss: 0.3232 - val_acc: 0.9500\n",
            "Epoch 576/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5081 - acc: 0.9556 - val_loss: 0.3231 - val_acc: 0.9500\n",
            "Epoch 577/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5081 - acc: 0.9556 - val_loss: 0.3232 - val_acc: 1.0000\n",
            "Epoch 578/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5081 - acc: 0.9611 - val_loss: 0.3232 - val_acc: 1.0000\n",
            "Epoch 579/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.5079 - acc: 0.9556 - val_loss: 0.3232 - val_acc: 0.9500\n",
            "Epoch 580/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5080 - acc: 0.9611 - val_loss: 0.3233 - val_acc: 0.9500\n",
            "Epoch 581/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5080 - acc: 0.9611 - val_loss: 0.3233 - val_acc: 1.0000\n",
            "Epoch 582/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5080 - acc: 0.9556 - val_loss: 0.3231 - val_acc: 1.0000\n",
            "Epoch 583/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5080 - acc: 0.9556 - val_loss: 0.3231 - val_acc: 1.0000\n",
            "Epoch 584/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.5079 - acc: 0.9500 - val_loss: 0.3231 - val_acc: 0.9500\n",
            "Epoch 585/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5080 - acc: 0.9667 - val_loss: 0.3231 - val_acc: 1.0000\n",
            "Epoch 586/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5080 - acc: 0.9556 - val_loss: 0.3231 - val_acc: 1.0000\n",
            "Epoch 587/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5079 - acc: 0.9500 - val_loss: 0.3231 - val_acc: 0.9500\n",
            "Epoch 588/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5080 - acc: 0.9611 - val_loss: 0.3231 - val_acc: 0.9500\n",
            "Epoch 589/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5079 - acc: 0.9611 - val_loss: 0.3231 - val_acc: 0.9500\n",
            "Epoch 590/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5079 - acc: 0.9611 - val_loss: 0.3230 - val_acc: 0.9500\n",
            "Epoch 591/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5079 - acc: 0.9611 - val_loss: 0.3230 - val_acc: 1.0000\n",
            "Epoch 592/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5078 - acc: 0.9556 - val_loss: 0.3231 - val_acc: 1.0000\n",
            "Epoch 593/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5078 - acc: 0.9611 - val_loss: 0.3230 - val_acc: 1.0000\n",
            "Epoch 594/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5078 - acc: 0.9556 - val_loss: 0.3230 - val_acc: 1.0000\n",
            "Epoch 595/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5078 - acc: 0.9611 - val_loss: 0.3231 - val_acc: 1.0000\n",
            "Epoch 596/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.5077 - acc: 0.9500 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 597/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5077 - acc: 0.9611 - val_loss: 0.3230 - val_acc: 1.0000\n",
            "Epoch 598/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5077 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 599/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5077 - acc: 0.9556 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 600/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5077 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00600: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 601/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5076 - acc: 0.9556 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 602/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5076 - acc: 0.9556 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 603/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.5076 - acc: 0.9667 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 604/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5076 - acc: 0.9667 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 605/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 606/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5076 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 607/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5076 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 608/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5076 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 609/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5076 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 610/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5076 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 611/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 612/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 613/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 614/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 615/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5075 - acc: 0.9667 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 616/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 617/800\n",
            "180/180 [==============================] - 0s 415us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 618/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 619/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 620/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 621/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5075 - acc: 0.9667 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 622/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 623/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 624/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 625/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 626/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 627/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 628/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 629/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 630/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 631/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 632/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 633/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 634/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 635/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 636/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 637/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 638/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 639/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 640/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 641/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 642/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 643/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 644/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 645/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 646/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 647/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 648/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 649/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 650/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 651/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 652/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 653/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 654/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 655/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 656/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 657/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.5074 - acc: 0.9556 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 658/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 659/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 660/800\n",
            "180/180 [==============================] - 0s 406us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 661/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 662/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5074 - acc: 0.9667 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 663/800\n",
            "180/180 [==============================] - 0s 335us/step - loss: 0.5074 - acc: 0.9556 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 664/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 665/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 666/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 667/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 668/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 669/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 670/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 671/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 672/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 673/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 674/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 675/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 676/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 677/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 678/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 679/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 680/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5073 - acc: 0.9667 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 681/800\n",
            "180/180 [==============================] - 0s 427us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 682/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 683/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 684/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 685/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 686/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 687/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 688/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 689/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 690/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 691/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 692/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 693/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 694/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 695/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 696/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 697/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 698/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 699/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 700/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 701/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 702/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 703/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 704/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.5072 - acc: 0.9667 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 705/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 706/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5073 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 707/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 708/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 709/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 710/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 711/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 712/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 713/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 714/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 715/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 716/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 717/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 718/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 719/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 720/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 721/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 722/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 723/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 724/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 725/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 726/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 727/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 728/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 729/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 730/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 731/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 732/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 733/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 734/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 735/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 736/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 737/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 738/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 739/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 740/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 741/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 742/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 743/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 744/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 745/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 746/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 747/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 748/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 749/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5070 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 750/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 751/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 752/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 753/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 754/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 755/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 756/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 757/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 758/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.5071 - acc: 0.9500 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 759/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 760/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 761/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 762/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 763/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 764/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 765/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 766/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 767/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 768/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 769/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 770/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5070 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 771/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 772/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5070 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 773/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 774/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 775/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 776/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5070 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 777/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 778/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 779/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 780/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 781/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5069 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 782/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.5070 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 783/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 784/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 785/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 786/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 787/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 788/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 789/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.5070 - acc: 0.9611 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 790/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 791/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5069 - acc: 0.9611 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 792/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.5069 - acc: 0.9611 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 793/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5069 - acc: 0.9611 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 794/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.5068 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 795/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 796/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 797/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 798/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5069 - acc: 0.9611 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 799/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5069 - acc: 0.9611 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 800/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00800: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
            "200/200 [==============================] - 0s 105us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0.491057288646698, 0.93]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2OYghoPPjUKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "3fe09fa2-e4ac-4497-fd9f-1a2b90e5bae2"
      },
      "cell_type": "code",
      "source": [
        "score2 = autoencoder2.predict( x_test2, batch_size=32, verbose=1,  steps=None)\n",
        "display('[test_loss, test_acc]')\n",
        "display(score2)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 0s 74us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[-3.8262815e-03,  5.2551866e-02,  6.3689315e-01, -3.9367224e-03,\n",
              "        -1.9887458e-03, -5.4442916e-02],\n",
              "       [-5.1220238e-02,  1.1607015e-01,  5.2193403e-03, -5.1724304e-02,\n",
              "        -2.7074758e-03, -2.4022104e-02],\n",
              "       [-1.6899738e-02, -9.9430894e-03,  8.9939630e-01, -1.7122829e-02,\n",
              "         8.6482787e-01, -6.3293010e-02],\n",
              "       ...,\n",
              "       [ 6.5779042e-01, -1.3897435e-02, -4.3334248e-03,  6.5602982e-01,\n",
              "         1.2824008e+00, -1.2700321e-02],\n",
              "       [ 2.3217554e+00, -5.3286506e-03,  1.0894061e+00,  2.3337369e+00,\n",
              "         4.0560138e-01, -7.5490735e-02],\n",
              "       [ 5.7478356e-01, -8.4188534e-03, -8.7396456e-03,  5.7256198e-01,\n",
              "         7.4112201e-01,  3.1248784e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NV95xokhjZ_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "50d8e9c9-3eb0-4d64-c1fe-2cc614810850"
      },
      "cell_type": "code",
      "source": [
        "display(score2[19,:])\n",
        "display(x_test2[19,:])\n",
        "display(x_train2[2,:])\n",
        "display(x_train[3,:])\n",
        "display(x_test[0,:])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([-0.00767877, -0.00466669, -0.01181935, -0.00781828,  0.36902094,\n",
              "        1.4584022 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([-0.24763037, -0.4292751 , -1.4694093 , -0.2507984 ,  0.43348488,\n",
              "        1.4690304 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([ 0.03809295, -0.21452783, -1.0977932 ,  0.03475823,  0.21923955,\n",
              "        1.0976255 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([8.53335151e+01, 7.88288937e+01, 7.13779116e+00, 9.84570089e+03,\n",
              "       6.51875228e+03, 5.53952782e+03])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([8.53334978e+01, 7.88288768e+01, 7.14071248e+00, 9.84569969e+03,\n",
              "       6.51875426e+03, 5.53948052e+03])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Xc2dLdYL3nV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 28047
        },
        "outputId": "75761474-e04a-4cae-cb72-9e39bb853381"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Results with full anomily \n",
        "full_anom = 1 \n",
        "anom_samples = 0\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,min_lr=1e-6,min_delta=0.00001,\n",
        "                              patience=150,verbose = 1)\n",
        "# history = autoencoder.fit(x_train2, x_train2,\n",
        "#                     epochs=nb_epoch,\n",
        "#                     batch_size=batch_size,\n",
        "#                     #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "#                     validation_split=.1,\n",
        "#                     verbose=1,callbacks=[reduce_lr])\n",
        "\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
        "                               verbose=0,\n",
        "                               save_best_only=True)\n",
        "tensorboard = TensorBoard(log_dir='./logs',\n",
        "                          histogram_freq=0,\n",
        "                          write_graph=True,\n",
        "                          write_images=True)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2, x_test2),\n",
        "                    validation_split=.1,\n",
        "                    shuffle=True,\n",
        "                    verbose=1,callbacks=[reduce_lr, checkpointer, tensorboard]).history \n",
        "\n",
        "score = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 270 samples, validate on 30 samples\n",
            "Epoch 1/800\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1077 - acc: 0.9296 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 2/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1038 - acc: 0.9259 - val_loss: 0.1416 - val_acc: 0.9000\n",
            "Epoch 3/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1030 - acc: 0.9519 - val_loss: 0.1424 - val_acc: 0.8667\n",
            "Epoch 4/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1052 - acc: 0.9296 - val_loss: 0.1444 - val_acc: 0.9000\n",
            "Epoch 5/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1060 - acc: 0.9370 - val_loss: 0.1407 - val_acc: 0.9000\n",
            "Epoch 6/800\n",
            "270/270 [==============================] - 0s 370us/step - loss: 0.1037 - acc: 0.9370 - val_loss: 0.1406 - val_acc: 0.9000\n",
            "Epoch 7/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1033 - acc: 0.9407 - val_loss: 0.1423 - val_acc: 0.9000\n",
            "Epoch 8/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1037 - acc: 0.9481 - val_loss: 0.1399 - val_acc: 0.9000\n",
            "Epoch 9/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1029 - acc: 0.9407 - val_loss: 0.1419 - val_acc: 0.8667\n",
            "Epoch 10/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1036 - acc: 0.9407 - val_loss: 0.1418 - val_acc: 0.9000\n",
            "Epoch 11/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1049 - acc: 0.9333 - val_loss: 0.1452 - val_acc: 0.8667\n",
            "Epoch 12/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1052 - acc: 0.9259 - val_loss: 0.1492 - val_acc: 0.8667\n",
            "Epoch 13/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1052 - acc: 0.9333 - val_loss: 0.1408 - val_acc: 0.9333\n",
            "Epoch 14/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1036 - acc: 0.9444 - val_loss: 0.1414 - val_acc: 0.9000\n",
            "Epoch 15/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1036 - acc: 0.9407 - val_loss: 0.1436 - val_acc: 0.8667\n",
            "Epoch 16/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1055 - acc: 0.9444 - val_loss: 0.1401 - val_acc: 0.9000\n",
            "Epoch 17/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1036 - acc: 0.9333 - val_loss: 0.1416 - val_acc: 0.9000\n",
            "Epoch 18/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1050 - acc: 0.9370 - val_loss: 0.1394 - val_acc: 0.9000\n",
            "Epoch 19/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1042 - acc: 0.9556 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 20/800\n",
            "270/270 [==============================] - 0s 367us/step - loss: 0.1041 - acc: 0.9444 - val_loss: 0.1406 - val_acc: 0.9000\n",
            "Epoch 21/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1034 - acc: 0.9407 - val_loss: 0.1402 - val_acc: 0.8667\n",
            "Epoch 22/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1036 - acc: 0.9185 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 23/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1044 - acc: 0.9407 - val_loss: 0.1455 - val_acc: 0.9333\n",
            "Epoch 24/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1042 - acc: 0.9444 - val_loss: 0.1404 - val_acc: 0.9000\n",
            "Epoch 25/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1035 - acc: 0.9333 - val_loss: 0.1405 - val_acc: 0.9000\n",
            "Epoch 26/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1032 - acc: 0.9370 - val_loss: 0.1412 - val_acc: 0.9000\n",
            "Epoch 27/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1032 - acc: 0.9519 - val_loss: 0.1435 - val_acc: 0.8667\n",
            "Epoch 28/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1038 - acc: 0.9519 - val_loss: 0.1415 - val_acc: 0.8333\n",
            "Epoch 29/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1039 - acc: 0.9444 - val_loss: 0.1430 - val_acc: 0.9000\n",
            "Epoch 30/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1049 - acc: 0.9370 - val_loss: 0.1438 - val_acc: 0.9000\n",
            "Epoch 31/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1036 - acc: 0.9444 - val_loss: 0.1433 - val_acc: 0.9667\n",
            "Epoch 32/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1037 - acc: 0.9519 - val_loss: 0.1517 - val_acc: 0.8667\n",
            "Epoch 33/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1053 - acc: 0.9481 - val_loss: 0.1398 - val_acc: 0.8667\n",
            "Epoch 34/800\n",
            "270/270 [==============================] - 0s 360us/step - loss: 0.1041 - acc: 0.9444 - val_loss: 0.1419 - val_acc: 0.9000\n",
            "Epoch 35/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1036 - acc: 0.9593 - val_loss: 0.1394 - val_acc: 0.9333\n",
            "Epoch 36/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1030 - acc: 0.9370 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 37/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1040 - acc: 0.9370 - val_loss: 0.1411 - val_acc: 0.9000\n",
            "Epoch 38/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1038 - acc: 0.9333 - val_loss: 0.1409 - val_acc: 0.9000\n",
            "Epoch 39/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1033 - acc: 0.9407 - val_loss: 0.1399 - val_acc: 0.9333\n",
            "Epoch 40/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1037 - acc: 0.9481 - val_loss: 0.1441 - val_acc: 0.8333\n",
            "Epoch 41/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1039 - acc: 0.9370 - val_loss: 0.1399 - val_acc: 0.9000\n",
            "Epoch 42/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1045 - acc: 0.9481 - val_loss: 0.1454 - val_acc: 0.9333\n",
            "Epoch 43/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1070 - acc: 0.9444 - val_loss: 0.1406 - val_acc: 0.9000\n",
            "Epoch 44/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1051 - acc: 0.9370 - val_loss: 0.1434 - val_acc: 0.9000\n",
            "Epoch 45/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1045 - acc: 0.9296 - val_loss: 0.1406 - val_acc: 0.9000\n",
            "Epoch 46/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1040 - acc: 0.9556 - val_loss: 0.1409 - val_acc: 0.9000\n",
            "Epoch 47/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1035 - acc: 0.9407 - val_loss: 0.1414 - val_acc: 0.8667\n",
            "Epoch 48/800\n",
            "270/270 [==============================] - 0s 347us/step - loss: 0.1043 - acc: 0.9407 - val_loss: 0.1397 - val_acc: 0.9000\n",
            "Epoch 49/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1037 - acc: 0.9370 - val_loss: 0.1450 - val_acc: 0.9000\n",
            "Epoch 50/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1038 - acc: 0.9519 - val_loss: 0.1399 - val_acc: 0.9333\n",
            "Epoch 51/800\n",
            "270/270 [==============================] - 0s 271us/step - loss: 0.1057 - acc: 0.9333 - val_loss: 0.1429 - val_acc: 0.9000\n",
            "Epoch 52/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1034 - acc: 0.9481 - val_loss: 0.1418 - val_acc: 0.9333\n",
            "Epoch 53/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1039 - acc: 0.9444 - val_loss: 0.1409 - val_acc: 0.9333\n",
            "Epoch 54/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1045 - acc: 0.9333 - val_loss: 0.1451 - val_acc: 0.8333\n",
            "Epoch 55/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1043 - acc: 0.9444 - val_loss: 0.1396 - val_acc: 0.9000\n",
            "Epoch 56/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1035 - acc: 0.9481 - val_loss: 0.1406 - val_acc: 0.9000\n",
            "Epoch 57/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1038 - acc: 0.9444 - val_loss: 0.1407 - val_acc: 0.9000\n",
            "Epoch 58/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1033 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 59/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1032 - acc: 0.9519 - val_loss: 0.1415 - val_acc: 0.8667\n",
            "Epoch 60/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1045 - acc: 0.9556 - val_loss: 0.1397 - val_acc: 0.9000\n",
            "Epoch 61/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1051 - acc: 0.9259 - val_loss: 0.1614 - val_acc: 0.7667\n",
            "Epoch 62/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1088 - acc: 0.9407 - val_loss: 0.1447 - val_acc: 0.9333\n",
            "Epoch 63/800\n",
            "270/270 [==============================] - 0s 345us/step - loss: 0.1049 - acc: 0.9333 - val_loss: 0.1411 - val_acc: 0.8667\n",
            "Epoch 64/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1031 - acc: 0.9593 - val_loss: 0.1446 - val_acc: 0.8667\n",
            "Epoch 65/800\n",
            "270/270 [==============================] - 0s 279us/step - loss: 0.1098 - acc: 0.9074 - val_loss: 0.1431 - val_acc: 0.8667\n",
            "Epoch 66/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1042 - acc: 0.9407 - val_loss: 0.1398 - val_acc: 0.9333\n",
            "Epoch 67/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1041 - acc: 0.9407 - val_loss: 0.1395 - val_acc: 0.9333\n",
            "Epoch 68/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1032 - acc: 0.9630 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 69/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1050 - acc: 0.9481 - val_loss: 0.1413 - val_acc: 0.9000\n",
            "Epoch 70/800\n",
            "270/270 [==============================] - 0s 278us/step - loss: 0.1040 - acc: 0.9296 - val_loss: 0.1399 - val_acc: 0.9000\n",
            "Epoch 71/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1042 - acc: 0.9407 - val_loss: 0.1475 - val_acc: 0.8667\n",
            "Epoch 72/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1072 - acc: 0.9481 - val_loss: 0.1404 - val_acc: 0.9333\n",
            "Epoch 73/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1030 - acc: 0.9519 - val_loss: 0.1406 - val_acc: 0.8667\n",
            "Epoch 74/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1032 - acc: 0.9481 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 75/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1035 - acc: 0.9593 - val_loss: 0.1400 - val_acc: 0.9000\n",
            "Epoch 76/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1032 - acc: 0.9519 - val_loss: 0.1423 - val_acc: 0.9000\n",
            "Epoch 77/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1043 - acc: 0.9444 - val_loss: 0.1443 - val_acc: 0.8667\n",
            "Epoch 78/800\n",
            "270/270 [==============================] - 0s 346us/step - loss: 0.1034 - acc: 0.9481 - val_loss: 0.1396 - val_acc: 0.8667\n",
            "Epoch 79/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1031 - acc: 0.9481 - val_loss: 0.1402 - val_acc: 0.9333\n",
            "Epoch 80/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1031 - acc: 0.9481 - val_loss: 0.1406 - val_acc: 0.9000\n",
            "Epoch 81/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1029 - acc: 0.9481 - val_loss: 0.1411 - val_acc: 0.9000\n",
            "Epoch 82/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1046 - acc: 0.9370 - val_loss: 0.1422 - val_acc: 0.8667\n",
            "Epoch 83/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1035 - acc: 0.9519 - val_loss: 0.1396 - val_acc: 0.9000\n",
            "Epoch 84/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1029 - acc: 0.9481 - val_loss: 0.1397 - val_acc: 0.9000\n",
            "Epoch 85/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1032 - acc: 0.9593 - val_loss: 0.1418 - val_acc: 0.8667\n",
            "Epoch 86/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1030 - acc: 0.9519 - val_loss: 0.1395 - val_acc: 0.9333\n",
            "Epoch 87/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1029 - acc: 0.9519 - val_loss: 0.1396 - val_acc: 0.9000\n",
            "Epoch 88/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1032 - acc: 0.9407 - val_loss: 0.1397 - val_acc: 0.9333\n",
            "Epoch 89/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1041 - acc: 0.9333 - val_loss: 0.1411 - val_acc: 0.9333\n",
            "Epoch 90/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1050 - acc: 0.9333 - val_loss: 0.1543 - val_acc: 0.8667\n",
            "Epoch 91/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1099 - acc: 0.9444 - val_loss: 0.1415 - val_acc: 0.9000\n",
            "Epoch 92/800\n",
            "270/270 [==============================] - 0s 360us/step - loss: 0.1036 - acc: 0.9481 - val_loss: 0.1401 - val_acc: 0.9333\n",
            "Epoch 93/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1038 - acc: 0.9444 - val_loss: 0.1433 - val_acc: 0.9000\n",
            "Epoch 94/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1033 - acc: 0.9556 - val_loss: 0.1417 - val_acc: 0.9000\n",
            "Epoch 95/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1038 - acc: 0.9333 - val_loss: 0.1404 - val_acc: 0.9000\n",
            "Epoch 96/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1034 - acc: 0.9481 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 97/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1034 - acc: 0.9481 - val_loss: 0.1406 - val_acc: 0.9333\n",
            "Epoch 98/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1036 - acc: 0.9444 - val_loss: 0.1399 - val_acc: 0.9333\n",
            "Epoch 99/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1040 - acc: 0.9519 - val_loss: 0.1412 - val_acc: 0.9000\n",
            "Epoch 100/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1046 - acc: 0.9370 - val_loss: 0.1407 - val_acc: 0.9000\n",
            "Epoch 101/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1031 - acc: 0.9481 - val_loss: 0.1417 - val_acc: 0.8667\n",
            "Epoch 102/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1032 - acc: 0.9444 - val_loss: 0.1395 - val_acc: 0.9000\n",
            "Epoch 103/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1038 - acc: 0.9444 - val_loss: 0.1397 - val_acc: 0.8667\n",
            "Epoch 104/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1033 - acc: 0.9370 - val_loss: 0.1426 - val_acc: 0.9000\n",
            "Epoch 105/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1040 - acc: 0.9519 - val_loss: 0.1397 - val_acc: 0.9000\n",
            "Epoch 106/800\n",
            "270/270 [==============================] - 0s 350us/step - loss: 0.1036 - acc: 0.9259 - val_loss: 0.1413 - val_acc: 0.9333\n",
            "Epoch 107/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1047 - acc: 0.9444 - val_loss: 0.1412 - val_acc: 0.9333\n",
            "Epoch 108/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1038 - acc: 0.9481 - val_loss: 0.1399 - val_acc: 0.9333\n",
            "Epoch 109/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1035 - acc: 0.9407 - val_loss: 0.1399 - val_acc: 0.9000\n",
            "Epoch 110/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1028 - acc: 0.9519 - val_loss: 0.1407 - val_acc: 0.8667\n",
            "Epoch 111/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1037 - acc: 0.9407 - val_loss: 0.1441 - val_acc: 0.9333\n",
            "Epoch 112/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1044 - acc: 0.9444 - val_loss: 0.1404 - val_acc: 0.9333\n",
            "Epoch 113/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1030 - acc: 0.9481 - val_loss: 0.1408 - val_acc: 0.9000\n",
            "Epoch 114/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1037 - acc: 0.9444 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 115/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1030 - acc: 0.9519 - val_loss: 0.1402 - val_acc: 0.8667\n",
            "Epoch 116/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1030 - acc: 0.9444 - val_loss: 0.1413 - val_acc: 0.9000\n",
            "Epoch 117/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1036 - acc: 0.9296 - val_loss: 0.1398 - val_acc: 0.8667\n",
            "Epoch 118/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1033 - acc: 0.9481 - val_loss: 0.1440 - val_acc: 0.9333\n",
            "Epoch 119/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1045 - acc: 0.9481 - val_loss: 0.1402 - val_acc: 0.9000\n",
            "Epoch 120/800\n",
            "270/270 [==============================] - 0s 369us/step - loss: 0.1031 - acc: 0.9519 - val_loss: 0.1421 - val_acc: 0.8000\n",
            "Epoch 121/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1042 - acc: 0.9370 - val_loss: 0.1414 - val_acc: 0.9000\n",
            "Epoch 122/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1041 - acc: 0.9444 - val_loss: 0.1410 - val_acc: 0.9333\n",
            "Epoch 123/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1031 - acc: 0.9481 - val_loss: 0.1411 - val_acc: 0.9000\n",
            "Epoch 124/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1033 - acc: 0.9519 - val_loss: 0.1396 - val_acc: 0.9333\n",
            "Epoch 125/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1037 - acc: 0.9556 - val_loss: 0.1421 - val_acc: 0.9000\n",
            "Epoch 126/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1043 - acc: 0.9333 - val_loss: 0.1401 - val_acc: 0.9333\n",
            "Epoch 127/800\n",
            "270/270 [==============================] - 0s 324us/step - loss: 0.1032 - acc: 0.9444 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 128/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1036 - acc: 0.9444 - val_loss: 0.1410 - val_acc: 0.9333\n",
            "Epoch 129/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1039 - acc: 0.9333 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 130/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1036 - acc: 0.9519 - val_loss: 0.1396 - val_acc: 0.9000\n",
            "Epoch 131/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1032 - acc: 0.9444 - val_loss: 0.1413 - val_acc: 0.9333\n",
            "Epoch 132/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1039 - acc: 0.9407 - val_loss: 0.1400 - val_acc: 0.9000\n",
            "Epoch 133/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1037 - acc: 0.9444 - val_loss: 0.1463 - val_acc: 0.9000\n",
            "Epoch 134/800\n",
            "270/270 [==============================] - 0s 357us/step - loss: 0.1049 - acc: 0.9296 - val_loss: 0.1397 - val_acc: 0.9000\n",
            "Epoch 135/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1037 - acc: 0.9407 - val_loss: 0.1409 - val_acc: 0.9000\n",
            "Epoch 136/800\n",
            "270/270 [==============================] - 0s 325us/step - loss: 0.1032 - acc: 0.9519 - val_loss: 0.1398 - val_acc: 0.9000\n",
            "Epoch 137/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1031 - acc: 0.9481 - val_loss: 0.1394 - val_acc: 0.9333\n",
            "Epoch 138/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1030 - acc: 0.9519 - val_loss: 0.1400 - val_acc: 0.8667\n",
            "Epoch 139/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1034 - acc: 0.9370 - val_loss: 0.1404 - val_acc: 0.9000\n",
            "Epoch 140/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1029 - acc: 0.9519 - val_loss: 0.1399 - val_acc: 0.9000\n",
            "Epoch 141/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1045 - acc: 0.9259 - val_loss: 0.1470 - val_acc: 0.8667\n",
            "Epoch 142/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1045 - acc: 0.9222 - val_loss: 0.1403 - val_acc: 0.8667\n",
            "Epoch 143/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1032 - acc: 0.9481 - val_loss: 0.1396 - val_acc: 0.9333\n",
            "Epoch 144/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1035 - acc: 0.9481 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 145/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1042 - acc: 0.9333 - val_loss: 0.1462 - val_acc: 0.9333\n",
            "Epoch 146/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1073 - acc: 0.9259 - val_loss: 0.1398 - val_acc: 0.8667\n",
            "Epoch 147/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1036 - acc: 0.9481 - val_loss: 0.1394 - val_acc: 0.9333\n",
            "Epoch 148/800\n",
            "270/270 [==============================] - 0s 376us/step - loss: 0.1033 - acc: 0.9593 - val_loss: 0.1458 - val_acc: 0.9333\n",
            "Epoch 149/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1050 - acc: 0.9407 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 150/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1031 - acc: 0.9519 - val_loss: 0.1424 - val_acc: 0.8667\n",
            "Epoch 151/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1030 - acc: 0.9556 - val_loss: 0.1405 - val_acc: 0.9333\n",
            "Epoch 152/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1032 - acc: 0.9519 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 153/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1033 - acc: 0.9481 - val_loss: 0.1456 - val_acc: 0.9000\n",
            "Epoch 154/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1038 - acc: 0.9444 - val_loss: 0.1430 - val_acc: 0.9000\n",
            "Epoch 155/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1038 - acc: 0.9481 - val_loss: 0.1403 - val_acc: 0.9000\n",
            "Epoch 156/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1034 - acc: 0.9444 - val_loss: 0.1405 - val_acc: 0.9000\n",
            "Epoch 157/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1037 - acc: 0.9481 - val_loss: 0.1402 - val_acc: 0.9333\n",
            "Epoch 158/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1034 - acc: 0.9407 - val_loss: 0.1396 - val_acc: 0.9333\n",
            "Epoch 159/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1033 - acc: 0.9444 - val_loss: 0.1433 - val_acc: 0.8667\n",
            "Epoch 160/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1040 - acc: 0.9481 - val_loss: 0.1406 - val_acc: 0.9000\n",
            "Epoch 161/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1032 - acc: 0.9407 - val_loss: 0.1401 - val_acc: 0.9000\n",
            "Epoch 162/800\n",
            "270/270 [==============================] - 0s 348us/step - loss: 0.1037 - acc: 0.9481 - val_loss: 0.1424 - val_acc: 0.8667\n",
            "Epoch 163/800\n",
            "270/270 [==============================] - 0s 327us/step - loss: 0.1042 - acc: 0.9370 - val_loss: 0.1395 - val_acc: 0.8667\n",
            "Epoch 164/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1029 - acc: 0.9556 - val_loss: 0.1410 - val_acc: 0.9000\n",
            "Epoch 165/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1030 - acc: 0.9556 - val_loss: 0.1404 - val_acc: 0.9333\n",
            "Epoch 166/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1036 - acc: 0.9444 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 167/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1051 - acc: 0.9222 - val_loss: 0.1404 - val_acc: 0.9333\n",
            "Epoch 168/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1049 - acc: 0.9370 - val_loss: 0.1427 - val_acc: 0.9000\n",
            "Epoch 169/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1037 - acc: 0.9444 - val_loss: 0.1402 - val_acc: 0.9333\n",
            "Epoch 170/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1038 - acc: 0.9370 - val_loss: 0.1439 - val_acc: 0.8667\n",
            "Epoch 171/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1035 - acc: 0.9481 - val_loss: 0.1411 - val_acc: 0.8667\n",
            "Epoch 172/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1038 - acc: 0.9519 - val_loss: 0.1405 - val_acc: 0.9000\n",
            "Epoch 173/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1030 - acc: 0.9519 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 174/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1033 - acc: 0.9444 - val_loss: 0.1394 - val_acc: 0.8667\n",
            "Epoch 175/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1038 - acc: 0.9370 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 176/800\n",
            "270/270 [==============================] - 0s 342us/step - loss: 0.1028 - acc: 0.9481 - val_loss: 0.1398 - val_acc: 0.9333\n",
            "Epoch 177/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1029 - acc: 0.9556 - val_loss: 0.1394 - val_acc: 0.9333\n",
            "Epoch 178/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1030 - acc: 0.9444 - val_loss: 0.1469 - val_acc: 0.8000\n",
            "Epoch 179/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1048 - acc: 0.9333 - val_loss: 0.1420 - val_acc: 0.9000\n",
            "Epoch 180/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1032 - acc: 0.9481 - val_loss: 0.1402 - val_acc: 0.9333\n",
            "Epoch 181/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1038 - acc: 0.9370 - val_loss: 0.1398 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00181: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 182/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1025 - acc: 0.9556 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 183/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1394 - val_acc: 0.9000\n",
            "Epoch 184/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 185/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 186/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 187/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 188/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 189/800\n",
            "270/270 [==============================] - 0s 333us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 190/800\n",
            "270/270 [==============================] - 0s 348us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 191/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 192/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 193/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 194/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 195/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1393 - val_acc: 0.9333\n",
            "Epoch 196/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 197/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 198/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1394 - val_acc: 0.9000\n",
            "Epoch 199/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 200/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 201/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 202/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 203/800\n",
            "270/270 [==============================] - 0s 366us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 204/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1395 - val_acc: 0.9000\n",
            "Epoch 205/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 206/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 207/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 208/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 209/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 210/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 211/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 212/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1023 - acc: 0.9519 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 213/800\n",
            "270/270 [==============================] - 0s 328us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1393 - val_acc: 0.9333\n",
            "Epoch 214/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 215/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1394 - val_acc: 0.9000\n",
            "Epoch 216/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1023 - acc: 0.9481 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 217/800\n",
            "270/270 [==============================] - 0s 377us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 218/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 219/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 220/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 221/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1395 - val_acc: 0.9000\n",
            "Epoch 222/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 223/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 224/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 225/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 226/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 227/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 228/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 229/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 230/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1394 - val_acc: 0.8667\n",
            "Epoch 231/800\n",
            "270/270 [==============================] - 0s 373us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 232/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 233/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 234/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 235/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 236/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 237/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 238/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 239/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1023 - acc: 0.9519 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 240/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 241/800\n",
            "270/270 [==============================] - 0s 330us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 242/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 243/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1023 - acc: 0.9519 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 244/800\n",
            "270/270 [==============================] - 0s 323us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 245/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 246/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 247/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 248/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 249/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 250/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 251/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 252/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 253/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 254/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1394 - val_acc: 0.9333\n",
            "Epoch 255/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 256/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1023 - acc: 0.9481 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 257/800\n",
            "270/270 [==============================] - 0s 278us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 258/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 259/800\n",
            "270/270 [==============================] - 0s 330us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 260/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 261/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 262/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 263/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 264/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 265/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 266/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 267/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.8667\n",
            "Epoch 268/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1024 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 269/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1386 - val_acc: 0.9000\n",
            "Epoch 270/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 271/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1392 - val_acc: 0.8667\n",
            "Epoch 272/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 273/800\n",
            "270/270 [==============================] - 0s 354us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 274/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1393 - val_acc: 0.8667\n",
            "Epoch 275/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1387 - val_acc: 0.9000\n",
            "Epoch 276/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 277/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1023 - acc: 0.9519 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 278/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 279/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.8667\n",
            "Epoch 280/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 281/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 282/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 283/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 284/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 285/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 286/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 287/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 288/800\n",
            "270/270 [==============================] - 0s 358us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 289/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 290/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 291/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1387 - val_acc: 0.9333\n",
            "Epoch 292/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1387 - val_acc: 0.9000\n",
            "Epoch 293/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 294/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1023 - acc: 0.9481 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 295/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 296/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 297/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1023 - acc: 0.9519 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 298/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 299/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 300/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 301/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 302/800\n",
            "270/270 [==============================] - 0s 357us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 303/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 304/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1387 - val_acc: 0.9333\n",
            "Epoch 305/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1387 - val_acc: 0.9000\n",
            "Epoch 306/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1022 - acc: 0.9630 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 307/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 308/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1384 - val_acc: 0.9333\n",
            "Epoch 309/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 310/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 311/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 312/800\n",
            "270/270 [==============================] - 0s 324us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 313/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 314/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 315/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1023 - acc: 0.9519 - val_loss: 0.1394 - val_acc: 0.9000\n",
            "Epoch 316/800\n",
            "270/270 [==============================] - 0s 395us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 317/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 318/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1021 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 319/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 320/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1386 - val_acc: 0.9000\n",
            "Epoch 321/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 322/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 323/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1023 - acc: 0.9519 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 324/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1387 - val_acc: 0.9000\n",
            "Epoch 325/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1021 - acc: 0.9519 - val_loss: 0.1387 - val_acc: 0.9333\n",
            "Epoch 326/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1386 - val_acc: 0.9333\n",
            "Epoch 327/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1021 - acc: 0.9519 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 328/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 329/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 330/800\n",
            "270/270 [==============================] - 0s 361us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 331/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00331: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 332/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 333/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 334/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 335/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 336/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 337/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 338/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 339/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 340/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 341/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 342/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 343/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 344/800\n",
            "270/270 [==============================] - 0s 367us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 345/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 346/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 347/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 348/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 349/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 350/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 351/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 352/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 353/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 354/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 355/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 356/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 357/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 358/800\n",
            "270/270 [==============================] - 0s 372us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 359/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1021 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 360/800\n",
            "270/270 [==============================] - 0s 324us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 361/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 362/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 363/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 364/800\n",
            "270/270 [==============================] - 0s 323us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 365/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 366/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 367/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 368/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 369/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 370/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 371/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 372/800\n",
            "270/270 [==============================] - 0s 360us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 373/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 374/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 375/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 376/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 377/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 378/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 379/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 380/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 381/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 382/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 383/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 384/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 385/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 386/800\n",
            "270/270 [==============================] - 0s 384us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 387/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 388/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 389/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 390/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 391/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 392/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 393/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 394/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 395/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 396/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 397/800\n",
            "270/270 [==============================] - 0s 325us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 398/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 399/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 400/800\n",
            "270/270 [==============================] - 0s 386us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 401/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 402/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 403/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 404/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 405/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 406/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 407/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 408/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 409/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 410/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 411/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 412/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 413/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 414/800\n",
            "270/270 [==============================] - 0s 371us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 415/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 416/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 417/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 418/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 419/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 420/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1387 - val_acc: 0.9000\n",
            "Epoch 421/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1387 - val_acc: 0.9000\n",
            "Epoch 422/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 423/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 424/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 425/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 426/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 427/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 428/800\n",
            "270/270 [==============================] - 0s 358us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 429/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 430/800\n",
            "270/270 [==============================] - 0s 331us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 431/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 432/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 433/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 434/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 435/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 436/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 437/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 438/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 439/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 440/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 441/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 442/800\n",
            "270/270 [==============================] - 0s 348us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 443/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 444/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 445/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 446/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 447/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 448/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 449/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 450/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 451/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 452/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1387 - val_acc: 0.9000\n",
            "Epoch 453/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 454/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 455/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 456/800\n",
            "270/270 [==============================] - 0s 338us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 457/800\n",
            "270/270 [==============================] - 0s 337us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 458/800\n",
            "270/270 [==============================] - 0s 338us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 459/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 460/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 461/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 462/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 463/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 464/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 465/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 466/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 467/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 468/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 469/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 470/800\n",
            "270/270 [==============================] - 0s 276us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 471/800\n",
            "270/270 [==============================] - 0s 324us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 472/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 473/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 474/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 475/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 476/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 477/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 478/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 479/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 480/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 481/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00481: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
            "Epoch 482/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 483/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 484/800\n",
            "270/270 [==============================] - 0s 276us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 485/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 486/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 487/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 488/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 489/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 490/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 491/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 492/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 493/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 494/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 495/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 496/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 497/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 498/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 499/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 500/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 501/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 502/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 503/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 504/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 505/800\n",
            "270/270 [==============================] - 0s 274us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 506/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 507/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 508/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 509/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 510/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 511/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 512/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 513/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 514/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 515/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 516/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 517/800\n",
            "270/270 [==============================] - 0s 276us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 518/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 519/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 520/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 521/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 522/800\n",
            "270/270 [==============================] - 0s 275us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 523/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 524/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 525/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 526/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 527/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 528/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 529/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 530/800\n",
            "270/270 [==============================] - 0s 370us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 531/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 532/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 533/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 534/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 535/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 536/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 537/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 538/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 539/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 540/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 541/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 542/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 543/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 544/800\n",
            "270/270 [==============================] - 0s 341us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 545/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 546/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 547/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 548/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 549/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 550/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 551/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 552/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 553/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 554/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 555/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 556/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 557/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 558/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 559/800\n",
            "270/270 [==============================] - 0s 345us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 560/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 561/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 562/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 563/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 564/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 565/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 566/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 567/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 568/800\n",
            "270/270 [==============================] - 0s 323us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 569/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 570/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 571/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 572/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 573/800\n",
            "270/270 [==============================] - 0s 327us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 574/800\n",
            "270/270 [==============================] - 0s 329us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 575/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 576/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 577/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 578/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 579/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 580/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 581/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 582/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 583/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 584/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 585/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 586/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 587/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 588/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 589/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 590/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 591/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 592/800\n",
            "270/270 [==============================] - 0s 342us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 593/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 594/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 595/800\n",
            "270/270 [==============================] - 0s 322us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 596/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 597/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 598/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 599/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 600/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 601/800\n",
            "270/270 [==============================] - 0s 345us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 602/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 603/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 604/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 605/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 606/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 607/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 608/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 609/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 610/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 611/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 612/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 613/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 614/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 615/800\n",
            "270/270 [==============================] - 0s 366us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 616/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 617/800\n",
            "270/270 [==============================] - 0s 334us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 618/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 619/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 620/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 621/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 622/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 623/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 624/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 625/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 626/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 627/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 628/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 629/800\n",
            "270/270 [==============================] - 0s 362us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 630/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 631/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00631: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
            "Epoch 632/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 633/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 634/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 635/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 636/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 637/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 638/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 639/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 640/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 641/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 642/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 643/800\n",
            "270/270 [==============================] - 0s 372us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 644/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 645/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 646/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 647/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 648/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 649/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 650/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 651/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 652/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 653/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 654/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 655/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 656/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 657/800\n",
            "270/270 [==============================] - 0s 374us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 658/800\n",
            "270/270 [==============================] - 0s 327us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 659/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 660/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 661/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 662/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 663/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 664/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 665/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 666/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 667/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 668/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 669/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 670/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 671/800\n",
            "270/270 [==============================] - 0s 376us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 672/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 673/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 674/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 675/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 676/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 677/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 678/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 679/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 680/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 681/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 682/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 683/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 684/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 685/800\n",
            "270/270 [==============================] - 0s 378us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 686/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 687/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 688/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 689/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 690/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 691/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 692/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 693/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 694/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 695/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 696/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 697/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 698/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 699/800\n",
            "270/270 [==============================] - 0s 369us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 700/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 701/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 702/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 703/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 704/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 705/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 706/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 707/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 708/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 709/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 710/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 711/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 712/800\n",
            "270/270 [==============================] - 0s 275us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 713/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 714/800\n",
            "270/270 [==============================] - 0s 348us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 715/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 716/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 717/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 718/800\n",
            "270/270 [==============================] - 0s 273us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 719/800\n",
            "270/270 [==============================] - 0s 278us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 720/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 721/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 722/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 723/800\n",
            "270/270 [==============================] - 0s 268us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 724/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 725/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 726/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 727/800\n",
            "270/270 [==============================] - 0s 273us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 728/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 729/800\n",
            "270/270 [==============================] - 0s 339us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 730/800\n",
            "270/270 [==============================] - 0s 279us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 731/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 732/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 733/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 734/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 735/800\n",
            "270/270 [==============================] - 0s 279us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 736/800\n",
            "270/270 [==============================] - 0s 276us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 737/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 738/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 739/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 740/800\n",
            "270/270 [==============================] - 0s 279us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 741/800\n",
            "270/270 [==============================] - 0s 271us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 742/800\n",
            "270/270 [==============================] - 0s 276us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 743/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 744/800\n",
            "270/270 [==============================] - 0s 343us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 745/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 746/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 747/800\n",
            "270/270 [==============================] - 0s 329us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 748/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 749/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 750/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 751/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 752/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 753/800\n",
            "270/270 [==============================] - 0s 272us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 754/800\n",
            "270/270 [==============================] - 0s 275us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 755/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 756/800\n",
            "270/270 [==============================] - 0s 275us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 757/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 758/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 759/800\n",
            "270/270 [==============================] - 0s 359us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 760/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 761/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 762/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 763/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 764/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 765/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 766/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 767/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 768/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 769/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 770/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 771/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 772/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 773/800\n",
            "270/270 [==============================] - 0s 371us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 774/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 775/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 776/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 777/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 778/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 779/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 780/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 781/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00781: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "Epoch 782/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 783/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 784/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 785/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 786/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 787/800\n",
            "270/270 [==============================] - 0s 344us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 788/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 789/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 790/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 791/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 792/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 793/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 794/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 795/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 796/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 797/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 798/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 799/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 800/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "300/300 [==============================] - 0s 102us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0.1051254536708196, 0.9566666666666667]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "u1doUpdStDAB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2329e949-2b26-44e0-a4ec-fa768e687d53"
      },
      "cell_type": "code",
      "source": [
        "x_test2.shape"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "metadata": {
        "id": "Zgz6pfU7oYwk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13212
        },
        "outputId": "bef0b49e-61b1-440c-c668-c514acce457c"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Results with full anomily \n",
        "full_anom = 0\n",
        "anom_samples = 1\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='acc', factor=0.2,min_lr=1e-7,min_delta=0.001,\n",
        "                              patience=200,verbose = 1)\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
        "                               verbose=0,\n",
        "                               save_best_only=True)\n",
        "tensorboard = TensorBoard(log_dir='./logs',\n",
        "                          histogram_freq=0,\n",
        "                          write_graph=True,\n",
        "                          write_images=True)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_test2, x_test2),\n",
        "                    #validation_split=.1,\n",
        "                    shuffle=True,\n",
        "                    verbose=1,callbacks=[reduce_lr, checkpointer, tensorboard]).history \n",
        "                         \n",
        "\n",
        "score = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 300 samples, validate on 307 samples\n",
            "Epoch 1/800\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.1205 - acc: 0.8967 - val_loss: 3.0520 - val_acc: 0.0000e+00\n",
            "Epoch 2/800\n",
            "300/300 [==============================] - 0s 417us/step - loss: 0.1184 - acc: 0.9233 - val_loss: 3.0335 - val_acc: 0.0000e+00\n",
            "Epoch 3/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1196 - acc: 0.9200 - val_loss: 2.9312 - val_acc: 0.0000e+00\n",
            "Epoch 4/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1199 - acc: 0.8967 - val_loss: 3.0575 - val_acc: 0.0000e+00\n",
            "Epoch 5/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1188 - acc: 0.9267 - val_loss: 3.0571 - val_acc: 0.0000e+00\n",
            "Epoch 6/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1200 - acc: 0.9133 - val_loss: 3.0526 - val_acc: 0.0000e+00\n",
            "Epoch 7/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1184 - acc: 0.9267 - val_loss: 3.0729 - val_acc: 0.0000e+00\n",
            "Epoch 8/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1193 - acc: 0.9033 - val_loss: 3.0949 - val_acc: 0.0000e+00\n",
            "Epoch 9/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1196 - acc: 0.9033 - val_loss: 3.1423 - val_acc: 0.0000e+00\n",
            "Epoch 10/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1188 - acc: 0.9233 - val_loss: 3.1466 - val_acc: 0.0000e+00\n",
            "Epoch 11/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1204 - acc: 0.8967 - val_loss: 3.0999 - val_acc: 0.0000e+00\n",
            "Epoch 12/800\n",
            "300/300 [==============================] - 0s 420us/step - loss: 0.1182 - acc: 0.9133 - val_loss: 3.1334 - val_acc: 0.0000e+00\n",
            "Epoch 13/800\n",
            "300/300 [==============================] - 0s 349us/step - loss: 0.1185 - acc: 0.9133 - val_loss: 3.1444 - val_acc: 0.0000e+00\n",
            "Epoch 14/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1193 - acc: 0.9100 - val_loss: 3.1233 - val_acc: 0.0000e+00\n",
            "Epoch 15/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1187 - acc: 0.9167 - val_loss: 3.1529 - val_acc: 0.0000e+00\n",
            "Epoch 16/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1186 - acc: 0.9167 - val_loss: 3.1221 - val_acc: 0.0000e+00\n",
            "Epoch 17/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1189 - acc: 0.9133 - val_loss: 3.1059 - val_acc: 0.0000e+00\n",
            "Epoch 18/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1190 - acc: 0.9267 - val_loss: 3.0921 - val_acc: 0.0000e+00\n",
            "Epoch 19/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1186 - acc: 0.9233 - val_loss: 3.2076 - val_acc: 0.0000e+00\n",
            "Epoch 20/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1185 - acc: 0.9200 - val_loss: 3.0874 - val_acc: 0.0000e+00\n",
            "Epoch 21/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1196 - acc: 0.9133 - val_loss: 3.1115 - val_acc: 0.0000e+00\n",
            "Epoch 22/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1185 - acc: 0.9100 - val_loss: 3.2145 - val_acc: 0.0000e+00\n",
            "Epoch 23/800\n",
            "300/300 [==============================] - 0s 423us/step - loss: 0.1193 - acc: 0.9167 - val_loss: 3.0650 - val_acc: 0.0000e+00\n",
            "Epoch 24/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1194 - acc: 0.9133 - val_loss: 3.0864 - val_acc: 0.0000e+00\n",
            "Epoch 25/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1181 - acc: 0.9233 - val_loss: 3.0754 - val_acc: 0.0000e+00\n",
            "Epoch 26/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1219 - acc: 0.9300 - val_loss: 3.1585 - val_acc: 0.0000e+00\n",
            "Epoch 27/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1200 - acc: 0.9133 - val_loss: 3.0885 - val_acc: 0.0000e+00\n",
            "Epoch 28/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1186 - acc: 0.9267 - val_loss: 3.2460 - val_acc: 0.0000e+00\n",
            "Epoch 29/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1194 - acc: 0.9200 - val_loss: 3.1169 - val_acc: 0.0000e+00\n",
            "Epoch 30/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1188 - acc: 0.9100 - val_loss: 3.1227 - val_acc: 0.0000e+00\n",
            "Epoch 31/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1190 - acc: 0.9233 - val_loss: 3.1664 - val_acc: 0.0000e+00\n",
            "Epoch 32/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1202 - acc: 0.9133 - val_loss: 3.2087 - val_acc: 0.0000e+00\n",
            "Epoch 33/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1187 - acc: 0.9267 - val_loss: 3.1755 - val_acc: 0.0000e+00\n",
            "Epoch 34/800\n",
            "300/300 [==============================] - 0s 406us/step - loss: 0.1185 - acc: 0.9267 - val_loss: 3.2110 - val_acc: 0.0000e+00\n",
            "Epoch 35/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1196 - acc: 0.9133 - val_loss: 3.1833 - val_acc: 0.0000e+00\n",
            "Epoch 36/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1187 - acc: 0.9167 - val_loss: 3.2532 - val_acc: 0.0000e+00\n",
            "Epoch 37/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1228 - acc: 0.8933 - val_loss: 3.2226 - val_acc: 0.0000e+00\n",
            "Epoch 38/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1177 - acc: 0.9333 - val_loss: 3.2772 - val_acc: 0.0000e+00\n",
            "Epoch 39/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1183 - acc: 0.9267 - val_loss: 3.2645 - val_acc: 0.0000e+00\n",
            "Epoch 40/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1178 - acc: 0.9200 - val_loss: 3.2427 - val_acc: 0.0000e+00\n",
            "Epoch 41/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1178 - acc: 0.9233 - val_loss: 3.2796 - val_acc: 0.0000e+00\n",
            "Epoch 42/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1182 - acc: 0.9367 - val_loss: 3.3168 - val_acc: 0.0000e+00\n",
            "Epoch 43/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1190 - acc: 0.9167 - val_loss: 3.3014 - val_acc: 0.0000e+00\n",
            "Epoch 44/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1199 - acc: 0.9133 - val_loss: 3.2753 - val_acc: 0.0000e+00\n",
            "Epoch 45/800\n",
            "300/300 [==============================] - 0s 423us/step - loss: 0.1180 - acc: 0.9233 - val_loss: 3.3281 - val_acc: 0.0000e+00\n",
            "Epoch 46/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1181 - acc: 0.9333 - val_loss: 3.2431 - val_acc: 0.0000e+00\n",
            "Epoch 47/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1184 - acc: 0.9100 - val_loss: 3.2826 - val_acc: 0.0000e+00\n",
            "Epoch 48/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1184 - acc: 0.9400 - val_loss: 3.2322 - val_acc: 0.0000e+00\n",
            "Epoch 49/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1184 - acc: 0.9200 - val_loss: 3.2231 - val_acc: 0.0000e+00\n",
            "Epoch 50/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1182 - acc: 0.9133 - val_loss: 3.2604 - val_acc: 0.0000e+00\n",
            "Epoch 51/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1179 - acc: 0.9233 - val_loss: 3.2439 - val_acc: 0.0000e+00\n",
            "Epoch 52/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1191 - acc: 0.9267 - val_loss: 3.2723 - val_acc: 0.0000e+00\n",
            "Epoch 53/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1181 - acc: 0.9267 - val_loss: 3.2758 - val_acc: 0.0000e+00\n",
            "Epoch 54/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1196 - acc: 0.9167 - val_loss: 3.2218 - val_acc: 0.0000e+00\n",
            "Epoch 55/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1184 - acc: 0.9200 - val_loss: 3.2460 - val_acc: 0.0000e+00\n",
            "Epoch 56/800\n",
            "300/300 [==============================] - 0s 403us/step - loss: 0.1185 - acc: 0.9200 - val_loss: 3.2149 - val_acc: 0.0000e+00\n",
            "Epoch 57/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1178 - acc: 0.9267 - val_loss: 3.2812 - val_acc: 0.0000e+00\n",
            "Epoch 58/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1179 - acc: 0.9267 - val_loss: 3.3172 - val_acc: 0.0000e+00\n",
            "Epoch 59/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1178 - acc: 0.9300 - val_loss: 3.3237 - val_acc: 0.0000e+00\n",
            "Epoch 60/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1180 - acc: 0.9233 - val_loss: 3.3295 - val_acc: 0.0000e+00\n",
            "Epoch 61/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1184 - acc: 0.9200 - val_loss: 3.3449 - val_acc: 0.0000e+00\n",
            "Epoch 62/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1178 - acc: 0.9200 - val_loss: 3.3828 - val_acc: 0.0000e+00\n",
            "Epoch 63/800\n",
            "300/300 [==============================] - 0s 386us/step - loss: 0.1184 - acc: 0.9300 - val_loss: 3.3324 - val_acc: 0.0000e+00\n",
            "Epoch 64/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1177 - acc: 0.9233 - val_loss: 3.3258 - val_acc: 0.0000e+00\n",
            "Epoch 65/800\n",
            "300/300 [==============================] - 0s 343us/step - loss: 0.1195 - acc: 0.9100 - val_loss: 3.3231 - val_acc: 0.0000e+00\n",
            "Epoch 66/800\n",
            "300/300 [==============================] - 0s 416us/step - loss: 0.1176 - acc: 0.9133 - val_loss: 3.3959 - val_acc: 0.0000e+00\n",
            "Epoch 67/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1179 - acc: 0.9267 - val_loss: 3.3573 - val_acc: 0.0000e+00\n",
            "Epoch 68/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1177 - acc: 0.9233 - val_loss: 3.3774 - val_acc: 0.0000e+00\n",
            "Epoch 69/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1194 - acc: 0.9200 - val_loss: 3.3184 - val_acc: 0.0000e+00\n",
            "Epoch 70/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1191 - acc: 0.9300 - val_loss: 3.2874 - val_acc: 0.0000e+00\n",
            "Epoch 71/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1203 - acc: 0.9067 - val_loss: 3.3005 - val_acc: 0.0000e+00\n",
            "Epoch 72/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1181 - acc: 0.9067 - val_loss: 3.3687 - val_acc: 0.0000e+00\n",
            "Epoch 73/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1178 - acc: 0.9233 - val_loss: 3.4164 - val_acc: 0.0000e+00\n",
            "Epoch 74/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1180 - acc: 0.9200 - val_loss: 3.3590 - val_acc: 0.0000e+00\n",
            "Epoch 75/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1180 - acc: 0.9200 - val_loss: 3.3669 - val_acc: 0.0000e+00\n",
            "Epoch 76/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1180 - acc: 0.9200 - val_loss: 3.3251 - val_acc: 0.0000e+00\n",
            "Epoch 77/800\n",
            "300/300 [==============================] - 0s 423us/step - loss: 0.1174 - acc: 0.9200 - val_loss: 3.4460 - val_acc: 0.0000e+00\n",
            "Epoch 78/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1177 - acc: 0.9200 - val_loss: 3.3973 - val_acc: 0.0000e+00\n",
            "Epoch 79/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1190 - acc: 0.9167 - val_loss: 3.3710 - val_acc: 0.0000e+00\n",
            "Epoch 80/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1187 - acc: 0.9300 - val_loss: 3.3568 - val_acc: 0.0000e+00\n",
            "Epoch 81/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1186 - acc: 0.9233 - val_loss: 3.3873 - val_acc: 0.0000e+00\n",
            "Epoch 82/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1189 - acc: 0.9167 - val_loss: 3.3899 - val_acc: 0.0000e+00\n",
            "Epoch 83/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1181 - acc: 0.9067 - val_loss: 3.4024 - val_acc: 0.0000e+00\n",
            "Epoch 84/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1181 - acc: 0.9267 - val_loss: 3.3980 - val_acc: 0.0000e+00\n",
            "Epoch 85/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1180 - acc: 0.9167 - val_loss: 3.4612 - val_acc: 0.0000e+00\n",
            "Epoch 86/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1177 - acc: 0.9200 - val_loss: 3.4463 - val_acc: 0.0000e+00\n",
            "Epoch 87/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1187 - acc: 0.9167 - val_loss: 3.4885 - val_acc: 0.0000e+00\n",
            "Epoch 88/800\n",
            "300/300 [==============================] - 0s 419us/step - loss: 0.1180 - acc: 0.9300 - val_loss: 3.3538 - val_acc: 0.0000e+00\n",
            "Epoch 89/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1189 - acc: 0.9167 - val_loss: 3.4315 - val_acc: 0.0000e+00\n",
            "Epoch 90/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1182 - acc: 0.9200 - val_loss: 3.4036 - val_acc: 0.0000e+00\n",
            "Epoch 91/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1177 - acc: 0.9167 - val_loss: 3.3580 - val_acc: 0.0000e+00\n",
            "Epoch 92/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1192 - acc: 0.9200 - val_loss: 3.4159 - val_acc: 0.0000e+00\n",
            "Epoch 93/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1180 - acc: 0.9267 - val_loss: 3.4045 - val_acc: 0.0000e+00\n",
            "Epoch 94/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1201 - acc: 0.9033 - val_loss: 3.4158 - val_acc: 0.0000e+00\n",
            "Epoch 95/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1181 - acc: 0.9133 - val_loss: 3.4685 - val_acc: 0.0000e+00\n",
            "Epoch 96/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1185 - acc: 0.9167 - val_loss: 3.5256 - val_acc: 0.0000e+00\n",
            "Epoch 97/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1187 - acc: 0.9033 - val_loss: 3.5129 - val_acc: 0.0000e+00\n",
            "Epoch 98/800\n",
            "300/300 [==============================] - 0s 428us/step - loss: 0.1205 - acc: 0.9167 - val_loss: 3.4115 - val_acc: 0.0000e+00\n",
            "Epoch 99/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1177 - acc: 0.9300 - val_loss: 3.5248 - val_acc: 0.0000e+00\n",
            "Epoch 100/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1171 - acc: 0.9233 - val_loss: 3.5193 - val_acc: 0.0000e+00\n",
            "Epoch 101/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1179 - acc: 0.9233 - val_loss: 3.4850 - val_acc: 0.0000e+00\n",
            "Epoch 102/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1183 - acc: 0.9133 - val_loss: 3.5074 - val_acc: 0.0000e+00\n",
            "Epoch 103/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1180 - acc: 0.9200 - val_loss: 3.5148 - val_acc: 0.0000e+00\n",
            "Epoch 104/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1174 - acc: 0.9133 - val_loss: 3.5668 - val_acc: 0.0000e+00\n",
            "Epoch 105/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1174 - acc: 0.9267 - val_loss: 3.5296 - val_acc: 0.0000e+00\n",
            "Epoch 106/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1178 - acc: 0.9233 - val_loss: 3.4919 - val_acc: 0.0000e+00\n",
            "Epoch 107/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1185 - acc: 0.8933 - val_loss: 3.5047 - val_acc: 0.0000e+00\n",
            "Epoch 108/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1173 - acc: 0.9267 - val_loss: 3.5373 - val_acc: 0.0000e+00\n",
            "Epoch 109/800\n",
            "300/300 [==============================] - 0s 416us/step - loss: 0.1181 - acc: 0.9200 - val_loss: 3.5215 - val_acc: 0.0000e+00\n",
            "Epoch 110/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1177 - acc: 0.9133 - val_loss: 3.4915 - val_acc: 0.0000e+00\n",
            "Epoch 111/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1179 - acc: 0.9200 - val_loss: 3.5862 - val_acc: 0.0000e+00\n",
            "Epoch 112/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1184 - acc: 0.9133 - val_loss: 3.6208 - val_acc: 0.0000e+00\n",
            "Epoch 113/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1181 - acc: 0.9067 - val_loss: 3.5703 - val_acc: 0.0000e+00\n",
            "Epoch 114/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1183 - acc: 0.9100 - val_loss: 3.5740 - val_acc: 0.0000e+00\n",
            "Epoch 115/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1184 - acc: 0.9167 - val_loss: 3.6127 - val_acc: 0.0000e+00\n",
            "Epoch 116/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1205 - acc: 0.9133 - val_loss: 3.5325 - val_acc: 0.0000e+00\n",
            "Epoch 117/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1170 - acc: 0.9267 - val_loss: 3.4540 - val_acc: 0.0000e+00\n",
            "Epoch 118/800\n",
            "300/300 [==============================] - 0s 344us/step - loss: 0.1186 - acc: 0.9300 - val_loss: 3.6139 - val_acc: 0.0000e+00\n",
            "Epoch 119/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1185 - acc: 0.9133 - val_loss: 3.5972 - val_acc: 0.0000e+00\n",
            "Epoch 120/800\n",
            "300/300 [==============================] - 0s 408us/step - loss: 0.1176 - acc: 0.9200 - val_loss: 3.6569 - val_acc: 0.0000e+00\n",
            "Epoch 121/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1177 - acc: 0.9067 - val_loss: 3.6153 - val_acc: 0.0000e+00\n",
            "Epoch 122/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1174 - acc: 0.9233 - val_loss: 3.6128 - val_acc: 0.0000e+00\n",
            "Epoch 123/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1179 - acc: 0.9200 - val_loss: 3.6273 - val_acc: 0.0000e+00\n",
            "Epoch 124/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1175 - acc: 0.9200 - val_loss: 3.6500 - val_acc: 0.0000e+00\n",
            "Epoch 125/800\n",
            "300/300 [==============================] - 0s 344us/step - loss: 0.1180 - acc: 0.9200 - val_loss: 3.5590 - val_acc: 0.0000e+00\n",
            "Epoch 126/800\n",
            "300/300 [==============================] - 0s 343us/step - loss: 0.1178 - acc: 0.9200 - val_loss: 3.6306 - val_acc: 0.0000e+00\n",
            "Epoch 127/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1184 - acc: 0.9000 - val_loss: 3.6215 - val_acc: 0.0000e+00\n",
            "Epoch 128/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1181 - acc: 0.9233 - val_loss: 3.6769 - val_acc: 0.0000e+00\n",
            "Epoch 129/800\n",
            "300/300 [==============================] - 0s 349us/step - loss: 0.1177 - acc: 0.9233 - val_loss: 3.5861 - val_acc: 0.0000e+00\n",
            "Epoch 130/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1179 - acc: 0.9200 - val_loss: 3.6434 - val_acc: 0.0000e+00\n",
            "Epoch 131/800\n",
            "300/300 [==============================] - 0s 397us/step - loss: 0.1177 - acc: 0.9233 - val_loss: 3.6205 - val_acc: 0.0000e+00\n",
            "Epoch 132/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1174 - acc: 0.9233 - val_loss: 3.6584 - val_acc: 0.0000e+00\n",
            "Epoch 133/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1171 - acc: 0.9267 - val_loss: 3.6499 - val_acc: 0.0000e+00\n",
            "Epoch 134/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1174 - acc: 0.9200 - val_loss: 3.6515 - val_acc: 0.0000e+00\n",
            "Epoch 135/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1179 - acc: 0.9033 - val_loss: 3.5997 - val_acc: 0.0000e+00\n",
            "Epoch 136/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1172 - acc: 0.9167 - val_loss: 3.6362 - val_acc: 0.0000e+00\n",
            "Epoch 137/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1170 - acc: 0.9133 - val_loss: 3.6161 - val_acc: 0.0000e+00\n",
            "Epoch 138/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1173 - acc: 0.9200 - val_loss: 3.6315 - val_acc: 0.0000e+00\n",
            "Epoch 139/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1174 - acc: 0.9233 - val_loss: 3.7318 - val_acc: 0.0000e+00\n",
            "Epoch 140/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1175 - acc: 0.9167 - val_loss: 3.6173 - val_acc: 0.0000e+00\n",
            "Epoch 141/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1185 - acc: 0.9133 - val_loss: 3.6665 - val_acc: 0.0000e+00\n",
            "Epoch 142/800\n",
            "300/300 [==============================] - 0s 417us/step - loss: 0.1171 - acc: 0.9233 - val_loss: 3.7271 - val_acc: 0.0000e+00\n",
            "Epoch 143/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1172 - acc: 0.9200 - val_loss: 3.7649 - val_acc: 0.0000e+00\n",
            "Epoch 144/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1172 - acc: 0.9200 - val_loss: 3.7762 - val_acc: 0.0000e+00\n",
            "Epoch 145/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1173 - acc: 0.9200 - val_loss: 3.7593 - val_acc: 0.0000e+00\n",
            "Epoch 146/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1180 - acc: 0.9067 - val_loss: 3.7615 - val_acc: 0.0000e+00\n",
            "Epoch 147/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1171 - acc: 0.9300 - val_loss: 3.7802 - val_acc: 0.0000e+00\n",
            "Epoch 148/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1169 - acc: 0.9133 - val_loss: 3.8192 - val_acc: 0.0000e+00\n",
            "Epoch 149/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1173 - acc: 0.9167 - val_loss: 3.8980 - val_acc: 0.0000e+00\n",
            "Epoch 150/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1173 - acc: 0.9333 - val_loss: 3.7944 - val_acc: 0.0000e+00\n",
            "Epoch 151/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1178 - acc: 0.9000 - val_loss: 3.7646 - val_acc: 0.0000e+00\n",
            "Epoch 152/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1199 - acc: 0.8833 - val_loss: 3.8668 - val_acc: 0.0000e+00\n",
            "Epoch 153/800\n",
            "300/300 [==============================] - 0s 417us/step - loss: 0.1168 - acc: 0.9267 - val_loss: 3.8491 - val_acc: 0.0000e+00\n",
            "Epoch 154/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1176 - acc: 0.9167 - val_loss: 3.8604 - val_acc: 0.0000e+00\n",
            "Epoch 155/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1171 - acc: 0.9233 - val_loss: 3.8535 - val_acc: 0.0000e+00\n",
            "Epoch 156/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1201 - acc: 0.9000 - val_loss: 3.8019 - val_acc: 0.0000e+00\n",
            "Epoch 157/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1170 - acc: 0.9233 - val_loss: 3.7790 - val_acc: 0.0000e+00\n",
            "Epoch 158/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1178 - acc: 0.9067 - val_loss: 3.7361 - val_acc: 0.0000e+00\n",
            "Epoch 159/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1173 - acc: 0.9133 - val_loss: 3.7822 - val_acc: 0.0000e+00\n",
            "Epoch 160/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1171 - acc: 0.9233 - val_loss: 3.8118 - val_acc: 0.0000e+00\n",
            "Epoch 161/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1190 - acc: 0.9133 - val_loss: 3.8502 - val_acc: 0.0000e+00\n",
            "Epoch 162/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1173 - acc: 0.9133 - val_loss: 3.8209 - val_acc: 0.0000e+00\n",
            "Epoch 163/800\n",
            "300/300 [==============================] - 0s 401us/step - loss: 0.1171 - acc: 0.9133 - val_loss: 3.8680 - val_acc: 0.0000e+00\n",
            "Epoch 164/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1166 - acc: 0.9100 - val_loss: 3.8236 - val_acc: 0.0000e+00\n",
            "Epoch 165/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1173 - acc: 0.9067 - val_loss: 3.7821 - val_acc: 0.0000e+00\n",
            "Epoch 166/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1170 - acc: 0.9033 - val_loss: 3.8420 - val_acc: 0.0000e+00\n",
            "Epoch 167/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1178 - acc: 0.9100 - val_loss: 3.9092 - val_acc: 0.0000e+00\n",
            "Epoch 168/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1167 - acc: 0.9167 - val_loss: 3.8276 - val_acc: 0.0000e+00\n",
            "Epoch 169/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1170 - acc: 0.9033 - val_loss: 3.8336 - val_acc: 0.0000e+00\n",
            "Epoch 170/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1169 - acc: 0.9100 - val_loss: 3.9111 - val_acc: 0.0000e+00\n",
            "Epoch 171/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1189 - acc: 0.9067 - val_loss: 3.8949 - val_acc: 0.0000e+00\n",
            "Epoch 172/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1194 - acc: 0.9067 - val_loss: 3.8288 - val_acc: 0.0000e+00\n",
            "Epoch 173/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1175 - acc: 0.9000 - val_loss: 3.7810 - val_acc: 0.0000e+00\n",
            "Epoch 174/800\n",
            "300/300 [==============================] - 0s 422us/step - loss: 0.1165 - acc: 0.9133 - val_loss: 3.8805 - val_acc: 0.0000e+00\n",
            "Epoch 175/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1171 - acc: 0.9133 - val_loss: 3.8518 - val_acc: 0.0000e+00\n",
            "Epoch 176/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1172 - acc: 0.9133 - val_loss: 3.9347 - val_acc: 0.0000e+00\n",
            "Epoch 177/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1167 - acc: 0.9100 - val_loss: 3.8712 - val_acc: 0.0000e+00\n",
            "Epoch 178/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1173 - acc: 0.9167 - val_loss: 3.9802 - val_acc: 0.0000e+00\n",
            "Epoch 179/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1177 - acc: 0.9033 - val_loss: 3.8885 - val_acc: 0.0000e+00\n",
            "Epoch 180/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1172 - acc: 0.9067 - val_loss: 4.0205 - val_acc: 0.0000e+00\n",
            "Epoch 181/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1178 - acc: 0.9100 - val_loss: 3.9173 - val_acc: 0.0000e+00\n",
            "Epoch 182/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1168 - acc: 0.9167 - val_loss: 3.8664 - val_acc: 0.0000e+00\n",
            "Epoch 183/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1167 - acc: 0.9200 - val_loss: 3.9083 - val_acc: 0.0000e+00\n",
            "Epoch 184/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1166 - acc: 0.9167 - val_loss: 3.9048 - val_acc: 0.0000e+00\n",
            "Epoch 185/800\n",
            "300/300 [==============================] - 0s 416us/step - loss: 0.1169 - acc: 0.9100 - val_loss: 3.9203 - val_acc: 0.0000e+00\n",
            "Epoch 186/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1174 - acc: 0.9167 - val_loss: 3.9047 - val_acc: 0.0000e+00\n",
            "Epoch 187/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1166 - acc: 0.9067 - val_loss: 3.8294 - val_acc: 0.0000e+00\n",
            "Epoch 188/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1171 - acc: 0.9000 - val_loss: 3.9480 - val_acc: 0.0000e+00\n",
            "Epoch 189/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1173 - acc: 0.9133 - val_loss: 3.9208 - val_acc: 0.0000e+00\n",
            "Epoch 190/800\n",
            "300/300 [==============================] - 0s 349us/step - loss: 0.1194 - acc: 0.9000 - val_loss: 3.9445 - val_acc: 0.0000e+00\n",
            "Epoch 191/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1174 - acc: 0.9133 - val_loss: 3.9945 - val_acc: 0.0000e+00\n",
            "Epoch 192/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1174 - acc: 0.9100 - val_loss: 4.0409 - val_acc: 0.0000e+00\n",
            "Epoch 193/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1166 - acc: 0.9133 - val_loss: 3.9988 - val_acc: 0.0000e+00\n",
            "Epoch 194/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1169 - acc: 0.9000 - val_loss: 4.0277 - val_acc: 0.0000e+00\n",
            "Epoch 195/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1171 - acc: 0.9133 - val_loss: 4.0855 - val_acc: 0.0000e+00\n",
            "Epoch 196/800\n",
            "300/300 [==============================] - 0s 410us/step - loss: 0.1170 - acc: 0.9200 - val_loss: 4.1040 - val_acc: 0.0000e+00\n",
            "Epoch 197/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1169 - acc: 0.9067 - val_loss: 4.0456 - val_acc: 0.0000e+00\n",
            "Epoch 198/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1164 - acc: 0.9133 - val_loss: 4.0889 - val_acc: 0.0000e+00\n",
            "Epoch 199/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1168 - acc: 0.9100 - val_loss: 4.0711 - val_acc: 0.0000e+00\n",
            "Epoch 200/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1171 - acc: 0.9133 - val_loss: 4.1217 - val_acc: 0.0000e+00\n",
            "Epoch 201/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1166 - acc: 0.8933 - val_loss: 4.1338 - val_acc: 0.0000e+00\n",
            "Epoch 202/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1167 - acc: 0.9200 - val_loss: 4.1913 - val_acc: 0.0000e+00\n",
            "Epoch 203/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1201 - acc: 0.8933 - val_loss: 4.2018 - val_acc: 0.0000e+00\n",
            "Epoch 204/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1175 - acc: 0.9200 - val_loss: 4.2361 - val_acc: 0.0000e+00\n",
            "Epoch 205/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1166 - acc: 0.9133 - val_loss: 4.2660 - val_acc: 0.0000e+00\n",
            "Epoch 206/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1183 - acc: 0.9067 - val_loss: 4.0853 - val_acc: 0.0000e+00\n",
            "Epoch 207/800\n",
            "300/300 [==============================] - 0s 409us/step - loss: 0.1169 - acc: 0.9067 - val_loss: 4.0703 - val_acc: 0.0000e+00\n",
            "Epoch 208/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1173 - acc: 0.9133 - val_loss: 4.0138 - val_acc: 0.0000e+00\n",
            "Epoch 209/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1179 - acc: 0.9000 - val_loss: 4.0452 - val_acc: 0.0000e+00\n",
            "Epoch 210/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1169 - acc: 0.9100 - val_loss: 4.0217 - val_acc: 0.0000e+00\n",
            "Epoch 211/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1168 - acc: 0.9167 - val_loss: 4.0169 - val_acc: 0.0000e+00\n",
            "Epoch 212/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1177 - acc: 0.9133 - val_loss: 3.9895 - val_acc: 0.0000e+00\n",
            "Epoch 213/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1170 - acc: 0.9200 - val_loss: 4.0555 - val_acc: 0.0000e+00\n",
            "Epoch 214/800\n",
            "300/300 [==============================] - 0s 385us/step - loss: 0.1178 - acc: 0.9100 - val_loss: 4.0196 - val_acc: 0.0000e+00\n",
            "Epoch 215/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1178 - acc: 0.9000 - val_loss: 3.9855 - val_acc: 0.0000e+00\n",
            "Epoch 216/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1167 - acc: 0.9100 - val_loss: 4.0276 - val_acc: 0.0000e+00\n",
            "Epoch 217/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1167 - acc: 0.9167 - val_loss: 3.9621 - val_acc: 0.0000e+00\n",
            "Epoch 218/800\n",
            "300/300 [==============================] - 0s 426us/step - loss: 0.1177 - acc: 0.9000 - val_loss: 4.0821 - val_acc: 0.0000e+00\n",
            "Epoch 219/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1167 - acc: 0.9100 - val_loss: 4.0694 - val_acc: 0.0000e+00\n",
            "Epoch 220/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1163 - acc: 0.9200 - val_loss: 4.0927 - val_acc: 0.0000e+00\n",
            "Epoch 221/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1167 - acc: 0.9133 - val_loss: 4.1059 - val_acc: 0.0000e+00\n",
            "Epoch 222/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1170 - acc: 0.9133 - val_loss: 4.1805 - val_acc: 0.0000e+00\n",
            "Epoch 223/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1169 - acc: 0.9067 - val_loss: 4.1734 - val_acc: 0.0000e+00\n",
            "Epoch 224/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1163 - acc: 0.9167 - val_loss: 4.1808 - val_acc: 0.0000e+00\n",
            "Epoch 225/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1167 - acc: 0.9200 - val_loss: 4.1912 - val_acc: 0.0000e+00\n",
            "Epoch 226/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1246 - acc: 0.9000 - val_loss: 4.2747 - val_acc: 0.0000e+00\n",
            "Epoch 227/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1172 - acc: 0.9033 - val_loss: 4.3332 - val_acc: 0.0000e+00\n",
            "Epoch 228/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1174 - acc: 0.9100 - val_loss: 4.2678 - val_acc: 0.0000e+00\n",
            "Epoch 229/800\n",
            "300/300 [==============================] - 0s 412us/step - loss: 0.1167 - acc: 0.9100 - val_loss: 4.2453 - val_acc: 0.0000e+00\n",
            "Epoch 230/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1167 - acc: 0.9033 - val_loss: 4.2330 - val_acc: 0.0000e+00\n",
            "Epoch 231/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1174 - acc: 0.9000 - val_loss: 4.2308 - val_acc: 0.0000e+00\n",
            "Epoch 232/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1180 - acc: 0.9167 - val_loss: 4.2287 - val_acc: 0.0000e+00\n",
            "Epoch 233/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1168 - acc: 0.9100 - val_loss: 4.2038 - val_acc: 0.0000e+00\n",
            "Epoch 234/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1168 - acc: 0.9133 - val_loss: 4.2005 - val_acc: 0.0000e+00\n",
            "Epoch 235/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1169 - acc: 0.9067 - val_loss: 4.2139 - val_acc: 0.0000e+00\n",
            "Epoch 236/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1166 - acc: 0.9133 - val_loss: 4.2488 - val_acc: 0.0000e+00\n",
            "Epoch 237/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1173 - acc: 0.9167 - val_loss: 4.2292 - val_acc: 0.0000e+00\n",
            "Epoch 238/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1172 - acc: 0.9033 - val_loss: 4.2297 - val_acc: 0.0000e+00\n",
            "Epoch 239/800\n",
            "300/300 [==============================] - 0s 396us/step - loss: 0.1163 - acc: 0.9067 - val_loss: 4.2614 - val_acc: 0.0000e+00\n",
            "Epoch 240/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1161 - acc: 0.9067 - val_loss: 4.3019 - val_acc: 0.0000e+00\n",
            "Epoch 241/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1159 - acc: 0.9200 - val_loss: 4.3488 - val_acc: 0.0000e+00\n",
            "Epoch 242/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1165 - acc: 0.9033 - val_loss: 4.3076 - val_acc: 0.0000e+00\n",
            "Epoch 243/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1163 - acc: 0.9067 - val_loss: 4.3893 - val_acc: 0.0000e+00\n",
            "Epoch 244/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1164 - acc: 0.9033 - val_loss: 4.3587 - val_acc: 0.0000e+00\n",
            "Epoch 245/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1167 - acc: 0.9167 - val_loss: 4.4266 - val_acc: 0.0000e+00\n",
            "Epoch 246/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1162 - acc: 0.9000 - val_loss: 4.4537 - val_acc: 0.0000e+00\n",
            "Epoch 247/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1169 - acc: 0.9100 - val_loss: 4.4154 - val_acc: 0.0000e+00\n",
            "Epoch 248/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1167 - acc: 0.9067 - val_loss: 4.4217 - val_acc: 0.0000e+00\n",
            "\n",
            "Epoch 00248: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 249/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1154 - acc: 0.9100 - val_loss: 4.4338 - val_acc: 0.0000e+00\n",
            "Epoch 250/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1153 - acc: 0.9100 - val_loss: 4.4468 - val_acc: 0.0000e+00\n",
            "Epoch 251/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1153 - acc: 0.9200 - val_loss: 4.4515 - val_acc: 0.0000e+00\n",
            "Epoch 252/800\n",
            "300/300 [==============================] - 0s 429us/step - loss: 0.1153 - acc: 0.9133 - val_loss: 4.4514 - val_acc: 0.0000e+00\n",
            "Epoch 253/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1154 - acc: 0.9100 - val_loss: 4.4630 - val_acc: 0.0000e+00\n",
            "Epoch 254/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1153 - acc: 0.9133 - val_loss: 4.4781 - val_acc: 0.0000e+00\n",
            "Epoch 255/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.4664 - val_acc: 0.0000e+00\n",
            "Epoch 256/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1153 - acc: 0.9067 - val_loss: 4.4838 - val_acc: 0.0000e+00\n",
            "Epoch 257/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.4863 - val_acc: 0.0000e+00\n",
            "Epoch 258/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.5005 - val_acc: 0.0000e+00\n",
            "Epoch 259/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1153 - acc: 0.9133 - val_loss: 4.5147 - val_acc: 0.0000e+00\n",
            "Epoch 260/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1154 - acc: 0.9167 - val_loss: 4.5014 - val_acc: 0.0000e+00\n",
            "Epoch 261/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.5218 - val_acc: 0.0000e+00\n",
            "Epoch 262/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.5339 - val_acc: 0.0000e+00\n",
            "Epoch 263/800\n",
            "300/300 [==============================] - 0s 410us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.5327 - val_acc: 0.0000e+00\n",
            "Epoch 264/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1153 - acc: 0.9200 - val_loss: 4.5425 - val_acc: 0.0000e+00\n",
            "Epoch 265/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1153 - acc: 0.9100 - val_loss: 4.5615 - val_acc: 0.0000e+00\n",
            "Epoch 266/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.5640 - val_acc: 0.0000e+00\n",
            "Epoch 267/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.5721 - val_acc: 0.0000e+00\n",
            "Epoch 268/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.5720 - val_acc: 0.0000e+00\n",
            "Epoch 269/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.5741 - val_acc: 0.0000e+00\n",
            "Epoch 270/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.6053 - val_acc: 0.0000e+00\n",
            "Epoch 271/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1153 - acc: 0.9200 - val_loss: 4.5949 - val_acc: 0.0000e+00\n",
            "Epoch 272/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.5957 - val_acc: 0.0000e+00\n",
            "Epoch 273/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1153 - acc: 0.9067 - val_loss: 4.6135 - val_acc: 0.0000e+00\n",
            "Epoch 274/800\n",
            "300/300 [==============================] - 0s 420us/step - loss: 0.1153 - acc: 0.9133 - val_loss: 4.6213 - val_acc: 0.0000e+00\n",
            "Epoch 275/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1152 - acc: 0.9100 - val_loss: 4.6303 - val_acc: 0.0000e+00\n",
            "Epoch 276/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1153 - acc: 0.9200 - val_loss: 4.6063 - val_acc: 0.0000e+00\n",
            "Epoch 277/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1152 - acc: 0.9100 - val_loss: 4.6244 - val_acc: 0.0000e+00\n",
            "Epoch 278/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1153 - acc: 0.9100 - val_loss: 4.6443 - val_acc: 0.0000e+00\n",
            "Epoch 279/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.6492 - val_acc: 0.0000e+00\n",
            "Epoch 280/800\n",
            "300/300 [==============================] - 0s 340us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.6572 - val_acc: 0.0000e+00\n",
            "Epoch 281/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.6614 - val_acc: 0.0000e+00\n",
            "Epoch 282/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.6718 - val_acc: 0.0000e+00\n",
            "Epoch 283/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.6687 - val_acc: 0.0000e+00\n",
            "Epoch 284/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.6938 - val_acc: 0.0000e+00\n",
            "Epoch 285/800\n",
            "300/300 [==============================] - 0s 391us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.6945 - val_acc: 0.0000e+00\n",
            "Epoch 286/800\n",
            "300/300 [==============================] - 0s 339us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.7023 - val_acc: 0.0000e+00\n",
            "Epoch 287/800\n",
            "300/300 [==============================] - 0s 337us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.7162 - val_acc: 0.0000e+00\n",
            "Epoch 288/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1152 - acc: 0.9100 - val_loss: 4.7307 - val_acc: 0.0000e+00\n",
            "Epoch 289/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.7408 - val_acc: 0.0000e+00\n",
            "Epoch 290/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.7419 - val_acc: 0.0000e+00\n",
            "Epoch 291/800\n",
            "300/300 [==============================] - 0s 338us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.7550 - val_acc: 0.0000e+00\n",
            "Epoch 292/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1152 - acc: 0.9233 - val_loss: 4.7435 - val_acc: 0.0000e+00\n",
            "Epoch 293/800\n",
            "300/300 [==============================] - 0s 345us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.7823 - val_acc: 0.0000e+00\n",
            "Epoch 294/800\n",
            "300/300 [==============================] - 0s 339us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.7693 - val_acc: 0.0000e+00\n",
            "Epoch 295/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.7847 - val_acc: 0.0000e+00\n",
            "Epoch 296/800\n",
            "300/300 [==============================] - 0s 385us/step - loss: 0.1153 - acc: 0.9100 - val_loss: 4.7911 - val_acc: 0.0000e+00\n",
            "Epoch 297/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.7898 - val_acc: 0.0000e+00\n",
            "Epoch 298/800\n",
            "300/300 [==============================] - 0s 337us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.8081 - val_acc: 0.0000e+00\n",
            "Epoch 299/800\n",
            "300/300 [==============================] - 0s 341us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 4.8231 - val_acc: 0.0000e+00\n",
            "Epoch 300/800\n",
            "300/300 [==============================] - 0s 340us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.8166 - val_acc: 0.0000e+00\n",
            "Epoch 301/800\n",
            "300/300 [==============================] - 0s 330us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.8435 - val_acc: 0.0000e+00\n",
            "Epoch 302/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.8233 - val_acc: 0.0000e+00\n",
            "Epoch 303/800\n",
            "300/300 [==============================] - 0s 338us/step - loss: 0.1152 - acc: 0.9200 - val_loss: 4.8443 - val_acc: 0.0000e+00\n",
            "Epoch 304/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.8636 - val_acc: 0.0000e+00\n",
            "Epoch 305/800\n",
            "300/300 [==============================] - 0s 345us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.8596 - val_acc: 0.0000e+00\n",
            "Epoch 306/800\n",
            "300/300 [==============================] - 0s 339us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.8540 - val_acc: 0.0000e+00\n",
            "Epoch 307/800\n",
            "300/300 [==============================] - 0s 345us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.8783 - val_acc: 0.0000e+00\n",
            "Epoch 308/800\n",
            "300/300 [==============================] - 0s 387us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.8918 - val_acc: 0.0000e+00\n",
            "Epoch 309/800\n",
            "300/300 [==============================] - 0s 342us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.8795 - val_acc: 0.0000e+00\n",
            "Epoch 310/800\n",
            "300/300 [==============================] - 0s 342us/step - loss: 0.1152 - acc: 0.9067 - val_loss: 4.8853 - val_acc: 0.0000e+00\n",
            "Epoch 311/800\n",
            "300/300 [==============================] - 0s 345us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.8899 - val_acc: 0.0000e+00\n",
            "Epoch 312/800\n",
            "300/300 [==============================] - 0s 339us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 4.9131 - val_acc: 0.0000e+00\n",
            "Epoch 313/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 4.9190 - val_acc: 0.0000e+00\n",
            "Epoch 314/800\n",
            "300/300 [==============================] - 0s 343us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.9232 - val_acc: 0.0000e+00\n",
            "Epoch 315/800\n",
            "300/300 [==============================] - 0s 344us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.9404 - val_acc: 0.0000e+00\n",
            "Epoch 316/800\n",
            "300/300 [==============================] - 0s 344us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 4.9577 - val_acc: 0.0000e+00\n",
            "Epoch 317/800\n",
            "300/300 [==============================] - 0s 340us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 4.9223 - val_acc: 0.0000e+00\n",
            "Epoch 318/800\n",
            "300/300 [==============================] - 0s 343us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.9538 - val_acc: 0.0000e+00\n",
            "Epoch 319/800\n",
            "300/300 [==============================] - 0s 391us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 4.9721 - val_acc: 0.0000e+00\n",
            "Epoch 320/800\n",
            "300/300 [==============================] - 0s 339us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 4.9789 - val_acc: 0.0000e+00\n",
            "Epoch 321/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.9780 - val_acc: 0.0000e+00\n",
            "Epoch 322/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1151 - acc: 0.9100 - val_loss: 4.9995 - val_acc: 0.0000e+00\n",
            "Epoch 323/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1150 - acc: 0.9133 - val_loss: 4.9822 - val_acc: 0.0000e+00\n",
            "Epoch 324/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.9655 - val_acc: 0.0000e+00\n",
            "Epoch 325/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1152 - acc: 0.9100 - val_loss: 4.9905 - val_acc: 0.0000e+00\n",
            "Epoch 326/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1151 - acc: 0.9100 - val_loss: 5.0043 - val_acc: 0.0000e+00\n",
            "Epoch 327/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 5.0076 - val_acc: 0.0000e+00\n",
            "Epoch 328/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 5.0154 - val_acc: 0.0000e+00\n",
            "Epoch 329/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 5.0365 - val_acc: 0.0000e+00\n",
            "Epoch 330/800\n",
            "300/300 [==============================] - 0s 401us/step - loss: 0.1151 - acc: 0.9233 - val_loss: 5.0320 - val_acc: 0.0000e+00\n",
            "Epoch 331/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 5.0654 - val_acc: 0.0000e+00\n",
            "Epoch 332/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 5.0605 - val_acc: 0.0000e+00\n",
            "Epoch 333/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1150 - acc: 0.9133 - val_loss: 5.0576 - val_acc: 0.0000e+00\n",
            "Epoch 334/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 5.0886 - val_acc: 0.0000e+00\n",
            "Epoch 335/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1150 - acc: 0.9133 - val_loss: 5.0924 - val_acc: 0.0000e+00\n",
            "Epoch 336/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 5.0826 - val_acc: 0.0000e+00\n",
            "Epoch 337/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1150 - acc: 0.9067 - val_loss: 5.0825 - val_acc: 0.0000e+00\n",
            "Epoch 338/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 5.1033 - val_acc: 0.0000e+00\n",
            "Epoch 339/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 5.1141 - val_acc: 0.0000e+00\n",
            "Epoch 340/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1150 - acc: 0.9133 - val_loss: 5.1110 - val_acc: 0.0000e+00\n",
            "Epoch 341/800\n",
            "300/300 [==============================] - 0s 420us/step - loss: 0.1150 - acc: 0.9167 - val_loss: 5.0980 - val_acc: 0.0000e+00\n",
            "Epoch 342/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 5.1328 - val_acc: 0.0000e+00\n",
            "Epoch 343/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 5.1290 - val_acc: 0.0000e+00\n",
            "Epoch 344/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1151 - acc: 0.9100 - val_loss: 5.1293 - val_acc: 0.0000e+00\n",
            "Epoch 345/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 5.1332 - val_acc: 0.0000e+00\n",
            "Epoch 346/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1150 - acc: 0.9100 - val_loss: 5.1417 - val_acc: 0.0000e+00\n",
            "Epoch 347/800\n",
            " 32/300 [==>...........................] - ETA: 0s - loss: 0.0882 - acc: 0.9375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-207-0577789a8ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0;31m#validation_split=.1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     verbose=1,callbacks=[reduce_lr, checkpointer, tensorboard]).history \n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1240\u001b[0m                         \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m    117\u001b[0m            (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   4117\u001b[0m     \"\"\"\n\u001b[1;32m   4118\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 4119\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   4120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   4031\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4033\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4034\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   4150\u001b[0m             \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4152\u001b[0;31m         \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'introselect'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m     \"\"\"\n\u001b[1;32m    580\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpartitioned\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DoKUgpm5vgNb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "49810e2c-823e-45b7-8c6e-a9b2c9815532"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['test'], loc='upper right');\n",
        "\n"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1b660eac50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RTZH1L09vtq7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1493
        },
        "outputId": "7959a2a7-ead1-4be1-961a-7756b5a94126"
      },
      "cell_type": "code",
      "source": [
        "x_test[0:85,:].astype('int')"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,    0,   67, 3785, 8740, 7435],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,    0,   67, 3785, 8740, 7435],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,    0,   67, 3785, 8740, 7435],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,    0,   67, 3785, 8740, 7435],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "metadata": {
        "id": "AVeSq6nUqU-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "d601ab21-6a9c-4220-91a1-8397713eecf4"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right');\n",
        "\n"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1b5d333ef0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4V37QvLdM5ZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27908
        },
        "outputId": "c56931a9-50bc-40b6-9eb0-ea318e3ede10"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Results with full anomily \n",
        "full_anom = 1 \n",
        "anom_samples = 0\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
        "                              patience=300,verbose = 1)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "                    validation_split=.1,\n",
        "                    verbose=1,callbacks=[reduce_lr])\n",
        "\n",
        "score = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 180 samples, validate on 20 samples\n",
            "Epoch 1/800\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1152 - acc: 0.8667 - val_loss: 0.1742 - val_acc: 0.7000\n",
            "Epoch 2/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1145 - acc: 0.8611 - val_loss: 0.1704 - val_acc: 0.7500\n",
            "Epoch 3/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1134 - acc: 0.8667 - val_loss: 0.1692 - val_acc: 0.8000\n",
            "Epoch 4/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1138 - acc: 0.8611 - val_loss: 0.1701 - val_acc: 0.7000\n",
            "Epoch 5/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1147 - acc: 0.8556 - val_loss: 0.1743 - val_acc: 0.7500\n",
            "Epoch 6/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1144 - acc: 0.8556 - val_loss: 0.1706 - val_acc: 0.7500\n",
            "Epoch 7/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1145 - acc: 0.8556 - val_loss: 0.1695 - val_acc: 0.8000\n",
            "Epoch 8/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1144 - acc: 0.8611 - val_loss: 0.1714 - val_acc: 0.7500\n",
            "Epoch 9/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1145 - acc: 0.8833 - val_loss: 0.1703 - val_acc: 0.8000\n",
            "Epoch 10/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1146 - acc: 0.8611 - val_loss: 0.1720 - val_acc: 0.7000\n",
            "Epoch 11/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1137 - acc: 0.8722 - val_loss: 0.1713 - val_acc: 0.7500\n",
            "Epoch 12/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1138 - acc: 0.8778 - val_loss: 0.1691 - val_acc: 0.8000\n",
            "Epoch 13/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1145 - acc: 0.8611 - val_loss: 0.1739 - val_acc: 0.7000\n",
            "Epoch 14/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1142 - acc: 0.8556 - val_loss: 0.1693 - val_acc: 0.7500\n",
            "Epoch 15/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1147 - acc: 0.8722 - val_loss: 0.1693 - val_acc: 0.7500\n",
            "Epoch 16/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.8500 - val_loss: 0.1694 - val_acc: 0.7000\n",
            "Epoch 17/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1145 - acc: 0.8667 - val_loss: 0.1716 - val_acc: 0.8000\n",
            "Epoch 18/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1144 - acc: 0.8778 - val_loss: 0.1682 - val_acc: 0.8000\n",
            "Epoch 19/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1138 - acc: 0.8722 - val_loss: 0.1703 - val_acc: 0.8000\n",
            "Epoch 20/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1134 - acc: 0.8444 - val_loss: 0.1687 - val_acc: 0.7500\n",
            "Epoch 21/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1136 - acc: 0.8944 - val_loss: 0.1700 - val_acc: 0.7500\n",
            "Epoch 22/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1156 - acc: 0.8444 - val_loss: 0.1683 - val_acc: 0.7500\n",
            "Epoch 23/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1135 - acc: 0.8944 - val_loss: 0.1698 - val_acc: 0.8000\n",
            "Epoch 24/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1138 - acc: 0.8667 - val_loss: 0.1686 - val_acc: 0.7500\n",
            "Epoch 25/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1137 - acc: 0.8611 - val_loss: 0.1715 - val_acc: 0.7000\n",
            "Epoch 26/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1137 - acc: 0.8500 - val_loss: 0.1689 - val_acc: 0.7500\n",
            "Epoch 27/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1134 - acc: 0.8611 - val_loss: 0.1673 - val_acc: 0.8000\n",
            "Epoch 28/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1146 - acc: 0.8611 - val_loss: 0.1710 - val_acc: 0.7500\n",
            "Epoch 29/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1142 - acc: 0.8556 - val_loss: 0.1678 - val_acc: 0.8000\n",
            "Epoch 30/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1131 - acc: 0.8667 - val_loss: 0.1673 - val_acc: 0.8000\n",
            "Epoch 31/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1142 - acc: 0.8722 - val_loss: 0.1724 - val_acc: 0.8000\n",
            "Epoch 32/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.8722 - val_loss: 0.1688 - val_acc: 0.8000\n",
            "Epoch 33/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1143 - acc: 0.8556 - val_loss: 0.1679 - val_acc: 0.8000\n",
            "Epoch 34/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1145 - acc: 0.8500 - val_loss: 0.1673 - val_acc: 0.7500\n",
            "Epoch 35/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1130 - acc: 0.8944 - val_loss: 0.1704 - val_acc: 0.7500\n",
            "Epoch 36/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1137 - acc: 0.8667 - val_loss: 0.1720 - val_acc: 0.7000\n",
            "Epoch 37/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1143 - acc: 0.8444 - val_loss: 0.1684 - val_acc: 0.7500\n",
            "Epoch 38/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1133 - acc: 0.8611 - val_loss: 0.1677 - val_acc: 0.7500\n",
            "Epoch 39/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.8556 - val_loss: 0.1694 - val_acc: 0.7500\n",
            "Epoch 40/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1139 - acc: 0.8556 - val_loss: 0.1699 - val_acc: 0.8000\n",
            "Epoch 41/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1138 - acc: 0.8611 - val_loss: 0.1673 - val_acc: 0.8000\n",
            "Epoch 42/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1136 - acc: 0.8722 - val_loss: 0.1675 - val_acc: 0.8000\n",
            "Epoch 43/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1137 - acc: 0.8333 - val_loss: 0.1690 - val_acc: 0.7500\n",
            "Epoch 44/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1138 - acc: 0.8556 - val_loss: 0.1697 - val_acc: 0.7500\n",
            "Epoch 45/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1137 - acc: 0.8500 - val_loss: 0.1700 - val_acc: 0.7500\n",
            "Epoch 46/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.1142 - acc: 0.8444 - val_loss: 0.1698 - val_acc: 0.7000\n",
            "Epoch 47/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1135 - acc: 0.8556 - val_loss: 0.1703 - val_acc: 0.8000\n",
            "Epoch 48/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1138 - acc: 0.8333 - val_loss: 0.1679 - val_acc: 0.7500\n",
            "Epoch 49/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1130 - acc: 0.8611 - val_loss: 0.1691 - val_acc: 0.7500\n",
            "Epoch 50/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1136 - acc: 0.8722 - val_loss: 0.1687 - val_acc: 0.8000\n",
            "Epoch 51/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1151 - acc: 0.8333 - val_loss: 0.1671 - val_acc: 0.8000\n",
            "Epoch 52/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1133 - acc: 0.8444 - val_loss: 0.1677 - val_acc: 0.8000\n",
            "Epoch 53/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1129 - acc: 0.8833 - val_loss: 0.1702 - val_acc: 0.7500\n",
            "Epoch 54/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1141 - acc: 0.8333 - val_loss: 0.1694 - val_acc: 0.8000\n",
            "Epoch 55/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.8333 - val_loss: 0.1716 - val_acc: 0.8000\n",
            "Epoch 56/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1152 - acc: 0.8389 - val_loss: 0.1688 - val_acc: 0.7500\n",
            "Epoch 57/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1132 - acc: 0.8500 - val_loss: 0.1671 - val_acc: 0.8000\n",
            "Epoch 58/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1125 - acc: 0.8667 - val_loss: 0.1671 - val_acc: 0.8000\n",
            "Epoch 59/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1132 - acc: 0.8667 - val_loss: 0.1666 - val_acc: 0.7500\n",
            "Epoch 60/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1136 - acc: 0.8500 - val_loss: 0.1678 - val_acc: 0.8000\n",
            "Epoch 61/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1136 - acc: 0.8667 - val_loss: 0.1686 - val_acc: 0.7000\n",
            "Epoch 62/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1129 - acc: 0.8556 - val_loss: 0.1682 - val_acc: 0.8000\n",
            "Epoch 63/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1129 - acc: 0.8778 - val_loss: 0.1695 - val_acc: 0.8000\n",
            "Epoch 64/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1131 - acc: 0.8778 - val_loss: 0.1674 - val_acc: 0.7500\n",
            "Epoch 65/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1135 - acc: 0.8444 - val_loss: 0.1668 - val_acc: 0.8000\n",
            "Epoch 66/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1127 - acc: 0.8778 - val_loss: 0.1707 - val_acc: 0.7000\n",
            "Epoch 67/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1136 - acc: 0.8500 - val_loss: 0.1696 - val_acc: 0.8000\n",
            "Epoch 68/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1183 - acc: 0.8444 - val_loss: 0.1692 - val_acc: 0.7500\n",
            "Epoch 69/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1133 - acc: 0.8500 - val_loss: 0.1677 - val_acc: 0.7500\n",
            "Epoch 70/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.1127 - acc: 0.8667 - val_loss: 0.1682 - val_acc: 0.8000\n",
            "Epoch 71/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1129 - acc: 0.8556 - val_loss: 0.1669 - val_acc: 0.8000\n",
            "Epoch 72/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1125 - acc: 0.8611 - val_loss: 0.1668 - val_acc: 0.8000\n",
            "Epoch 73/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1129 - acc: 0.8556 - val_loss: 0.1680 - val_acc: 0.7500\n",
            "Epoch 74/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1129 - acc: 0.8556 - val_loss: 0.1695 - val_acc: 0.7000\n",
            "Epoch 75/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1138 - acc: 0.8500 - val_loss: 0.1683 - val_acc: 0.8500\n",
            "Epoch 76/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1123 - acc: 0.8611 - val_loss: 0.1692 - val_acc: 0.7500\n",
            "Epoch 77/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1146 - acc: 0.8722 - val_loss: 0.1663 - val_acc: 0.8000\n",
            "Epoch 78/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1129 - acc: 0.8611 - val_loss: 0.1683 - val_acc: 0.7500\n",
            "Epoch 79/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.8500 - val_loss: 0.1654 - val_acc: 0.7500\n",
            "Epoch 80/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1125 - acc: 0.8833 - val_loss: 0.1667 - val_acc: 0.8000\n",
            "Epoch 81/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1128 - acc: 0.8722 - val_loss: 0.1652 - val_acc: 0.8500\n",
            "Epoch 82/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1128 - acc: 0.8833 - val_loss: 0.1680 - val_acc: 0.7500\n",
            "Epoch 83/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1122 - acc: 0.8667 - val_loss: 0.1674 - val_acc: 0.8000\n",
            "Epoch 84/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1133 - acc: 0.8500 - val_loss: 0.1721 - val_acc: 0.7500\n",
            "Epoch 85/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1130 - acc: 0.8222 - val_loss: 0.1663 - val_acc: 0.8000\n",
            "Epoch 86/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1125 - acc: 0.8722 - val_loss: 0.1669 - val_acc: 0.8000\n",
            "Epoch 87/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1125 - acc: 0.8667 - val_loss: 0.1691 - val_acc: 0.7000\n",
            "Epoch 88/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1125 - acc: 0.8556 - val_loss: 0.1669 - val_acc: 0.8000\n",
            "Epoch 89/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1127 - acc: 0.8722 - val_loss: 0.1666 - val_acc: 0.8000\n",
            "Epoch 90/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1130 - acc: 0.8556 - val_loss: 0.1668 - val_acc: 0.8500\n",
            "Epoch 91/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1131 - acc: 0.8278 - val_loss: 0.1663 - val_acc: 0.8000\n",
            "Epoch 92/800\n",
            "180/180 [==============================] - 0s 331us/step - loss: 0.1128 - acc: 0.8444 - val_loss: 0.1657 - val_acc: 0.8000\n",
            "Epoch 93/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.1127 - acc: 0.8500 - val_loss: 0.1666 - val_acc: 0.8000\n",
            "Epoch 94/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1141 - acc: 0.8389 - val_loss: 0.1647 - val_acc: 0.8000\n",
            "Epoch 95/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1125 - acc: 0.8667 - val_loss: 0.1654 - val_acc: 0.8000\n",
            "Epoch 96/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1127 - acc: 0.8611 - val_loss: 0.1678 - val_acc: 0.7500\n",
            "Epoch 97/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1127 - acc: 0.8556 - val_loss: 0.1678 - val_acc: 0.7500\n",
            "Epoch 98/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1128 - acc: 0.8278 - val_loss: 0.1667 - val_acc: 0.7500\n",
            "Epoch 99/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1130 - acc: 0.8611 - val_loss: 0.1724 - val_acc: 0.7500\n",
            "Epoch 100/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1190 - acc: 0.8333 - val_loss: 0.1678 - val_acc: 0.8000\n",
            "Epoch 101/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1122 - acc: 0.8556 - val_loss: 0.1671 - val_acc: 0.8000\n",
            "Epoch 102/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1125 - acc: 0.8667 - val_loss: 0.1653 - val_acc: 0.8500\n",
            "Epoch 103/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1125 - acc: 0.8667 - val_loss: 0.1664 - val_acc: 0.8000\n",
            "Epoch 104/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1122 - acc: 0.8556 - val_loss: 0.1650 - val_acc: 0.7500\n",
            "Epoch 105/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1121 - acc: 0.8778 - val_loss: 0.1673 - val_acc: 0.7000\n",
            "Epoch 106/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1125 - acc: 0.8500 - val_loss: 0.1661 - val_acc: 0.8500\n",
            "Epoch 107/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1126 - acc: 0.8444 - val_loss: 0.1652 - val_acc: 0.7500\n",
            "Epoch 108/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1122 - acc: 0.8611 - val_loss: 0.1680 - val_acc: 0.7500\n",
            "Epoch 109/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1120 - acc: 0.8333 - val_loss: 0.1653 - val_acc: 0.7500\n",
            "Epoch 110/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1139 - acc: 0.8722 - val_loss: 0.1663 - val_acc: 0.7000\n",
            "Epoch 111/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1128 - acc: 0.8333 - val_loss: 0.1657 - val_acc: 0.7500\n",
            "Epoch 112/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1124 - acc: 0.8444 - val_loss: 0.1683 - val_acc: 0.7000\n",
            "Epoch 113/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1134 - acc: 0.8556 - val_loss: 0.1666 - val_acc: 0.8000\n",
            "Epoch 114/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1123 - acc: 0.8500 - val_loss: 0.1662 - val_acc: 0.8500\n",
            "Epoch 115/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1124 - acc: 0.8500 - val_loss: 0.1642 - val_acc: 0.8000\n",
            "Epoch 116/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1121 - acc: 0.8778 - val_loss: 0.1671 - val_acc: 0.7500\n",
            "Epoch 117/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1125 - acc: 0.8556 - val_loss: 0.1673 - val_acc: 0.8000\n",
            "Epoch 118/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1133 - acc: 0.8444 - val_loss: 0.1650 - val_acc: 0.8000\n",
            "Epoch 119/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1133 - acc: 0.8667 - val_loss: 0.1646 - val_acc: 0.8000\n",
            "Epoch 120/800\n",
            "180/180 [==============================] - 0s 259us/step - loss: 0.1120 - acc: 0.8667 - val_loss: 0.1685 - val_acc: 0.7500\n",
            "Epoch 121/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1139 - acc: 0.8667 - val_loss: 0.1653 - val_acc: 0.8000\n",
            "Epoch 122/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1122 - acc: 0.8722 - val_loss: 0.1656 - val_acc: 0.8000\n",
            "Epoch 123/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1119 - acc: 0.8444 - val_loss: 0.1659 - val_acc: 0.8000\n",
            "Epoch 124/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1120 - acc: 0.8667 - val_loss: 0.1660 - val_acc: 0.7000\n",
            "Epoch 125/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1129 - acc: 0.8611 - val_loss: 0.1653 - val_acc: 0.8000\n",
            "Epoch 126/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1122 - acc: 0.8722 - val_loss: 0.1689 - val_acc: 0.7500\n",
            "Epoch 127/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1123 - acc: 0.8611 - val_loss: 0.1676 - val_acc: 0.8000\n",
            "Epoch 128/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1130 - acc: 0.8500 - val_loss: 0.1641 - val_acc: 0.8000\n",
            "Epoch 129/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1122 - acc: 0.8556 - val_loss: 0.1667 - val_acc: 0.7500\n",
            "Epoch 130/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1119 - acc: 0.8667 - val_loss: 0.1651 - val_acc: 0.8000\n",
            "Epoch 131/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1119 - acc: 0.8611 - val_loss: 0.1654 - val_acc: 0.8500\n",
            "Epoch 132/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1117 - acc: 0.8722 - val_loss: 0.1663 - val_acc: 0.8000\n",
            "Epoch 133/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1122 - acc: 0.8611 - val_loss: 0.1651 - val_acc: 0.7500\n",
            "Epoch 134/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1122 - acc: 0.8611 - val_loss: 0.1654 - val_acc: 0.7500\n",
            "Epoch 135/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1121 - acc: 0.8444 - val_loss: 0.1653 - val_acc: 0.7500\n",
            "Epoch 136/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1133 - acc: 0.8556 - val_loss: 0.1670 - val_acc: 0.7000\n",
            "Epoch 137/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1124 - acc: 0.8778 - val_loss: 0.1656 - val_acc: 0.8000\n",
            "Epoch 138/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1119 - acc: 0.8556 - val_loss: 0.1649 - val_acc: 0.8000\n",
            "Epoch 139/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1126 - acc: 0.8500 - val_loss: 0.1649 - val_acc: 0.8000\n",
            "Epoch 140/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1117 - acc: 0.8611 - val_loss: 0.1642 - val_acc: 0.8000\n",
            "Epoch 141/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1124 - acc: 0.8667 - val_loss: 0.1639 - val_acc: 0.8000\n",
            "Epoch 142/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1124 - acc: 0.8556 - val_loss: 0.1647 - val_acc: 0.8500\n",
            "Epoch 143/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1118 - acc: 0.8722 - val_loss: 0.1657 - val_acc: 0.8000\n",
            "Epoch 144/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1124 - acc: 0.8667 - val_loss: 0.1685 - val_acc: 0.7500\n",
            "Epoch 145/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1126 - acc: 0.8556 - val_loss: 0.1656 - val_acc: 0.8500\n",
            "Epoch 146/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1131 - acc: 0.8389 - val_loss: 0.1640 - val_acc: 0.8000\n",
            "Epoch 147/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1122 - acc: 0.8556 - val_loss: 0.1660 - val_acc: 0.7500\n",
            "Epoch 148/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1124 - acc: 0.8556 - val_loss: 0.1645 - val_acc: 0.7500\n",
            "Epoch 149/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1117 - acc: 0.8833 - val_loss: 0.1638 - val_acc: 0.8000\n",
            "Epoch 150/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1121 - acc: 0.8556 - val_loss: 0.1641 - val_acc: 0.8000\n",
            "Epoch 151/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1126 - acc: 0.8722 - val_loss: 0.1635 - val_acc: 0.8000\n",
            "Epoch 152/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1122 - acc: 0.8833 - val_loss: 0.1666 - val_acc: 0.8000\n",
            "Epoch 153/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1119 - acc: 0.8500 - val_loss: 0.1663 - val_acc: 0.8000\n",
            "Epoch 154/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1124 - acc: 0.8444 - val_loss: 0.1641 - val_acc: 0.8000\n",
            "Epoch 155/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1118 - acc: 0.8500 - val_loss: 0.1655 - val_acc: 0.8500\n",
            "Epoch 156/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1126 - acc: 0.8389 - val_loss: 0.1649 - val_acc: 0.8000\n",
            "Epoch 157/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1114 - acc: 0.8778 - val_loss: 0.1638 - val_acc: 0.7500\n",
            "Epoch 158/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1123 - acc: 0.8722 - val_loss: 0.1663 - val_acc: 0.8000\n",
            "Epoch 159/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1126 - acc: 0.8611 - val_loss: 0.1647 - val_acc: 0.8000\n",
            "Epoch 160/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1121 - acc: 0.8444 - val_loss: 0.1650 - val_acc: 0.7500\n",
            "Epoch 161/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1121 - acc: 0.8444 - val_loss: 0.1648 - val_acc: 0.8500\n",
            "Epoch 162/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1126 - acc: 0.8611 - val_loss: 0.1644 - val_acc: 0.8000\n",
            "Epoch 163/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1119 - acc: 0.8667 - val_loss: 0.1646 - val_acc: 0.8000\n",
            "Epoch 164/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1120 - acc: 0.8556 - val_loss: 0.1634 - val_acc: 0.7500\n",
            "Epoch 165/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1140 - acc: 0.8667 - val_loss: 0.1694 - val_acc: 0.8000\n",
            "Epoch 166/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1128 - acc: 0.8556 - val_loss: 0.1650 - val_acc: 0.7500\n",
            "Epoch 167/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1117 - acc: 0.8389 - val_loss: 0.1641 - val_acc: 0.8500\n",
            "Epoch 168/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1118 - acc: 0.8778 - val_loss: 0.1685 - val_acc: 0.7500\n",
            "Epoch 169/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1130 - acc: 0.8444 - val_loss: 0.1641 - val_acc: 0.7500\n",
            "Epoch 170/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1122 - acc: 0.8444 - val_loss: 0.1651 - val_acc: 0.8000\n",
            "Epoch 171/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1121 - acc: 0.8667 - val_loss: 0.1629 - val_acc: 0.8000\n",
            "Epoch 172/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1119 - acc: 0.8556 - val_loss: 0.1637 - val_acc: 0.8000\n",
            "Epoch 173/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1123 - acc: 0.8611 - val_loss: 0.1637 - val_acc: 0.8500\n",
            "Epoch 174/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1125 - acc: 0.8667 - val_loss: 0.1685 - val_acc: 0.8000\n",
            "Epoch 175/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1129 - acc: 0.8556 - val_loss: 0.1639 - val_acc: 0.7500\n",
            "Epoch 176/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1115 - acc: 0.8611 - val_loss: 0.1675 - val_acc: 0.7500\n",
            "Epoch 177/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1119 - acc: 0.8500 - val_loss: 0.1654 - val_acc: 0.7500\n",
            "Epoch 178/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1121 - acc: 0.8611 - val_loss: 0.1654 - val_acc: 0.8000\n",
            "Epoch 179/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1117 - acc: 0.8333 - val_loss: 0.1638 - val_acc: 0.8000\n",
            "Epoch 180/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1123 - acc: 0.8667 - val_loss: 0.1627 - val_acc: 0.8500\n",
            "Epoch 181/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1120 - acc: 0.8833 - val_loss: 0.1646 - val_acc: 0.8000\n",
            "Epoch 182/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1116 - acc: 0.8722 - val_loss: 0.1702 - val_acc: 0.7500\n",
            "Epoch 183/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1135 - acc: 0.8500 - val_loss: 0.1679 - val_acc: 0.7500\n",
            "Epoch 184/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1117 - acc: 0.8500 - val_loss: 0.1633 - val_acc: 0.8000\n",
            "Epoch 185/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1117 - acc: 0.8667 - val_loss: 0.1654 - val_acc: 0.7000\n",
            "Epoch 186/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1115 - acc: 0.8556 - val_loss: 0.1637 - val_acc: 0.8500\n",
            "Epoch 187/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1112 - acc: 0.8611 - val_loss: 0.1650 - val_acc: 0.8000\n",
            "Epoch 188/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1116 - acc: 0.8389 - val_loss: 0.1625 - val_acc: 0.8000\n",
            "Epoch 189/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1127 - acc: 0.8444 - val_loss: 0.1638 - val_acc: 0.8000\n",
            "Epoch 190/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1119 - acc: 0.8444 - val_loss: 0.1636 - val_acc: 0.7500\n",
            "Epoch 191/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1115 - acc: 0.8778 - val_loss: 0.1638 - val_acc: 0.8000\n",
            "Epoch 192/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1113 - acc: 0.8667 - val_loss: 0.1636 - val_acc: 0.8000\n",
            "Epoch 193/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1119 - acc: 0.8611 - val_loss: 0.1648 - val_acc: 0.7500\n",
            "Epoch 194/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1118 - acc: 0.8611 - val_loss: 0.1635 - val_acc: 0.8000\n",
            "Epoch 195/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1122 - acc: 0.8556 - val_loss: 0.1627 - val_acc: 0.8000\n",
            "Epoch 196/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1127 - acc: 0.8611 - val_loss: 0.1647 - val_acc: 0.7500\n",
            "Epoch 197/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1113 - acc: 0.8722 - val_loss: 0.1656 - val_acc: 0.8500\n",
            "Epoch 198/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1120 - acc: 0.8556 - val_loss: 0.1688 - val_acc: 0.7500\n",
            "Epoch 199/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1145 - acc: 0.8500 - val_loss: 0.1642 - val_acc: 0.8500\n",
            "Epoch 200/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1120 - acc: 0.8722 - val_loss: 0.1654 - val_acc: 0.7500\n",
            "Epoch 201/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1119 - acc: 0.8556 - val_loss: 0.1633 - val_acc: 0.8000\n",
            "Epoch 202/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1114 - acc: 0.8556 - val_loss: 0.1637 - val_acc: 0.8000\n",
            "Epoch 203/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1115 - acc: 0.8500 - val_loss: 0.1635 - val_acc: 0.7500\n",
            "Epoch 204/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1113 - acc: 0.8444 - val_loss: 0.1654 - val_acc: 0.8000\n",
            "Epoch 205/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1116 - acc: 0.8833 - val_loss: 0.1634 - val_acc: 0.8000\n",
            "Epoch 206/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1122 - acc: 0.8667 - val_loss: 0.1793 - val_acc: 0.7000\n",
            "Epoch 207/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.8556 - val_loss: 0.1661 - val_acc: 0.7500\n",
            "Epoch 208/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.1112 - acc: 0.8333 - val_loss: 0.1644 - val_acc: 0.8500\n",
            "Epoch 209/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1117 - acc: 0.8611 - val_loss: 0.1630 - val_acc: 0.8000\n",
            "Epoch 210/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1111 - acc: 0.8611 - val_loss: 0.1646 - val_acc: 0.8000\n",
            "Epoch 211/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1108 - acc: 0.8556 - val_loss: 0.1628 - val_acc: 0.8500\n",
            "Epoch 212/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1112 - acc: 0.8722 - val_loss: 0.1624 - val_acc: 0.7500\n",
            "Epoch 213/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1114 - acc: 0.8778 - val_loss: 0.1646 - val_acc: 0.8500\n",
            "Epoch 214/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1116 - acc: 0.8444 - val_loss: 0.1643 - val_acc: 0.8500\n",
            "Epoch 215/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1116 - acc: 0.8556 - val_loss: 0.1648 - val_acc: 0.8000\n",
            "Epoch 216/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1115 - acc: 0.8333 - val_loss: 0.1615 - val_acc: 0.8000\n",
            "Epoch 217/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1112 - acc: 0.8667 - val_loss: 0.1643 - val_acc: 0.8000\n",
            "Epoch 218/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1114 - acc: 0.8389 - val_loss: 0.1620 - val_acc: 0.8000\n",
            "Epoch 219/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1111 - acc: 0.8722 - val_loss: 0.1640 - val_acc: 0.8000\n",
            "Epoch 220/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1111 - acc: 0.8500 - val_loss: 0.1659 - val_acc: 0.8500\n",
            "Epoch 221/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1119 - acc: 0.8389 - val_loss: 0.1626 - val_acc: 0.8000\n",
            "Epoch 222/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1118 - acc: 0.8667 - val_loss: 0.1623 - val_acc: 0.8000\n",
            "Epoch 223/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1114 - acc: 0.8833 - val_loss: 0.1628 - val_acc: 0.8000\n",
            "Epoch 224/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1110 - acc: 0.8444 - val_loss: 0.1626 - val_acc: 0.7500\n",
            "Epoch 225/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1120 - acc: 0.8722 - val_loss: 0.1677 - val_acc: 0.7000\n",
            "Epoch 226/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1131 - acc: 0.8556 - val_loss: 0.1661 - val_acc: 0.8000\n",
            "Epoch 227/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1127 - acc: 0.8444 - val_loss: 0.1641 - val_acc: 0.8500\n",
            "Epoch 228/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1114 - acc: 0.8500 - val_loss: 0.1652 - val_acc: 0.7500\n",
            "Epoch 229/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1132 - acc: 0.8389 - val_loss: 0.1633 - val_acc: 0.8000\n",
            "Epoch 230/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1113 - acc: 0.8444 - val_loss: 0.1647 - val_acc: 0.7500\n",
            "Epoch 231/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1111 - acc: 0.8556 - val_loss: 0.1680 - val_acc: 0.7500\n",
            "Epoch 232/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1134 - acc: 0.8389 - val_loss: 0.1684 - val_acc: 0.7500\n",
            "Epoch 233/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1126 - acc: 0.8500 - val_loss: 0.1680 - val_acc: 0.7000\n",
            "Epoch 234/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1121 - acc: 0.8500 - val_loss: 0.1632 - val_acc: 0.7500\n",
            "Epoch 235/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1115 - acc: 0.8556 - val_loss: 0.1626 - val_acc: 0.7500\n",
            "Epoch 236/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1117 - acc: 0.8667 - val_loss: 0.1639 - val_acc: 0.7000\n",
            "Epoch 237/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1117 - acc: 0.8500 - val_loss: 0.1621 - val_acc: 0.8000\n",
            "Epoch 238/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1113 - acc: 0.8611 - val_loss: 0.1631 - val_acc: 0.8000\n",
            "Epoch 239/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1115 - acc: 0.8611 - val_loss: 0.1643 - val_acc: 0.8000\n",
            "Epoch 240/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1117 - acc: 0.8722 - val_loss: 0.1620 - val_acc: 0.7500\n",
            "Epoch 241/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1112 - acc: 0.8778 - val_loss: 0.1642 - val_acc: 0.8000\n",
            "Epoch 242/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1121 - acc: 0.8667 - val_loss: 0.1642 - val_acc: 0.7500\n",
            "Epoch 243/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1120 - acc: 0.8500 - val_loss: 0.1625 - val_acc: 0.8500\n",
            "Epoch 244/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1108 - acc: 0.8667 - val_loss: 0.1625 - val_acc: 0.8000\n",
            "Epoch 245/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1112 - acc: 0.8556 - val_loss: 0.1629 - val_acc: 0.8500\n",
            "Epoch 246/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.1628 - val_acc: 0.8000\n",
            "Epoch 247/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1114 - acc: 0.8500 - val_loss: 0.1623 - val_acc: 0.8500\n",
            "Epoch 248/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1112 - acc: 0.8667 - val_loss: 0.1633 - val_acc: 0.7500\n",
            "Epoch 249/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1111 - acc: 0.8556 - val_loss: 0.1643 - val_acc: 0.8500\n",
            "Epoch 250/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1111 - acc: 0.8611 - val_loss: 0.1629 - val_acc: 0.8000\n",
            "Epoch 251/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.1628 - val_acc: 0.8500\n",
            "Epoch 252/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1108 - acc: 0.8556 - val_loss: 0.1645 - val_acc: 0.7500\n",
            "Epoch 253/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1117 - acc: 0.8444 - val_loss: 0.1652 - val_acc: 0.7500\n",
            "Epoch 254/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.1109 - acc: 0.8556 - val_loss: 0.1631 - val_acc: 0.8500\n",
            "Epoch 255/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1106 - acc: 0.8611 - val_loss: 0.1639 - val_acc: 0.7500\n",
            "Epoch 256/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1113 - acc: 0.8444 - val_loss: 0.1621 - val_acc: 0.8000\n",
            "Epoch 257/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1106 - acc: 0.8778 - val_loss: 0.1644 - val_acc: 0.8000\n",
            "Epoch 258/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1112 - acc: 0.8389 - val_loss: 0.1626 - val_acc: 0.8500\n",
            "Epoch 259/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1112 - acc: 0.8611 - val_loss: 0.1661 - val_acc: 0.8000\n",
            "Epoch 260/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1126 - acc: 0.8444 - val_loss: 0.1619 - val_acc: 0.8000\n",
            "Epoch 261/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1115 - acc: 0.8667 - val_loss: 0.1625 - val_acc: 0.7500\n",
            "Epoch 262/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1113 - acc: 0.8778 - val_loss: 0.1620 - val_acc: 0.8000\n",
            "Epoch 263/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1112 - acc: 0.8667 - val_loss: 0.1635 - val_acc: 0.8000\n",
            "Epoch 264/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1109 - acc: 0.8556 - val_loss: 0.1630 - val_acc: 0.8500\n",
            "Epoch 265/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1110 - acc: 0.8611 - val_loss: 0.1618 - val_acc: 0.8000\n",
            "Epoch 266/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1106 - acc: 0.8833 - val_loss: 0.1677 - val_acc: 0.7000\n",
            "Epoch 267/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1117 - acc: 0.8444 - val_loss: 0.1647 - val_acc: 0.7500\n",
            "Epoch 268/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1110 - acc: 0.8333 - val_loss: 0.1626 - val_acc: 0.8000\n",
            "Epoch 269/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1115 - acc: 0.8500 - val_loss: 0.1633 - val_acc: 0.7500\n",
            "Epoch 270/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1113 - acc: 0.8389 - val_loss: 0.1617 - val_acc: 0.8500\n",
            "Epoch 271/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1110 - acc: 0.8667 - val_loss: 0.1645 - val_acc: 0.7500\n",
            "Epoch 272/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1123 - acc: 0.8556 - val_loss: 0.1636 - val_acc: 0.7000\n",
            "Epoch 273/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1110 - acc: 0.8722 - val_loss: 0.1643 - val_acc: 0.8000\n",
            "Epoch 274/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1119 - acc: 0.8833 - val_loss: 0.1631 - val_acc: 0.7500\n",
            "Epoch 275/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1111 - acc: 0.8611 - val_loss: 0.1650 - val_acc: 0.8000\n",
            "Epoch 276/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1113 - acc: 0.8500 - val_loss: 0.1633 - val_acc: 0.7500\n",
            "Epoch 277/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1114 - acc: 0.8444 - val_loss: 0.1628 - val_acc: 0.7500\n",
            "Epoch 278/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1112 - acc: 0.8556 - val_loss: 0.1656 - val_acc: 0.7500\n",
            "Epoch 279/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1110 - acc: 0.8722 - val_loss: 0.1616 - val_acc: 0.8500\n",
            "Epoch 280/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1105 - acc: 0.8611 - val_loss: 0.1615 - val_acc: 0.7500\n",
            "Epoch 281/800\n",
            "180/180 [==============================] - 0s 259us/step - loss: 0.1108 - acc: 0.8611 - val_loss: 0.1621 - val_acc: 0.8000\n",
            "Epoch 282/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1106 - acc: 0.8667 - val_loss: 0.1641 - val_acc: 0.7500\n",
            "Epoch 283/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1126 - acc: 0.8667 - val_loss: 0.1636 - val_acc: 0.8000\n",
            "Epoch 284/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1116 - acc: 0.8611 - val_loss: 0.1650 - val_acc: 0.7500\n",
            "Epoch 285/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1143 - acc: 0.8167 - val_loss: 0.1617 - val_acc: 0.8000\n",
            "Epoch 286/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1109 - acc: 0.8722 - val_loss: 0.1616 - val_acc: 0.8000\n",
            "Epoch 287/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1107 - acc: 0.8778 - val_loss: 0.1622 - val_acc: 0.8500\n",
            "Epoch 288/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1105 - acc: 0.8722 - val_loss: 0.1661 - val_acc: 0.8000\n",
            "Epoch 289/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1115 - acc: 0.8611 - val_loss: 0.1648 - val_acc: 0.8500\n",
            "Epoch 290/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1118 - acc: 0.8556 - val_loss: 0.1626 - val_acc: 0.8000\n",
            "Epoch 291/800\n",
            "180/180 [==============================] - 0s 257us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.1626 - val_acc: 0.8000\n",
            "Epoch 292/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1105 - acc: 0.8556 - val_loss: 0.1628 - val_acc: 0.8000\n",
            "Epoch 293/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1110 - acc: 0.8500 - val_loss: 0.1641 - val_acc: 0.8000\n",
            "Epoch 294/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1109 - acc: 0.8444 - val_loss: 0.1635 - val_acc: 0.8500\n",
            "Epoch 295/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1114 - acc: 0.8556 - val_loss: 0.1644 - val_acc: 0.7500\n",
            "Epoch 296/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1109 - acc: 0.8500 - val_loss: 0.1617 - val_acc: 0.8500\n",
            "Epoch 297/800\n",
            "180/180 [==============================] - 0s 252us/step - loss: 0.1112 - acc: 0.8722 - val_loss: 0.1630 - val_acc: 0.8500\n",
            "Epoch 298/800\n",
            "180/180 [==============================] - 0s 255us/step - loss: 0.1114 - acc: 0.8722 - val_loss: 0.1625 - val_acc: 0.8000\n",
            "Epoch 299/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1104 - acc: 0.8667 - val_loss: 0.1637 - val_acc: 0.8000\n",
            "Epoch 300/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1123 - acc: 0.8500 - val_loss: 0.1621 - val_acc: 0.7500\n",
            "Epoch 301/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1108 - acc: 0.8611 - val_loss: 0.1614 - val_acc: 0.8500\n",
            "Epoch 302/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1108 - acc: 0.8556 - val_loss: 0.1623 - val_acc: 0.8000\n",
            "Epoch 303/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1112 - acc: 0.8722 - val_loss: 0.1626 - val_acc: 0.9000\n",
            "Epoch 304/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1103 - acc: 0.8778 - val_loss: 0.1612 - val_acc: 0.8000\n",
            "Epoch 305/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1104 - acc: 0.8611 - val_loss: 0.1610 - val_acc: 0.7500\n",
            "Epoch 306/800\n",
            "180/180 [==============================] - 0s 249us/step - loss: 0.1105 - acc: 0.8722 - val_loss: 0.1645 - val_acc: 0.7500\n",
            "Epoch 307/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1106 - acc: 0.8611 - val_loss: 0.1619 - val_acc: 0.8000\n",
            "Epoch 308/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1103 - acc: 0.8556 - val_loss: 0.1616 - val_acc: 0.8000\n",
            "Epoch 309/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1119 - acc: 0.8444 - val_loss: 0.1628 - val_acc: 0.7500\n",
            "Epoch 310/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1106 - acc: 0.8667 - val_loss: 0.1636 - val_acc: 0.8000\n",
            "Epoch 311/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1131 - acc: 0.8389 - val_loss: 0.1614 - val_acc: 0.8000\n",
            "Epoch 312/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1107 - acc: 0.8444 - val_loss: 0.1613 - val_acc: 0.8500\n",
            "Epoch 313/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1114 - acc: 0.8333 - val_loss: 0.1625 - val_acc: 0.8000\n",
            "Epoch 314/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1107 - acc: 0.8667 - val_loss: 0.1628 - val_acc: 0.8500\n",
            "Epoch 315/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1107 - acc: 0.8556 - val_loss: 0.1631 - val_acc: 0.7500\n",
            "Epoch 316/800\n",
            "180/180 [==============================] - 0s 251us/step - loss: 0.1114 - acc: 0.8500 - val_loss: 0.1616 - val_acc: 0.8000\n",
            "Epoch 317/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1107 - acc: 0.8500 - val_loss: 0.1636 - val_acc: 0.8000\n",
            "Epoch 318/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1107 - acc: 0.8667 - val_loss: 0.1624 - val_acc: 0.8000\n",
            "Epoch 319/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.1626 - val_acc: 0.8500\n",
            "Epoch 320/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1105 - acc: 0.8611 - val_loss: 0.1628 - val_acc: 0.8000\n",
            "Epoch 321/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1109 - acc: 0.8500 - val_loss: 0.1615 - val_acc: 0.8000\n",
            "Epoch 322/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1105 - acc: 0.8722 - val_loss: 0.1619 - val_acc: 0.8000\n",
            "Epoch 323/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1105 - acc: 0.8611 - val_loss: 0.1608 - val_acc: 0.8500\n",
            "Epoch 324/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1108 - acc: 0.8778 - val_loss: 0.1634 - val_acc: 0.7500\n",
            "Epoch 325/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1108 - acc: 0.8722 - val_loss: 0.1636 - val_acc: 0.7500\n",
            "Epoch 326/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1110 - acc: 0.8500 - val_loss: 0.1611 - val_acc: 0.8000\n",
            "Epoch 327/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1104 - acc: 0.8722 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 328/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1107 - acc: 0.8667 - val_loss: 0.1631 - val_acc: 0.7500\n",
            "Epoch 329/800\n",
            "180/180 [==============================] - 0s 257us/step - loss: 0.1112 - acc: 0.8444 - val_loss: 0.1623 - val_acc: 0.8500\n",
            "Epoch 330/800\n",
            "180/180 [==============================] - 0s 254us/step - loss: 0.1108 - acc: 0.8556 - val_loss: 0.1623 - val_acc: 0.7500\n",
            "Epoch 331/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1103 - acc: 0.8444 - val_loss: 0.1617 - val_acc: 0.8500\n",
            "Epoch 332/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1106 - acc: 0.8444 - val_loss: 0.1623 - val_acc: 0.7500\n",
            "Epoch 333/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1103 - acc: 0.8500 - val_loss: 0.1643 - val_acc: 0.8000\n",
            "Epoch 334/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1115 - acc: 0.8500 - val_loss: 0.1629 - val_acc: 0.7500\n",
            "Epoch 335/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1106 - acc: 0.8667 - val_loss: 0.1609 - val_acc: 0.8000\n",
            "Epoch 336/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1105 - acc: 0.8444 - val_loss: 0.1624 - val_acc: 0.7500\n",
            "Epoch 337/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1108 - acc: 0.8611 - val_loss: 0.1620 - val_acc: 0.8000\n",
            "Epoch 338/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1104 - acc: 0.8778 - val_loss: 0.1612 - val_acc: 0.8000\n",
            "Epoch 339/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1113 - acc: 0.8944 - val_loss: 0.1654 - val_acc: 0.7500\n",
            "Epoch 340/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1112 - acc: 0.8611 - val_loss: 0.1643 - val_acc: 0.7000\n",
            "Epoch 341/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1106 - acc: 0.8500 - val_loss: 0.1622 - val_acc: 0.8000\n",
            "Epoch 342/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1104 - acc: 0.8778 - val_loss: 0.1618 - val_acc: 0.8000\n",
            "Epoch 343/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1103 - acc: 0.8556 - val_loss: 0.1617 - val_acc: 0.8500\n",
            "Epoch 344/800\n",
            "180/180 [==============================] - 0s 251us/step - loss: 0.1109 - acc: 0.8556 - val_loss: 0.1651 - val_acc: 0.7000\n",
            "Epoch 345/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1111 - acc: 0.8611 - val_loss: 0.1661 - val_acc: 0.7000\n",
            "Epoch 346/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1108 - acc: 0.8389 - val_loss: 0.1622 - val_acc: 0.8500\n",
            "Epoch 347/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1103 - acc: 0.8667 - val_loss: 0.1614 - val_acc: 0.8000\n",
            "Epoch 348/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1103 - acc: 0.8500 - val_loss: 0.1605 - val_acc: 0.8000\n",
            "Epoch 349/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1104 - acc: 0.8778 - val_loss: 0.1653 - val_acc: 0.7500\n",
            "Epoch 350/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1120 - acc: 0.8556 - val_loss: 0.1614 - val_acc: 0.8500\n",
            "Epoch 351/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1105 - acc: 0.8556 - val_loss: 0.1653 - val_acc: 0.7000\n",
            "Epoch 352/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1104 - acc: 0.8500 - val_loss: 0.1679 - val_acc: 0.7500\n",
            "Epoch 353/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1114 - acc: 0.8500 - val_loss: 0.1618 - val_acc: 0.8000\n",
            "Epoch 354/800\n",
            "180/180 [==============================] - 0s 250us/step - loss: 0.1106 - acc: 0.8611 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 355/800\n",
            "180/180 [==============================] - 0s 259us/step - loss: 0.1102 - acc: 0.8611 - val_loss: 0.1615 - val_acc: 0.8000\n",
            "Epoch 356/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1105 - acc: 0.8556 - val_loss: 0.1609 - val_acc: 0.8500\n",
            "Epoch 357/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.1610 - val_acc: 0.8000\n",
            "Epoch 358/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1110 - acc: 0.8944 - val_loss: 0.1639 - val_acc: 0.8500\n",
            "Epoch 359/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1112 - acc: 0.8556 - val_loss: 0.1612 - val_acc: 0.8500\n",
            "Epoch 360/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1107 - acc: 0.8722 - val_loss: 0.1614 - val_acc: 0.8000\n",
            "Epoch 361/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1115 - acc: 0.8556 - val_loss: 0.1616 - val_acc: 0.8000\n",
            "Epoch 362/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1101 - acc: 0.8444 - val_loss: 0.1612 - val_acc: 0.8500\n",
            "Epoch 363/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1103 - acc: 0.8556 - val_loss: 0.1604 - val_acc: 0.7500\n",
            "Epoch 364/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1110 - acc: 0.8611 - val_loss: 0.1676 - val_acc: 0.7500\n",
            "Epoch 365/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1116 - acc: 0.8333 - val_loss: 0.1604 - val_acc: 0.7500\n",
            "Epoch 366/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.1642 - val_acc: 0.7500\n",
            "Epoch 367/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1127 - acc: 0.8333 - val_loss: 0.1622 - val_acc: 0.8000\n",
            "Epoch 368/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1102 - acc: 0.8500 - val_loss: 0.1610 - val_acc: 0.7500\n",
            "Epoch 369/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1101 - acc: 0.8389 - val_loss: 0.1637 - val_acc: 0.8000\n",
            "Epoch 370/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.1625 - val_acc: 0.8500\n",
            "Epoch 371/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1104 - acc: 0.8500 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 372/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1104 - acc: 0.8556 - val_loss: 0.1647 - val_acc: 0.8500\n",
            "Epoch 373/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1103 - acc: 0.8500 - val_loss: 0.1640 - val_acc: 0.7500\n",
            "Epoch 374/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1107 - acc: 0.8667 - val_loss: 0.1612 - val_acc: 0.8500\n",
            "Epoch 375/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1108 - acc: 0.8722 - val_loss: 0.1629 - val_acc: 0.7500\n",
            "Epoch 376/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1101 - acc: 0.8556 - val_loss: 0.1616 - val_acc: 0.8000\n",
            "Epoch 377/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1108 - acc: 0.8667 - val_loss: 0.1640 - val_acc: 0.7500\n",
            "Epoch 378/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1102 - acc: 0.8611 - val_loss: 0.1627 - val_acc: 0.8500\n",
            "Epoch 379/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1105 - acc: 0.8444 - val_loss: 0.1604 - val_acc: 0.8500\n",
            "Epoch 380/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1108 - acc: 0.8667 - val_loss: 0.1606 - val_acc: 0.8000\n",
            "Epoch 381/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1101 - acc: 0.8500 - val_loss: 0.1621 - val_acc: 0.8500\n",
            "Epoch 382/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.1618 - val_acc: 0.8000\n",
            "Epoch 383/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1107 - acc: 0.8611 - val_loss: 0.1624 - val_acc: 0.8500\n",
            "Epoch 384/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1116 - acc: 0.8500 - val_loss: 0.1606 - val_acc: 0.8000\n",
            "Epoch 385/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1105 - acc: 0.8667 - val_loss: 0.1604 - val_acc: 0.8500\n",
            "Epoch 386/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1098 - acc: 0.8833 - val_loss: 0.1610 - val_acc: 0.8500\n",
            "Epoch 387/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1100 - acc: 0.8778 - val_loss: 0.1615 - val_acc: 0.8500\n",
            "Epoch 388/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1101 - acc: 0.8611 - val_loss: 0.1613 - val_acc: 0.7500\n",
            "Epoch 389/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1102 - acc: 0.8611 - val_loss: 0.1599 - val_acc: 0.8000\n",
            "Epoch 390/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1103 - acc: 0.8722 - val_loss: 0.1616 - val_acc: 0.8500\n",
            "Epoch 391/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1101 - acc: 0.8667 - val_loss: 0.1620 - val_acc: 0.8000\n",
            "Epoch 392/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1104 - acc: 0.8556 - val_loss: 0.1638 - val_acc: 0.7500\n",
            "Epoch 393/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1105 - acc: 0.8611 - val_loss: 0.1626 - val_acc: 0.8500\n",
            "Epoch 394/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1102 - acc: 0.8611 - val_loss: 0.1610 - val_acc: 0.8500\n",
            "Epoch 395/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1101 - acc: 0.8500 - val_loss: 0.1655 - val_acc: 0.8000\n",
            "Epoch 396/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1115 - acc: 0.8389 - val_loss: 0.1661 - val_acc: 0.7000\n",
            "Epoch 397/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.1598 - val_acc: 0.7500\n",
            "Epoch 398/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1101 - acc: 0.8556 - val_loss: 0.1620 - val_acc: 0.7500\n",
            "Epoch 399/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1102 - acc: 0.8667 - val_loss: 0.1623 - val_acc: 0.7500\n",
            "Epoch 400/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1100 - acc: 0.8778 - val_loss: 0.1632 - val_acc: 0.7500\n",
            "Epoch 401/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1105 - acc: 0.8500 - val_loss: 0.1632 - val_acc: 0.7500\n",
            "Epoch 402/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.1616 - val_acc: 0.8500\n",
            "Epoch 403/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1105 - acc: 0.8556 - val_loss: 0.1610 - val_acc: 0.7500\n",
            "Epoch 404/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1102 - acc: 0.8500 - val_loss: 0.1616 - val_acc: 0.8000\n",
            "Epoch 405/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1100 - acc: 0.8500 - val_loss: 0.1612 - val_acc: 0.8000\n",
            "Epoch 406/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1097 - acc: 0.8389 - val_loss: 0.1619 - val_acc: 0.7500\n",
            "Epoch 407/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1101 - acc: 0.8611 - val_loss: 0.1609 - val_acc: 0.7500\n",
            "Epoch 408/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1105 - acc: 0.8500 - val_loss: 0.1604 - val_acc: 0.8500\n",
            "Epoch 409/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1102 - acc: 0.8667 - val_loss: 0.1623 - val_acc: 0.8000\n",
            "Epoch 410/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1106 - acc: 0.8556 - val_loss: 0.1626 - val_acc: 0.7500\n",
            "Epoch 411/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1104 - acc: 0.8444 - val_loss: 0.1609 - val_acc: 0.8500\n",
            "Epoch 412/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1111 - acc: 0.8667 - val_loss: 0.1611 - val_acc: 0.7500\n",
            "Epoch 413/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1103 - acc: 0.8444 - val_loss: 0.1611 - val_acc: 0.7500\n",
            "Epoch 414/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1101 - acc: 0.8611 - val_loss: 0.1615 - val_acc: 0.7500\n",
            "Epoch 415/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1103 - acc: 0.8611 - val_loss: 0.1607 - val_acc: 0.7500\n",
            "Epoch 416/800\n",
            "180/180 [==============================] - 0s 257us/step - loss: 0.1106 - acc: 0.8444 - val_loss: 0.1610 - val_acc: 0.8500\n",
            "Epoch 417/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1109 - acc: 0.8556 - val_loss: 0.1592 - val_acc: 0.8000\n",
            "Epoch 418/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1107 - acc: 0.8556 - val_loss: 0.1612 - val_acc: 0.7500\n",
            "Epoch 419/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1105 - acc: 0.8333 - val_loss: 0.1607 - val_acc: 0.8000\n",
            "Epoch 420/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1103 - acc: 0.8611 - val_loss: 0.1594 - val_acc: 0.8000\n",
            "Epoch 421/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1103 - acc: 0.8722 - val_loss: 0.1610 - val_acc: 0.8000\n",
            "Epoch 422/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1099 - acc: 0.8556 - val_loss: 0.1600 - val_acc: 0.7500\n",
            "Epoch 423/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1100 - acc: 0.8556 - val_loss: 0.1605 - val_acc: 0.8000\n",
            "Epoch 424/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1097 - acc: 0.8667 - val_loss: 0.1607 - val_acc: 0.8000\n",
            "Epoch 425/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1105 - acc: 0.8444 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 426/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1104 - acc: 0.8722 - val_loss: 0.1605 - val_acc: 0.8500\n",
            "Epoch 427/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.1610 - val_acc: 0.8000\n",
            "Epoch 428/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1095 - acc: 0.8444 - val_loss: 0.1611 - val_acc: 0.7500\n",
            "Epoch 429/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1103 - acc: 0.8333 - val_loss: 0.1606 - val_acc: 0.7500\n",
            "Epoch 430/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1098 - acc: 0.8500 - val_loss: 0.1611 - val_acc: 0.7500\n",
            "Epoch 431/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1100 - acc: 0.8611 - val_loss: 0.1640 - val_acc: 0.7500\n",
            "Epoch 432/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1103 - acc: 0.8500 - val_loss: 0.1592 - val_acc: 0.8500\n",
            "Epoch 433/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1097 - acc: 0.8722 - val_loss: 0.1630 - val_acc: 0.8500\n",
            "Epoch 434/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1108 - acc: 0.8444 - val_loss: 0.1617 - val_acc: 0.7500\n",
            "Epoch 435/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1096 - acc: 0.8500 - val_loss: 0.1610 - val_acc: 0.8000\n",
            "Epoch 436/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1099 - acc: 0.8500 - val_loss: 0.1646 - val_acc: 0.7000\n",
            "Epoch 437/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1108 - acc: 0.8444 - val_loss: 0.1629 - val_acc: 0.7500\n",
            "Epoch 438/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1104 - acc: 0.8611 - val_loss: 0.1603 - val_acc: 0.8500\n",
            "Epoch 439/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1098 - acc: 0.8556 - val_loss: 0.1607 - val_acc: 0.8500\n",
            "Epoch 440/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1101 - acc: 0.8778 - val_loss: 0.1593 - val_acc: 0.8500\n",
            "Epoch 441/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1101 - acc: 0.8556 - val_loss: 0.1610 - val_acc: 0.8500\n",
            "Epoch 442/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1117 - acc: 0.8556 - val_loss: 0.1602 - val_acc: 0.8000\n",
            "Epoch 443/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1112 - acc: 0.8611 - val_loss: 0.1618 - val_acc: 0.7500\n",
            "Epoch 444/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1099 - acc: 0.8556 - val_loss: 0.1605 - val_acc: 0.8000\n",
            "Epoch 445/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1100 - acc: 0.8444 - val_loss: 0.1633 - val_acc: 0.7500\n",
            "Epoch 446/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.1610 - val_acc: 0.7500\n",
            "Epoch 447/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1096 - acc: 0.8500 - val_loss: 0.1597 - val_acc: 0.8500\n",
            "Epoch 448/800\n",
            "180/180 [==============================] - 0s 254us/step - loss: 0.1100 - acc: 0.8444 - val_loss: 0.1595 - val_acc: 0.8000\n",
            "Epoch 449/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1098 - acc: 0.8611 - val_loss: 0.1602 - val_acc: 0.7500\n",
            "Epoch 450/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1101 - acc: 0.8611 - val_loss: 0.1593 - val_acc: 0.7500\n",
            "Epoch 451/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1098 - acc: 0.8889 - val_loss: 0.1620 - val_acc: 0.7000\n",
            "Epoch 452/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1103 - acc: 0.8611 - val_loss: 0.1612 - val_acc: 0.8000\n",
            "Epoch 453/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1097 - acc: 0.8500 - val_loss: 0.1628 - val_acc: 0.8000\n",
            "Epoch 454/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1099 - acc: 0.8444 - val_loss: 0.1601 - val_acc: 0.8500\n",
            "Epoch 455/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1099 - acc: 0.8667 - val_loss: 0.1603 - val_acc: 0.7500\n",
            "Epoch 456/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1100 - acc: 0.8667 - val_loss: 0.1595 - val_acc: 0.8000\n",
            "Epoch 457/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1106 - acc: 0.8556 - val_loss: 0.1607 - val_acc: 0.7000\n",
            "Epoch 458/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1107 - acc: 0.8389 - val_loss: 0.1612 - val_acc: 0.8000\n",
            "Epoch 459/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1096 - acc: 0.8833 - val_loss: 0.1598 - val_acc: 0.8500\n",
            "Epoch 460/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1095 - acc: 0.8611 - val_loss: 0.1591 - val_acc: 0.8000\n",
            "Epoch 461/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1094 - acc: 0.8722 - val_loss: 0.1595 - val_acc: 0.8500\n",
            "Epoch 462/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1097 - acc: 0.8556 - val_loss: 0.1605 - val_acc: 0.8000\n",
            "Epoch 463/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1097 - acc: 0.8500 - val_loss: 0.1619 - val_acc: 0.8000\n",
            "Epoch 464/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1096 - acc: 0.8556 - val_loss: 0.1601 - val_acc: 0.8000\n",
            "Epoch 465/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1099 - acc: 0.8389 - val_loss: 0.1595 - val_acc: 0.8500\n",
            "Epoch 466/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1097 - acc: 0.8611 - val_loss: 0.1609 - val_acc: 0.8000\n",
            "Epoch 467/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1095 - acc: 0.8611 - val_loss: 0.1607 - val_acc: 0.8000\n",
            "Epoch 468/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1097 - acc: 0.8667 - val_loss: 0.1614 - val_acc: 0.7500\n",
            "Epoch 469/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1097 - acc: 0.8667 - val_loss: 0.1612 - val_acc: 0.7500\n",
            "Epoch 470/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1100 - acc: 0.8611 - val_loss: 0.1618 - val_acc: 0.8000\n",
            "Epoch 471/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1097 - acc: 0.8722 - val_loss: 0.1615 - val_acc: 0.7500\n",
            "Epoch 472/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1107 - acc: 0.8500 - val_loss: 0.1614 - val_acc: 0.8000\n",
            "Epoch 473/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1101 - acc: 0.8667 - val_loss: 0.1609 - val_acc: 0.7500\n",
            "Epoch 474/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1096 - acc: 0.8500 - val_loss: 0.1603 - val_acc: 0.8500\n",
            "Epoch 475/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1100 - acc: 0.8778 - val_loss: 0.1606 - val_acc: 0.8500\n",
            "Epoch 476/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1102 - acc: 0.8611 - val_loss: 0.1631 - val_acc: 0.8000\n",
            "Epoch 477/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.1614 - val_acc: 0.7500\n",
            "Epoch 478/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1097 - acc: 0.8611 - val_loss: 0.1603 - val_acc: 0.8500\n",
            "Epoch 479/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1099 - acc: 0.8611 - val_loss: 0.1599 - val_acc: 0.8500\n",
            "Epoch 480/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1094 - acc: 0.8722 - val_loss: 0.1593 - val_acc: 0.8000\n",
            "Epoch 481/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1100 - acc: 0.8389 - val_loss: 0.1591 - val_acc: 0.8500\n",
            "Epoch 482/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1097 - acc: 0.8556 - val_loss: 0.1603 - val_acc: 0.8500\n",
            "Epoch 483/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1099 - acc: 0.8778 - val_loss: 0.1614 - val_acc: 0.7500\n",
            "Epoch 484/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1099 - acc: 0.8667 - val_loss: 0.1606 - val_acc: 0.8500\n",
            "Epoch 485/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1100 - acc: 0.8889 - val_loss: 0.1597 - val_acc: 0.8000\n",
            "Epoch 486/800\n",
            "180/180 [==============================] - 0s 331us/step - loss: 0.1101 - acc: 0.8444 - val_loss: 0.1590 - val_acc: 0.7500\n",
            "Epoch 487/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1094 - acc: 0.8556 - val_loss: 0.1614 - val_acc: 0.8000\n",
            "Epoch 488/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1102 - acc: 0.8667 - val_loss: 0.1617 - val_acc: 0.7500\n",
            "Epoch 489/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1104 - acc: 0.8444 - val_loss: 0.1614 - val_acc: 0.8500\n",
            "Epoch 490/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1096 - acc: 0.8500 - val_loss: 0.1603 - val_acc: 0.7500\n",
            "Epoch 491/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1095 - acc: 0.8444 - val_loss: 0.1614 - val_acc: 0.7500\n",
            "Epoch 492/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1105 - acc: 0.8556 - val_loss: 0.1609 - val_acc: 0.7500\n",
            "Epoch 493/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1095 - acc: 0.8500 - val_loss: 0.1602 - val_acc: 0.8500\n",
            "Epoch 494/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1099 - acc: 0.8556 - val_loss: 0.1594 - val_acc: 0.8500\n",
            "Epoch 495/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.1111 - acc: 0.8500 - val_loss: 0.1601 - val_acc: 0.8500\n",
            "Epoch 496/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1094 - acc: 0.8333 - val_loss: 0.1602 - val_acc: 0.8500\n",
            "Epoch 497/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1097 - acc: 0.8611 - val_loss: 0.1597 - val_acc: 0.8000\n",
            "Epoch 498/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1098 - acc: 0.8556 - val_loss: 0.1619 - val_acc: 0.7500\n",
            "Epoch 499/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1096 - acc: 0.8500 - val_loss: 0.1608 - val_acc: 0.7500\n",
            "Epoch 500/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1093 - acc: 0.8778 - val_loss: 0.1607 - val_acc: 0.8000\n",
            "Epoch 501/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1108 - acc: 0.8389 - val_loss: 0.1595 - val_acc: 0.8000\n",
            "Epoch 502/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1097 - acc: 0.8667 - val_loss: 0.1599 - val_acc: 0.7500\n",
            "Epoch 503/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1101 - acc: 0.8722 - val_loss: 0.1597 - val_acc: 0.8000\n",
            "Epoch 504/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1101 - acc: 0.8444 - val_loss: 0.1594 - val_acc: 0.8500\n",
            "Epoch 505/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1104 - acc: 0.8667 - val_loss: 0.1594 - val_acc: 0.8500\n",
            "Epoch 506/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1105 - acc: 0.8222 - val_loss: 0.1635 - val_acc: 0.8000\n",
            "Epoch 507/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1109 - acc: 0.8778 - val_loss: 0.1610 - val_acc: 0.7000\n",
            "Epoch 508/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1095 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 509/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1102 - acc: 0.8611 - val_loss: 0.1600 - val_acc: 0.8000\n",
            "Epoch 510/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1093 - acc: 0.8611 - val_loss: 0.1630 - val_acc: 0.7500\n",
            "Epoch 511/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1100 - acc: 0.8611 - val_loss: 0.1601 - val_acc: 0.7500\n",
            "Epoch 512/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1101 - acc: 0.8556 - val_loss: 0.1609 - val_acc: 0.7500\n",
            "Epoch 513/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1099 - acc: 0.8611 - val_loss: 0.1601 - val_acc: 0.7500\n",
            "Epoch 514/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1094 - acc: 0.8611 - val_loss: 0.1646 - val_acc: 0.7500\n",
            "Epoch 515/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1116 - acc: 0.8556 - val_loss: 0.1597 - val_acc: 0.8500\n",
            "Epoch 516/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1098 - acc: 0.8611 - val_loss: 0.1613 - val_acc: 0.8000\n",
            "Epoch 517/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1103 - acc: 0.8611 - val_loss: 0.1624 - val_acc: 0.8500\n",
            "Epoch 518/800\n",
            "180/180 [==============================] - 0s 259us/step - loss: 0.1097 - acc: 0.8611 - val_loss: 0.1587 - val_acc: 0.8500\n",
            "Epoch 519/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1100 - acc: 0.8556 - val_loss: 0.1587 - val_acc: 0.8000\n",
            "Epoch 520/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1096 - acc: 0.8667 - val_loss: 0.1600 - val_acc: 0.8000\n",
            "Epoch 521/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1097 - acc: 0.8500 - val_loss: 0.1585 - val_acc: 0.8500\n",
            "Epoch 522/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1102 - acc: 0.8722 - val_loss: 0.1610 - val_acc: 0.7500\n",
            "Epoch 523/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1093 - acc: 0.8556 - val_loss: 0.1598 - val_acc: 0.8500\n",
            "Epoch 524/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1094 - acc: 0.8611 - val_loss: 0.1606 - val_acc: 0.8000\n",
            "Epoch 525/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1095 - acc: 0.8611 - val_loss: 0.1657 - val_acc: 0.7500\n",
            "Epoch 526/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1103 - acc: 0.8444 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 527/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1095 - acc: 0.8444 - val_loss: 0.1637 - val_acc: 0.8500\n",
            "Epoch 528/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1098 - acc: 0.8500 - val_loss: 0.1607 - val_acc: 0.8000\n",
            "Epoch 529/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1100 - acc: 0.8611 - val_loss: 0.1598 - val_acc: 0.7500\n",
            "Epoch 530/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1089 - acc: 0.8667 - val_loss: 0.1612 - val_acc: 0.8000\n",
            "Epoch 531/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1106 - acc: 0.8556 - val_loss: 0.1610 - val_acc: 0.8500\n",
            "Epoch 532/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.1097 - acc: 0.8611 - val_loss: 0.1609 - val_acc: 0.7500\n",
            "Epoch 533/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1092 - acc: 0.8722 - val_loss: 0.1620 - val_acc: 0.8500\n",
            "Epoch 534/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1099 - acc: 0.8611 - val_loss: 0.1589 - val_acc: 0.8000\n",
            "Epoch 535/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1092 - acc: 0.8778 - val_loss: 0.1596 - val_acc: 0.7500\n",
            "Epoch 536/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1101 - acc: 0.8611 - val_loss: 0.1603 - val_acc: 0.7500\n",
            "Epoch 537/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1103 - acc: 0.8556 - val_loss: 0.1580 - val_acc: 0.7500\n",
            "Epoch 538/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1093 - acc: 0.8500 - val_loss: 0.1598 - val_acc: 0.7500\n",
            "Epoch 539/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1090 - acc: 0.8722 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 540/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1102 - acc: 0.8667 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 541/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1090 - acc: 0.8500 - val_loss: 0.1582 - val_acc: 0.7500\n",
            "Epoch 542/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1093 - acc: 0.8667 - val_loss: 0.1638 - val_acc: 0.7500\n",
            "Epoch 543/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1099 - acc: 0.8444 - val_loss: 0.1631 - val_acc: 0.7000\n",
            "Epoch 544/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1093 - acc: 0.8500 - val_loss: 0.1620 - val_acc: 0.8000\n",
            "Epoch 545/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1096 - acc: 0.8444 - val_loss: 0.1596 - val_acc: 0.8500\n",
            "Epoch 546/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1100 - acc: 0.8722 - val_loss: 0.1599 - val_acc: 0.7500\n",
            "Epoch 547/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1093 - acc: 0.8556 - val_loss: 0.1591 - val_acc: 0.8000\n",
            "Epoch 548/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1100 - acc: 0.8833 - val_loss: 0.1606 - val_acc: 0.7500\n",
            "Epoch 549/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1095 - acc: 0.8778 - val_loss: 0.1591 - val_acc: 0.7500\n",
            "Epoch 550/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1092 - acc: 0.8444 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 551/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1102 - acc: 0.8500 - val_loss: 0.1597 - val_acc: 0.7500\n",
            "Epoch 552/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1089 - acc: 0.8667 - val_loss: 0.1611 - val_acc: 0.8500\n",
            "Epoch 553/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1096 - acc: 0.8611 - val_loss: 0.1598 - val_acc: 0.8000\n",
            "Epoch 554/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1104 - acc: 0.8500 - val_loss: 0.1604 - val_acc: 0.8500\n",
            "Epoch 555/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1096 - acc: 0.8556 - val_loss: 0.1588 - val_acc: 0.8500\n",
            "Epoch 556/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1094 - acc: 0.8667 - val_loss: 0.1626 - val_acc: 0.8500\n",
            "Epoch 557/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1108 - acc: 0.8556 - val_loss: 0.1605 - val_acc: 0.8500\n",
            "Epoch 558/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1095 - acc: 0.8500 - val_loss: 0.1605 - val_acc: 0.7500\n",
            "Epoch 559/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1096 - acc: 0.8556 - val_loss: 0.1605 - val_acc: 0.8500\n",
            "Epoch 560/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1100 - acc: 0.8556 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 561/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1095 - acc: 0.8833 - val_loss: 0.1596 - val_acc: 0.8000\n",
            "Epoch 562/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1102 - acc: 0.8444 - val_loss: 0.1598 - val_acc: 0.7500\n",
            "Epoch 563/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1097 - acc: 0.8611 - val_loss: 0.1590 - val_acc: 0.8500\n",
            "Epoch 564/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1090 - acc: 0.8667 - val_loss: 0.1612 - val_acc: 0.7500\n",
            "Epoch 565/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1093 - acc: 0.8556 - val_loss: 0.1605 - val_acc: 0.8500\n",
            "Epoch 566/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1098 - acc: 0.8500 - val_loss: 0.1592 - val_acc: 0.9000\n",
            "Epoch 567/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1101 - acc: 0.8722 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 568/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1096 - acc: 0.8722 - val_loss: 0.1600 - val_acc: 0.7500\n",
            "Epoch 569/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1091 - acc: 0.8611 - val_loss: 0.1588 - val_acc: 0.8500\n",
            "Epoch 570/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1096 - acc: 0.8778 - val_loss: 0.1603 - val_acc: 0.7500\n",
            "Epoch 571/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1096 - acc: 0.8500 - val_loss: 0.1593 - val_acc: 0.8500\n",
            "Epoch 572/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1102 - acc: 0.8389 - val_loss: 0.1592 - val_acc: 0.8000\n",
            "Epoch 573/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1091 - acc: 0.8722 - val_loss: 0.1595 - val_acc: 0.8500\n",
            "Epoch 574/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1097 - acc: 0.8333 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 575/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1094 - acc: 0.8667 - val_loss: 0.1601 - val_acc: 0.8500\n",
            "Epoch 576/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1093 - acc: 0.8611 - val_loss: 0.1592 - val_acc: 0.8500\n",
            "Epoch 577/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1096 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.7500\n",
            "Epoch 578/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.1093 - acc: 0.8611 - val_loss: 0.1592 - val_acc: 0.8500\n",
            "Epoch 579/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1089 - acc: 0.8556 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 580/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1093 - acc: 0.8611 - val_loss: 0.1605 - val_acc: 0.7500\n",
            "Epoch 581/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1097 - acc: 0.8556 - val_loss: 0.1585 - val_acc: 0.8500\n",
            "Epoch 582/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1091 - acc: 0.8944 - val_loss: 0.1611 - val_acc: 0.8500\n",
            "Epoch 583/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1100 - acc: 0.8556 - val_loss: 0.1634 - val_acc: 0.7500\n",
            "Epoch 584/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1106 - acc: 0.8500 - val_loss: 0.1597 - val_acc: 0.7500\n",
            "Epoch 585/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1093 - acc: 0.8556 - val_loss: 0.1592 - val_acc: 0.7500\n",
            "Epoch 586/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1092 - acc: 0.8611 - val_loss: 0.1606 - val_acc: 0.8500\n",
            "Epoch 587/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1090 - acc: 0.8667 - val_loss: 0.1615 - val_acc: 0.7500\n",
            "Epoch 588/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1095 - acc: 0.8556 - val_loss: 0.1591 - val_acc: 0.8500\n",
            "Epoch 589/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1093 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 590/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1094 - acc: 0.8500 - val_loss: 0.1605 - val_acc: 0.7500\n",
            "Epoch 591/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1092 - acc: 0.8611 - val_loss: 0.1587 - val_acc: 0.7500\n",
            "Epoch 592/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1089 - acc: 0.8667 - val_loss: 0.1607 - val_acc: 0.8000\n",
            "Epoch 593/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1096 - acc: 0.8611 - val_loss: 0.1588 - val_acc: 0.8000\n",
            "Epoch 594/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1090 - acc: 0.8556 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 595/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1093 - acc: 0.8778 - val_loss: 0.1585 - val_acc: 0.8500\n",
            "Epoch 596/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1091 - acc: 0.8611 - val_loss: 0.1577 - val_acc: 0.8500\n",
            "Epoch 597/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1093 - acc: 0.8667 - val_loss: 0.1598 - val_acc: 0.8000\n",
            "Epoch 598/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1095 - acc: 0.8667 - val_loss: 0.1597 - val_acc: 0.7500\n",
            "Epoch 599/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1092 - acc: 0.8556 - val_loss: 0.1580 - val_acc: 0.8500\n",
            "Epoch 600/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1090 - acc: 0.8667 - val_loss: 0.1589 - val_acc: 0.8500\n",
            "Epoch 601/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.1088 - acc: 0.8778 - val_loss: 0.1591 - val_acc: 0.9000\n",
            "Epoch 602/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1091 - acc: 0.8722 - val_loss: 0.1632 - val_acc: 0.7500\n",
            "Epoch 603/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1095 - acc: 0.8500 - val_loss: 0.1577 - val_acc: 0.7500\n",
            "\n",
            "Epoch 00603: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 604/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1089 - acc: 0.8722 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 605/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1085 - acc: 0.8500 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 606/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 607/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1084 - acc: 0.8556 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 608/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1587 - val_acc: 0.8500\n",
            "Epoch 609/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1590 - val_acc: 0.8000\n",
            "Epoch 610/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1084 - acc: 0.8500 - val_loss: 0.1588 - val_acc: 0.8000\n",
            "Epoch 611/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1084 - acc: 0.8556 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 612/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 613/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1085 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 614/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 615/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 616/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 617/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8500\n",
            "Epoch 618/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 619/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1083 - acc: 0.8556 - val_loss: 0.1586 - val_acc: 0.8500\n",
            "Epoch 620/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 621/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.1084 - acc: 0.8556 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 622/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 623/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 624/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 625/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 626/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 627/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 628/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8500\n",
            "Epoch 629/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8500\n",
            "Epoch 630/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 631/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 632/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 633/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1588 - val_acc: 0.8000\n",
            "Epoch 634/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1084 - acc: 0.8556 - val_loss: 0.1588 - val_acc: 0.8000\n",
            "Epoch 635/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 636/800\n",
            "180/180 [==============================] - 0s 336us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 637/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1587 - val_acc: 0.8000\n",
            "Epoch 638/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 639/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 640/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 641/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1084 - acc: 0.8722 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 642/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8500\n",
            "Epoch 643/800\n",
            "180/180 [==============================] - 0s 328us/step - loss: 0.1084 - acc: 0.8556 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 644/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 645/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8500\n",
            "Epoch 646/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8500\n",
            "Epoch 647/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 648/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 649/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 650/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 651/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 652/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 653/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 654/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8500\n",
            "Epoch 655/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 656/800\n",
            "180/180 [==============================] - 0s 254us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 657/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 658/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 659/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1084 - acc: 0.8556 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 660/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 661/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 662/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 663/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 664/800\n",
            "180/180 [==============================] - 0s 255us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 665/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 666/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 667/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 668/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 669/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 670/800\n",
            "180/180 [==============================] - 0s 253us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 671/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1083 - acc: 0.8778 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 672/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8500\n",
            "Epoch 673/800\n",
            "180/180 [==============================] - 0s 256us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 674/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1083 - acc: 0.8556 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 675/800\n",
            "180/180 [==============================] - 0s 256us/step - loss: 0.1083 - acc: 0.8556 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 676/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 677/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 678/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 679/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 680/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 681/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 682/800\n",
            "180/180 [==============================] - 0s 255us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 683/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 684/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 685/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 686/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1083 - acc: 0.8556 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 687/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1083 - acc: 0.8778 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 688/800\n",
            "180/180 [==============================] - 0s 257us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 689/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 690/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 691/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 692/800\n",
            "180/180 [==============================] - 0s 256us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 693/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 694/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 695/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 696/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 697/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 698/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1083 - acc: 0.8778 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 699/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 700/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 701/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 702/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 703/800\n",
            "180/180 [==============================] - 0s 256us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 704/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 705/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 706/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 707/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 708/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 709/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 710/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 711/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 712/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 713/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 714/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 715/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 716/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1083 - acc: 0.8778 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 717/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 718/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 719/800\n",
            "180/180 [==============================] - 0s 255us/step - loss: 0.1084 - acc: 0.8500 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 720/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 721/800\n",
            "180/180 [==============================] - 0s 253us/step - loss: 0.1083 - acc: 0.8556 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 722/800\n",
            "180/180 [==============================] - 0s 252us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 723/800\n",
            "180/180 [==============================] - 0s 252us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 724/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1083 - acc: 0.8778 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 725/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 726/800\n",
            "180/180 [==============================] - 0s 256us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 727/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 728/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 729/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 730/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 731/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 732/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 733/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1580 - val_acc: 0.8000\n",
            "Epoch 734/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 735/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 736/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 737/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 738/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 739/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1580 - val_acc: 0.8000\n",
            "Epoch 740/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1579 - val_acc: 0.8500\n",
            "Epoch 741/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 742/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 743/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 744/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 745/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 746/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 747/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 748/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1083 - acc: 0.8556 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 749/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 750/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 751/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1580 - val_acc: 0.8000\n",
            "Epoch 752/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 753/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 754/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 755/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 756/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 757/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 758/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 759/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 760/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1579 - val_acc: 0.8000\n",
            "Epoch 761/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 762/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 763/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 764/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 765/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 766/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 767/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1580 - val_acc: 0.8000\n",
            "Epoch 768/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.7500\n",
            "Epoch 769/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1580 - val_acc: 0.8500\n",
            "Epoch 770/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1580 - val_acc: 0.8500\n",
            "Epoch 771/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 772/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 773/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 774/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 775/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 776/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 777/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1082 - acc: 0.8556 - val_loss: 0.1578 - val_acc: 0.8000\n",
            "Epoch 778/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1579 - val_acc: 0.8000\n",
            "Epoch 779/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 780/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 781/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 782/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 783/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1081 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 784/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 785/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1081 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 786/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1579 - val_acc: 0.8500\n",
            "Epoch 787/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 788/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1082 - acc: 0.8556 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 789/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 790/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1581 - val_acc: 0.7500\n",
            "Epoch 791/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1579 - val_acc: 0.8000\n",
            "Epoch 792/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1579 - val_acc: 0.8000\n",
            "Epoch 793/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1082 - acc: 0.8778 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 794/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1081 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 795/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 796/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 797/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1578 - val_acc: 0.8000\n",
            "Epoch 798/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 799/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1082 - acc: 0.8778 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 800/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1083 - acc: 0.8556 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "200/200 [==============================] - 0s 108us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[28.785220642089843, 0.215]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UluQVqf8OBBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 28186
        },
        "outputId": "63bdb3ef-0965-42f9-99b0-8de73890331a"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Results with full anomily \n",
        "full_anom = 1 \n",
        "anom_samples = 0\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
        "                              patience=200,verbose = 1)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "                    validation_split=.1,\n",
        "                    verbose=1,callbacks=[reduce_lr])\n",
        "\n",
        "score = autoencoder.predict( x_test2, batch_size=32, verbose=1, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 180 samples, validate on 20 samples\n",
            "Epoch 1/800\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 0.1203 - acc: 0.8389 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 2/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1150 - acc: 0.8722 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 3/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1154 - acc: 0.8944 - val_loss: 0.0508 - val_acc: 0.8500\n",
            "Epoch 4/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1158 - acc: 0.8778 - val_loss: 0.0509 - val_acc: 0.8500\n",
            "Epoch 5/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1155 - acc: 0.8778 - val_loss: 0.0510 - val_acc: 0.8000\n",
            "Epoch 6/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1156 - acc: 0.8889 - val_loss: 0.0494 - val_acc: 0.9000\n",
            "Epoch 7/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1157 - acc: 0.8833 - val_loss: 0.0509 - val_acc: 0.9000\n",
            "Epoch 8/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1162 - acc: 0.8778 - val_loss: 0.0498 - val_acc: 0.8500\n",
            "Epoch 9/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1161 - acc: 0.8889 - val_loss: 0.0493 - val_acc: 0.9000\n",
            "Epoch 10/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1158 - acc: 0.8889 - val_loss: 0.0514 - val_acc: 0.8500\n",
            "Epoch 11/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1183 - acc: 0.8667 - val_loss: 0.0508 - val_acc: 0.8500\n",
            "Epoch 12/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1151 - acc: 0.8944 - val_loss: 0.0495 - val_acc: 0.8500\n",
            "Epoch 13/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1164 - acc: 0.8722 - val_loss: 0.0492 - val_acc: 0.8000\n",
            "Epoch 14/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1152 - acc: 0.9000 - val_loss: 0.0515 - val_acc: 0.8500\n",
            "Epoch 15/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1165 - acc: 0.9056 - val_loss: 0.0504 - val_acc: 0.8000\n",
            "Epoch 16/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1154 - acc: 0.8944 - val_loss: 0.0506 - val_acc: 0.8500\n",
            "Epoch 17/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1152 - acc: 0.9056 - val_loss: 0.0536 - val_acc: 0.7500\n",
            "Epoch 18/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1155 - acc: 0.8944 - val_loss: 0.0492 - val_acc: 0.8000\n",
            "Epoch 19/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1153 - acc: 0.9111 - val_loss: 0.0512 - val_acc: 0.8500\n",
            "Epoch 20/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1169 - acc: 0.8944 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 21/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1159 - acc: 0.9111 - val_loss: 0.0503 - val_acc: 0.7500\n",
            "Epoch 22/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1157 - acc: 0.9056 - val_loss: 0.0507 - val_acc: 0.8000\n",
            "Epoch 23/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1161 - acc: 0.9111 - val_loss: 0.0508 - val_acc: 0.8000\n",
            "Epoch 24/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.1161 - acc: 0.9167 - val_loss: 0.0519 - val_acc: 0.8000\n",
            "Epoch 25/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1153 - acc: 0.9056 - val_loss: 0.0497 - val_acc: 0.8500\n",
            "Epoch 26/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1151 - acc: 0.9000 - val_loss: 0.0491 - val_acc: 0.8000\n",
            "Epoch 27/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1157 - acc: 0.9111 - val_loss: 0.0526 - val_acc: 0.8500\n",
            "Epoch 28/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1165 - acc: 0.9222 - val_loss: 0.0520 - val_acc: 0.8000\n",
            "Epoch 29/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1179 - acc: 0.9111 - val_loss: 0.0516 - val_acc: 0.7000\n",
            "Epoch 30/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1158 - acc: 0.8889 - val_loss: 0.0504 - val_acc: 0.7000\n",
            "Epoch 31/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1155 - acc: 0.9056 - val_loss: 0.0509 - val_acc: 0.8000\n",
            "Epoch 32/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1165 - acc: 0.9000 - val_loss: 0.0518 - val_acc: 0.8000\n",
            "Epoch 33/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1170 - acc: 0.8722 - val_loss: 0.0501 - val_acc: 0.8000\n",
            "Epoch 34/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1155 - acc: 0.9056 - val_loss: 0.0522 - val_acc: 0.8000\n",
            "Epoch 35/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1154 - acc: 0.9056 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 36/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1153 - acc: 0.9000 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 37/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1156 - acc: 0.9000 - val_loss: 0.0494 - val_acc: 0.8000\n",
            "Epoch 38/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1154 - acc: 0.9167 - val_loss: 0.0509 - val_acc: 0.8000\n",
            "Epoch 39/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1161 - acc: 0.8944 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 40/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1155 - acc: 0.9167 - val_loss: 0.0494 - val_acc: 0.8000\n",
            "Epoch 41/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1149 - acc: 0.9056 - val_loss: 0.0514 - val_acc: 0.8000\n",
            "Epoch 42/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1153 - acc: 0.9111 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 43/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 0.0529 - val_acc: 0.8500\n",
            "Epoch 44/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1164 - acc: 0.9278 - val_loss: 0.0498 - val_acc: 0.8000\n",
            "Epoch 45/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1154 - acc: 0.8722 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 46/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1150 - acc: 0.9111 - val_loss: 0.0495 - val_acc: 0.7500\n",
            "Epoch 47/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.1152 - acc: 0.9222 - val_loss: 0.0500 - val_acc: 0.8500\n",
            "Epoch 48/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1161 - acc: 0.9111 - val_loss: 0.0530 - val_acc: 0.8500\n",
            "Epoch 49/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1157 - acc: 0.9278 - val_loss: 0.0507 - val_acc: 0.8000\n",
            "Epoch 50/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1154 - acc: 0.9278 - val_loss: 0.0510 - val_acc: 0.8000\n",
            "Epoch 51/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1165 - acc: 0.9111 - val_loss: 0.0529 - val_acc: 0.7500\n",
            "Epoch 52/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1163 - acc: 0.9222 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 53/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1161 - acc: 0.9167 - val_loss: 0.0501 - val_acc: 0.8500\n",
            "Epoch 54/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1153 - acc: 0.9111 - val_loss: 0.0501 - val_acc: 0.7500\n",
            "Epoch 55/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1154 - acc: 0.9333 - val_loss: 0.0500 - val_acc: 0.8000\n",
            "Epoch 56/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1159 - acc: 0.9222 - val_loss: 0.0494 - val_acc: 0.8000\n",
            "Epoch 57/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1150 - acc: 0.9278 - val_loss: 0.0506 - val_acc: 0.8500\n",
            "Epoch 58/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1164 - acc: 0.9056 - val_loss: 0.0512 - val_acc: 0.8000\n",
            "Epoch 59/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0503 - val_acc: 0.7500\n",
            "Epoch 60/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1154 - acc: 0.9222 - val_loss: 0.0510 - val_acc: 0.7500\n",
            "Epoch 61/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1175 - acc: 0.8944 - val_loss: 0.0515 - val_acc: 0.7500\n",
            "Epoch 62/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1158 - acc: 0.9222 - val_loss: 0.0521 - val_acc: 0.7500\n",
            "Epoch 63/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1164 - acc: 0.9278 - val_loss: 0.0495 - val_acc: 0.8500\n",
            "Epoch 64/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1146 - acc: 0.9333 - val_loss: 0.0496 - val_acc: 0.8000\n",
            "Epoch 65/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1157 - acc: 0.9278 - val_loss: 0.0497 - val_acc: 0.8000\n",
            "Epoch 66/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1156 - acc: 0.9333 - val_loss: 0.0522 - val_acc: 0.8000\n",
            "Epoch 67/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1164 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.8500\n",
            "Epoch 68/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1149 - acc: 0.9278 - val_loss: 0.0493 - val_acc: 0.8500\n",
            "Epoch 69/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1148 - acc: 0.9333 - val_loss: 0.0525 - val_acc: 0.8500\n",
            "Epoch 70/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1159 - acc: 0.9167 - val_loss: 0.0511 - val_acc: 0.7500\n",
            "Epoch 71/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1170 - acc: 0.9056 - val_loss: 0.0494 - val_acc: 0.8500\n",
            "Epoch 72/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1148 - acc: 0.9222 - val_loss: 0.0552 - val_acc: 0.8500\n",
            "Epoch 73/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1177 - acc: 0.9111 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 74/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1148 - acc: 0.9389 - val_loss: 0.0541 - val_acc: 0.8500\n",
            "Epoch 75/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1160 - acc: 0.9278 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 76/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1148 - acc: 0.9278 - val_loss: 0.0517 - val_acc: 0.9000\n",
            "Epoch 77/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1168 - acc: 0.9333 - val_loss: 0.0492 - val_acc: 0.9000\n",
            "Epoch 78/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1166 - acc: 0.9333 - val_loss: 0.0517 - val_acc: 0.9000\n",
            "Epoch 79/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1168 - acc: 0.9167 - val_loss: 0.0509 - val_acc: 0.9500\n",
            "Epoch 80/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1151 - acc: 0.9444 - val_loss: 0.0515 - val_acc: 0.9000\n",
            "Epoch 81/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1162 - acc: 0.9500 - val_loss: 0.0502 - val_acc: 0.8000\n",
            "Epoch 82/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 83/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1157 - acc: 0.9222 - val_loss: 0.0512 - val_acc: 0.9000\n",
            "Epoch 84/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1154 - acc: 0.9389 - val_loss: 0.0492 - val_acc: 0.8000\n",
            "Epoch 85/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 86/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1149 - acc: 0.9278 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 87/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1156 - acc: 0.9278 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 88/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 0.0511 - val_acc: 0.8500\n",
            "Epoch 89/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1160 - acc: 0.9389 - val_loss: 0.0533 - val_acc: 0.8000\n",
            "Epoch 90/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1158 - acc: 0.9333 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 91/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1163 - acc: 0.9389 - val_loss: 0.0519 - val_acc: 0.8500\n",
            "Epoch 92/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1156 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 93/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1153 - acc: 0.9111 - val_loss: 0.0497 - val_acc: 0.8500\n",
            "Epoch 94/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1153 - acc: 0.9500 - val_loss: 0.0506 - val_acc: 0.8000\n",
            "Epoch 95/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1153 - acc: 0.9389 - val_loss: 0.0510 - val_acc: 0.8500\n",
            "Epoch 96/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1155 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 97/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1156 - acc: 0.9389 - val_loss: 0.0514 - val_acc: 0.8500\n",
            "Epoch 98/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1149 - acc: 0.9278 - val_loss: 0.0510 - val_acc: 0.8500\n",
            "Epoch 99/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0503 - val_acc: 0.9000\n",
            "Epoch 100/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1156 - acc: 0.9389 - val_loss: 0.0517 - val_acc: 0.8500\n",
            "Epoch 101/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1171 - acc: 0.9333 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 102/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1156 - acc: 0.9389 - val_loss: 0.0555 - val_acc: 0.7500\n",
            "Epoch 103/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1181 - acc: 0.9000 - val_loss: 0.0522 - val_acc: 0.9000\n",
            "Epoch 104/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1151 - acc: 0.9389 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 105/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1151 - acc: 0.9278 - val_loss: 0.0493 - val_acc: 0.8500\n",
            "Epoch 106/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1151 - acc: 0.9222 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 107/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1162 - acc: 0.9444 - val_loss: 0.0500 - val_acc: 0.8500\n",
            "Epoch 108/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1145 - acc: 0.9500 - val_loss: 0.0538 - val_acc: 0.8000\n",
            "Epoch 109/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1164 - acc: 0.9278 - val_loss: 0.0509 - val_acc: 0.8500\n",
            "Epoch 110/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1154 - acc: 0.9222 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 111/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0487 - val_acc: 0.8500\n",
            "Epoch 112/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1154 - acc: 0.9389 - val_loss: 0.0502 - val_acc: 0.9000\n",
            "Epoch 113/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1156 - acc: 0.9333 - val_loss: 0.0496 - val_acc: 0.8000\n",
            "Epoch 114/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1148 - acc: 0.9444 - val_loss: 0.0540 - val_acc: 0.8000\n",
            "Epoch 115/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1173 - acc: 0.9222 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 116/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1151 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 117/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1149 - acc: 0.9444 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 118/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0520 - val_acc: 0.8000\n",
            "Epoch 119/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0513 - val_acc: 0.9000\n",
            "Epoch 120/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1152 - acc: 0.9222 - val_loss: 0.0499 - val_acc: 0.9000\n",
            "Epoch 121/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0496 - val_acc: 0.8000\n",
            "Epoch 122/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1152 - acc: 0.9222 - val_loss: 0.0499 - val_acc: 0.7500\n",
            "Epoch 123/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0515 - val_acc: 0.8000\n",
            "Epoch 124/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1158 - acc: 0.9278 - val_loss: 0.0493 - val_acc: 0.8000\n",
            "Epoch 125/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1160 - acc: 0.9167 - val_loss: 0.0507 - val_acc: 0.8000\n",
            "Epoch 126/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1154 - acc: 0.9444 - val_loss: 0.0492 - val_acc: 0.9000\n",
            "Epoch 127/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1151 - acc: 0.9333 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 128/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1151 - acc: 0.9333 - val_loss: 0.0495 - val_acc: 0.8500\n",
            "Epoch 129/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1153 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 130/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1150 - acc: 0.9333 - val_loss: 0.0502 - val_acc: 0.9500\n",
            "Epoch 131/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1153 - acc: 0.9222 - val_loss: 0.0516 - val_acc: 0.9000\n",
            "Epoch 132/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1156 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.8000\n",
            "Epoch 133/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1158 - acc: 0.9278 - val_loss: 0.0503 - val_acc: 0.8500\n",
            "Epoch 134/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1151 - acc: 0.9389 - val_loss: 0.0504 - val_acc: 0.8000\n",
            "Epoch 135/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1149 - acc: 0.9444 - val_loss: 0.0505 - val_acc: 0.7500\n",
            "Epoch 136/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1152 - acc: 0.9389 - val_loss: 0.0487 - val_acc: 0.8000\n",
            "Epoch 137/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1151 - acc: 0.9389 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 138/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1158 - acc: 0.9167 - val_loss: 0.0533 - val_acc: 0.8500\n",
            "Epoch 139/800\n",
            "180/180 [==============================] - 0s 334us/step - loss: 0.1172 - acc: 0.9333 - val_loss: 0.0501 - val_acc: 0.9000\n",
            "Epoch 140/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1148 - acc: 0.9333 - val_loss: 0.0508 - val_acc: 0.8000\n",
            "Epoch 141/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1150 - acc: 0.9222 - val_loss: 0.0496 - val_acc: 0.9000\n",
            "Epoch 142/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1151 - acc: 0.9333 - val_loss: 0.0497 - val_acc: 0.8500\n",
            "Epoch 143/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1150 - acc: 0.9333 - val_loss: 0.0515 - val_acc: 0.8500\n",
            "Epoch 144/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1156 - acc: 0.9333 - val_loss: 0.0495 - val_acc: 0.9500\n",
            "Epoch 145/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0520 - val_acc: 0.8000\n",
            "Epoch 146/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1149 - acc: 0.9389 - val_loss: 0.0497 - val_acc: 0.8000\n",
            "Epoch 147/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1150 - acc: 0.9278 - val_loss: 0.0514 - val_acc: 0.9000\n",
            "Epoch 148/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1153 - acc: 0.9389 - val_loss: 0.0508 - val_acc: 0.8500\n",
            "Epoch 149/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1149 - acc: 0.9444 - val_loss: 0.0495 - val_acc: 0.9000\n",
            "Epoch 150/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1148 - acc: 0.9222 - val_loss: 0.0509 - val_acc: 0.9000\n",
            "Epoch 151/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1148 - acc: 0.9222 - val_loss: 0.0497 - val_acc: 0.8000\n",
            "Epoch 152/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1157 - acc: 0.9167 - val_loss: 0.0510 - val_acc: 0.9000\n",
            "Epoch 153/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1149 - acc: 0.9389 - val_loss: 0.0546 - val_acc: 0.8500\n",
            "Epoch 154/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1151 - acc: 0.9278 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 155/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1148 - acc: 0.9500 - val_loss: 0.0519 - val_acc: 0.9000\n",
            "Epoch 156/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1152 - acc: 0.9389 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 157/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1146 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.8500\n",
            "Epoch 158/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1150 - acc: 0.9278 - val_loss: 0.0495 - val_acc: 0.8000\n",
            "Epoch 159/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1153 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 160/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1149 - acc: 0.9278 - val_loss: 0.0507 - val_acc: 0.8500\n",
            "Epoch 161/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1156 - acc: 0.9222 - val_loss: 0.0495 - val_acc: 0.9000\n",
            "Epoch 162/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1156 - acc: 0.9222 - val_loss: 0.0506 - val_acc: 0.9000\n",
            "Epoch 163/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1158 - acc: 0.9389 - val_loss: 0.0504 - val_acc: 0.7500\n",
            "Epoch 164/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 165/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1145 - acc: 0.9278 - val_loss: 0.0513 - val_acc: 0.9000\n",
            "Epoch 166/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1162 - acc: 0.9222 - val_loss: 0.0493 - val_acc: 0.9500\n",
            "Epoch 167/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1147 - acc: 0.9333 - val_loss: 0.0505 - val_acc: 0.8500\n",
            "Epoch 168/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1154 - acc: 0.9278 - val_loss: 0.0513 - val_acc: 0.8500\n",
            "Epoch 169/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1147 - acc: 0.9222 - val_loss: 0.0497 - val_acc: 0.9500\n",
            "Epoch 170/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1146 - acc: 0.9389 - val_loss: 0.0492 - val_acc: 0.9000\n",
            "Epoch 171/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1145 - acc: 0.9444 - val_loss: 0.0504 - val_acc: 0.8500\n",
            "Epoch 172/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0509 - val_acc: 0.9000\n",
            "Epoch 173/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1158 - acc: 0.9389 - val_loss: 0.0501 - val_acc: 0.8500\n",
            "Epoch 174/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1148 - acc: 0.9389 - val_loss: 0.0511 - val_acc: 0.8500\n",
            "Epoch 175/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1149 - acc: 0.9333 - val_loss: 0.0492 - val_acc: 0.8000\n",
            "Epoch 176/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0506 - val_acc: 0.8500\n",
            "Epoch 177/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1146 - acc: 0.9444 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 178/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1144 - acc: 0.9389 - val_loss: 0.0497 - val_acc: 0.9000\n",
            "Epoch 179/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1154 - acc: 0.9278 - val_loss: 0.0513 - val_acc: 0.9000\n",
            "Epoch 180/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1161 - acc: 0.9389 - val_loss: 0.0524 - val_acc: 0.8000\n",
            "Epoch 181/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1158 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 182/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1150 - acc: 0.9222 - val_loss: 0.0495 - val_acc: 0.9000\n",
            "Epoch 183/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1158 - acc: 0.9389 - val_loss: 0.0502 - val_acc: 0.9000\n",
            "Epoch 184/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.1146 - acc: 0.9389 - val_loss: 0.0499 - val_acc: 0.8000\n",
            "Epoch 185/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1155 - acc: 0.9389 - val_loss: 0.0493 - val_acc: 0.8500\n",
            "Epoch 186/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1150 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 187/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1149 - acc: 0.9278 - val_loss: 0.0513 - val_acc: 0.8500\n",
            "Epoch 188/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1162 - acc: 0.9278 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 189/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1147 - acc: 0.9222 - val_loss: 0.0501 - val_acc: 0.9000\n",
            "Epoch 190/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1148 - acc: 0.9389 - val_loss: 0.0497 - val_acc: 0.8500\n",
            "Epoch 191/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1146 - acc: 0.9333 - val_loss: 0.0501 - val_acc: 0.9000\n",
            "Epoch 192/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1146 - acc: 0.9389 - val_loss: 0.0499 - val_acc: 0.9000\n",
            "Epoch 193/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1146 - acc: 0.9500 - val_loss: 0.0517 - val_acc: 0.9000\n",
            "Epoch 194/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1157 - acc: 0.9222 - val_loss: 0.0513 - val_acc: 0.9000\n",
            "Epoch 195/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1145 - acc: 0.9389 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 196/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1146 - acc: 0.9444 - val_loss: 0.0502 - val_acc: 0.8000\n",
            "Epoch 197/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1146 - acc: 0.9333 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 198/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1151 - acc: 0.9222 - val_loss: 0.0519 - val_acc: 0.9000\n",
            "Epoch 199/800\n",
            "180/180 [==============================] - 0s 257us/step - loss: 0.1149 - acc: 0.9333 - val_loss: 0.0500 - val_acc: 0.9000\n",
            "Epoch 200/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1147 - acc: 0.9333 - val_loss: 0.0501 - val_acc: 0.8500\n",
            "Epoch 201/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1156 - acc: 0.9278 - val_loss: 0.0514 - val_acc: 0.8000\n",
            "Epoch 202/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1161 - acc: 0.9222 - val_loss: 0.0512 - val_acc: 0.9000\n",
            "Epoch 203/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1166 - acc: 0.8944 - val_loss: 0.0510 - val_acc: 0.9000\n",
            "Epoch 204/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1150 - acc: 0.9278 - val_loss: 0.0517 - val_acc: 0.9000\n",
            "Epoch 205/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1151 - acc: 0.9278 - val_loss: 0.0499 - val_acc: 0.9000\n",
            "Epoch 206/800\n",
            "180/180 [==============================] - 0s 328us/step - loss: 0.1145 - acc: 0.9556 - val_loss: 0.0506 - val_acc: 0.9000\n",
            "Epoch 207/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1149 - acc: 0.9222 - val_loss: 0.0501 - val_acc: 0.9000\n",
            "Epoch 208/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1148 - acc: 0.9278 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 209/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1145 - acc: 0.9444 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 210/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 211/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1146 - acc: 0.9333 - val_loss: 0.0507 - val_acc: 0.8500\n",
            "Epoch 212/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1152 - acc: 0.9389 - val_loss: 0.0494 - val_acc: 0.8500\n",
            "Epoch 213/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1149 - acc: 0.9333 - val_loss: 0.0510 - val_acc: 0.9000\n",
            "Epoch 214/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1158 - acc: 0.9333 - val_loss: 0.0502 - val_acc: 0.9000\n",
            "Epoch 215/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1146 - acc: 0.9278 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 216/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1146 - acc: 0.9389 - val_loss: 0.0510 - val_acc: 0.9500\n",
            "Epoch 217/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1148 - acc: 0.9444 - val_loss: 0.0504 - val_acc: 0.9000\n",
            "Epoch 218/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1157 - acc: 0.9333 - val_loss: 0.0500 - val_acc: 0.9000\n",
            "Epoch 219/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0494 - val_acc: 0.9500\n",
            "Epoch 220/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1155 - acc: 0.9111 - val_loss: 0.0499 - val_acc: 0.9000\n",
            "Epoch 221/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1145 - acc: 0.9444 - val_loss: 0.0494 - val_acc: 0.8000\n",
            "Epoch 222/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1148 - acc: 0.9333 - val_loss: 0.0518 - val_acc: 0.8500\n",
            "Epoch 223/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1158 - acc: 0.9222 - val_loss: 0.0498 - val_acc: 0.8500\n",
            "Epoch 224/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1146 - acc: 0.9278 - val_loss: 0.0495 - val_acc: 0.9000\n",
            "Epoch 225/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1144 - acc: 0.9389 - val_loss: 0.0508 - val_acc: 0.9000\n",
            "Epoch 226/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0512 - val_acc: 0.8000\n",
            "Epoch 227/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1152 - acc: 0.9278 - val_loss: 0.0498 - val_acc: 0.8500\n",
            "Epoch 228/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1145 - acc: 0.9389 - val_loss: 0.0508 - val_acc: 0.8000\n",
            "Epoch 229/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.1146 - acc: 0.9167 - val_loss: 0.0498 - val_acc: 0.9000\n",
            "Epoch 230/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0539 - val_acc: 0.7500\n",
            "Epoch 231/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1156 - acc: 0.9167 - val_loss: 0.0503 - val_acc: 0.8500\n",
            "Epoch 232/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 233/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1146 - acc: 0.9278 - val_loss: 0.0543 - val_acc: 0.8500\n",
            "Epoch 234/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1158 - acc: 0.9111 - val_loss: 0.0496 - val_acc: 0.9000\n",
            "Epoch 235/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1148 - acc: 0.9333 - val_loss: 0.0493 - val_acc: 0.8500\n",
            "Epoch 236/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1151 - acc: 0.9278 - val_loss: 0.0506 - val_acc: 0.9500\n",
            "Epoch 237/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1151 - acc: 0.9333 - val_loss: 0.0495 - val_acc: 0.9000\n",
            "Epoch 238/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0504 - val_acc: 0.9000\n",
            "Epoch 239/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 0.0499 - val_acc: 0.9500\n",
            "Epoch 240/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1147 - acc: 0.9278 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 241/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1149 - acc: 0.9278 - val_loss: 0.0519 - val_acc: 0.9500\n",
            "Epoch 242/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1155 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 243/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1145 - acc: 0.9222 - val_loss: 0.0495 - val_acc: 0.8500\n",
            "Epoch 244/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 0.0499 - val_acc: 0.8000\n",
            "Epoch 245/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1142 - acc: 0.9444 - val_loss: 0.0500 - val_acc: 0.8500\n",
            "Epoch 246/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1154 - acc: 0.9333 - val_loss: 0.0497 - val_acc: 0.8500\n",
            "Epoch 247/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1145 - acc: 0.9389 - val_loss: 0.0508 - val_acc: 0.8000\n",
            "Epoch 248/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1148 - acc: 0.9222 - val_loss: 0.0494 - val_acc: 0.9000\n",
            "Epoch 249/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1139 - acc: 0.9389 - val_loss: 0.0508 - val_acc: 0.9000\n",
            "Epoch 250/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1149 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.8000\n",
            "Epoch 251/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1154 - acc: 0.9167 - val_loss: 0.0506 - val_acc: 0.8500\n",
            "Epoch 252/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1149 - acc: 0.9222 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 253/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1144 - acc: 0.9389 - val_loss: 0.0492 - val_acc: 0.7500\n",
            "Epoch 254/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1145 - acc: 0.9444 - val_loss: 0.0504 - val_acc: 0.9000\n",
            "Epoch 255/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1156 - acc: 0.9333 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 256/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1144 - acc: 0.9389 - val_loss: 0.0497 - val_acc: 0.9000\n",
            "Epoch 257/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1146 - acc: 0.9222 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 258/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1159 - acc: 0.9278 - val_loss: 0.0507 - val_acc: 0.8500\n",
            "Epoch 259/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1156 - acc: 0.9278 - val_loss: 0.0508 - val_acc: 0.9000\n",
            "Epoch 260/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1150 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 261/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1147 - acc: 0.9389 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 262/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1145 - acc: 0.9333 - val_loss: 0.0505 - val_acc: 0.9500\n",
            "Epoch 263/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1147 - acc: 0.9500 - val_loss: 0.0503 - val_acc: 0.9500\n",
            "Epoch 264/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0495 - val_acc: 0.9000\n",
            "Epoch 265/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1147 - acc: 0.9333 - val_loss: 0.0500 - val_acc: 0.8500\n",
            "Epoch 266/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1149 - acc: 0.9389 - val_loss: 0.0495 - val_acc: 0.8500\n",
            "Epoch 267/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1146 - acc: 0.9444 - val_loss: 0.0495 - val_acc: 0.9500\n",
            "Epoch 268/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1145 - acc: 0.9333 - val_loss: 0.0505 - val_acc: 0.8500\n",
            "Epoch 269/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1155 - acc: 0.9333 - val_loss: 0.0495 - val_acc: 0.8500\n",
            "Epoch 270/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1146 - acc: 0.9389 - val_loss: 0.0503 - val_acc: 0.8500\n",
            "Epoch 271/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1147 - acc: 0.9167 - val_loss: 0.0495 - val_acc: 0.9000\n",
            "Epoch 272/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 0.0504 - val_acc: 0.9000\n",
            "Epoch 273/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1141 - acc: 0.9389 - val_loss: 0.0504 - val_acc: 0.8500\n",
            "Epoch 274/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.1156 - acc: 0.9278 - val_loss: 0.0511 - val_acc: 0.8500\n",
            "Epoch 275/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0487 - val_acc: 0.9000\n",
            "Epoch 276/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1142 - acc: 0.9389 - val_loss: 0.0495 - val_acc: 0.8000\n",
            "Epoch 277/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1147 - acc: 0.9500 - val_loss: 0.0492 - val_acc: 0.9000\n",
            "Epoch 278/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1145 - acc: 0.9500 - val_loss: 0.0496 - val_acc: 0.9000\n",
            "Epoch 279/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1143 - acc: 0.9222 - val_loss: 0.0494 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00279: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 280/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1140 - acc: 0.9222 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 281/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 282/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 283/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 284/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 285/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 286/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 287/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 288/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 289/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 290/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 291/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 292/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 293/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1138 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 294/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 295/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 296/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 297/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 298/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 299/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1138 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 300/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 301/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 302/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 303/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 304/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 305/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 306/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 307/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 308/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 309/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 310/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 311/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 312/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 313/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.9278 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 314/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 315/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 316/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 317/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 318/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 319/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9500\n",
            "Epoch 320/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 321/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 322/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 323/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 324/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1138 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9500\n",
            "Epoch 325/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9500\n",
            "Epoch 326/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 327/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1138 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 328/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 329/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 330/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 331/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 332/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 333/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 334/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 335/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 336/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 337/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 338/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 339/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 340/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 341/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 342/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 343/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 344/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 345/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 346/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 347/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1136 - acc: 0.9444 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 348/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 349/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 350/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 351/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 352/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 353/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 354/800\n",
            "180/180 [==============================] - 0s 324us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 355/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 356/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 357/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0492 - val_acc: 0.9500\n",
            "Epoch 358/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 359/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 360/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 361/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1137 - acc: 0.9500 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 362/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 363/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 364/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 365/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 366/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 367/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 368/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 369/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 370/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 371/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 372/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0492 - val_acc: 0.9500\n",
            "Epoch 373/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 374/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 375/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 376/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 377/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 378/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 379/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9500\n",
            "Epoch 380/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 381/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 382/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 383/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 384/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 385/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 386/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 387/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 388/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 389/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 390/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1138 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 391/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 392/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 393/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 394/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 395/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 396/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 397/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 398/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 399/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1136 - acc: 0.9444 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 400/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 401/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1138 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9500\n",
            "Epoch 402/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 403/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 404/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 405/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 406/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 407/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 408/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 409/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1136 - acc: 0.9444 - val_loss: 0.0489 - val_acc: 0.9500\n",
            "Epoch 410/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9500\n",
            "Epoch 411/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 412/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 413/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9500\n",
            "Epoch 414/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 415/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.9500\n",
            "Epoch 416/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 417/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0487 - val_acc: 0.9000\n",
            "Epoch 418/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 419/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 420/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 421/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 422/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 423/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 424/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 425/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 426/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 427/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 428/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 429/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 430/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 431/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8000\n",
            "Epoch 432/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 433/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 434/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 435/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 436/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 437/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 438/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 439/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0491 - val_acc: 0.9500\n",
            "Epoch 440/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 441/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 442/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9500\n",
            "Epoch 443/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 444/800\n",
            "180/180 [==============================] - 0s 254us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 445/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 446/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 447/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 448/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 449/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 450/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9500\n",
            "Epoch 451/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 452/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 453/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 454/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 455/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 456/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1136 - acc: 0.9444 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 457/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 458/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 459/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 460/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 461/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 462/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 463/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 464/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 465/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 466/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 467/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 468/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 469/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 470/800\n",
            "180/180 [==============================] - 0s 329us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 471/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 472/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 473/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 474/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 475/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 476/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1136 - acc: 0.9278 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 477/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 478/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 479/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00479: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 480/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 481/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 482/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 483/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 484/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 485/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 486/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 487/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 488/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 489/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 490/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 491/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 492/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 493/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 494/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 495/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 496/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 497/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 498/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 499/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 500/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 501/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 502/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 503/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 504/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 505/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 506/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 507/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 508/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 509/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 510/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 511/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 512/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 513/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 514/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 515/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 516/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 517/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 518/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 519/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 520/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 521/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 522/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 523/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 524/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 525/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 526/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 527/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 528/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 529/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 530/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 531/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 532/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 533/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 534/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 535/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 536/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 537/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 538/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 539/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 540/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 541/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 542/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 543/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 544/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 545/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 546/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 547/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 548/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 549/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 550/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 551/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 552/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 553/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 554/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 555/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 556/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 557/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 558/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 559/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 560/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 561/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 562/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 563/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 564/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 565/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 566/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 567/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 568/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 569/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 570/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 571/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 572/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 573/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 574/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 575/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 576/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 577/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 578/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 579/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 580/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 581/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 582/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 583/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 584/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 585/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 586/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 587/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 588/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 589/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 590/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 591/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 592/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 593/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 594/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 595/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 596/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 597/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 598/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 599/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 600/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 601/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 602/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 603/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 604/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 605/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 606/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 607/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 608/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 609/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 610/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 611/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 612/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 613/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 614/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 615/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 616/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 617/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 618/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 619/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 620/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 621/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 622/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 623/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 624/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 625/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 626/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 627/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 628/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 629/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 630/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 631/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 632/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 633/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 634/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 635/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 636/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 637/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 638/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 639/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 640/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 641/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 642/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 643/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 644/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 645/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 646/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 647/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 648/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 649/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 650/800\n",
            "180/180 [==============================] - 0s 323us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 651/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 652/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 653/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 654/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 655/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 656/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 657/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 658/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 659/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 660/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 661/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 662/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 663/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 664/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 665/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 666/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 667/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 668/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 669/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 670/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 671/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 672/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 673/800\n",
            "180/180 [==============================] - 0s 406us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 674/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 675/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 676/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 677/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 678/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 679/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00679: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
            "Epoch 680/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 681/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 682/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 683/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 684/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 685/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 686/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 687/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 688/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 689/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 690/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 691/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 692/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 693/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 694/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 695/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 696/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 697/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 698/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 699/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 700/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 701/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 702/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 703/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 704/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 705/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 706/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 707/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 708/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 709/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 710/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 711/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 712/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 713/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 714/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 715/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 716/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 717/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 718/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 719/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 720/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 721/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 722/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 723/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 724/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 725/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 726/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 727/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 728/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 729/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 730/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 731/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 732/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 733/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 734/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 735/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 736/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 737/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 738/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 739/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 740/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 741/800\n",
            "180/180 [==============================] - 0s 331us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 742/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 743/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 744/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 745/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 746/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 747/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 748/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 749/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 750/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 751/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 752/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 753/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 754/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 755/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 756/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 757/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 758/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 759/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 760/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 761/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 762/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 763/800\n",
            "180/180 [==============================] - 0s 334us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 764/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 765/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 766/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 767/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 768/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 769/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 770/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 771/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 772/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 773/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 774/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 775/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 776/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 777/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 778/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 779/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 780/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 781/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 782/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 783/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 784/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 785/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 786/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 787/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 788/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 789/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 790/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 791/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 792/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 793/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 794/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 795/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 796/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 797/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 798/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 799/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 800/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "200/200 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[-0.23071837, -0.03977853, -0.30753464, -0.23373485, -0.2245971 ,\n",
              "         0.0804491 ],\n",
              "       [ 1.2501553 ,  0.1461766 ,  2.3173544 ,  1.25168   , -0.31123096,\n",
              "        -0.9387397 ],\n",
              "       [ 0.38003436, -0.8984928 ,  1.0986574 ,  0.3778442 ,  1.9418195 ,\n",
              "        -0.77557313],\n",
              "       ...,\n",
              "       [-0.34294498,  0.00456637,  1.2267983 , -0.34612447, -0.24486047,\n",
              "        -0.80579376],\n",
              "       [ 0.03626356, -0.01529723, -0.7169802 ,  0.03368816, -0.24747998,\n",
              "         1.0480211 ],\n",
              "       [-0.97515094,  1.1910412 , -0.922286  , -0.97556263, -0.78397596,\n",
              "         2.395676  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UeVPCQwagH0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6771863e-7a72-46cf-9746-bf74abea6807"
      },
      "cell_type": "code",
      "source": [
        "score2 = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score2)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 0s 139us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0.8472060966491699, 0.57]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lZnB5kVDh98q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b1a4a8a8-43ae-49b8-9290-352a5fcc31ff"
      },
      "cell_type": "code",
      "source": [
        "display(x_train[3,:])\n",
        "display(x_train[0,:])\n",
        "display(x_train[5,:])\n",
        "\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([8.53335151e+01, 7.88288937e+01, 7.13779116e+00, 9.84570089e+03,\n",
              "       6.51875228e+03, 5.53952782e+03])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([8.53335430e+01, 7.88288506e+01, 7.13932366e+00, 9.84570282e+03,\n",
              "       6.51875732e+03, 5.53950301e+03])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([8.53335452e+01, 7.88288630e+01, 7.13976024e+00, 9.84570297e+03,\n",
              "       6.51875588e+03, 5.53949594e+03])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "q43WIBzaOTsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "7d5bce6d-028d-4ae8-c6f0-f1226a2275f4"
      },
      "cell_type": "code",
      "source": [
        "display(score[0,:])\n",
        "display(x_test2[0,:])\n",
        "display(x_train2[2,:])\n",
        "display(x_train[3,:])\n",
        "display(x_test[0,:])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([-0.2799706 ,  0.7340043 , -0.57149446,  0.20620513,  0.7250215 ,\n",
              "        0.545471  ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([-0.13627917,  0.71676571, -0.56267982,  0.3875516 ,  0.71680732,\n",
              "        0.574813  ])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([-0.18443958,  1.23373152, -1.62555058,  0.42156024,  1.3637031 ,\n",
              "        1.601184  ])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([7.98813047e+01, 6.53505302e+01, 1.27098814e+00, 9.01627079e+03,\n",
              "       4.86375687e+03, 2.22070061e+03])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([7.98813043e+01, 3.41690118e-01, 1.26727822e+00, 9.01627280e+03,\n",
              "       3.80362979e+02, 2.22112900e+03])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "kFC4_jKKrKs5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27319
        },
        "outputId": "8c9d0434-5e68-4449-ec82-5d9f1b2d0d43"
      },
      "cell_type": "code",
      "source": [
        "#Results with one sample anomily \n",
        "# the duration of the anom can be tuned with anom_samples\n",
        "full_anom = 0\n",
        "anom_samples = 1\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
        "                              patience=300,verbose = 1)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "                    validation_split=.1,\n",
        "                    verbose=1,callbacks=[reduce_lr])\n",
        "\n",
        "score = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 180 samples, validate on 20 samples\n",
            "Epoch 1/800\n",
            "180/180 [==============================] - 9s 48ms/step - loss: 1.5007 - acc: 0.1944 - val_loss: 1.4750 - val_acc: 0.0500\n",
            "Epoch 2/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 1.4188 - acc: 0.1778 - val_loss: 1.3748 - val_acc: 0.1000\n",
            "Epoch 3/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 1.3436 - acc: 0.1778 - val_loss: 1.2763 - val_acc: 0.1000\n",
            "Epoch 4/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 1.2729 - acc: 0.1889 - val_loss: 1.1892 - val_acc: 0.1000\n",
            "Epoch 5/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 1.2061 - acc: 0.2000 - val_loss: 1.1073 - val_acc: 0.0500\n",
            "Epoch 6/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 1.1525 - acc: 0.2222 - val_loss: 1.0312 - val_acc: 0.0500\n",
            "Epoch 7/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 1.0978 - acc: 0.2389 - val_loss: 0.9676 - val_acc: 0.0500\n",
            "Epoch 8/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 1.0522 - acc: 0.2389 - val_loss: 0.9153 - val_acc: 0.0500\n",
            "Epoch 9/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 1.0107 - acc: 0.2333 - val_loss: 0.8732 - val_acc: 0.0500\n",
            "Epoch 10/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.9725 - acc: 0.2500 - val_loss: 0.8354 - val_acc: 0.1500\n",
            "Epoch 11/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.9422 - acc: 0.2500 - val_loss: 0.8030 - val_acc: 0.1500\n",
            "Epoch 12/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.9117 - acc: 0.2722 - val_loss: 0.7754 - val_acc: 0.1500\n",
            "Epoch 13/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.8858 - acc: 0.2833 - val_loss: 0.7522 - val_acc: 0.2000\n",
            "Epoch 14/800\n",
            "180/180 [==============================] - 0s 407us/step - loss: 0.8624 - acc: 0.2944 - val_loss: 0.7316 - val_acc: 0.2000\n",
            "Epoch 15/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.8392 - acc: 0.2944 - val_loss: 0.7142 - val_acc: 0.2000\n",
            "Epoch 16/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.8239 - acc: 0.3000 - val_loss: 0.6994 - val_acc: 0.2000\n",
            "Epoch 17/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.8069 - acc: 0.2889 - val_loss: 0.6862 - val_acc: 0.2000\n",
            "Epoch 18/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.7897 - acc: 0.2944 - val_loss: 0.6746 - val_acc: 0.2000\n",
            "Epoch 19/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.7771 - acc: 0.2944 - val_loss: 0.6637 - val_acc: 0.1500\n",
            "Epoch 20/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.7660 - acc: 0.2889 - val_loss: 0.6535 - val_acc: 0.1500\n",
            "Epoch 21/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.7481 - acc: 0.2889 - val_loss: 0.6434 - val_acc: 0.1500\n",
            "Epoch 22/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.7363 - acc: 0.2944 - val_loss: 0.6339 - val_acc: 0.1500\n",
            "Epoch 23/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.7256 - acc: 0.3000 - val_loss: 0.6249 - val_acc: 0.1500\n",
            "Epoch 24/800\n",
            "180/180 [==============================] - 0s 328us/step - loss: 0.7132 - acc: 0.3000 - val_loss: 0.6160 - val_acc: 0.1500\n",
            "Epoch 25/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.7003 - acc: 0.3111 - val_loss: 0.6074 - val_acc: 0.1500\n",
            "Epoch 26/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.6919 - acc: 0.3278 - val_loss: 0.5993 - val_acc: 0.1500\n",
            "Epoch 27/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.6804 - acc: 0.3222 - val_loss: 0.5914 - val_acc: 0.1500\n",
            "Epoch 28/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.6699 - acc: 0.3278 - val_loss: 0.5837 - val_acc: 0.1500\n",
            "Epoch 29/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.6585 - acc: 0.3278 - val_loss: 0.5755 - val_acc: 0.1500\n",
            "Epoch 30/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.6484 - acc: 0.3389 - val_loss: 0.5679 - val_acc: 0.1500\n",
            "Epoch 31/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.6386 - acc: 0.3611 - val_loss: 0.5605 - val_acc: 0.1500\n",
            "Epoch 32/800\n",
            "180/180 [==============================] - 0s 473us/step - loss: 0.6282 - acc: 0.3611 - val_loss: 0.5532 - val_acc: 0.1500\n",
            "Epoch 33/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.6191 - acc: 0.3667 - val_loss: 0.5460 - val_acc: 0.2000\n",
            "Epoch 34/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.6105 - acc: 0.3833 - val_loss: 0.5387 - val_acc: 0.2000\n",
            "Epoch 35/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.6019 - acc: 0.3722 - val_loss: 0.5318 - val_acc: 0.2000\n",
            "Epoch 36/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.5935 - acc: 0.3889 - val_loss: 0.5253 - val_acc: 0.2000\n",
            "Epoch 37/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.5843 - acc: 0.3889 - val_loss: 0.5186 - val_acc: 0.2000\n",
            "Epoch 38/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.5755 - acc: 0.4056 - val_loss: 0.5122 - val_acc: 0.2000\n",
            "Epoch 39/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.5672 - acc: 0.4056 - val_loss: 0.5058 - val_acc: 0.2500\n",
            "Epoch 40/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.5619 - acc: 0.4111 - val_loss: 0.4996 - val_acc: 0.3500\n",
            "Epoch 41/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.5539 - acc: 0.4111 - val_loss: 0.4934 - val_acc: 0.3500\n",
            "Epoch 42/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.5457 - acc: 0.4167 - val_loss: 0.4873 - val_acc: 0.3500\n",
            "Epoch 43/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.5392 - acc: 0.4389 - val_loss: 0.4813 - val_acc: 0.3500\n",
            "Epoch 44/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.5312 - acc: 0.4444 - val_loss: 0.4754 - val_acc: 0.4000\n",
            "Epoch 45/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.5251 - acc: 0.4611 - val_loss: 0.4695 - val_acc: 0.4000\n",
            "Epoch 46/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.5185 - acc: 0.4778 - val_loss: 0.4635 - val_acc: 0.4000\n",
            "Epoch 47/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.5124 - acc: 0.4833 - val_loss: 0.4575 - val_acc: 0.4000\n",
            "Epoch 48/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.5050 - acc: 0.4889 - val_loss: 0.4516 - val_acc: 0.4000\n",
            "Epoch 49/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4986 - acc: 0.4944 - val_loss: 0.4456 - val_acc: 0.4000\n",
            "Epoch 50/800\n",
            "180/180 [==============================] - 0s 480us/step - loss: 0.4920 - acc: 0.4944 - val_loss: 0.4398 - val_acc: 0.4000\n",
            "Epoch 51/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.4860 - acc: 0.4944 - val_loss: 0.4339 - val_acc: 0.4000\n",
            "Epoch 52/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4799 - acc: 0.4944 - val_loss: 0.4282 - val_acc: 0.4000\n",
            "Epoch 53/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.4741 - acc: 0.5000 - val_loss: 0.4225 - val_acc: 0.4000\n",
            "Epoch 54/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4687 - acc: 0.5000 - val_loss: 0.4170 - val_acc: 0.4000\n",
            "Epoch 55/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.4627 - acc: 0.4889 - val_loss: 0.4113 - val_acc: 0.4000\n",
            "Epoch 56/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4570 - acc: 0.4889 - val_loss: 0.4055 - val_acc: 0.4000\n",
            "Epoch 57/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4512 - acc: 0.4944 - val_loss: 0.3998 - val_acc: 0.4000\n",
            "Epoch 58/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4457 - acc: 0.4944 - val_loss: 0.3941 - val_acc: 0.4000\n",
            "Epoch 59/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4400 - acc: 0.5000 - val_loss: 0.3885 - val_acc: 0.4000\n",
            "Epoch 60/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4348 - acc: 0.5056 - val_loss: 0.3827 - val_acc: 0.4000\n",
            "Epoch 61/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4297 - acc: 0.5222 - val_loss: 0.3772 - val_acc: 0.4000\n",
            "Epoch 62/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4241 - acc: 0.5167 - val_loss: 0.3718 - val_acc: 0.4000\n",
            "Epoch 63/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.4191 - acc: 0.5333 - val_loss: 0.3664 - val_acc: 0.4000\n",
            "Epoch 64/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4132 - acc: 0.5444 - val_loss: 0.3613 - val_acc: 0.4500\n",
            "Epoch 65/800\n",
            "180/180 [==============================] - 0s 392us/step - loss: 0.4086 - acc: 0.5389 - val_loss: 0.3560 - val_acc: 0.4500\n",
            "Epoch 66/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4038 - acc: 0.5389 - val_loss: 0.3506 - val_acc: 0.4500\n",
            "Epoch 67/800\n",
            "180/180 [==============================] - 0s 487us/step - loss: 0.3983 - acc: 0.5444 - val_loss: 0.3453 - val_acc: 0.5000\n",
            "Epoch 68/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.3933 - acc: 0.5556 - val_loss: 0.3400 - val_acc: 0.5500\n",
            "Epoch 69/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.3886 - acc: 0.5722 - val_loss: 0.3349 - val_acc: 0.5500\n",
            "Epoch 70/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.3830 - acc: 0.5556 - val_loss: 0.3297 - val_acc: 0.5500\n",
            "Epoch 71/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.3788 - acc: 0.5500 - val_loss: 0.3246 - val_acc: 0.5500\n",
            "Epoch 72/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.3741 - acc: 0.5611 - val_loss: 0.3196 - val_acc: 0.5500\n",
            "Epoch 73/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.3692 - acc: 0.5611 - val_loss: 0.3146 - val_acc: 0.5500\n",
            "Epoch 74/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.3644 - acc: 0.5556 - val_loss: 0.3098 - val_acc: 0.5500\n",
            "Epoch 75/800\n",
            "180/180 [==============================] - 0s 338us/step - loss: 0.3599 - acc: 0.5500 - val_loss: 0.3050 - val_acc: 0.5500\n",
            "Epoch 76/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.3557 - acc: 0.5556 - val_loss: 0.3005 - val_acc: 0.5500\n",
            "Epoch 77/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.3510 - acc: 0.5611 - val_loss: 0.2959 - val_acc: 0.5500\n",
            "Epoch 78/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.3460 - acc: 0.5722 - val_loss: 0.2914 - val_acc: 0.5500\n",
            "Epoch 79/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.3422 - acc: 0.5778 - val_loss: 0.2870 - val_acc: 0.5500\n",
            "Epoch 80/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.3376 - acc: 0.5611 - val_loss: 0.2824 - val_acc: 0.5500\n",
            "Epoch 81/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.3335 - acc: 0.5778 - val_loss: 0.2783 - val_acc: 0.5500\n",
            "Epoch 82/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.3289 - acc: 0.5722 - val_loss: 0.2743 - val_acc: 0.5500\n",
            "Epoch 83/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.3251 - acc: 0.5889 - val_loss: 0.2706 - val_acc: 0.5500\n",
            "Epoch 84/800\n",
            "180/180 [==============================] - 0s 496us/step - loss: 0.3208 - acc: 0.5944 - val_loss: 0.2666 - val_acc: 0.5500\n",
            "Epoch 85/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.3169 - acc: 0.5889 - val_loss: 0.2628 - val_acc: 0.5500\n",
            "Epoch 86/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.3127 - acc: 0.5889 - val_loss: 0.2585 - val_acc: 0.5500\n",
            "Epoch 87/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.3091 - acc: 0.6000 - val_loss: 0.2550 - val_acc: 0.5500\n",
            "Epoch 88/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.3045 - acc: 0.5889 - val_loss: 0.2515 - val_acc: 0.5500\n",
            "Epoch 89/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.3010 - acc: 0.5833 - val_loss: 0.2477 - val_acc: 0.5500\n",
            "Epoch 90/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.2974 - acc: 0.5944 - val_loss: 0.2438 - val_acc: 0.5500\n",
            "Epoch 91/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.2930 - acc: 0.5889 - val_loss: 0.2404 - val_acc: 0.6000\n",
            "Epoch 92/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.2897 - acc: 0.5889 - val_loss: 0.2366 - val_acc: 0.6000\n",
            "Epoch 93/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.2859 - acc: 0.6000 - val_loss: 0.2335 - val_acc: 0.6000\n",
            "Epoch 94/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.2824 - acc: 0.6000 - val_loss: 0.2304 - val_acc: 0.6000\n",
            "Epoch 95/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.2791 - acc: 0.6000 - val_loss: 0.2272 - val_acc: 0.6000\n",
            "Epoch 96/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.2753 - acc: 0.6111 - val_loss: 0.2243 - val_acc: 0.6000\n",
            "Epoch 97/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.2718 - acc: 0.6111 - val_loss: 0.2221 - val_acc: 0.6000\n",
            "Epoch 98/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.2686 - acc: 0.6056 - val_loss: 0.2183 - val_acc: 0.6000\n",
            "Epoch 99/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.2650 - acc: 0.6056 - val_loss: 0.2157 - val_acc: 0.6000\n",
            "Epoch 100/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.2619 - acc: 0.6111 - val_loss: 0.2122 - val_acc: 0.6000\n",
            "Epoch 101/800\n",
            "180/180 [==============================] - 0s 405us/step - loss: 0.2584 - acc: 0.6278 - val_loss: 0.2096 - val_acc: 0.6000\n",
            "Epoch 102/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.2556 - acc: 0.6056 - val_loss: 0.2066 - val_acc: 0.6000\n",
            "Epoch 103/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.2527 - acc: 0.6222 - val_loss: 0.2034 - val_acc: 0.6500\n",
            "Epoch 104/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.2495 - acc: 0.6278 - val_loss: 0.2005 - val_acc: 0.6500\n",
            "Epoch 105/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.2466 - acc: 0.6389 - val_loss: 0.1979 - val_acc: 0.6500\n",
            "Epoch 106/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.2436 - acc: 0.6389 - val_loss: 0.1955 - val_acc: 0.6000\n",
            "Epoch 107/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.2413 - acc: 0.6167 - val_loss: 0.1937 - val_acc: 0.6500\n",
            "Epoch 108/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.2385 - acc: 0.6333 - val_loss: 0.1916 - val_acc: 0.6500\n",
            "Epoch 109/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.2358 - acc: 0.6333 - val_loss: 0.1885 - val_acc: 0.6500\n",
            "Epoch 110/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.2329 - acc: 0.6389 - val_loss: 0.1873 - val_acc: 0.6500\n",
            "Epoch 111/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.2307 - acc: 0.6556 - val_loss: 0.1861 - val_acc: 0.6500\n",
            "Epoch 112/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.2284 - acc: 0.6389 - val_loss: 0.1823 - val_acc: 0.5500\n",
            "Epoch 113/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.2256 - acc: 0.6611 - val_loss: 0.1805 - val_acc: 0.5500\n",
            "Epoch 114/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.2239 - acc: 0.6611 - val_loss: 0.1781 - val_acc: 0.5500\n",
            "Epoch 115/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.2212 - acc: 0.6611 - val_loss: 0.1763 - val_acc: 0.6000\n",
            "Epoch 116/800\n",
            "180/180 [==============================] - 0s 336us/step - loss: 0.2190 - acc: 0.6667 - val_loss: 0.1745 - val_acc: 0.6000\n",
            "Epoch 117/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.2171 - acc: 0.6611 - val_loss: 0.1728 - val_acc: 0.5500\n",
            "Epoch 118/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.2149 - acc: 0.6778 - val_loss: 0.1728 - val_acc: 0.5500\n",
            "Epoch 119/800\n",
            "180/180 [==============================] - 0s 450us/step - loss: 0.2130 - acc: 0.6833 - val_loss: 0.1694 - val_acc: 0.6000\n",
            "Epoch 120/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.2109 - acc: 0.6778 - val_loss: 0.1673 - val_acc: 0.6000\n",
            "Epoch 121/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.2087 - acc: 0.6833 - val_loss: 0.1663 - val_acc: 0.6000\n",
            "Epoch 122/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.2072 - acc: 0.6722 - val_loss: 0.1646 - val_acc: 0.5500\n",
            "Epoch 123/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.2051 - acc: 0.6833 - val_loss: 0.1628 - val_acc: 0.6000\n",
            "Epoch 124/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.2036 - acc: 0.6722 - val_loss: 0.1614 - val_acc: 0.6000\n",
            "Epoch 125/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.2017 - acc: 0.6833 - val_loss: 0.1601 - val_acc: 0.6000\n",
            "Epoch 126/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1999 - acc: 0.7000 - val_loss: 0.1590 - val_acc: 0.6000\n",
            "Epoch 127/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1984 - acc: 0.6889 - val_loss: 0.1571 - val_acc: 0.5500\n",
            "Epoch 128/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1970 - acc: 0.6833 - val_loss: 0.1557 - val_acc: 0.5500\n",
            "Epoch 129/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1950 - acc: 0.6944 - val_loss: 0.1550 - val_acc: 0.5500\n",
            "Epoch 130/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1940 - acc: 0.7056 - val_loss: 0.1544 - val_acc: 0.5500\n",
            "Epoch 131/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1926 - acc: 0.6889 - val_loss: 0.1517 - val_acc: 0.5500\n",
            "Epoch 132/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1915 - acc: 0.7056 - val_loss: 0.1509 - val_acc: 0.5500\n",
            "Epoch 133/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1897 - acc: 0.7056 - val_loss: 0.1498 - val_acc: 0.5500\n",
            "Epoch 134/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.1881 - acc: 0.7000 - val_loss: 0.1483 - val_acc: 0.5500\n",
            "Epoch 135/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1870 - acc: 0.6944 - val_loss: 0.1480 - val_acc: 0.5500\n",
            "Epoch 136/800\n",
            "180/180 [==============================] - 0s 438us/step - loss: 0.1862 - acc: 0.6944 - val_loss: 0.1461 - val_acc: 0.5500\n",
            "Epoch 137/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.1842 - acc: 0.7056 - val_loss: 0.1452 - val_acc: 0.5500\n",
            "Epoch 138/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1832 - acc: 0.7056 - val_loss: 0.1448 - val_acc: 0.5500\n",
            "Epoch 139/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1822 - acc: 0.7111 - val_loss: 0.1426 - val_acc: 0.5500\n",
            "Epoch 140/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1808 - acc: 0.7167 - val_loss: 0.1429 - val_acc: 0.5500\n",
            "Epoch 141/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1797 - acc: 0.7222 - val_loss: 0.1430 - val_acc: 0.5500\n",
            "Epoch 142/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1788 - acc: 0.7222 - val_loss: 0.1413 - val_acc: 0.5500\n",
            "Epoch 143/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1775 - acc: 0.7222 - val_loss: 0.1397 - val_acc: 0.5500\n",
            "Epoch 144/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1766 - acc: 0.7222 - val_loss: 0.1390 - val_acc: 0.5000\n",
            "Epoch 145/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1757 - acc: 0.7056 - val_loss: 0.1387 - val_acc: 0.5500\n",
            "Epoch 146/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1744 - acc: 0.7222 - val_loss: 0.1381 - val_acc: 0.5000\n",
            "Epoch 147/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.1742 - acc: 0.7222 - val_loss: 0.1362 - val_acc: 0.5000\n",
            "Epoch 148/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1726 - acc: 0.7167 - val_loss: 0.1352 - val_acc: 0.5000\n",
            "Epoch 149/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1713 - acc: 0.7056 - val_loss: 0.1342 - val_acc: 0.5000\n",
            "Epoch 150/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1708 - acc: 0.7056 - val_loss: 0.1336 - val_acc: 0.5000\n",
            "Epoch 151/800\n",
            "180/180 [==============================] - 0s 330us/step - loss: 0.1698 - acc: 0.7111 - val_loss: 0.1330 - val_acc: 0.5000\n",
            "Epoch 152/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1691 - acc: 0.7056 - val_loss: 0.1327 - val_acc: 0.5000\n",
            "Epoch 153/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1687 - acc: 0.7167 - val_loss: 0.1322 - val_acc: 0.5000\n",
            "Epoch 154/800\n",
            "180/180 [==============================] - 0s 483us/step - loss: 0.1675 - acc: 0.7056 - val_loss: 0.1313 - val_acc: 0.5000\n",
            "Epoch 155/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1671 - acc: 0.7056 - val_loss: 0.1306 - val_acc: 0.5000\n",
            "Epoch 156/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1658 - acc: 0.7222 - val_loss: 0.1294 - val_acc: 0.5000\n",
            "Epoch 157/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1651 - acc: 0.7000 - val_loss: 0.1298 - val_acc: 0.5000\n",
            "Epoch 158/800\n",
            "180/180 [==============================] - 0s 337us/step - loss: 0.1644 - acc: 0.7167 - val_loss: 0.1289 - val_acc: 0.5500\n",
            "Epoch 159/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1638 - acc: 0.6889 - val_loss: 0.1304 - val_acc: 0.5500\n",
            "Epoch 160/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1632 - acc: 0.7111 - val_loss: 0.1275 - val_acc: 0.5500\n",
            "Epoch 161/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1628 - acc: 0.7056 - val_loss: 0.1267 - val_acc: 0.5500\n",
            "Epoch 162/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1615 - acc: 0.7111 - val_loss: 0.1262 - val_acc: 0.5500\n",
            "Epoch 163/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.1606 - acc: 0.7000 - val_loss: 0.1257 - val_acc: 0.5500\n",
            "Epoch 164/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1601 - acc: 0.7056 - val_loss: 0.1246 - val_acc: 0.5500\n",
            "Epoch 165/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1593 - acc: 0.7056 - val_loss: 0.1250 - val_acc: 0.5500\n",
            "Epoch 166/800\n",
            "180/180 [==============================] - 0s 334us/step - loss: 0.1590 - acc: 0.7000 - val_loss: 0.1232 - val_acc: 0.5500\n",
            "Epoch 167/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1584 - acc: 0.7222 - val_loss: 0.1244 - val_acc: 0.5500\n",
            "Epoch 168/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.1576 - acc: 0.7167 - val_loss: 0.1240 - val_acc: 0.5500\n",
            "Epoch 169/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1571 - acc: 0.7222 - val_loss: 0.1225 - val_acc: 0.5500\n",
            "Epoch 170/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1570 - acc: 0.7000 - val_loss: 0.1215 - val_acc: 0.6000\n",
            "Epoch 171/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.1559 - acc: 0.7111 - val_loss: 0.1222 - val_acc: 0.6000\n",
            "Epoch 172/800\n",
            "180/180 [==============================] - 0s 464us/step - loss: 0.1554 - acc: 0.6944 - val_loss: 0.1217 - val_acc: 0.6000\n",
            "Epoch 173/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1547 - acc: 0.7167 - val_loss: 0.1210 - val_acc: 0.6000\n",
            "Epoch 174/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1546 - acc: 0.7111 - val_loss: 0.1209 - val_acc: 0.6000\n",
            "Epoch 175/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1539 - acc: 0.7056 - val_loss: 0.1197 - val_acc: 0.6000\n",
            "Epoch 176/800\n",
            "180/180 [==============================] - 0s 334us/step - loss: 0.1535 - acc: 0.7278 - val_loss: 0.1192 - val_acc: 0.6000\n",
            "Epoch 177/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.1528 - acc: 0.7278 - val_loss: 0.1199 - val_acc: 0.6000\n",
            "Epoch 178/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1526 - acc: 0.7167 - val_loss: 0.1193 - val_acc: 0.6000\n",
            "Epoch 179/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1519 - acc: 0.7278 - val_loss: 0.1179 - val_acc: 0.6000\n",
            "Epoch 180/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1516 - acc: 0.7222 - val_loss: 0.1185 - val_acc: 0.6000\n",
            "Epoch 181/800\n",
            "180/180 [==============================] - 0s 335us/step - loss: 0.1517 - acc: 0.7167 - val_loss: 0.1184 - val_acc: 0.6000\n",
            "Epoch 182/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1507 - acc: 0.7389 - val_loss: 0.1173 - val_acc: 0.6000\n",
            "Epoch 183/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1501 - acc: 0.7278 - val_loss: 0.1166 - val_acc: 0.6000\n",
            "Epoch 184/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1497 - acc: 0.7389 - val_loss: 0.1169 - val_acc: 0.6000\n",
            "Epoch 185/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.1494 - acc: 0.7333 - val_loss: 0.1156 - val_acc: 0.6000\n",
            "Epoch 186/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1488 - acc: 0.7333 - val_loss: 0.1156 - val_acc: 0.6000\n",
            "Epoch 187/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1483 - acc: 0.7333 - val_loss: 0.1156 - val_acc: 0.6000\n",
            "Epoch 188/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.1480 - acc: 0.7278 - val_loss: 0.1159 - val_acc: 0.6000\n",
            "Epoch 189/800\n",
            "180/180 [==============================] - 0s 436us/step - loss: 0.1474 - acc: 0.7222 - val_loss: 0.1148 - val_acc: 0.6000\n",
            "Epoch 190/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1474 - acc: 0.7333 - val_loss: 0.1158 - val_acc: 0.6000\n",
            "Epoch 191/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1472 - acc: 0.7389 - val_loss: 0.1137 - val_acc: 0.6000\n",
            "Epoch 192/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1464 - acc: 0.7278 - val_loss: 0.1135 - val_acc: 0.6000\n",
            "Epoch 193/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1461 - acc: 0.7278 - val_loss: 0.1127 - val_acc: 0.6000\n",
            "Epoch 194/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1457 - acc: 0.7167 - val_loss: 0.1127 - val_acc: 0.6000\n",
            "Epoch 195/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1456 - acc: 0.7333 - val_loss: 0.1123 - val_acc: 0.6000\n",
            "Epoch 196/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1450 - acc: 0.7278 - val_loss: 0.1118 - val_acc: 0.6000\n",
            "Epoch 197/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1448 - acc: 0.7222 - val_loss: 0.1122 - val_acc: 0.6000\n",
            "Epoch 198/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1442 - acc: 0.7278 - val_loss: 0.1128 - val_acc: 0.6000\n",
            "Epoch 199/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.1439 - acc: 0.7278 - val_loss: 0.1119 - val_acc: 0.6000\n",
            "Epoch 200/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1434 - acc: 0.7278 - val_loss: 0.1103 - val_acc: 0.6000\n",
            "Epoch 201/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1430 - acc: 0.7278 - val_loss: 0.1117 - val_acc: 0.6000\n",
            "Epoch 202/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1428 - acc: 0.7278 - val_loss: 0.1111 - val_acc: 0.6000\n",
            "Epoch 203/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.1428 - acc: 0.7278 - val_loss: 0.1123 - val_acc: 0.6000\n",
            "Epoch 204/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1424 - acc: 0.7222 - val_loss: 0.1096 - val_acc: 0.6000\n",
            "Epoch 205/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1418 - acc: 0.7278 - val_loss: 0.1100 - val_acc: 0.6000\n",
            "Epoch 206/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.1419 - acc: 0.7444 - val_loss: 0.1096 - val_acc: 0.6000\n",
            "Epoch 207/800\n",
            "180/180 [==============================] - 0s 486us/step - loss: 0.1413 - acc: 0.7278 - val_loss: 0.1088 - val_acc: 0.6000\n",
            "Epoch 208/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1411 - acc: 0.7278 - val_loss: 0.1096 - val_acc: 0.6000\n",
            "Epoch 209/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1411 - acc: 0.7167 - val_loss: 0.1085 - val_acc: 0.6000\n",
            "Epoch 210/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1404 - acc: 0.7389 - val_loss: 0.1086 - val_acc: 0.6000\n",
            "Epoch 211/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1400 - acc: 0.7333 - val_loss: 0.1090 - val_acc: 0.6000\n",
            "Epoch 212/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1399 - acc: 0.7278 - val_loss: 0.1097 - val_acc: 0.5500\n",
            "Epoch 213/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1399 - acc: 0.7278 - val_loss: 0.1086 - val_acc: 0.6000\n",
            "Epoch 214/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1395 - acc: 0.7278 - val_loss: 0.1087 - val_acc: 0.6500\n",
            "Epoch 215/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1389 - acc: 0.7278 - val_loss: 0.1088 - val_acc: 0.6500\n",
            "Epoch 216/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1388 - acc: 0.7278 - val_loss: 0.1068 - val_acc: 0.6500\n",
            "Epoch 217/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1386 - acc: 0.7333 - val_loss: 0.1082 - val_acc: 0.6000\n",
            "Epoch 218/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1385 - acc: 0.7222 - val_loss: 0.1066 - val_acc: 0.6500\n",
            "Epoch 219/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1378 - acc: 0.7278 - val_loss: 0.1069 - val_acc: 0.6000\n",
            "Epoch 220/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1377 - acc: 0.7278 - val_loss: 0.1054 - val_acc: 0.6000\n",
            "Epoch 221/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1373 - acc: 0.7167 - val_loss: 0.1075 - val_acc: 0.6000\n",
            "Epoch 222/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1374 - acc: 0.7389 - val_loss: 0.1066 - val_acc: 0.6500\n",
            "Epoch 223/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1369 - acc: 0.7278 - val_loss: 0.1059 - val_acc: 0.6000\n",
            "Epoch 224/800\n",
            "180/180 [==============================] - 0s 420us/step - loss: 0.1371 - acc: 0.7333 - val_loss: 0.1059 - val_acc: 0.6500\n",
            "Epoch 225/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1365 - acc: 0.7444 - val_loss: 0.1052 - val_acc: 0.6500\n",
            "Epoch 226/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1360 - acc: 0.7500 - val_loss: 0.1052 - val_acc: 0.6500\n",
            "Epoch 227/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1357 - acc: 0.7278 - val_loss: 0.1048 - val_acc: 0.6500\n",
            "Epoch 228/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1357 - acc: 0.7444 - val_loss: 0.1040 - val_acc: 0.6500\n",
            "Epoch 229/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1354 - acc: 0.7500 - val_loss: 0.1056 - val_acc: 0.6500\n",
            "Epoch 230/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1356 - acc: 0.7500 - val_loss: 0.1047 - val_acc: 0.6500\n",
            "Epoch 231/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1349 - acc: 0.7444 - val_loss: 0.1054 - val_acc: 0.6000\n",
            "Epoch 232/800\n",
            "180/180 [==============================] - 0s 415us/step - loss: 0.1351 - acc: 0.7444 - val_loss: 0.1037 - val_acc: 0.6000\n",
            "Epoch 233/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1347 - acc: 0.7500 - val_loss: 0.1041 - val_acc: 0.6000\n",
            "Epoch 234/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1344 - acc: 0.7500 - val_loss: 0.1046 - val_acc: 0.6500\n",
            "Epoch 235/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1337 - acc: 0.7500 - val_loss: 0.1038 - val_acc: 0.6000\n",
            "Epoch 236/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1344 - acc: 0.7333 - val_loss: 0.1036 - val_acc: 0.6000\n",
            "Epoch 237/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1335 - acc: 0.7500 - val_loss: 0.1036 - val_acc: 0.6500\n",
            "Epoch 238/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.1334 - acc: 0.7500 - val_loss: 0.1045 - val_acc: 0.6500\n",
            "Epoch 239/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1333 - acc: 0.7444 - val_loss: 0.1032 - val_acc: 0.6500\n",
            "Epoch 240/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.1330 - acc: 0.7500 - val_loss: 0.1032 - val_acc: 0.6500\n",
            "Epoch 241/800\n",
            "180/180 [==============================] - 0s 430us/step - loss: 0.1333 - acc: 0.7333 - val_loss: 0.1023 - val_acc: 0.6500\n",
            "Epoch 242/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1328 - acc: 0.7500 - val_loss: 0.1029 - val_acc: 0.6500\n",
            "Epoch 243/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1327 - acc: 0.7444 - val_loss: 0.1017 - val_acc: 0.6500\n",
            "Epoch 244/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1319 - acc: 0.7500 - val_loss: 0.1035 - val_acc: 0.5500\n",
            "Epoch 245/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1332 - acc: 0.7333 - val_loss: 0.1020 - val_acc: 0.6500\n",
            "Epoch 246/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.1319 - acc: 0.7444 - val_loss: 0.1049 - val_acc: 0.6500\n",
            "Epoch 247/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1322 - acc: 0.7389 - val_loss: 0.1020 - val_acc: 0.6500\n",
            "Epoch 248/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1313 - acc: 0.7556 - val_loss: 0.1015 - val_acc: 0.6500\n",
            "Epoch 249/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1313 - acc: 0.7500 - val_loss: 0.1011 - val_acc: 0.6500\n",
            "Epoch 250/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1312 - acc: 0.7556 - val_loss: 0.1004 - val_acc: 0.6500\n",
            "Epoch 251/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1310 - acc: 0.7556 - val_loss: 0.1017 - val_acc: 0.6500\n",
            "Epoch 252/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1307 - acc: 0.7556 - val_loss: 0.1028 - val_acc: 0.6500\n",
            "Epoch 253/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1307 - acc: 0.7556 - val_loss: 0.1013 - val_acc: 0.6000\n",
            "Epoch 254/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.1303 - acc: 0.7444 - val_loss: 0.0999 - val_acc: 0.7000\n",
            "Epoch 255/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.1304 - acc: 0.7500 - val_loss: 0.1012 - val_acc: 0.6500\n",
            "Epoch 256/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1301 - acc: 0.7556 - val_loss: 0.1013 - val_acc: 0.7000\n",
            "Epoch 257/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1298 - acc: 0.7444 - val_loss: 0.0994 - val_acc: 0.7000\n",
            "Epoch 258/800\n",
            "180/180 [==============================] - 0s 484us/step - loss: 0.1299 - acc: 0.7611 - val_loss: 0.1015 - val_acc: 0.7000\n",
            "Epoch 259/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1295 - acc: 0.7556 - val_loss: 0.1029 - val_acc: 0.6000\n",
            "Epoch 260/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1297 - acc: 0.7611 - val_loss: 0.0998 - val_acc: 0.7000\n",
            "Epoch 261/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1290 - acc: 0.7611 - val_loss: 0.0997 - val_acc: 0.7000\n",
            "Epoch 262/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1291 - acc: 0.7444 - val_loss: 0.1002 - val_acc: 0.7000\n",
            "Epoch 263/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.1290 - acc: 0.7611 - val_loss: 0.1009 - val_acc: 0.7000\n",
            "Epoch 264/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1291 - acc: 0.7500 - val_loss: 0.1011 - val_acc: 0.7000\n",
            "Epoch 265/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1289 - acc: 0.7611 - val_loss: 0.0997 - val_acc: 0.6500\n",
            "Epoch 266/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1283 - acc: 0.7500 - val_loss: 0.0977 - val_acc: 0.8000\n",
            "Epoch 267/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1284 - acc: 0.7611 - val_loss: 0.0993 - val_acc: 0.7500\n",
            "Epoch 268/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1280 - acc: 0.7444 - val_loss: 0.0982 - val_acc: 0.7500\n",
            "Epoch 269/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.1279 - acc: 0.7667 - val_loss: 0.1005 - val_acc: 0.7000\n",
            "Epoch 270/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1280 - acc: 0.7500 - val_loss: 0.0988 - val_acc: 0.7500\n",
            "Epoch 271/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1276 - acc: 0.7556 - val_loss: 0.0990 - val_acc: 0.7000\n",
            "Epoch 272/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1277 - acc: 0.7556 - val_loss: 0.0987 - val_acc: 0.7500\n",
            "Epoch 273/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1272 - acc: 0.7611 - val_loss: 0.0998 - val_acc: 0.7000\n",
            "Epoch 274/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1269 - acc: 0.7611 - val_loss: 0.0980 - val_acc: 0.7500\n",
            "Epoch 275/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1273 - acc: 0.7611 - val_loss: 0.0983 - val_acc: 0.7500\n",
            "Epoch 276/800\n",
            "180/180 [==============================] - 0s 481us/step - loss: 0.1267 - acc: 0.7556 - val_loss: 0.0976 - val_acc: 0.7500\n",
            "Epoch 277/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1267 - acc: 0.7667 - val_loss: 0.0972 - val_acc: 0.7500\n",
            "Epoch 278/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1267 - acc: 0.7556 - val_loss: 0.0998 - val_acc: 0.7500\n",
            "Epoch 279/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1268 - acc: 0.7556 - val_loss: 0.0982 - val_acc: 0.7000\n",
            "Epoch 280/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1266 - acc: 0.7611 - val_loss: 0.0975 - val_acc: 0.7500\n",
            "Epoch 281/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.1260 - acc: 0.7556 - val_loss: 0.0987 - val_acc: 0.7500\n",
            "Epoch 282/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1260 - acc: 0.7722 - val_loss: 0.1006 - val_acc: 0.7500\n",
            "Epoch 283/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1263 - acc: 0.7611 - val_loss: 0.0992 - val_acc: 0.7000\n",
            "Epoch 284/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1262 - acc: 0.7556 - val_loss: 0.0969 - val_acc: 0.7500\n",
            "Epoch 285/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.1260 - acc: 0.7500 - val_loss: 0.0995 - val_acc: 0.7500\n",
            "Epoch 286/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1257 - acc: 0.7556 - val_loss: 0.0969 - val_acc: 0.7500\n",
            "Epoch 287/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1257 - acc: 0.7556 - val_loss: 0.0970 - val_acc: 0.7500\n",
            "Epoch 288/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1252 - acc: 0.7722 - val_loss: 0.0965 - val_acc: 0.7500\n",
            "Epoch 289/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1251 - acc: 0.7500 - val_loss: 0.0956 - val_acc: 0.8000\n",
            "Epoch 290/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.1248 - acc: 0.7667 - val_loss: 0.0961 - val_acc: 0.7500\n",
            "Epoch 291/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.1249 - acc: 0.7500 - val_loss: 0.0959 - val_acc: 0.7500\n",
            "Epoch 292/800\n",
            "180/180 [==============================] - 0s 333us/step - loss: 0.1249 - acc: 0.7722 - val_loss: 0.0964 - val_acc: 0.7000\n",
            "Epoch 293/800\n",
            "180/180 [==============================] - 0s 488us/step - loss: 0.1246 - acc: 0.7667 - val_loss: 0.0962 - val_acc: 0.7500\n",
            "Epoch 294/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1245 - acc: 0.7667 - val_loss: 0.0955 - val_acc: 0.7500\n",
            "Epoch 295/800\n",
            "180/180 [==============================] - 0s 331us/step - loss: 0.1246 - acc: 0.7611 - val_loss: 0.0953 - val_acc: 0.8000\n",
            "Epoch 296/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1243 - acc: 0.7722 - val_loss: 0.0976 - val_acc: 0.8000\n",
            "Epoch 297/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1246 - acc: 0.7722 - val_loss: 0.0961 - val_acc: 0.7500\n",
            "Epoch 298/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1239 - acc: 0.7722 - val_loss: 0.0952 - val_acc: 0.8000\n",
            "Epoch 299/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1238 - acc: 0.7778 - val_loss: 0.0977 - val_acc: 0.7500\n",
            "Epoch 300/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1245 - acc: 0.7722 - val_loss: 0.0961 - val_acc: 0.8000\n",
            "Epoch 301/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1238 - acc: 0.7833 - val_loss: 0.0958 - val_acc: 0.8000\n",
            "Epoch 302/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1239 - acc: 0.7500 - val_loss: 0.0954 - val_acc: 0.7500\n",
            "Epoch 303/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1237 - acc: 0.7667 - val_loss: 0.0979 - val_acc: 0.8000\n",
            "Epoch 304/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1234 - acc: 0.7722 - val_loss: 0.0940 - val_acc: 0.8000\n",
            "Epoch 305/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1238 - acc: 0.7722 - val_loss: 0.0956 - val_acc: 0.8000\n",
            "Epoch 306/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1230 - acc: 0.7722 - val_loss: 0.0960 - val_acc: 0.7000\n",
            "Epoch 307/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1232 - acc: 0.7722 - val_loss: 0.0955 - val_acc: 0.8000\n",
            "Epoch 308/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1231 - acc: 0.7667 - val_loss: 0.0946 - val_acc: 0.8000\n",
            "Epoch 309/800\n",
            "180/180 [==============================] - 0s 338us/step - loss: 0.1232 - acc: 0.7667 - val_loss: 0.0958 - val_acc: 0.7500\n",
            "Epoch 310/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1228 - acc: 0.7722 - val_loss: 0.0947 - val_acc: 0.7500\n",
            "Epoch 311/800\n",
            "180/180 [==============================] - 0s 432us/step - loss: 0.1228 - acc: 0.7889 - val_loss: 0.0946 - val_acc: 0.8500\n",
            "Epoch 312/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1225 - acc: 0.7667 - val_loss: 0.0939 - val_acc: 0.8000\n",
            "Epoch 313/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1227 - acc: 0.7833 - val_loss: 0.0943 - val_acc: 0.8000\n",
            "Epoch 314/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1224 - acc: 0.7889 - val_loss: 0.0938 - val_acc: 0.8500\n",
            "Epoch 315/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1221 - acc: 0.7778 - val_loss: 0.0966 - val_acc: 0.7500\n",
            "Epoch 316/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1222 - acc: 0.7722 - val_loss: 0.0934 - val_acc: 0.8000\n",
            "Epoch 317/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1224 - acc: 0.7833 - val_loss: 0.0938 - val_acc: 0.8000\n",
            "Epoch 318/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1218 - acc: 0.7778 - val_loss: 0.0932 - val_acc: 0.8000\n",
            "Epoch 319/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1214 - acc: 0.7778 - val_loss: 0.0959 - val_acc: 0.8000\n",
            "Epoch 320/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1220 - acc: 0.7611 - val_loss: 0.0941 - val_acc: 0.8000\n",
            "Epoch 321/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1216 - acc: 0.7833 - val_loss: 0.0946 - val_acc: 0.8000\n",
            "Epoch 322/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1218 - acc: 0.7889 - val_loss: 0.0946 - val_acc: 0.7500\n",
            "Epoch 323/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1215 - acc: 0.7778 - val_loss: 0.0947 - val_acc: 0.8000\n",
            "Epoch 324/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1216 - acc: 0.7667 - val_loss: 0.0926 - val_acc: 0.7500\n",
            "Epoch 325/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1215 - acc: 0.7778 - val_loss: 0.0937 - val_acc: 0.8000\n",
            "Epoch 326/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.1212 - acc: 0.7944 - val_loss: 0.0933 - val_acc: 0.8000\n",
            "Epoch 327/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1217 - acc: 0.7722 - val_loss: 0.0939 - val_acc: 0.7500\n",
            "Epoch 328/800\n",
            "180/180 [==============================] - 0s 481us/step - loss: 0.1210 - acc: 0.7889 - val_loss: 0.0955 - val_acc: 0.8000\n",
            "Epoch 329/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1209 - acc: 0.7889 - val_loss: 0.0947 - val_acc: 0.7500\n",
            "Epoch 330/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1207 - acc: 0.7833 - val_loss: 0.0939 - val_acc: 0.7500\n",
            "Epoch 331/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1214 - acc: 0.7778 - val_loss: 0.0930 - val_acc: 0.8500\n",
            "Epoch 332/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1208 - acc: 0.7833 - val_loss: 0.0930 - val_acc: 0.8500\n",
            "Epoch 333/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1206 - acc: 0.7722 - val_loss: 0.0940 - val_acc: 0.8000\n",
            "Epoch 334/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1205 - acc: 0.7778 - val_loss: 0.0928 - val_acc: 0.8000\n",
            "Epoch 335/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1201 - acc: 0.7833 - val_loss: 0.0930 - val_acc: 0.8000\n",
            "Epoch 336/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.1203 - acc: 0.7889 - val_loss: 0.0943 - val_acc: 0.8500\n",
            "Epoch 337/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1204 - acc: 0.7778 - val_loss: 0.0950 - val_acc: 0.8000\n",
            "Epoch 338/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1201 - acc: 0.8056 - val_loss: 0.0932 - val_acc: 0.8500\n",
            "Epoch 339/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1203 - acc: 0.7889 - val_loss: 0.0930 - val_acc: 0.7500\n",
            "Epoch 340/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1199 - acc: 0.7944 - val_loss: 0.0913 - val_acc: 0.8500\n",
            "Epoch 341/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1196 - acc: 0.8000 - val_loss: 0.0929 - val_acc: 0.8500\n",
            "Epoch 342/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1198 - acc: 0.7778 - val_loss: 0.0940 - val_acc: 0.8500\n",
            "Epoch 343/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1198 - acc: 0.7889 - val_loss: 0.0914 - val_acc: 0.8500\n",
            "Epoch 344/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1197 - acc: 0.7722 - val_loss: 0.0923 - val_acc: 0.8500\n",
            "Epoch 345/800\n",
            "180/180 [==============================] - 0s 394us/step - loss: 0.1198 - acc: 0.7778 - val_loss: 0.0916 - val_acc: 0.8000\n",
            "Epoch 346/800\n",
            "180/180 [==============================] - 0s 399us/step - loss: 0.1194 - acc: 0.7833 - val_loss: 0.0919 - val_acc: 0.8000\n",
            "Epoch 347/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1193 - acc: 0.7944 - val_loss: 0.0913 - val_acc: 0.8000\n",
            "Epoch 348/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.1194 - acc: 0.7778 - val_loss: 0.0904 - val_acc: 0.8000\n",
            "Epoch 349/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1190 - acc: 0.7722 - val_loss: 0.0923 - val_acc: 0.8500\n",
            "Epoch 350/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1190 - acc: 0.7833 - val_loss: 0.0931 - val_acc: 0.8500\n",
            "Epoch 351/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1190 - acc: 0.7889 - val_loss: 0.0906 - val_acc: 0.8000\n",
            "Epoch 352/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1188 - acc: 0.7833 - val_loss: 0.0924 - val_acc: 0.7500\n",
            "Epoch 353/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1190 - acc: 0.7778 - val_loss: 0.0918 - val_acc: 0.8000\n",
            "Epoch 354/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1188 - acc: 0.7889 - val_loss: 0.0921 - val_acc: 0.7500\n",
            "Epoch 355/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1191 - acc: 0.7833 - val_loss: 0.0913 - val_acc: 0.8500\n",
            "Epoch 356/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1186 - acc: 0.7944 - val_loss: 0.0918 - val_acc: 0.8500\n",
            "Epoch 357/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1183 - acc: 0.7833 - val_loss: 0.0946 - val_acc: 0.7000\n",
            "Epoch 358/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1187 - acc: 0.7889 - val_loss: 0.0907 - val_acc: 0.8500\n",
            "Epoch 359/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1182 - acc: 0.7944 - val_loss: 0.0930 - val_acc: 0.8000\n",
            "Epoch 360/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1186 - acc: 0.7944 - val_loss: 0.0918 - val_acc: 0.8000\n",
            "Epoch 361/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1178 - acc: 0.8000 - val_loss: 0.0924 - val_acc: 0.8500\n",
            "Epoch 362/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1184 - acc: 0.8000 - val_loss: 0.0912 - val_acc: 0.8000\n",
            "Epoch 363/800\n",
            "180/180 [==============================] - 0s 488us/step - loss: 0.1180 - acc: 0.7944 - val_loss: 0.0913 - val_acc: 0.8500\n",
            "Epoch 364/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1179 - acc: 0.7833 - val_loss: 0.0914 - val_acc: 0.8500\n",
            "Epoch 365/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1180 - acc: 0.7889 - val_loss: 0.0904 - val_acc: 0.8500\n",
            "Epoch 366/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1178 - acc: 0.7944 - val_loss: 0.0908 - val_acc: 0.8500\n",
            "Epoch 367/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.1175 - acc: 0.7889 - val_loss: 0.0909 - val_acc: 0.8500\n",
            "Epoch 368/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1178 - acc: 0.7944 - val_loss: 0.0914 - val_acc: 0.8000\n",
            "Epoch 369/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1178 - acc: 0.7944 - val_loss: 0.0906 - val_acc: 0.8500\n",
            "Epoch 370/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1174 - acc: 0.7889 - val_loss: 0.0904 - val_acc: 0.8500\n",
            "Epoch 371/800\n",
            "180/180 [==============================] - 0s 336us/step - loss: 0.1171 - acc: 0.8111 - val_loss: 0.0909 - val_acc: 0.8000\n",
            "Epoch 372/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1180 - acc: 0.7889 - val_loss: 0.0897 - val_acc: 0.8000\n",
            "Epoch 373/800\n",
            "180/180 [==============================] - 0s 395us/step - loss: 0.1178 - acc: 0.8056 - val_loss: 0.0900 - val_acc: 0.8500\n",
            "Epoch 374/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1180 - acc: 0.7778 - val_loss: 0.0906 - val_acc: 0.8000\n",
            "Epoch 375/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.1178 - acc: 0.8000 - val_loss: 0.0917 - val_acc: 0.8500\n",
            "Epoch 376/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1171 - acc: 0.7889 - val_loss: 0.0914 - val_acc: 0.7500\n",
            "Epoch 377/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1174 - acc: 0.8000 - val_loss: 0.0908 - val_acc: 0.8500\n",
            "Epoch 378/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1177 - acc: 0.7889 - val_loss: 0.0902 - val_acc: 0.8000\n",
            "Epoch 379/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1167 - acc: 0.8000 - val_loss: 0.0905 - val_acc: 0.8000\n",
            "Epoch 380/800\n",
            "180/180 [==============================] - 0s 411us/step - loss: 0.1171 - acc: 0.8222 - val_loss: 0.0908 - val_acc: 0.8000\n",
            "Epoch 381/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.1167 - acc: 0.7944 - val_loss: 0.0904 - val_acc: 0.7500\n",
            "Epoch 382/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1167 - acc: 0.7944 - val_loss: 0.0888 - val_acc: 0.8000\n",
            "Epoch 383/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.1168 - acc: 0.8111 - val_loss: 0.0895 - val_acc: 0.8000\n",
            "Epoch 384/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1166 - acc: 0.8167 - val_loss: 0.0894 - val_acc: 0.8000\n",
            "Epoch 385/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1168 - acc: 0.7944 - val_loss: 0.0896 - val_acc: 0.8500\n",
            "Epoch 386/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1168 - acc: 0.8111 - val_loss: 0.0900 - val_acc: 0.8500\n",
            "Epoch 387/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1166 - acc: 0.8222 - val_loss: 0.0930 - val_acc: 0.7500\n",
            "Epoch 388/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1165 - acc: 0.7778 - val_loss: 0.0897 - val_acc: 0.8500\n",
            "Epoch 389/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1164 - acc: 0.8056 - val_loss: 0.0940 - val_acc: 0.7500\n",
            "Epoch 390/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1169 - acc: 0.8111 - val_loss: 0.0919 - val_acc: 0.8000\n",
            "Epoch 391/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1168 - acc: 0.7889 - val_loss: 0.0889 - val_acc: 0.8500\n",
            "Epoch 392/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.1165 - acc: 0.8000 - val_loss: 0.0876 - val_acc: 0.8000\n",
            "Epoch 393/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1162 - acc: 0.8056 - val_loss: 0.0915 - val_acc: 0.8000\n",
            "Epoch 394/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1160 - acc: 0.8056 - val_loss: 0.0915 - val_acc: 0.8500\n",
            "Epoch 395/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1163 - acc: 0.8000 - val_loss: 0.0892 - val_acc: 0.8000\n",
            "Epoch 396/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1158 - acc: 0.8056 - val_loss: 0.0911 - val_acc: 0.8500\n",
            "Epoch 397/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1160 - acc: 0.7944 - val_loss: 0.0894 - val_acc: 0.8500\n",
            "Epoch 398/800\n",
            "180/180 [==============================] - 0s 483us/step - loss: 0.1159 - acc: 0.7944 - val_loss: 0.0916 - val_acc: 0.8500\n",
            "Epoch 399/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1161 - acc: 0.8000 - val_loss: 0.0910 - val_acc: 0.8000\n",
            "Epoch 400/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1162 - acc: 0.8222 - val_loss: 0.0909 - val_acc: 0.8000\n",
            "Epoch 401/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1158 - acc: 0.8111 - val_loss: 0.0885 - val_acc: 0.8500\n",
            "Epoch 402/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1154 - acc: 0.8222 - val_loss: 0.0903 - val_acc: 0.8000\n",
            "Epoch 403/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1156 - acc: 0.7944 - val_loss: 0.0913 - val_acc: 0.8500\n",
            "Epoch 404/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1158 - acc: 0.8111 - val_loss: 0.0893 - val_acc: 0.8000\n",
            "Epoch 405/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1158 - acc: 0.8167 - val_loss: 0.0911 - val_acc: 0.8500\n",
            "Epoch 406/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1156 - acc: 0.8056 - val_loss: 0.0902 - val_acc: 0.7500\n",
            "Epoch 407/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1153 - acc: 0.8056 - val_loss: 0.0888 - val_acc: 0.8500\n",
            "Epoch 408/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1154 - acc: 0.8000 - val_loss: 0.0910 - val_acc: 0.8500\n",
            "Epoch 409/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1154 - acc: 0.8056 - val_loss: 0.0893 - val_acc: 0.7500\n",
            "Epoch 410/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1151 - acc: 0.8000 - val_loss: 0.0899 - val_acc: 0.8000\n",
            "Epoch 411/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1151 - acc: 0.8056 - val_loss: 0.0905 - val_acc: 0.8500\n",
            "Epoch 412/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1148 - acc: 0.8056 - val_loss: 0.0899 - val_acc: 0.8000\n",
            "Epoch 413/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1158 - acc: 0.8056 - val_loss: 0.0889 - val_acc: 0.8500\n",
            "Epoch 414/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1152 - acc: 0.7944 - val_loss: 0.0879 - val_acc: 0.8000\n",
            "Epoch 415/800\n",
            "180/180 [==============================] - 0s 489us/step - loss: 0.1148 - acc: 0.7944 - val_loss: 0.0882 - val_acc: 0.8500\n",
            "Epoch 416/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1152 - acc: 0.8222 - val_loss: 0.0879 - val_acc: 0.8500\n",
            "Epoch 417/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1152 - acc: 0.8167 - val_loss: 0.0892 - val_acc: 0.8000\n",
            "Epoch 418/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1154 - acc: 0.8000 - val_loss: 0.0890 - val_acc: 0.8500\n",
            "Epoch 419/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1146 - acc: 0.8056 - val_loss: 0.0875 - val_acc: 0.9000\n",
            "Epoch 420/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1146 - acc: 0.8111 - val_loss: 0.0895 - val_acc: 0.8500\n",
            "Epoch 421/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1147 - acc: 0.8056 - val_loss: 0.0912 - val_acc: 0.9000\n",
            "Epoch 422/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1143 - acc: 0.8056 - val_loss: 0.0890 - val_acc: 0.9000\n",
            "Epoch 423/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1156 - acc: 0.8333 - val_loss: 0.0889 - val_acc: 0.8500\n",
            "Epoch 424/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1145 - acc: 0.8222 - val_loss: 0.0884 - val_acc: 0.8000\n",
            "Epoch 425/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1143 - acc: 0.8278 - val_loss: 0.0880 - val_acc: 0.8000\n",
            "Epoch 426/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1142 - acc: 0.8278 - val_loss: 0.0881 - val_acc: 0.9000\n",
            "Epoch 427/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1147 - acc: 0.8167 - val_loss: 0.0890 - val_acc: 0.8000\n",
            "Epoch 428/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1145 - acc: 0.8278 - val_loss: 0.0875 - val_acc: 0.7500\n",
            "Epoch 429/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1144 - acc: 0.8222 - val_loss: 0.0893 - val_acc: 0.8500\n",
            "Epoch 430/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1145 - acc: 0.7944 - val_loss: 0.0884 - val_acc: 0.8500\n",
            "Epoch 431/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1145 - acc: 0.8167 - val_loss: 0.0891 - val_acc: 0.8000\n",
            "Epoch 432/800\n",
            "180/180 [==============================] - 0s 426us/step - loss: 0.1144 - acc: 0.7944 - val_loss: 0.0875 - val_acc: 0.7500\n",
            "Epoch 433/800\n",
            "180/180 [==============================] - 0s 417us/step - loss: 0.1142 - acc: 0.8111 - val_loss: 0.0881 - val_acc: 0.8000\n",
            "Epoch 434/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1148 - acc: 0.8167 - val_loss: 0.0894 - val_acc: 0.9000\n",
            "Epoch 435/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1141 - acc: 0.8167 - val_loss: 0.0900 - val_acc: 0.8000\n",
            "Epoch 436/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1146 - acc: 0.8167 - val_loss: 0.0905 - val_acc: 0.9000\n",
            "Epoch 437/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1146 - acc: 0.8167 - val_loss: 0.0881 - val_acc: 0.8500\n",
            "Epoch 438/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.1138 - acc: 0.8056 - val_loss: 0.0880 - val_acc: 0.8500\n",
            "Epoch 439/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1140 - acc: 0.8111 - val_loss: 0.0869 - val_acc: 0.8500\n",
            "Epoch 440/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1139 - acc: 0.8389 - val_loss: 0.0876 - val_acc: 0.8500\n",
            "Epoch 441/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1136 - acc: 0.7889 - val_loss: 0.0878 - val_acc: 0.8500\n",
            "Epoch 442/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.1140 - acc: 0.8111 - val_loss: 0.0903 - val_acc: 0.8500\n",
            "Epoch 443/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1143 - acc: 0.8111 - val_loss: 0.0881 - val_acc: 0.9000\n",
            "Epoch 444/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1138 - acc: 0.8389 - val_loss: 0.0880 - val_acc: 0.9000\n",
            "Epoch 445/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1143 - acc: 0.8111 - val_loss: 0.0899 - val_acc: 0.9000\n",
            "Epoch 446/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1134 - acc: 0.8278 - val_loss: 0.0888 - val_acc: 0.9000\n",
            "Epoch 447/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1139 - acc: 0.8167 - val_loss: 0.0874 - val_acc: 0.8500\n",
            "Epoch 448/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1135 - acc: 0.8389 - val_loss: 0.0923 - val_acc: 0.8500\n",
            "Epoch 449/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1142 - acc: 0.8222 - val_loss: 0.0907 - val_acc: 0.8000\n",
            "Epoch 450/800\n",
            "180/180 [==============================] - 0s 490us/step - loss: 0.1139 - acc: 0.8111 - val_loss: 0.0873 - val_acc: 0.9000\n",
            "Epoch 451/800\n",
            "180/180 [==============================] - 0s 436us/step - loss: 0.1133 - acc: 0.8222 - val_loss: 0.0897 - val_acc: 0.8500\n",
            "Epoch 452/800\n",
            "180/180 [==============================] - 0s 337us/step - loss: 0.1140 - acc: 0.8222 - val_loss: 0.0891 - val_acc: 0.9000\n",
            "Epoch 453/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1134 - acc: 0.8167 - val_loss: 0.0897 - val_acc: 0.9000\n",
            "Epoch 454/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1134 - acc: 0.8111 - val_loss: 0.0890 - val_acc: 0.9000\n",
            "Epoch 455/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1132 - acc: 0.8278 - val_loss: 0.0867 - val_acc: 0.9000\n",
            "Epoch 456/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1131 - acc: 0.8389 - val_loss: 0.0874 - val_acc: 0.8500\n",
            "Epoch 457/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1132 - acc: 0.8111 - val_loss: 0.0881 - val_acc: 0.8500\n",
            "Epoch 458/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1131 - acc: 0.8167 - val_loss: 0.0888 - val_acc: 0.8500\n",
            "Epoch 459/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1130 - acc: 0.8222 - val_loss: 0.0870 - val_acc: 0.8500\n",
            "Epoch 460/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1134 - acc: 0.8222 - val_loss: 0.0871 - val_acc: 0.8500\n",
            "Epoch 461/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1133 - acc: 0.8333 - val_loss: 0.0873 - val_acc: 0.9000\n",
            "Epoch 462/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1138 - acc: 0.8333 - val_loss: 0.0899 - val_acc: 0.8500\n",
            "Epoch 463/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1133 - acc: 0.8444 - val_loss: 0.0881 - val_acc: 0.8500\n",
            "Epoch 464/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1132 - acc: 0.8167 - val_loss: 0.0882 - val_acc: 0.7500\n",
            "Epoch 465/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.1140 - acc: 0.8222 - val_loss: 0.0871 - val_acc: 0.9000\n",
            "Epoch 466/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1136 - acc: 0.8278 - val_loss: 0.0878 - val_acc: 0.8500\n",
            "Epoch 467/800\n",
            "180/180 [==============================] - 0s 476us/step - loss: 0.1130 - acc: 0.8278 - val_loss: 0.0885 - val_acc: 0.8500\n",
            "Epoch 468/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1130 - acc: 0.8167 - val_loss: 0.0875 - val_acc: 0.9000\n",
            "Epoch 469/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1131 - acc: 0.8222 - val_loss: 0.0872 - val_acc: 0.9000\n",
            "Epoch 470/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1130 - acc: 0.8444 - val_loss: 0.0893 - val_acc: 0.8000\n",
            "Epoch 471/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.1126 - acc: 0.8278 - val_loss: 0.0854 - val_acc: 0.8500\n",
            "Epoch 472/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1128 - acc: 0.8333 - val_loss: 0.0866 - val_acc: 0.9000\n",
            "Epoch 473/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1129 - acc: 0.8333 - val_loss: 0.0866 - val_acc: 0.8500\n",
            "Epoch 474/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1130 - acc: 0.8333 - val_loss: 0.0860 - val_acc: 0.8500\n",
            "Epoch 475/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1125 - acc: 0.8444 - val_loss: 0.0858 - val_acc: 0.8500\n",
            "Epoch 476/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1127 - acc: 0.8556 - val_loss: 0.0879 - val_acc: 0.8500\n",
            "Epoch 477/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1131 - acc: 0.8556 - val_loss: 0.0883 - val_acc: 0.9000\n",
            "Epoch 478/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.1128 - acc: 0.8389 - val_loss: 0.0873 - val_acc: 0.8500\n",
            "Epoch 479/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1126 - acc: 0.8444 - val_loss: 0.0888 - val_acc: 0.9500\n",
            "Epoch 480/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.1128 - acc: 0.8389 - val_loss: 0.0868 - val_acc: 0.8500\n",
            "Epoch 481/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1125 - acc: 0.8500 - val_loss: 0.0854 - val_acc: 0.8500\n",
            "Epoch 482/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1124 - acc: 0.8500 - val_loss: 0.0868 - val_acc: 0.8500\n",
            "Epoch 483/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1128 - acc: 0.8611 - val_loss: 0.0884 - val_acc: 0.9000\n",
            "Epoch 484/800\n",
            "180/180 [==============================] - 0s 462us/step - loss: 0.1123 - acc: 0.8222 - val_loss: 0.0875 - val_acc: 0.8500\n",
            "Epoch 485/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1124 - acc: 0.8500 - val_loss: 0.0868 - val_acc: 0.8000\n",
            "Epoch 486/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1122 - acc: 0.8389 - val_loss: 0.0860 - val_acc: 0.8500\n",
            "Epoch 487/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.1121 - acc: 0.8500 - val_loss: 0.0873 - val_acc: 0.8500\n",
            "Epoch 488/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1121 - acc: 0.8444 - val_loss: 0.0880 - val_acc: 0.8500\n",
            "Epoch 489/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1124 - acc: 0.8556 - val_loss: 0.0871 - val_acc: 0.9000\n",
            "Epoch 490/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1124 - acc: 0.8389 - val_loss: 0.0863 - val_acc: 0.8000\n",
            "Epoch 491/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1119 - acc: 0.8389 - val_loss: 0.0865 - val_acc: 0.8500\n",
            "Epoch 492/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1122 - acc: 0.8222 - val_loss: 0.0858 - val_acc: 0.8500\n",
            "Epoch 493/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1119 - acc: 0.8611 - val_loss: 0.0872 - val_acc: 0.9000\n",
            "Epoch 494/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1120 - acc: 0.8167 - val_loss: 0.0862 - val_acc: 0.8000\n",
            "Epoch 495/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1116 - acc: 0.8333 - val_loss: 0.0861 - val_acc: 0.8500\n",
            "Epoch 496/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1119 - acc: 0.8444 - val_loss: 0.0892 - val_acc: 0.8500\n",
            "Epoch 497/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1117 - acc: 0.8333 - val_loss: 0.0867 - val_acc: 0.8500\n",
            "Epoch 498/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1118 - acc: 0.8611 - val_loss: 0.0882 - val_acc: 0.8500\n",
            "Epoch 499/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1122 - acc: 0.8556 - val_loss: 0.0877 - val_acc: 0.9000\n",
            "Epoch 500/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1119 - acc: 0.8444 - val_loss: 0.0864 - val_acc: 0.8500\n",
            "Epoch 501/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1118 - acc: 0.8444 - val_loss: 0.0866 - val_acc: 0.8500\n",
            "Epoch 502/800\n",
            "180/180 [==============================] - 0s 451us/step - loss: 0.1121 - acc: 0.8389 - val_loss: 0.0877 - val_acc: 0.8000\n",
            "Epoch 503/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1117 - acc: 0.8333 - val_loss: 0.0858 - val_acc: 0.8500\n",
            "Epoch 504/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1120 - acc: 0.8667 - val_loss: 0.0859 - val_acc: 0.8000\n",
            "Epoch 505/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1114 - acc: 0.8444 - val_loss: 0.0866 - val_acc: 0.8500\n",
            "Epoch 506/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1120 - acc: 0.8278 - val_loss: 0.0869 - val_acc: 0.8500\n",
            "Epoch 507/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1118 - acc: 0.8611 - val_loss: 0.0873 - val_acc: 0.8500\n",
            "Epoch 508/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1123 - acc: 0.8333 - val_loss: 0.0882 - val_acc: 0.9500\n",
            "Epoch 509/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1125 - acc: 0.8444 - val_loss: 0.0866 - val_acc: 0.8000\n",
            "Epoch 510/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1114 - acc: 0.8556 - val_loss: 0.0868 - val_acc: 0.8000\n",
            "Epoch 511/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1115 - acc: 0.8444 - val_loss: 0.0858 - val_acc: 0.9000\n",
            "Epoch 512/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1117 - acc: 0.8611 - val_loss: 0.0869 - val_acc: 0.8500\n",
            "Epoch 513/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1116 - acc: 0.8611 - val_loss: 0.0876 - val_acc: 0.9500\n",
            "Epoch 514/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1114 - acc: 0.8500 - val_loss: 0.0901 - val_acc: 0.8500\n",
            "Epoch 515/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.1119 - acc: 0.8500 - val_loss: 0.0860 - val_acc: 0.8500\n",
            "Epoch 516/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1115 - acc: 0.8500 - val_loss: 0.0849 - val_acc: 0.9000\n",
            "Epoch 517/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1116 - acc: 0.8611 - val_loss: 0.0868 - val_acc: 0.9000\n",
            "Epoch 518/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1118 - acc: 0.8611 - val_loss: 0.0871 - val_acc: 0.9000\n",
            "Epoch 519/800\n",
            "180/180 [==============================] - 0s 402us/step - loss: 0.1113 - acc: 0.8500 - val_loss: 0.0864 - val_acc: 0.9000\n",
            "Epoch 520/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1115 - acc: 0.8222 - val_loss: 0.0851 - val_acc: 0.9000\n",
            "Epoch 521/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1116 - acc: 0.8389 - val_loss: 0.0846 - val_acc: 0.9000\n",
            "Epoch 522/800\n",
            "180/180 [==============================] - 0s 334us/step - loss: 0.1116 - acc: 0.8611 - val_loss: 0.0878 - val_acc: 0.9000\n",
            "Epoch 523/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1116 - acc: 0.8722 - val_loss: 0.0856 - val_acc: 0.8500\n",
            "Epoch 524/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1115 - acc: 0.8611 - val_loss: 0.0880 - val_acc: 0.9000\n",
            "Epoch 525/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1114 - acc: 0.8500 - val_loss: 0.0867 - val_acc: 0.9000\n",
            "Epoch 526/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1108 - acc: 0.8556 - val_loss: 0.0877 - val_acc: 0.9000\n",
            "Epoch 527/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1113 - acc: 0.8667 - val_loss: 0.0886 - val_acc: 0.8000\n",
            "Epoch 528/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1112 - acc: 0.8500 - val_loss: 0.0843 - val_acc: 0.8000\n",
            "Epoch 529/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.1113 - acc: 0.8556 - val_loss: 0.0862 - val_acc: 0.8500\n",
            "Epoch 530/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1110 - acc: 0.8500 - val_loss: 0.0870 - val_acc: 0.9000\n",
            "Epoch 531/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.0864 - val_acc: 0.9000\n",
            "Epoch 532/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1114 - acc: 0.8611 - val_loss: 0.0881 - val_acc: 0.8500\n",
            "Epoch 533/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1111 - acc: 0.8667 - val_loss: 0.0876 - val_acc: 0.9000\n",
            "Epoch 534/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1107 - acc: 0.8611 - val_loss: 0.0866 - val_acc: 0.8000\n",
            "Epoch 535/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1111 - acc: 0.8500 - val_loss: 0.0863 - val_acc: 0.8500\n",
            "Epoch 536/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1112 - acc: 0.8611 - val_loss: 0.0876 - val_acc: 0.8500\n",
            "Epoch 537/800\n",
            "180/180 [==============================] - 0s 485us/step - loss: 0.1111 - acc: 0.8722 - val_loss: 0.0859 - val_acc: 0.9000\n",
            "Epoch 538/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.1109 - acc: 0.8778 - val_loss: 0.0853 - val_acc: 0.8500\n",
            "Epoch 539/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1109 - acc: 0.8833 - val_loss: 0.0885 - val_acc: 0.9000\n",
            "Epoch 540/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.0880 - val_acc: 0.8500\n",
            "Epoch 541/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1120 - acc: 0.8611 - val_loss: 0.0847 - val_acc: 0.8000\n",
            "Epoch 542/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1113 - acc: 0.8500 - val_loss: 0.0882 - val_acc: 0.9000\n",
            "Epoch 543/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.1109 - acc: 0.8500 - val_loss: 0.0863 - val_acc: 0.8000\n",
            "Epoch 544/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1114 - acc: 0.8722 - val_loss: 0.0883 - val_acc: 0.8500\n",
            "Epoch 545/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1106 - acc: 0.8556 - val_loss: 0.0863 - val_acc: 0.8000\n",
            "Epoch 546/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1107 - acc: 0.8611 - val_loss: 0.0866 - val_acc: 0.8500\n",
            "Epoch 547/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1107 - acc: 0.8667 - val_loss: 0.0864 - val_acc: 0.8500\n",
            "Epoch 548/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1113 - acc: 0.8667 - val_loss: 0.0847 - val_acc: 0.8000\n",
            "Epoch 549/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1109 - acc: 0.8444 - val_loss: 0.0897 - val_acc: 0.9000\n",
            "Epoch 550/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1108 - acc: 0.8667 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 551/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1108 - acc: 0.8556 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 552/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1104 - acc: 0.8667 - val_loss: 0.0860 - val_acc: 0.9500\n",
            "Epoch 553/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.1110 - acc: 0.8722 - val_loss: 0.0860 - val_acc: 0.8500\n",
            "Epoch 554/800\n",
            "180/180 [==============================] - 0s 520us/step - loss: 0.1107 - acc: 0.8667 - val_loss: 0.0855 - val_acc: 0.8500\n",
            "Epoch 555/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1109 - acc: 0.8778 - val_loss: 0.0836 - val_acc: 0.8500\n",
            "Epoch 556/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.1108 - acc: 0.8667 - val_loss: 0.0850 - val_acc: 0.8500\n",
            "Epoch 557/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1111 - acc: 0.8611 - val_loss: 0.0886 - val_acc: 0.8500\n",
            "Epoch 558/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1113 - acc: 0.8778 - val_loss: 0.0874 - val_acc: 0.8500\n",
            "Epoch 559/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1110 - acc: 0.8556 - val_loss: 0.0855 - val_acc: 0.8500\n",
            "Epoch 560/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1103 - acc: 0.8611 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 561/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1105 - acc: 0.8833 - val_loss: 0.0861 - val_acc: 0.9000\n",
            "Epoch 562/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.1104 - acc: 0.8833 - val_loss: 0.0868 - val_acc: 0.8500\n",
            "Epoch 563/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.1105 - acc: 0.8722 - val_loss: 0.0864 - val_acc: 0.8000\n",
            "Epoch 564/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1108 - acc: 0.8667 - val_loss: 0.0854 - val_acc: 0.8500\n",
            "Epoch 565/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1105 - acc: 0.8667 - val_loss: 0.0853 - val_acc: 0.8500\n",
            "Epoch 566/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.1101 - acc: 0.8556 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 567/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.0851 - val_acc: 0.8500\n",
            "Epoch 568/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1101 - acc: 0.8722 - val_loss: 0.0878 - val_acc: 0.8500\n",
            "Epoch 569/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.1108 - acc: 0.8667 - val_loss: 0.0849 - val_acc: 0.8500\n",
            "Epoch 570/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1104 - acc: 0.8778 - val_loss: 0.0870 - val_acc: 0.8500\n",
            "Epoch 571/800\n",
            "180/180 [==============================] - 0s 396us/step - loss: 0.1106 - acc: 0.8722 - val_loss: 0.0870 - val_acc: 0.9000\n",
            "Epoch 572/800\n",
            "180/180 [==============================] - 0s 404us/step - loss: 0.1110 - acc: 0.8833 - val_loss: 0.0851 - val_acc: 0.9000\n",
            "Epoch 573/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1106 - acc: 0.8444 - val_loss: 0.0852 - val_acc: 0.9000\n",
            "Epoch 574/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1110 - acc: 0.8611 - val_loss: 0.0855 - val_acc: 0.8500\n",
            "Epoch 575/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1103 - acc: 0.8611 - val_loss: 0.0858 - val_acc: 0.9000\n",
            "Epoch 576/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1109 - acc: 0.8667 - val_loss: 0.0851 - val_acc: 0.8500\n",
            "Epoch 577/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1100 - acc: 0.8611 - val_loss: 0.0875 - val_acc: 0.9000\n",
            "Epoch 578/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.1105 - acc: 0.8722 - val_loss: 0.0857 - val_acc: 0.8500\n",
            "Epoch 579/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1103 - acc: 0.8667 - val_loss: 0.0834 - val_acc: 0.8500\n",
            "Epoch 580/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1101 - acc: 0.8722 - val_loss: 0.0848 - val_acc: 0.8500\n",
            "Epoch 581/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1100 - acc: 0.8611 - val_loss: 0.0854 - val_acc: 0.8000\n",
            "Epoch 582/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.1103 - acc: 0.8778 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 583/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1101 - acc: 0.8722 - val_loss: 0.0869 - val_acc: 0.8500\n",
            "Epoch 584/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1105 - acc: 0.8722 - val_loss: 0.0847 - val_acc: 0.9000\n",
            "Epoch 585/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1102 - acc: 0.8722 - val_loss: 0.0862 - val_acc: 0.9000\n",
            "Epoch 586/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1107 - acc: 0.8833 - val_loss: 0.0855 - val_acc: 0.9000\n",
            "Epoch 587/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1101 - acc: 0.8833 - val_loss: 0.0863 - val_acc: 0.8500\n",
            "Epoch 588/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1098 - acc: 0.8722 - val_loss: 0.0846 - val_acc: 0.8500\n",
            "Epoch 589/800\n",
            "180/180 [==============================] - 0s 481us/step - loss: 0.1102 - acc: 0.8833 - val_loss: 0.0864 - val_acc: 0.8500\n",
            "Epoch 590/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1107 - acc: 0.8556 - val_loss: 0.0862 - val_acc: 0.8500\n",
            "Epoch 591/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1103 - acc: 0.8889 - val_loss: 0.0895 - val_acc: 0.9000\n",
            "Epoch 592/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1113 - acc: 0.8556 - val_loss: 0.0855 - val_acc: 0.9000\n",
            "Epoch 593/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1102 - acc: 0.9000 - val_loss: 0.0838 - val_acc: 0.8000\n",
            "Epoch 594/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1097 - acc: 0.9000 - val_loss: 0.0849 - val_acc: 0.9000\n",
            "Epoch 595/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1097 - acc: 0.8722 - val_loss: 0.0863 - val_acc: 0.9000\n",
            "Epoch 596/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1101 - acc: 0.8722 - val_loss: 0.0848 - val_acc: 0.9000\n",
            "Epoch 597/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1097 - acc: 0.8889 - val_loss: 0.0867 - val_acc: 0.8500\n",
            "Epoch 598/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1096 - acc: 0.8722 - val_loss: 0.0852 - val_acc: 0.8500\n",
            "Epoch 599/800\n",
            "180/180 [==============================] - 0s 394us/step - loss: 0.1099 - acc: 0.8833 - val_loss: 0.0858 - val_acc: 0.9000\n",
            "Epoch 600/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1101 - acc: 0.8778 - val_loss: 0.0846 - val_acc: 0.9000\n",
            "Epoch 601/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1096 - acc: 0.8667 - val_loss: 0.0834 - val_acc: 0.8000\n",
            "Epoch 602/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1095 - acc: 0.8722 - val_loss: 0.0843 - val_acc: 0.9000\n",
            "Epoch 603/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1101 - acc: 0.9000 - val_loss: 0.0835 - val_acc: 0.8500\n",
            "Epoch 604/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.1097 - acc: 0.8833 - val_loss: 0.0857 - val_acc: 0.8500\n",
            "Epoch 605/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1104 - acc: 0.8722 - val_loss: 0.0837 - val_acc: 0.8500\n",
            "Epoch 606/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.1096 - acc: 0.8944 - val_loss: 0.0843 - val_acc: 0.8000\n",
            "Epoch 607/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1098 - acc: 0.8722 - val_loss: 0.0844 - val_acc: 0.8500\n",
            "Epoch 608/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.1095 - acc: 0.8722 - val_loss: 0.0872 - val_acc: 0.8000\n",
            "Epoch 609/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1095 - acc: 0.8778 - val_loss: 0.0879 - val_acc: 0.8500\n",
            "Epoch 610/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1102 - acc: 0.8667 - val_loss: 0.0848 - val_acc: 0.9000\n",
            "Epoch 611/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1096 - acc: 0.8667 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 612/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1102 - acc: 0.8778 - val_loss: 0.0848 - val_acc: 0.9000\n",
            "Epoch 613/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1099 - acc: 0.8833 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 614/800\n",
            "180/180 [==============================] - 0s 330us/step - loss: 0.1104 - acc: 0.8667 - val_loss: 0.0837 - val_acc: 0.8000\n",
            "Epoch 615/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1101 - acc: 0.8722 - val_loss: 0.0840 - val_acc: 0.9000\n",
            "Epoch 616/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.1094 - acc: 0.8833 - val_loss: 0.0907 - val_acc: 0.8500\n",
            "Epoch 617/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1103 - acc: 0.8833 - val_loss: 0.0864 - val_acc: 0.8500\n",
            "Epoch 618/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1095 - acc: 0.8722 - val_loss: 0.0855 - val_acc: 0.9000\n",
            "Epoch 619/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1094 - acc: 0.8778 - val_loss: 0.0861 - val_acc: 0.9000\n",
            "Epoch 620/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1093 - acc: 0.8889 - val_loss: 0.0842 - val_acc: 0.8000\n",
            "Epoch 621/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1094 - acc: 0.8833 - val_loss: 0.0844 - val_acc: 0.9000\n",
            "Epoch 622/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1090 - acc: 0.8833 - val_loss: 0.0839 - val_acc: 0.9500\n",
            "Epoch 623/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1092 - acc: 0.8833 - val_loss: 0.0862 - val_acc: 0.9000\n",
            "Epoch 624/800\n",
            "180/180 [==============================] - 0s 488us/step - loss: 0.1093 - acc: 0.8500 - val_loss: 0.0866 - val_acc: 0.8500\n",
            "Epoch 625/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1103 - acc: 0.8722 - val_loss: 0.0850 - val_acc: 0.8500\n",
            "Epoch 626/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.1095 - acc: 0.8833 - val_loss: 0.0847 - val_acc: 0.9000\n",
            "Epoch 627/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1093 - acc: 0.8889 - val_loss: 0.0848 - val_acc: 0.8500\n",
            "Epoch 628/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1097 - acc: 0.8889 - val_loss: 0.0848 - val_acc: 0.8500\n",
            "Epoch 629/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1092 - acc: 0.8944 - val_loss: 0.0843 - val_acc: 0.8500\n",
            "Epoch 630/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1093 - acc: 0.8833 - val_loss: 0.0842 - val_acc: 0.9000\n",
            "Epoch 631/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1093 - acc: 0.9000 - val_loss: 0.0845 - val_acc: 0.8000\n",
            "Epoch 632/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1100 - acc: 0.9056 - val_loss: 0.0847 - val_acc: 0.9000\n",
            "Epoch 633/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1091 - acc: 0.8500 - val_loss: 0.0848 - val_acc: 0.9000\n",
            "Epoch 634/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1095 - acc: 0.8611 - val_loss: 0.0847 - val_acc: 0.8000\n",
            "Epoch 635/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1096 - acc: 0.8778 - val_loss: 0.0895 - val_acc: 0.9500\n",
            "Epoch 636/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1094 - acc: 0.9000 - val_loss: 0.0876 - val_acc: 0.9000\n",
            "Epoch 637/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1098 - acc: 0.8833 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 638/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1093 - acc: 0.8833 - val_loss: 0.0858 - val_acc: 0.9000\n",
            "Epoch 639/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1095 - acc: 0.8833 - val_loss: 0.0839 - val_acc: 0.8500\n",
            "Epoch 640/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1090 - acc: 0.8889 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 641/800\n",
            "180/180 [==============================] - 0s 463us/step - loss: 0.1092 - acc: 0.9000 - val_loss: 0.0835 - val_acc: 0.8500\n",
            "Epoch 642/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.1088 - acc: 0.8889 - val_loss: 0.0846 - val_acc: 0.9000\n",
            "Epoch 643/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1088 - acc: 0.8722 - val_loss: 0.0870 - val_acc: 0.9000\n",
            "Epoch 644/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1100 - acc: 0.8889 - val_loss: 0.0834 - val_acc: 0.8500\n",
            "Epoch 645/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1089 - acc: 0.8778 - val_loss: 0.0850 - val_acc: 0.9000\n",
            "Epoch 646/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1090 - acc: 0.8833 - val_loss: 0.0873 - val_acc: 0.8500\n",
            "Epoch 647/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.1094 - acc: 0.8500 - val_loss: 0.0864 - val_acc: 0.9500\n",
            "Epoch 648/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1091 - acc: 0.8833 - val_loss: 0.0852 - val_acc: 0.9500\n",
            "Epoch 649/800\n",
            "180/180 [==============================] - 0s 392us/step - loss: 0.1092 - acc: 0.8944 - val_loss: 0.0850 - val_acc: 0.8500\n",
            "Epoch 650/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1095 - acc: 0.8556 - val_loss: 0.0848 - val_acc: 0.9000\n",
            "Epoch 651/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1090 - acc: 0.8833 - val_loss: 0.0861 - val_acc: 0.9000\n",
            "Epoch 652/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1099 - acc: 0.8667 - val_loss: 0.0850 - val_acc: 0.9500\n",
            "Epoch 653/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1090 - acc: 0.8833 - val_loss: 0.0836 - val_acc: 0.8000\n",
            "Epoch 654/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1089 - acc: 0.8944 - val_loss: 0.0837 - val_acc: 0.8000\n",
            "Epoch 655/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1091 - acc: 0.8944 - val_loss: 0.0845 - val_acc: 0.9000\n",
            "Epoch 656/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1086 - acc: 0.8833 - val_loss: 0.0880 - val_acc: 0.9000\n",
            "Epoch 657/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1105 - acc: 0.9000 - val_loss: 0.0853 - val_acc: 0.8000\n",
            "Epoch 658/800\n",
            "180/180 [==============================] - 0s 412us/step - loss: 0.1094 - acc: 0.8833 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 659/800\n",
            "180/180 [==============================] - 0s 420us/step - loss: 0.1089 - acc: 0.9000 - val_loss: 0.0866 - val_acc: 0.9000\n",
            "Epoch 660/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.1094 - acc: 0.8833 - val_loss: 0.0881 - val_acc: 0.9500\n",
            "Epoch 661/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1090 - acc: 0.9000 - val_loss: 0.0848 - val_acc: 0.8500\n",
            "Epoch 662/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1093 - acc: 0.8389 - val_loss: 0.0842 - val_acc: 0.9500\n",
            "Epoch 663/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1088 - acc: 0.8889 - val_loss: 0.0841 - val_acc: 0.8500\n",
            "Epoch 664/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1095 - acc: 0.8833 - val_loss: 0.0847 - val_acc: 0.9000\n",
            "Epoch 665/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1087 - acc: 0.8667 - val_loss: 0.0833 - val_acc: 0.9000\n",
            "Epoch 666/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1088 - acc: 0.8833 - val_loss: 0.0901 - val_acc: 0.9000\n",
            "Epoch 667/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1092 - acc: 0.8889 - val_loss: 0.0849 - val_acc: 0.9500\n",
            "Epoch 668/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1086 - acc: 0.8611 - val_loss: 0.0836 - val_acc: 0.8500\n",
            "Epoch 669/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1087 - acc: 0.8833 - val_loss: 0.0836 - val_acc: 0.9000\n",
            "Epoch 670/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1089 - acc: 0.8889 - val_loss: 0.0848 - val_acc: 0.9000\n",
            "Epoch 671/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1093 - acc: 0.8722 - val_loss: 0.0836 - val_acc: 0.8500\n",
            "Epoch 672/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1089 - acc: 0.8778 - val_loss: 0.0833 - val_acc: 0.8500\n",
            "Epoch 673/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1087 - acc: 0.8944 - val_loss: 0.0855 - val_acc: 0.8500\n",
            "Epoch 674/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1088 - acc: 0.8889 - val_loss: 0.0850 - val_acc: 0.9000\n",
            "Epoch 675/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.1095 - acc: 0.8722 - val_loss: 0.0855 - val_acc: 0.9000\n",
            "Epoch 676/800\n",
            "180/180 [==============================] - 0s 434us/step - loss: 0.1085 - acc: 0.8889 - val_loss: 0.0843 - val_acc: 0.9000\n",
            "Epoch 677/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.1087 - acc: 0.8833 - val_loss: 0.0840 - val_acc: 0.9000\n",
            "Epoch 678/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1087 - acc: 0.8722 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 679/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1089 - acc: 0.8833 - val_loss: 0.0836 - val_acc: 0.9000\n",
            "Epoch 680/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1088 - acc: 0.8778 - val_loss: 0.0857 - val_acc: 0.8500\n",
            "Epoch 681/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1086 - acc: 0.8889 - val_loss: 0.0859 - val_acc: 0.9000\n",
            "Epoch 682/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1097 - acc: 0.8889 - val_loss: 0.0856 - val_acc: 0.9000\n",
            "Epoch 683/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1090 - acc: 0.8778 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 684/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1089 - acc: 0.8889 - val_loss: 0.0838 - val_acc: 0.8500\n",
            "Epoch 685/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1085 - acc: 0.9000 - val_loss: 0.0830 - val_acc: 0.9000\n",
            "Epoch 686/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1083 - acc: 0.8944 - val_loss: 0.0832 - val_acc: 0.9000\n",
            "Epoch 687/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1083 - acc: 0.8889 - val_loss: 0.0834 - val_acc: 0.9000\n",
            "Epoch 688/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1086 - acc: 0.8889 - val_loss: 0.0847 - val_acc: 0.9000\n",
            "Epoch 689/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1082 - acc: 0.8778 - val_loss: 0.0838 - val_acc: 0.8500\n",
            "Epoch 690/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1097 - acc: 0.8944 - val_loss: 0.0896 - val_acc: 0.9000\n",
            "Epoch 691/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1089 - acc: 0.8778 - val_loss: 0.0839 - val_acc: 0.9000\n",
            "Epoch 692/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1083 - acc: 0.9056 - val_loss: 0.0878 - val_acc: 0.9000\n",
            "Epoch 693/800\n",
            "180/180 [==============================] - 0s 397us/step - loss: 0.1088 - acc: 0.9000 - val_loss: 0.0853 - val_acc: 0.8500\n",
            "Epoch 694/800\n",
            "180/180 [==============================] - 0s 417us/step - loss: 0.1098 - acc: 0.8778 - val_loss: 0.0846 - val_acc: 0.9000\n",
            "Epoch 695/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1086 - acc: 0.8833 - val_loss: 0.0853 - val_acc: 0.9000\n",
            "Epoch 696/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1091 - acc: 0.8833 - val_loss: 0.0837 - val_acc: 0.9000\n",
            "Epoch 697/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1083 - acc: 0.8944 - val_loss: 0.0830 - val_acc: 0.8500\n",
            "Epoch 698/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1087 - acc: 0.8889 - val_loss: 0.0850 - val_acc: 0.9000\n",
            "Epoch 699/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1082 - acc: 0.8889 - val_loss: 0.0845 - val_acc: 0.9000\n",
            "Epoch 700/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1083 - acc: 0.8944 - val_loss: 0.0834 - val_acc: 0.9000\n",
            "Epoch 701/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1083 - acc: 0.9000 - val_loss: 0.0845 - val_acc: 0.8500\n",
            "Epoch 702/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1085 - acc: 0.8944 - val_loss: 0.0837 - val_acc: 0.9000\n",
            "Epoch 703/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1085 - acc: 0.8722 - val_loss: 0.0852 - val_acc: 0.9000\n",
            "Epoch 704/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1084 - acc: 0.8778 - val_loss: 0.0846 - val_acc: 0.9000\n",
            "Epoch 705/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1081 - acc: 0.9056 - val_loss: 0.0846 - val_acc: 0.9000\n",
            "Epoch 706/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1082 - acc: 0.9111 - val_loss: 0.0834 - val_acc: 0.8500\n",
            "Epoch 707/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1084 - acc: 0.8833 - val_loss: 0.0839 - val_acc: 0.9000\n",
            "Epoch 708/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1086 - acc: 0.9056 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 709/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1083 - acc: 0.8889 - val_loss: 0.0868 - val_acc: 0.8500\n",
            "Epoch 710/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.1093 - acc: 0.8722 - val_loss: 0.0838 - val_acc: 0.9000\n",
            "Epoch 711/800\n",
            "180/180 [==============================] - 0s 458us/step - loss: 0.1082 - acc: 0.8944 - val_loss: 0.0828 - val_acc: 0.9000\n",
            "Epoch 712/800\n",
            "180/180 [==============================] - 0s 333us/step - loss: 0.1082 - acc: 0.8944 - val_loss: 0.0839 - val_acc: 0.8500\n",
            "Epoch 713/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.0853 - val_acc: 0.9000\n",
            "Epoch 714/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1083 - acc: 0.8833 - val_loss: 0.0847 - val_acc: 0.9000\n",
            "Epoch 715/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.1082 - acc: 0.9056 - val_loss: 0.0842 - val_acc: 0.9000\n",
            "Epoch 716/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1083 - acc: 0.9056 - val_loss: 0.0835 - val_acc: 0.9000\n",
            "Epoch 717/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1082 - acc: 0.8944 - val_loss: 0.0836 - val_acc: 0.9000\n",
            "Epoch 718/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1086 - acc: 0.8778 - val_loss: 0.0869 - val_acc: 0.9000\n",
            "Epoch 719/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1087 - acc: 0.8778 - val_loss: 0.0844 - val_acc: 0.9000\n",
            "Epoch 720/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1084 - acc: 0.8944 - val_loss: 0.0844 - val_acc: 0.9000\n",
            "Epoch 721/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1087 - acc: 0.8889 - val_loss: 0.0834 - val_acc: 0.9500\n",
            "Epoch 722/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1083 - acc: 0.8833 - val_loss: 0.0848 - val_acc: 0.9000\n",
            "Epoch 723/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1083 - acc: 0.8833 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 724/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1081 - acc: 0.8778 - val_loss: 0.0839 - val_acc: 0.8500\n",
            "Epoch 725/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.0863 - val_acc: 0.9500\n",
            "Epoch 726/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1090 - acc: 0.9056 - val_loss: 0.0836 - val_acc: 0.9000\n",
            "Epoch 727/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1082 - acc: 0.8889 - val_loss: 0.0834 - val_acc: 0.9000\n",
            "Epoch 728/800\n",
            "180/180 [==============================] - 0s 488us/step - loss: 0.1080 - acc: 0.9000 - val_loss: 0.0841 - val_acc: 0.8500\n",
            "Epoch 729/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1083 - acc: 0.8778 - val_loss: 0.0844 - val_acc: 0.9000\n",
            "Epoch 730/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1081 - acc: 0.8833 - val_loss: 0.0836 - val_acc: 0.9000\n",
            "Epoch 731/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1081 - acc: 0.8889 - val_loss: 0.0855 - val_acc: 0.9000\n",
            "Epoch 732/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1081 - acc: 0.8889 - val_loss: 0.0834 - val_acc: 0.9000\n",
            "Epoch 733/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1081 - acc: 0.8889 - val_loss: 0.0847 - val_acc: 0.8500\n",
            "Epoch 734/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1086 - acc: 0.8722 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 735/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1079 - acc: 0.8944 - val_loss: 0.0839 - val_acc: 0.9000\n",
            "Epoch 736/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1078 - acc: 0.8889 - val_loss: 0.0830 - val_acc: 0.9000\n",
            "Epoch 737/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1084 - acc: 0.8889 - val_loss: 0.0842 - val_acc: 0.9000\n",
            "Epoch 738/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1086 - acc: 0.8833 - val_loss: 0.0829 - val_acc: 0.8500\n",
            "Epoch 739/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.1080 - acc: 0.8944 - val_loss: 0.0852 - val_acc: 0.8500\n",
            "Epoch 740/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1084 - acc: 0.8833 - val_loss: 0.0826 - val_acc: 0.9000\n",
            "Epoch 741/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.1081 - acc: 0.8778 - val_loss: 0.0826 - val_acc: 0.9000\n",
            "Epoch 742/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1084 - acc: 0.8944 - val_loss: 0.0832 - val_acc: 0.8500\n",
            "Epoch 743/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1080 - acc: 0.8944 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 744/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1079 - acc: 0.9056 - val_loss: 0.0834 - val_acc: 0.9000\n",
            "Epoch 745/800\n",
            "180/180 [==============================] - 0s 389us/step - loss: 0.1076 - acc: 0.9000 - val_loss: 0.0851 - val_acc: 0.8500\n",
            "Epoch 746/800\n",
            "180/180 [==============================] - 0s 393us/step - loss: 0.1080 - acc: 0.8889 - val_loss: 0.0831 - val_acc: 0.9000\n",
            "Epoch 747/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1079 - acc: 0.9000 - val_loss: 0.0832 - val_acc: 0.8500\n",
            "Epoch 748/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1080 - acc: 0.8889 - val_loss: 0.0839 - val_acc: 0.9000\n",
            "Epoch 749/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1087 - acc: 0.8833 - val_loss: 0.0843 - val_acc: 0.8500\n",
            "Epoch 750/800\n",
            "180/180 [==============================] - 0s 395us/step - loss: 0.1082 - acc: 0.8889 - val_loss: 0.0838 - val_acc: 0.9000\n",
            "Epoch 751/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1078 - acc: 0.8833 - val_loss: 0.0838 - val_acc: 0.9000\n",
            "Epoch 752/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1084 - acc: 0.8778 - val_loss: 0.0839 - val_acc: 0.9000\n",
            "Epoch 753/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1079 - acc: 0.8722 - val_loss: 0.0861 - val_acc: 0.8500\n",
            "Epoch 754/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.1086 - acc: 0.8889 - val_loss: 0.0839 - val_acc: 0.8500\n",
            "Epoch 755/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1079 - acc: 0.8889 - val_loss: 0.0838 - val_acc: 0.9000\n",
            "Epoch 756/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1082 - acc: 0.9111 - val_loss: 0.0856 - val_acc: 0.9000\n",
            "Epoch 757/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.1079 - acc: 0.8833 - val_loss: 0.0833 - val_acc: 0.9000\n",
            "Epoch 758/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1081 - acc: 0.9000 - val_loss: 0.0827 - val_acc: 0.9000\n",
            "Epoch 759/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1080 - acc: 0.8944 - val_loss: 0.0838 - val_acc: 0.9500\n",
            "Epoch 760/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.1080 - acc: 0.8944 - val_loss: 0.0855 - val_acc: 0.9000\n",
            "Epoch 761/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1085 - acc: 0.8722 - val_loss: 0.0834 - val_acc: 0.9000\n",
            "Epoch 762/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1079 - acc: 0.9000 - val_loss: 0.0830 - val_acc: 0.9000\n",
            "Epoch 763/800\n",
            "180/180 [==============================] - 0s 504us/step - loss: 0.1079 - acc: 0.8944 - val_loss: 0.0853 - val_acc: 0.9000\n",
            "Epoch 764/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1081 - acc: 0.8833 - val_loss: 0.0840 - val_acc: 0.9000\n",
            "Epoch 765/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1077 - acc: 0.8944 - val_loss: 0.0847 - val_acc: 0.8500\n",
            "Epoch 766/800\n",
            "180/180 [==============================] - 0s 392us/step - loss: 0.1084 - acc: 0.8944 - val_loss: 0.0835 - val_acc: 0.9000\n",
            "Epoch 767/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.1076 - acc: 0.8944 - val_loss: 0.0863 - val_acc: 0.9000\n",
            "Epoch 768/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1077 - acc: 0.9000 - val_loss: 0.0847 - val_acc: 0.9000\n",
            "Epoch 769/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.1079 - acc: 0.9000 - val_loss: 0.0835 - val_acc: 0.9000\n",
            "Epoch 770/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1087 - acc: 0.8944 - val_loss: 0.0837 - val_acc: 0.9000\n",
            "Epoch 771/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1076 - acc: 0.8778 - val_loss: 0.0868 - val_acc: 0.9000\n",
            "Epoch 772/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1086 - acc: 0.8778 - val_loss: 0.0842 - val_acc: 0.9000\n",
            "Epoch 773/800\n",
            "180/180 [==============================] - 0s 338us/step - loss: 0.1077 - acc: 0.8722 - val_loss: 0.0835 - val_acc: 0.9000\n",
            "Epoch 774/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1080 - acc: 0.8944 - val_loss: 0.0845 - val_acc: 0.9000\n",
            "Epoch 775/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1077 - acc: 0.8833 - val_loss: 0.0845 - val_acc: 0.9000\n",
            "Epoch 776/800\n",
            "180/180 [==============================] - 0s 338us/step - loss: 0.1074 - acc: 0.8944 - val_loss: 0.0833 - val_acc: 0.8500\n",
            "Epoch 777/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1076 - acc: 0.8944 - val_loss: 0.0823 - val_acc: 0.8500\n",
            "Epoch 778/800\n",
            "180/180 [==============================] - 0s 389us/step - loss: 0.1075 - acc: 0.8889 - val_loss: 0.0851 - val_acc: 0.9000\n",
            "Epoch 779/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.1077 - acc: 0.9056 - val_loss: 0.0839 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00779: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 780/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1074 - acc: 0.8889 - val_loss: 0.0823 - val_acc: 0.8500\n",
            "Epoch 781/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1069 - acc: 0.8944 - val_loss: 0.0826 - val_acc: 0.9000\n",
            "Epoch 782/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1070 - acc: 0.8889 - val_loss: 0.0827 - val_acc: 0.9000\n",
            "Epoch 783/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1070 - acc: 0.8889 - val_loss: 0.0827 - val_acc: 0.9000\n",
            "Epoch 784/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1070 - acc: 0.8889 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 785/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1069 - acc: 0.8944 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 786/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1069 - acc: 0.8889 - val_loss: 0.0826 - val_acc: 0.9000\n",
            "Epoch 787/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1070 - acc: 0.8944 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 788/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1070 - acc: 0.9000 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 789/800\n",
            "180/180 [==============================] - 0s 464us/step - loss: 0.1069 - acc: 0.8889 - val_loss: 0.0824 - val_acc: 0.9000\n",
            "Epoch 790/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1070 - acc: 0.8944 - val_loss: 0.0825 - val_acc: 0.8500\n",
            "Epoch 791/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1070 - acc: 0.8944 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 792/800\n",
            "180/180 [==============================] - 0s 338us/step - loss: 0.1069 - acc: 0.9000 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 793/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1069 - acc: 0.9000 - val_loss: 0.0824 - val_acc: 0.9000\n",
            "Epoch 794/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1070 - acc: 0.8944 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 795/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1070 - acc: 0.8889 - val_loss: 0.0824 - val_acc: 0.9000\n",
            "Epoch 796/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1070 - acc: 0.9000 - val_loss: 0.0824 - val_acc: 0.9000\n",
            "Epoch 797/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1069 - acc: 0.8944 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 798/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1070 - acc: 0.8944 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 799/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1070 - acc: 0.8889 - val_loss: 0.0824 - val_acc: 0.9000\n",
            "Epoch 800/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1069 - acc: 0.9000 - val_loss: 0.0824 - val_acc: 0.9000\n",
            "210/210 [==============================] - 0s 130us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[5.602794224875314, 0.276190476332392]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "f-RQZlxV2GaH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}