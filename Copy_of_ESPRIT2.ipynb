{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ESPRIT2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/opooladz/ESPRIT-Autoencoder-Anomaly-Detection/blob/master/Copy_of_ESPRIT2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ctjGCWel6JV5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install nvidia-cuda-toolkit\n",
        "!pip3 install numba\n",
        "\n",
        "import os\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/lib/nvidia-cuda-toolkit/libdevice\"\n",
        "os.environ['NUMBAPRO_NVVM'] = \"/usr/lib/x86_64-linux-gnu/libnvvm.so\"\n",
        "\n",
        "from numba import cuda\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "@cuda.jit\n",
        "def hello(data):\n",
        "    data[cuda.blockIdx.x, cuda.threadIdx.x] = cuda.blockIdx.x\n",
        "\n",
        "numBlocks = 5\n",
        "threadsPerBlock = 10\n",
        "\n",
        "data = np.ones((numBlocks, threadsPerBlock), dtype=np.uint8)\n",
        "\n",
        "hello[numBlocks, threadsPerBlock](data)\n",
        "\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ls_UG_Iv50o5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "6b1d0bb1-fb1b-4c54-b587-57bde9266cc1"
      },
      "cell_type": "code",
      "source": [
        "!pip install numba"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numba\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/89/6f1755892d60ddd528090dc313349e7cc491170d6737f6b3a7a5b317ef81/numba-0.39.0-cp36-cp36m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.9MB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from numba) (1.14.5)\n",
            "Collecting llvmlite>=0.24.0dev0 (from numba)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/05/c1b933d6b3dd6a234b681605e4154c44d21ee22cbef315c4eb9d64e6ab6a/llvmlite-0.24.0-cp36-cp36m-manylinux1_x86_64.whl (15.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 15.9MB 2.5MB/s \n",
            "\u001b[?25hInstalling collected packages: llvmlite, numba\n",
            "Successfully installed llvmlite-0.24.0 numba-0.39.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "32BPXqrHfNrs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5d2af99-b50d-430c-cb90-63b0d579678e"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import toeplitz\n",
        "from numpy import linalg as lg\n",
        "from time import time\n",
        "from typing import Tuple\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import regularizers\n",
        "from numba import jit\n",
        "\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "\n",
        "@jit\n",
        "def compute_autocovariance(x: np.ndarray, M: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    This function compute the auto-covariance matrix of a numpy signal.\n",
        "    The auto-covariance is computed as follows\n",
        "    .. math:: \\textbf{R}=\\frac{1}{N}\\sum_{M-1}^{N-1}\\textbf{x}_{m}\\textbf{x}_{m}^{H}\n",
        "    where :math:`\\textbf{x}_{m}^{T}=[x[m],x[m-1],x[m-M+1]]`.\n",
        "    :param x: 1-D vector of size N\n",
        "    :param M:  int, optional. Size of signal block.\n",
        "    :returns: NxN ndarray\n",
        "    \"\"\"\n",
        "\n",
        "    # Create covariance matrix for psd estimation\n",
        "    # length of the vector x\n",
        "    x = np.asarray(x).squeeze()\n",
        "    assert x.ndim == 1, '1-D only'\n",
        "    N = x.size\n",
        "\n",
        "    # Create column vector (Nx1) from row array\n",
        "    x_vect = x[None, :].T\n",
        "\n",
        "    # init covariance matrix\n",
        "    yn = x_vect[M-1::-1]  # reverse order from M-1 to 0\n",
        "\n",
        "    R = yn @ yn.conj().T  # zeroth lag\n",
        "    # about 5-8% of computation time\n",
        "    for i in range(1, N-M):  # no zero because we just computed it\n",
        "        # extract the column vector\n",
        "        yn = x_vect[M-1+i:i-1:-1]\n",
        "\n",
        "        R = R + yn @ yn.conj().T\n",
        "\n",
        "    return R / N\n",
        "@jit\n",
        "def wrapper(x):\n",
        "  return np.convolve(x,xc,mode=\"valid\")\n",
        "\n",
        "@jit\n",
        "def esprit1(x: np.ndarray, L: int, M: int=None, fs: int=1,\n",
        "           verbose: bool=False) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    This function estimate the frequency components based on the ESPRIT algorithm [ROY89]_\n",
        "    The frequencies are related to the roots as :math:`z=e^{-2j\\pi f/Fe}`.\n",
        "    See [STO97]_ section 4.7 for more information about the implementation.\n",
        "    :param x: ndarray, Nsamples\n",
        "    :param L: int. Number of components to be extracted.\n",
        "    :param M:  int, optional. Size of signal block.\n",
        "    :param Fs: float. Sampling Frequency.\n",
        "    :returns: ndarray ndarray containing the L frequencies\n",
        "    >>> import numpy as np\n",
        "    >>> import spectral_analysis.spectral_analysis as sa\n",
        "    >>> Fe=500\n",
        "    >>> t=1.*np.arange(100)/Fe\n",
        "    >>> x=np.exp(2j*np.pi*55.2*t)\n",
        "    >>> f=sa.Esprit(x,1,None,Fe)\n",
        "    >>> print(f)\n",
        "    \"\"\"\n",
        "\n",
        "    x = np.asarray(x).squeeze()\n",
        "    assert x.ndim in (1, 2)\n",
        "    # length of the vector x\n",
        "    if x.ndim == 1:\n",
        "        N = x.size\n",
        "    else:\n",
        "        N = x.shape[1]\n",
        "\n",
        "    if M is None:\n",
        "        M = N // 2\n",
        "# %% extract signal subspace  99.9 % of computation time\n",
        "    tic = time()\n",
        "    if x.ndim == 1 and isinstance(M, int):\n",
        "        R = compute_autocovariance(x, M)  # 75% of computation time        \n",
        "    else:\n",
        "        # the random phase of transmit/receive/target actually helps--need at least 5-6 observations to make useful\n",
        "        R = np.cov(x, rowvar=False)\n",
        "    if verbose:\n",
        "        print('autocov sec.', time()-tic)\n",
        "    # R = subspace.corrmtx(x.astype(complex128),M).astype(float) #f2py fortran\n",
        "\n",
        "    tic = time()\n",
        "    #U, S, V = lg.svd(R)  # 25% of computation time\n",
        "    w, v = lg.eig(R)    \n",
        "    idx = w.argsort()[::-1]   \n",
        "    w = w[idx]\n",
        "    v = v[:,idx]    \n",
        "    if verbose:\n",
        "        print('svd sec.', time()-tic)\n",
        "# %% take eigenvalues and determine sinusoid frequencies\n",
        "    # Remove last row\n",
        "    S1 = v[:-1, :L]\n",
        "    # Remove first row\n",
        "    S2 = v[1:, :L]\n",
        "\n",
        "    # Compute matrix Phi (Stoica 4.7.12)  <0.1 % of computation time\n",
        "    Phi = lg.inv(S1.conj().T @ S1) @ S1.conj().T @ S2\n",
        "\n",
        "    # Perform eigenvalue decomposition <0.1 % of computation time\n",
        "    V, U = lg.eig(Phi)\n",
        "\n",
        "    # extract frequencies ((note that there a minus sign since Yn are defined as [y(n), y(n-1),y(n-2),..].T))\n",
        "    ang = -np.angle(V)\n",
        "\n",
        "    # frequency normalisation\n",
        "    f = fs*ang / (2.*np.pi)\n",
        "    t = np.arange(0, 0.01, 1/fs)\n",
        "    \n",
        "    x2 = np.exp(-1j*2*np.pi*t[::-1])[:,np.newaxis]**f\n",
        "    #display(xc.shape)\n",
        "    #ampCisoid = np.apply_along_axis(lambda q: np.convolve(q,xc,mode=\"valid\"),axis = 0,arr=x2)\n",
        "    ampCisoid = np.apply_along_axis(wrapper,axis = 0,arr=x2)\n",
        "    return f, np.abs(w[:L]), np.abs(ampCisoid)*1./480., np.angle(ampCisoid)\n",
        "  \n",
        "\n",
        "def esprit2(x: np.ndarray, L: int, M: int=None, fs: int=1,\n",
        "           verbose: bool=False) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    This function estimate the frequency components based on the ESPRIT algorithm [ROY89]_\n",
        "    The frequencies are related to the roots as :math:`z=e^{-2j\\pi f/Fe}`.\n",
        "    See [STO97]_ section 4.7 for more information about the implementation.\n",
        "    :param x: ndarray, Nsamples\n",
        "    :param L: int. Number of components to be extracted.\n",
        "    :param M:  int, optional. Size of signal block.\n",
        "    :param Fs: float. Sampling Frequency.\n",
        "    :returns: ndarray ndarray containing the L frequencies\n",
        "    >>> import numpy as np\n",
        "    >>> import spectral_analysis.spectral_analysis as sa\n",
        "    >>> Fe=500\n",
        "    >>> t=1.*np.arange(100)/Fe\n",
        "    >>> x=np.exp(2j*np.pi*55.2*t)\n",
        "    >>> f=sa.Esprit(x,1,None,Fe)\n",
        "    >>> print(f)\n",
        "    \"\"\"\n",
        "\n",
        "    x = np.asarray(x).squeeze()\n",
        "    assert x.ndim in (1, 2)\n",
        "    # length of the vector x\n",
        "    if x.ndim == 1:\n",
        "        N = x.size\n",
        "    else:\n",
        "        N = x.shape[1]\n",
        "\n",
        "    if M is None:\n",
        "        M = N // 2\n",
        "# %% extract signal subspace  99.9 % of computation time\n",
        "    tic = time()\n",
        "    if x.ndim == 1 and isinstance(M, int):\n",
        "        R = compute_autocovariance(x, M)  # 75% of computation time\n",
        "    else:\n",
        "        # the random phase of transmit/receive/target actually helps--need at least 5-6 observations to make useful\n",
        "        R = np.cov(x, rowvar=False)\n",
        "    if verbose:\n",
        "        print('autocov sec.', time()-tic)\n",
        "    # R = subspace.corrmtx(x.astype(complex128),M).astype(float) #f2py fortran\n",
        "\n",
        "    tic = time()\n",
        "    U, S, V = lg.svd(R)  # 25% of computation time\n",
        "    #w, v = lg.eig(R)    \n",
        "    #idx = w.argsort()[::-1]   \n",
        "    #w = w[idx]\n",
        "    #v = v[:,idx]    \n",
        "    if verbose:\n",
        "        print('svd sec.', time()-tic)\n",
        "# %% take eigenvalues and determine sinusoid frequencies\n",
        "    # Remove last row\n",
        "    S1 = U[:-1, :L]\n",
        "    # Remove first row\n",
        "    S2 = U[1:, :L]\n",
        "\n",
        "    # Compute matrix Phi (Stoica 4.7.12)  <0.1 % of computation time\n",
        "    Phi = lg.inv(S1.conj().T @ S1) @ S1.conj().T @ S2\n",
        "\n",
        "    # Perform eigenvalue decomposition <0.1 % of computation time\n",
        "    V, U = lg.eig(Phi)\n",
        "\n",
        "    # extract frequencies ((note that there a minus sign since Yn are defined as [y(n), y(n-1),y(n-2),..].T))\n",
        "    ang = -np.angle(V)\n",
        "\n",
        "    # frequency normalisation\n",
        "    f = fs*ang / (2.*np.pi)\n",
        "\n",
        "    return f, S[:L]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "vpUQO1epmo5v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "31085f14-f489-438e-ae0f-20cb09b3259a"
      },
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "\n",
        "# Bool: Needs to be set by user \n",
        "full_anom = 0\n",
        "anom_samples = 1\n",
        "\n",
        "x = np.random.randn(4096).astype(np.complex128)\n",
        "F = 12345.6\n",
        "\n",
        "f0 = 12345.6\n",
        "f1 = 1000.6\n",
        "f2 = 726.6\n",
        "f3 = 57.3\n",
        "\n",
        "f0=np.random.uniform(low=0.,high = 10000.)\n",
        "f1=np.random.uniform(low=0.,high = 10000.)\n",
        "f2=np.random.uniform(low=0.,high = 10000.)\n",
        "f3 = np.random.uniform(low=0.,high = 10000.)\n",
        "\n",
        "\n",
        "c0 = 15.\n",
        "c1 = 7.\n",
        "c2 = 10.\n",
        "c0= np.random.uniform(low=3.,high = 100.)\n",
        "c1= np.random.uniform(low=3.,high = 100.)\n",
        "c2= np.random.uniform(low=3.,high = 100.)\n",
        "c3 = np.random.uniform(low=3.,high = 100.)\n",
        "\n",
        "fs = 48e3\n",
        "snr = 20.  # dB\n",
        "Ntone = 6\n",
        "\n",
        "t = np.arange(0, 0.01, 1/fs)\n",
        "\n",
        "nvar = 10**(-snr/10.)\n",
        "\n",
        "\n",
        "\n",
        "M = [100] * 300  # iterating over block length\n",
        "\n",
        "py = DataFrame(index=M, columns=['err', 'sigma','cisoidAmp','cisoidAngle'])\n",
        "fortreal = DataFrame(index=M, columns=['err', 'sigma','cisoidAmp','cisoidAngle'])\n",
        "fortcmpl = DataFrame(index=M, columns=['err', 'sigma','cisoidAmp','cisoidAngle'])\n",
        "fest = []\n",
        "fest2 = []\n",
        "cisoidAmp = []\n",
        "cisoidAmp2 = []\n",
        "i = 0\n",
        "for m in M:\n",
        "    i = i + 1\n",
        "    # Generate fist tripplet of cisoid  \n",
        "    # Train data start\n",
        "    xc = c0*np.exp(1j*2*np.pi*f0*t)+c1*np.exp(1j*2*np.pi*f1*t) +c2*np.exp(1j*2*np.pi*f2*t)\n",
        "    xc1 = xc + np.sqrt(nvar)*(np.random.randn(t.size) + 1j*np.random.randn(t.size))\n",
        "  \n",
        "    tmpFest, sigma,tmpAmp,cisoidAngle = esprit1(xc1, Ntone//2, M=m, fs=fs, verbose=False)\n",
        "    fest.append(tmpFest)\n",
        "    tmpAmp = tmpAmp[0]\n",
        "    cisoidAmp.append(tmpAmp)\n",
        "    # Train data end \n",
        "    \n",
        "    # Test section start\n",
        "    \n",
        "    # Inject Anomaly\n",
        "    if not(full_anom or i%40):\n",
        "      display(i)\n",
        "      for j in np.arange(anom_samples):\n",
        "        display(i)\n",
        "        xc2 = c0*np.exp(1j*2*np.pi*f0*t)+c1*np.exp(1j*2*np.pi*f1*t) +c3*np.exp(1j*2*np.pi*f3*t)+ np.sqrt(nvar)*(np.random.randn(t.size) + 1j*np.random.randn(t.size))\n",
        "        tmpFest, sigma,tmpAmp,cisoidAngle = esprit1(xc2, Ntone//2, M=m, fs=fs, verbose=False)\n",
        "        fest2.append(tmpFest)\n",
        "        tmpAmp = tmpAmp[0]\n",
        "        cisoidAmp2.append(tmpAmp) \n",
        "    # When not Anomaly use xc as baseline signal and add AWGN - Run through esprit\n",
        "    xc2 = xc +  np.sqrt(nvar)*(np.random.randn(t.size) + 1j*np.random.randn(t.size))\n",
        "    if full_anom:\n",
        "      xc2 = c0*np.exp(1j*2*np.pi*f0*t)+c1*np.exp(1j*2*np.pi*f1*t) +c3*np.exp(1j*2*np.pi*f3*t)+ np.sqrt(nvar)*(np.random.randn(t.size) + 1j*np.random.randn(t.size))\n",
        "    tmpFest, sigma,tmpAmp,cisoidAngle = esprit1(xc2, Ntone//2, M=m, fs=fs, verbose=False)\n",
        "    fest2.append(tmpFest)\n",
        "    tmpAmp = tmpAmp[0]\n",
        "    cisoidAmp2.append(tmpAmp)  \n",
        "    # Test section end \n",
        "\n",
        "# Create train and test set     \n",
        "x_train = np.hstack((cisoidAmp,fest))    \n",
        "x_test = np.hstack((cisoidAmp2,fest2))\n",
        "    "
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "240"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "240"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "280"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "280"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "u0i86OadtTfo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "481fe2be-dfda-4dc0-db27-6d0856cad56d"
      },
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "metadata": {
        "id": "FKHmRNFTldag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "f76f5e3b-d385-4fd3-8d62-c3acf382fd0d"
      },
      "cell_type": "code",
      "source": [
        "full_anom = 0\n",
        "anom_samples = 1\n",
        "fest2 = []\n",
        "cisoidAmp2 = []\n",
        "i = 0\n",
        "for m in M:\n",
        "    i = i + 1\n",
        "    \n",
        "    # Test section start\n",
        "    \n",
        "    # Inject Anomaly\n",
        "    if not(full_anom or i%20):\n",
        "      display(i)\n",
        "      for j in np.arange(anom_samples):\n",
        "        display(i)\n",
        "        xc2 = c0*np.exp(1j*2*np.pi*f0*t)+c1*np.exp(1j*2*np.pi*f1*t) +c2*np.exp(1j*2*np.pi*f3*t)+ np.sqrt(nvar)*(np.random.randn(t.size) + 1j*np.random.randn(t.size))\n",
        "        tmpFest, sigma,tmpAmp,cisoidAngle = esprit1(xc2, Ntone//2, M=m, fs=fs, verbose=False)\n",
        "        fest2.append(tmpFest)\n",
        "        tmpAmp = tmpAmp[0]\n",
        "        cisoidAmp2.append(tmpAmp) \n",
        "    # When not Anomaly use xc as baseline signal and add AWGN - Run through esprit\n",
        "    xc2 = xc +  np.sqrt(nvar)*(np.random.randn(t.size) + 1j*np.random.randn(t.size))\n",
        "    if full_anom:\n",
        "      xc2 = c0*np.exp(1j*2*np.pi*f0*t)+c1*np.exp(1j*2*np.pi*f1*t) +c2*np.exp(1j*2*np.pi*f3*t)+ np.sqrt(nvar)*(np.random.randn(t.size) + 1j*np.random.randn(t.size))\n",
        "    tmpFest, sigma,tmpAmp,cisoidAngle = esprit1(xc2, Ntone//2, M=m, fs=fs, verbose=False)\n",
        "    fest2.append(tmpFest)\n",
        "    tmpAmp = tmpAmp[0]\n",
        "    cisoidAmp2.append(tmpAmp)  \n",
        "    # Test section end \n",
        "\n",
        "# Create train and test set     \n",
        "x_test = np.hstack((cisoidAmp2,fest2))"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ri27AZRJdco4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7137
        },
        "outputId": "157ea5e9-0ef4-4be9-8e5b-9713e5b25d94"
      },
      "cell_type": "code",
      "source": [
        "display(cisoidAmp2)\n",
        "display(cisoidAmp)\n",
        "\n"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[array([93.00542398, 68.47235078,  9.18655282]),\n",
              " array([93.00543023, 68.47235094,  9.18527796]),\n",
              " array([93.00545337, 68.47235109,  9.18466791]),\n",
              " array([93.00544724, 68.47235073,  9.18694677]),\n",
              " array([93.00544428, 68.47235109,  9.18504655]),\n",
              " array([93.00542367, 68.47235106,  9.18476745]),\n",
              " array([93.00544329, 68.47235048,  9.18740015]),\n",
              " array([93.00545165, 68.47235099,  9.18517441]),\n",
              " array([93.00542956, 68.47235104,  9.1876641 ]),\n",
              " array([93.00545083, 68.47235108,  9.18556481]),\n",
              " array([93.00543306, 68.47235103,  9.18655683]),\n",
              " array([93.0054376 , 68.47235109,  9.18438757]),\n",
              " array([93.00543856, 68.47235107,  9.18627001]),\n",
              " array([93.00543117, 68.47235094,  9.18627307]),\n",
              " array([93.00542879, 68.47235068,  9.18682128]),\n",
              " array([93.00544571, 68.47235108,  9.1871391 ]),\n",
              " array([93.00542213, 68.47235097,  9.18695734]),\n",
              " array([93.0054344 , 68.47235083,  9.18656433]),\n",
              " array([93.00542734, 68.47235097,  9.18853224]),\n",
              " array([93.00543287,  0.71454789,  9.18535378]),\n",
              " array([93.00542979, 68.47235088,  9.18449268]),\n",
              " array([93.0054581 , 68.47235102,  9.18656461]),\n",
              " array([93.00542105, 68.47235095,  9.18714196]),\n",
              " array([93.00544155, 68.47235086,  9.18351568]),\n",
              " array([93.00544167, 68.47235094,  9.18548603]),\n",
              " array([93.00542886, 68.47235102,  9.18537936]),\n",
              " array([93.00544362, 68.47235109,  9.18615436]),\n",
              " array([93.00543928, 68.47235109,  9.18740181]),\n",
              " array([93.00543353, 68.47235102,  9.18537053]),\n",
              " array([93.00542792, 68.47235099,  9.18469119]),\n",
              " array([93.00542026, 68.47235067,  9.18537264]),\n",
              " array([93.00543503, 68.47235001,  9.18781632]),\n",
              " array([93.00542746, 68.47234963,  9.18835716]),\n",
              " array([93.00543543, 68.47235101,  9.18570324]),\n",
              " array([93.00544356, 68.47235109,  9.18543818]),\n",
              " array([93.00542027, 68.47235071,  9.1856682 ]),\n",
              " array([93.00542843, 68.47235106,  9.1878912 ]),\n",
              " array([93.00543064, 68.47235108,  9.18585415]),\n",
              " array([93.00542633, 68.47235108,  9.18893926]),\n",
              " array([93.00542828, 68.47235078,  9.18417431]),\n",
              " array([93.00543984,  0.71880723,  9.18568723]),\n",
              " array([93.00543714, 68.47235108,  9.18620624]),\n",
              " array([93.00543622, 68.47235101,  9.18793571]),\n",
              " array([93.00544642, 68.47235109,  9.1876558 ]),\n",
              " array([93.00542823, 68.47235073,  9.18671946]),\n",
              " array([93.00542812, 68.47235069,  9.1866206 ]),\n",
              " array([93.00542865, 68.47235109,  9.18901176]),\n",
              " array([93.00543229, 68.47235106,  9.1870357 ]),\n",
              " array([93.00542341, 68.47235093,  9.18710381]),\n",
              " array([93.00543599, 68.47235109,  9.18641403]),\n",
              " array([93.00544328, 68.47235108,  9.18811239]),\n",
              " array([93.00543239, 68.47235099,  9.1844147 ]),\n",
              " array([93.00543265, 68.47235082,  9.18730261]),\n",
              " array([93.0054382 , 68.47235062,  9.1857963 ]),\n",
              " array([93.00544467, 68.47235105,  9.18592681]),\n",
              " array([93.0054224 , 68.47235073,  9.18500359]),\n",
              " array([93.00543344, 68.47235109,  9.18614994]),\n",
              " array([93.00544968, 68.47235107,  9.18803594]),\n",
              " array([93.00543135, 68.472351  ,  9.1852103 ]),\n",
              " array([93.00542748, 68.472351  ,  9.18581941]),\n",
              " array([93.00543404, 68.47235077,  9.18506331]),\n",
              " array([93.00544977,  0.7153496 ,  9.18650674]),\n",
              " array([93.00544007, 68.47235072,  9.18709405]),\n",
              " array([93.00543082, 68.47235095,  9.18700866]),\n",
              " array([93.00545117, 68.47235086,  9.18658722]),\n",
              " array([93.00543898, 68.47235109,  9.1866329 ]),\n",
              " array([93.00544244, 68.47235097,  9.18403234]),\n",
              " array([93.00544062, 68.47235077,  9.18669257]),\n",
              " array([93.00543525, 68.4723504 ,  9.18683267]),\n",
              " array([93.00542479, 68.47235069,  9.18742383]),\n",
              " array([93.00544405, 68.47235001,  9.18432687]),\n",
              " array([93.0054465 , 68.4723504 ,  9.18503814]),\n",
              " array([93.00544317, 68.47235101,  9.184663  ]),\n",
              " array([93.00543151, 68.47235104,  9.18495202]),\n",
              " array([93.00543858, 68.47235108,  9.18630606]),\n",
              " array([93.00542163, 68.472351  ,  9.18701283]),\n",
              " array([93.00543204, 68.47235092,  9.18508795]),\n",
              " array([93.005439  , 68.47235015,  9.18470163]),\n",
              " array([93.00544081, 68.47235096,  9.18548289]),\n",
              " array([93.00543914, 68.47235001,  9.18458624]),\n",
              " array([93.0054288 , 68.47235094,  9.18824954]),\n",
              " array([93.00542546, 68.4723508 ,  9.18794499]),\n",
              " array([93.0054339 ,  0.72039679,  9.18646705]),\n",
              " array([93.00543778, 68.47235104,  9.18205522]),\n",
              " array([93.00543137, 68.47235054,  9.18893545]),\n",
              " array([93.00544323, 68.4723509 ,  9.18890536]),\n",
              " array([93.00543428, 68.47235096,  9.18679449]),\n",
              " array([93.0054445 , 68.47235098,  9.18660656]),\n",
              " array([93.00545654, 68.47235097,  9.18866265]),\n",
              " array([93.00542123, 68.4723507 ,  9.18677762]),\n",
              " array([93.00544079, 68.47235109,  9.18700167]),\n",
              " array([93.00542606, 68.4723509 ,  9.18831792]),\n",
              " array([93.0054455 , 68.47235104,  9.1863046 ]),\n",
              " array([93.00544066, 68.47235109,  9.184825  ]),\n",
              " array([93.00543865, 68.47235088,  9.18609108]),\n",
              " array([93.00544856, 68.47235086,  9.18578662]),\n",
              " array([93.0054436 , 68.47235095,  9.18280316]),\n",
              " array([93.00544307, 68.47235082,  9.18615603]),\n",
              " array([93.00544049, 68.47235103,  9.1836865 ]),\n",
              " array([93.00542488, 68.47235109,  9.18420173]),\n",
              " array([93.00544062, 68.47235058,  9.18646526]),\n",
              " array([93.0054304 , 68.47235068,  9.18696204]),\n",
              " array([93.00543528, 68.47235065,  9.1849148 ]),\n",
              " array([93.00543952,  0.72192902,  9.18441845]),\n",
              " array([93.00544531, 68.4723507 ,  9.18936639]),\n",
              " array([93.00543844, 68.47235108,  9.18631562]),\n",
              " array([93.00543296, 68.47235104,  9.18603092]),\n",
              " array([93.00542333, 68.47235082,  9.18636251]),\n",
              " array([93.00542694, 68.47235085,  9.18305383]),\n",
              " array([93.00543931, 68.47235092,  9.18490258]),\n",
              " array([93.00544004, 68.47235096,  9.18536157]),\n",
              " array([93.00544418, 68.47235103,  9.18570884]),\n",
              " array([93.00541961, 68.472351  ,  9.18746603]),\n",
              " array([93.00544169, 68.47235068,  9.18757067]),\n",
              " array([93.00544609, 68.47235079,  9.18480778]),\n",
              " array([93.00543974, 68.47235083,  9.18776791]),\n",
              " array([93.0054424 , 68.47235104,  9.18598992]),\n",
              " array([93.00543619, 68.47235105,  9.18520465]),\n",
              " array([93.00544323, 68.47235091,  9.18615872]),\n",
              " array([93.00542409, 68.47235109,  9.18843972]),\n",
              " array([93.0054404 , 68.47235094,  9.18714463]),\n",
              " array([93.00545481, 68.47235089,  9.18496083]),\n",
              " array([93.00544926, 68.47235108,  9.18513642]),\n",
              " array([93.00543536, 68.47235102,  9.18443466]),\n",
              " array([93.00543707,  0.71722933,  9.18525698]),\n",
              " array([93.00539747, 68.47235106,  9.18964708]),\n",
              " array([93.00543504, 68.47235074,  9.18665206]),\n",
              " array([93.00543777, 68.47235075,  9.18549782]),\n",
              " array([93.00544699, 68.47235105,  9.18872195]),\n",
              " array([93.00543297, 68.47235066,  9.1847207 ]),\n",
              " array([93.00543786, 68.47235093,  9.18672907]),\n",
              " array([93.00544944, 68.47235098,  9.18330429]),\n",
              " array([93.00542769, 68.47235106,  9.18562325]),\n",
              " array([93.00543138, 68.47235106,  9.18629126]),\n",
              " array([93.00542796, 68.47235089,  9.18797052]),\n",
              " array([93.00544178, 68.47235103,  9.1861693 ]),\n",
              " array([93.00544123, 68.47235104,  9.18789274]),\n",
              " array([93.00543378, 68.4723509 ,  9.18776336]),\n",
              " array([93.0054282 , 68.47235108,  9.18636924]),\n",
              " array([93.00544522, 68.47235105,  9.18553115]),\n",
              " array([93.00544742, 68.47235055,  9.18497176]),\n",
              " array([93.00543122, 68.47235104,  9.18522914]),\n",
              " array([93.00543574, 68.47235109,  9.18629674]),\n",
              " array([93.00543001, 68.47235071,  9.18384277]),\n",
              " array([93.00544675, 68.47235107,  9.18565648]),\n",
              " array([93.00544175,  0.7177462 ,  9.18613261]),\n",
              " array([93.00543691, 68.47235109,  9.1857821 ]),\n",
              " array([93.00543344, 68.47235102,  9.18481865]),\n",
              " array([93.0054374 , 68.47235093,  9.18589589]),\n",
              " array([93.00543787, 68.47235024,  9.18378411]),\n",
              " array([93.00544204, 68.47235044,  9.19000192]),\n",
              " array([93.00544393, 68.47235106,  9.18538881]),\n",
              " array([93.00544039, 68.47235109,  9.18760199]),\n",
              " array([93.00546779, 68.47235108,  9.18636402]),\n",
              " array([93.0054332 , 68.47235027,  9.18588664]),\n",
              " array([93.00544259, 68.47235109,  9.1872021 ]),\n",
              " array([93.00544351, 68.47235042,  9.1887179 ]),\n",
              " array([93.00544775, 68.47235106,  9.1845799 ]),\n",
              " array([93.00545578, 68.47235108,  9.18739766]),\n",
              " array([93.00542763, 68.47235025,  9.18793591]),\n",
              " array([93.00542725, 68.47235104,  9.18553822]),\n",
              " array([93.005443  , 68.47235109,  9.18740097]),\n",
              " array([93.00543988, 68.47235085,  9.18295669]),\n",
              " array([93.00543604, 68.4723509 ,  9.18743146]),\n",
              " array([93.00546187, 68.47235041,  9.18480516]),\n",
              " array([93.00543989, 68.47235105,  9.18595362]),\n",
              " array([93.00543609,  0.71578886,  9.18621788]),\n",
              " array([93.00542433, 68.47235098,  9.18654161]),\n",
              " array([93.00544491, 68.47235071,  9.18606551]),\n",
              " array([93.005425  , 68.47235108,  9.1867356 ]),\n",
              " array([93.00541998, 68.47235041,  9.18599452]),\n",
              " array([93.00542801, 68.47235061,  9.1849859 ]),\n",
              " array([93.0054573 , 68.47235098,  9.18549223]),\n",
              " array([93.0054312 , 68.4723504 ,  9.18800073]),\n",
              " array([93.00544611, 68.47235044,  9.18639154]),\n",
              " array([93.00543598, 68.472351  ,  9.18418067]),\n",
              " array([93.00543262, 68.47235076,  9.1828981 ]),\n",
              " array([93.00542745, 68.47235073,  9.18445406]),\n",
              " array([93.00544002, 68.47235101,  9.18814078]),\n",
              " array([93.00544988, 68.47235108,  9.1862424 ]),\n",
              " array([93.00542814, 68.4723508 ,  9.18673294]),\n",
              " array([93.00543607, 68.47235001,  9.18699564]),\n",
              " array([93.00543009, 68.47235106,  9.18587635]),\n",
              " array([93.00545441, 68.47235108,  9.18501656]),\n",
              " array([93.00541695, 68.47235073,  9.18403194]),\n",
              " array([93.00543593, 68.472351  ,  9.18510328]),\n",
              " array([93.00544298, 68.4723508 ,  9.18487128]),\n",
              " array([93.0054503 ,  0.71711212,  9.18565323]),\n",
              " array([93.00545228, 68.47235088,  9.18831543]),\n",
              " array([93.00544111, 68.47235109,  9.18392976]),\n",
              " array([93.00543457, 68.47235026,  9.18650589]),\n",
              " array([93.00542695, 68.47234945,  9.18555551]),\n",
              " array([93.00543184, 68.47235109,  9.18658554]),\n",
              " array([93.0054525 , 68.47235108,  9.18679746]),\n",
              " array([93.00542204, 68.47235107,  9.18656483]),\n",
              " array([93.00544581, 68.47235019,  9.18736362]),\n",
              " array([93.00543127, 68.47235109,  9.18535983]),\n",
              " array([93.00542267, 68.47235103,  9.18602994]),\n",
              " array([93.0054114 , 68.47235092,  9.18777211]),\n",
              " array([93.005441  , 68.47235109,  9.1869032 ]),\n",
              " array([93.00544206, 68.47235109,  9.18486128]),\n",
              " array([93.00542865, 68.47235102,  9.18558067]),\n",
              " array([93.00544595, 68.47235073,  9.18444185]),\n",
              " array([93.0054228 , 68.47235097,  9.18628214]),\n",
              " array([93.00542635, 68.47235108,  9.18494788]),\n",
              " array([93.00543554, 68.47235107,  9.18602574]),\n",
              " array([93.00542053, 68.47235068,  9.18669738]),\n",
              " array([93.00540442, 68.47235109,  9.18548544]),\n",
              " array([93.00544798,  0.71332692,  9.18733507]),\n",
              " array([93.00544171, 68.47235109,  9.1859276 ])]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[array([93.00544826, 68.47235071,  9.18382735]),\n",
              " array([93.00544046, 68.47235107,  9.1852524 ]),\n",
              " array([93.00542699, 68.47235071,  9.18516183]),\n",
              " array([93.00543024, 68.47235027,  9.18525339]),\n",
              " array([93.00542015, 68.47235096,  9.18518695]),\n",
              " array([93.00544385, 68.47235108,  9.18429215]),\n",
              " array([93.00544764, 68.4723507 ,  9.18658561]),\n",
              " array([93.00542074, 68.47235077,  9.1885925 ]),\n",
              " array([93.00542092, 68.47235108,  9.18651842]),\n",
              " array([93.00544275, 68.47235083,  9.18374881]),\n",
              " array([93.00543151, 68.47235098,  9.18749926]),\n",
              " array([93.00545047, 68.47235089,  9.18494787]),\n",
              " array([93.00543821, 68.47235087,  9.18587203]),\n",
              " array([93.00544978, 68.47235094,  9.18580337]),\n",
              " array([93.00545341, 68.47235103,  9.1858805 ]),\n",
              " array([93.00544423, 68.47235045,  9.18540527]),\n",
              " array([93.00544968, 68.47235106,  9.18846549]),\n",
              " array([93.0054327 , 68.47235109,  9.18698757]),\n",
              " array([93.0054339 , 68.47235098,  9.18554322]),\n",
              " array([93.00543667, 68.47235106,  9.18846946]),\n",
              " array([93.00543408, 68.47235105,  9.18643519]),\n",
              " array([93.00545154, 68.47235102,  9.18591125]),\n",
              " array([93.0054293 , 68.47235109,  9.18451353]),\n",
              " array([93.00544006, 68.47235053,  9.18713902]),\n",
              " array([93.0054366 , 68.47235108,  9.18830967]),\n",
              " array([93.00544953, 68.47235062,  9.18584275]),\n",
              " array([93.00543081, 68.47235107,  9.18485124]),\n",
              " array([93.00542585, 68.47235106,  9.18739453]),\n",
              " array([93.00542328, 68.47235108,  9.18478588]),\n",
              " array([93.00544011, 68.47235095,  9.18480095]),\n",
              " array([93.00543415, 68.47235101,  9.18963047]),\n",
              " array([93.00545125, 68.47235068,  9.18315723]),\n",
              " array([93.00544791, 68.4723509 ,  9.18366379]),\n",
              " array([93.00543586, 68.47235013,  9.18647663]),\n",
              " array([93.00543468, 68.47235096,  9.18608396]),\n",
              " array([93.00543294, 68.47235062,  9.19066681]),\n",
              " array([93.00545985, 68.47235098,  9.18644256]),\n",
              " array([93.00544159, 68.47234988,  9.18949727]),\n",
              " array([93.0054287 , 68.47235069,  9.18606931]),\n",
              " array([93.00543695, 68.47235097,  9.18488113]),\n",
              " array([93.00543798, 68.47235062,  9.1888235 ]),\n",
              " array([93.00543668, 68.4723505 ,  9.18507425]),\n",
              " array([93.00542421, 68.47235109,  9.18522966]),\n",
              " array([93.00543398, 68.47235032,  9.1855647 ]),\n",
              " array([93.00543538, 68.47235094,  9.18397188]),\n",
              " array([93.00543072, 68.47235105,  9.1896582 ]),\n",
              " array([93.00543496, 68.47235108,  9.18616634]),\n",
              " array([93.00542764, 68.47235097,  9.18759861]),\n",
              " array([93.0054412 , 68.47235083,  9.18553471]),\n",
              " array([93.00544534, 68.47235108,  9.18638993]),\n",
              " array([93.00543414, 68.47235104,  9.18423175]),\n",
              " array([93.00543621, 68.47235109,  9.18476523]),\n",
              " array([93.00542993, 68.47235099,  9.18476798]),\n",
              " array([93.00542228, 68.47235041,  9.18706474]),\n",
              " array([93.00544215, 68.47235104,  9.18647967]),\n",
              " array([93.00544815, 68.47234972,  9.18871967]),\n",
              " array([93.0054314 , 68.47234993,  9.1861858 ]),\n",
              " array([93.00541997, 68.47235105,  9.18534054]),\n",
              " array([93.00543937, 68.47235109,  9.18797609]),\n",
              " array([93.00544754, 68.47235107,  9.1884871 ]),\n",
              " array([93.00543234, 68.47235091,  9.18552284]),\n",
              " array([93.00543536, 68.47235103,  9.18625877]),\n",
              " array([93.00543973, 68.47235108,  9.18459078]),\n",
              " array([93.00544881, 68.472351  ,  9.18612575]),\n",
              " array([93.00544458, 68.47235096,  9.18459456]),\n",
              " array([93.00545243, 68.47235107,  9.18593256]),\n",
              " array([93.0054326 , 68.47235109,  9.18706096]),\n",
              " array([93.0054278 , 68.47235086,  9.18697279]),\n",
              " array([93.00544236, 68.47235066,  9.18483291]),\n",
              " array([93.00544833, 68.47234948,  9.18725703]),\n",
              " array([93.00544782, 68.472351  ,  9.18369634]),\n",
              " array([93.00543212, 68.47234998,  9.18743043]),\n",
              " array([93.00543759, 68.47235096,  9.1866167 ]),\n",
              " array([93.0054354 , 68.47235097,  9.18649955]),\n",
              " array([93.00544937, 68.47235099,  9.18687069]),\n",
              " array([93.00544254, 68.47235041,  9.18455337]),\n",
              " array([93.00544322, 68.47235109,  9.18564239]),\n",
              " array([93.00543918, 68.47235109,  9.18890834]),\n",
              " array([93.00543061, 68.47235042,  9.18508697]),\n",
              " array([93.00543112, 68.472351  ,  9.18695105]),\n",
              " array([93.00544887, 68.47235105,  9.18740217]),\n",
              " array([93.00543101, 68.47235099,  9.18765672]),\n",
              " array([93.00544615, 68.47235064,  9.1865754 ]),\n",
              " array([93.00544668, 68.47235082,  9.1870424 ]),\n",
              " array([93.00543417, 68.47235107,  9.18850621]),\n",
              " array([93.00542909, 68.47235108,  9.18614416]),\n",
              " array([93.00544494, 68.47235107,  9.18223906]),\n",
              " array([93.00542601, 68.47235109,  9.18841504]),\n",
              " array([93.00544334, 68.47235109,  9.18549205]),\n",
              " array([93.00543973, 68.47235075,  9.18741515]),\n",
              " array([93.00542073, 68.47235106,  9.18262099]),\n",
              " array([93.00544098, 68.47235109,  9.1863789 ]),\n",
              " array([93.0054447 , 68.47235088,  9.18754808]),\n",
              " array([93.00544839, 68.47235048,  9.18904927]),\n",
              " array([93.00543529, 68.47235059,  9.18580631]),\n",
              " array([93.00544117, 68.47235071,  9.18509117]),\n",
              " array([93.00542543, 68.47235103,  9.18523187]),\n",
              " array([93.00542032, 68.47235107,  9.18579802]),\n",
              " array([93.00542956, 68.47235046,  9.18514704]),\n",
              " array([93.0054266 , 68.47235109,  9.18564502]),\n",
              " array([93.00542869, 68.47235094,  9.18642732]),\n",
              " array([93.00543226, 68.47235108,  9.18956064]),\n",
              " array([93.00543972, 68.47235079,  9.18721569]),\n",
              " array([93.00543942, 68.47235103,  9.18494011]),\n",
              " array([93.00544198, 68.47235069,  9.18601538]),\n",
              " array([93.00542302, 68.47235083,  9.18571166]),\n",
              " array([93.00542758, 68.47235109,  9.18267604]),\n",
              " array([93.00542002, 68.47235033,  9.18792438]),\n",
              " array([93.00545259, 68.47235098,  9.1863157 ]),\n",
              " array([93.00543262, 68.47235074,  9.18572197]),\n",
              " array([93.00543375, 68.47235089,  9.18662358]),\n",
              " array([93.0054237 , 68.47235092,  9.18618145]),\n",
              " array([93.00542703, 68.47235108,  9.19011815]),\n",
              " array([93.00543914, 68.47235071,  9.18892056]),\n",
              " array([93.00544745, 68.47235106,  9.18405328]),\n",
              " array([93.00544447, 68.47235078,  9.18634312]),\n",
              " array([93.00543653, 68.47235102,  9.18636628]),\n",
              " array([93.00543631, 68.47235087,  9.18417499]),\n",
              " array([93.00544615, 68.47235101,  9.18839189]),\n",
              " array([93.00544633, 68.47235109,  9.1862611 ]),\n",
              " array([93.00543687, 68.47235109,  9.18756441]),\n",
              " array([93.00542723, 68.47235109,  9.18555018]),\n",
              " array([93.00543396, 68.4723509 ,  9.18845315]),\n",
              " array([93.00545475, 68.47235083,  9.18577808]),\n",
              " array([93.00542835, 68.47235107,  9.18491242]),\n",
              " array([93.00544997, 68.47235102,  9.18523973]),\n",
              " array([93.00542908, 68.47235047,  9.18537603]),\n",
              " array([93.00542276, 68.47235109,  9.18567825]),\n",
              " array([93.00544429, 68.47235108,  9.18610655]),\n",
              " array([93.00542426, 68.47235042,  9.18883405]),\n",
              " array([93.00543384, 68.47235045,  9.18466556]),\n",
              " array([93.00543999, 68.47235003,  9.18244234]),\n",
              " array([93.00544562, 68.47235046,  9.18699889]),\n",
              " array([93.00543045, 68.47235082,  9.18667098]),\n",
              " array([93.005439  , 68.47235082,  9.18449258]),\n",
              " array([93.00544735, 68.47235096,  9.18598382]),\n",
              " array([93.0054306 , 68.47235097,  9.18673424]),\n",
              " array([93.0054391 , 68.47235103,  9.18628248]),\n",
              " array([93.00544417, 68.47235107,  9.18666268]),\n",
              " array([93.00544125, 68.472351  ,  9.1837269 ]),\n",
              " array([93.00542235, 68.47235105,  9.18806189]),\n",
              " array([93.00545665, 68.47235109,  9.18658172]),\n",
              " array([93.00542675, 68.47235093,  9.18689143]),\n",
              " array([93.00543264, 68.4723507 ,  9.18563838]),\n",
              " array([93.00542965, 68.47235016,  9.18493829]),\n",
              " array([93.0054484 , 68.47235094,  9.18864184]),\n",
              " array([93.00545774, 68.47235085,  9.18685824]),\n",
              " array([93.00542686, 68.4723509 ,  9.18641023]),\n",
              " array([93.0054191 , 68.472351  ,  9.18680269]),\n",
              " array([93.00543369, 68.47235027,  9.18444203]),\n",
              " array([93.00543276, 68.47235031,  9.18547437]),\n",
              " array([93.00543216, 68.47235079,  9.18631099]),\n",
              " array([93.0054318 , 68.47235109,  9.18813104]),\n",
              " array([93.00544766, 68.47235105,  9.18564528]),\n",
              " array([93.00543555, 68.47235109,  9.18433976]),\n",
              " array([93.00544337, 68.47235109,  9.18625822]),\n",
              " array([93.00543507, 68.47235107,  9.18622406]),\n",
              " array([93.00543001, 68.47235108,  9.18796678]),\n",
              " array([93.00545232, 68.4723509 ,  9.18456356]),\n",
              " array([93.00543455, 68.47235073,  9.18756989]),\n",
              " array([93.00544411, 68.47235085,  9.18795264]),\n",
              " array([93.005435  , 68.47235046,  9.18432185]),\n",
              " array([93.00542784, 68.47235082,  9.18600936]),\n",
              " array([93.00544665, 68.47235109,  9.1849456 ]),\n",
              " array([93.00544302, 68.47235103,  9.18546308]),\n",
              " array([93.00545278, 68.47234971,  9.18743185]),\n",
              " array([93.00543766, 68.47235108,  9.18790236]),\n",
              " array([93.00544625, 68.47235106,  9.18559145]),\n",
              " array([93.00543116, 68.47235105,  9.18487573]),\n",
              " array([93.0054314 , 68.47235104,  9.18515415]),\n",
              " array([93.00543303, 68.47235109,  9.18556969]),\n",
              " array([93.00542253, 68.47235056,  9.18312867]),\n",
              " array([93.00542145, 68.47235097,  9.18523455]),\n",
              " array([93.0054484 , 68.47235033,  9.18620415]),\n",
              " array([93.00543748, 68.47235081,  9.18580617]),\n",
              " array([93.00543552, 68.47235042,  9.18672682]),\n",
              " array([93.00542856, 68.47235109,  9.18766472]),\n",
              " array([93.00544487, 68.47235105,  9.18584896]),\n",
              " array([93.00544081, 68.47235101,  9.18694867]),\n",
              " array([93.00543369, 68.47235109,  9.18759633]),\n",
              " array([93.00543206, 68.47235106,  9.1850566 ]),\n",
              " array([93.00544267, 68.47235073,  9.18650041]),\n",
              " array([93.00544347, 68.47235093,  9.18681756]),\n",
              " array([93.00545943, 68.47235081,  9.18535539]),\n",
              " array([93.00544267, 68.47235109,  9.18314386]),\n",
              " array([93.00544166, 68.47235085,  9.18518674]),\n",
              " array([93.00543771, 68.47235107,  9.18441994]),\n",
              " array([93.00543286, 68.47235101,  9.18760988]),\n",
              " array([93.00542982, 68.47235087,  9.19016215]),\n",
              " array([93.00542183, 68.47235109,  9.18669804]),\n",
              " array([93.00542288, 68.47235107,  9.18514604]),\n",
              " array([93.00542354, 68.47235095,  9.18608594]),\n",
              " array([93.00543731, 68.47235103,  9.18733514]),\n",
              " array([93.00544874, 68.47235109,  9.18401789]),\n",
              " array([93.00541907, 68.47235093,  9.18470706]),\n",
              " array([93.00543705, 68.47235108,  9.18538928]),\n",
              " array([93.00544714, 68.47235098,  9.18832542]),\n",
              " array([93.00545876, 68.47235011,  9.18650722]),\n",
              " array([93.00544549, 68.47235107,  9.18898664]),\n",
              " array([93.00542875, 68.47235088,  9.18620471])]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UE4XLjKyNYB1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6964
        },
        "outputId": "c005affa-15a2-4f77-8e08-243a64dc442b"
      },
      "cell_type": "code",
      "source": [
        "display(fest2)\n",
        "display(fest)\n",
        "\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[array([2520.24601186, 6518.75541612, 5539.51346662]),\n",
              " array([2520.24082735, 6518.75611803, 5539.48113757]),\n",
              " array([2520.24404723, 6518.76260246, 5539.4891568 ]),\n",
              " array([2520.24776107, 6518.75218071, 5539.51915847]),\n",
              " array([2520.24187595, 6518.75417206, 5539.50322696]),\n",
              " array([2520.24262793, 6518.75941024, 5539.5336541 ]),\n",
              " array([2520.2371879 , 6518.75880462, 5539.48806348]),\n",
              " array([2520.24333602, 6518.75399104, 5539.55758521]),\n",
              " array([2520.24603343, 6518.75308744, 5539.50149856]),\n",
              " array([2520.24636987, 6518.7621706 , 5539.56075229]),\n",
              " array([2520.24179651, 6518.7579379 , 5539.42204218]),\n",
              " array([2520.25104699, 6518.75558791, 5539.49075416]),\n",
              " array([2520.24387559, 6518.75885616, 5539.50815474]),\n",
              " array([2520.24293999, 6518.7570123 , 5539.55807999]),\n",
              " array([2520.24548104, 6518.75312361, 5539.5309619 ]),\n",
              " array([2520.24812994, 6518.75516011, 5539.50841978]),\n",
              " array([2520.24610148, 6518.75977128, 5539.56489617]),\n",
              " array([2520.24617791, 6518.75742377, 5539.52893209]),\n",
              " array([2520.2460039 , 6518.75301124, 5539.52882296]),\n",
              " array([2520.23811173, 6518.75022442, 5539.5146987 ]),\n",
              " array([2520.24963296, 6518.75770679, 5539.41249941]),\n",
              " array([2520.244912  , 6518.75538126, 5539.51651005]),\n",
              " array([2520.24737404, 6518.75673495, 5539.46083657]),\n",
              " array([2520.25191001, 6518.76166292, 5539.48753256]),\n",
              " array([2520.23995952, 6518.75213344, 5539.52136913]),\n",
              " array([2520.24454156, 6518.75877376, 5539.47694848]),\n",
              " array([2520.24720823, 6518.76157921, 5539.46148278]),\n",
              " array([2520.23937598, 6518.761538  , 5539.52046007]),\n",
              " array([2520.24568318, 6518.75524145, 5539.47889502]),\n",
              " array([2520.24412565, 6518.75865353, 5539.47569304]),\n",
              " array([2520.244525  , 6518.75567329, 5539.49511427]),\n",
              " array([2520.24489915, 6518.76166919, 5539.52369778]),\n",
              " array([2520.24776176, 6518.74942582, 5539.53566322]),\n",
              " array([2520.24600977, 6518.75727201, 5539.47559825]),\n",
              " array([2520.24920391, 6518.75526229, 5539.50701281]),\n",
              " array([2520.24473802, 6518.75683604, 5539.50690408]),\n",
              " array([2520.2471602 , 6518.7576076 , 5539.50370114]),\n",
              " array([2520.25055102, 6518.75446962, 5539.5365843 ]),\n",
              " array([2520.24424487, 6518.7577719 , 5539.4503813 ]),\n",
              " array([2520.245259  , 6518.76151912, 5539.52052716]),\n",
              " array([2520.24632423, 6518.75337541, 5539.50632653]),\n",
              " array([2520.24417025, 6518.75676292, 5539.53047981]),\n",
              " array([2520.24315292, 6518.74811499, 5539.51666681]),\n",
              " array([2520.24342674, 6518.75363481, 5539.4966809 ]),\n",
              " array([2520.24755317, 6518.7502627 , 5539.5253028 ]),\n",
              " array([2520.24935101, 6518.75362779, 5539.56535088]),\n",
              " array([2520.24683513, 6518.75438458, 5539.4945668 ]),\n",
              " array([2520.24381287, 6518.75309234, 5539.4941838 ]),\n",
              " array([2520.24392144, 6518.75742629, 5539.42715926]),\n",
              " array([2520.24408582, 6518.76138304, 5539.47536471]),\n",
              " array([2520.24083086, 6518.75725167, 5539.48634973]),\n",
              " array([2520.24531868, 6518.75890516, 5539.46440746]),\n",
              " array([2520.24193839, 6518.75477523, 5539.51652953]),\n",
              " array([2520.24798806, 6518.75723426, 5539.51035162]),\n",
              " array([2520.25174031, 6518.7565756 , 5539.52233979]),\n",
              " array([2520.24524511, 6518.75505038, 5539.49384197]),\n",
              " array([2520.24603238, 6518.75975872, 5539.53473878]),\n",
              " array([2520.24147423, 6518.75921072, 5539.5546923 ]),\n",
              " array([2520.24945493, 6518.75806929, 5539.55311292]),\n",
              " array([2520.24377345, 6518.75652052, 5539.55355951]),\n",
              " array([2520.24194682, 6518.76005741, 5539.45864535]),\n",
              " array([2520.24757543, 6518.75542184, 5539.49865713]),\n",
              " array([2520.24389757, 6518.76186654, 5539.49636202]),\n",
              " array([2520.24416041, 6518.75353053, 5539.58479502]),\n",
              " array([2520.24591734, 6518.75882134, 5539.51138615]),\n",
              " array([2520.25020933, 6518.74721405, 5539.50605918]),\n",
              " array([2520.24623023, 6518.75224161, 5539.46676564]),\n",
              " array([2520.2478529 , 6518.75229419, 5539.45379589]),\n",
              " array([2520.23984268, 6518.75289703, 5539.52237386]),\n",
              " array([2520.24165766, 6518.7543971 , 5539.49647473]),\n",
              " array([2520.24504157, 6518.75408499, 5539.51245234]),\n",
              " array([2520.2390805 , 6518.75457904, 5539.50302824]),\n",
              " array([2520.24364968, 6518.75860856, 5539.50915815]),\n",
              " array([2520.24651312, 6518.75221585, 5539.51895732]),\n",
              " array([2520.24492763, 6518.75497541, 5539.48199424]),\n",
              " array([2520.2500913 , 6518.75812719, 5539.57502454]),\n",
              " array([2520.24439815, 6518.75478377, 5539.52393995]),\n",
              " array([2520.24920861, 6518.75929636, 5539.47087323]),\n",
              " array([2520.24088754, 6518.75162503, 5539.51945226]),\n",
              " array([2520.24280546, 6518.75622188, 5539.50641409]),\n",
              " array([2520.2447126 , 6518.75501587, 5539.49584105]),\n",
              " array([2520.24827216, 6518.75626173, 5539.47446268]),\n",
              " array([2520.24569312, 6518.75478803, 5539.54520248]),\n",
              " array([2520.24291102, 6518.7616783 , 5539.45215097]),\n",
              " array([2520.24208083, 6518.75044803, 5539.43921612]),\n",
              " array([2520.24934108, 6518.75758915, 5539.53585088]),\n",
              " array([2520.24475732, 6518.75532691, 5539.5058805 ]),\n",
              " array([2520.24736288, 6518.75142545, 5539.53514016]),\n",
              " array([2520.24614764, 6518.75316591, 5539.53243616]),\n",
              " array([2520.24043266, 6518.7600663 , 5539.54438484]),\n",
              " array([2520.2457437 , 6518.75287355, 5539.56164987]),\n",
              " array([2520.24648191, 6518.75167271, 5539.54396909]),\n",
              " array([2520.24375021, 6518.75386599, 5539.53047896]),\n",
              " array([2520.24329301, 6518.75587962, 5539.51784388]),\n",
              " array([2520.24343854, 6518.76404941, 5539.51769306]),\n",
              " array([2520.24581734, 6518.75475711, 5539.50451782]),\n",
              " array([2520.24254048, 6518.756363  , 5539.55710794]),\n",
              " array([2520.24436317, 6518.75916585, 5539.54256538]),\n",
              " array([2520.25089129, 6518.75948319, 5539.51961356]),\n",
              " array([2520.24464849, 6518.75397508, 5539.51180209]),\n",
              " array([2520.24281928, 6518.75611908, 5539.46880239]),\n",
              " array([2520.24390241, 6518.75626591, 5539.50761702]),\n",
              " array([2520.25298873, 6518.75737349, 5539.50953017]),\n",
              " array([2520.2480781 , 6518.75265726, 5539.51052014]),\n",
              " array([2520.25135297, 6518.75063519, 5539.58040158]),\n",
              " array([2520.25444389, 6518.74483909, 5539.54777084]),\n",
              " array([2520.24552682, 6518.75343447, 5539.52235102]),\n",
              " array([2520.24525496, 6518.75945675, 5539.49208952]),\n",
              " array([2520.24176935, 6518.75632126, 5539.49311657]),\n",
              " array([2520.24716573, 6518.7544157 , 5539.49580664]),\n",
              " array([2520.24488298, 6518.75922841, 5539.52783378]),\n",
              " array([2520.24426905, 6518.75619791, 5539.49264239]),\n",
              " array([2520.24750734, 6518.75726056, 5539.47786395]),\n",
              " array([2520.24270333, 6518.74718065, 5539.50231301]),\n",
              " array([2520.24508513, 6518.75856588, 5539.51997197]),\n",
              " array([2520.24301943, 6518.75232114, 5539.46933452]),\n",
              " array([2520.24781782, 6518.75594488, 5539.48202572]),\n",
              " array([2520.25232979, 6518.75685476, 5539.47311973]),\n",
              " array([2520.24562807, 6518.75708244, 5539.51919044]),\n",
              " array([2520.24097171, 6518.75204684, 5539.57632157]),\n",
              " array([2520.24683928, 6518.7530517 , 5539.51404506]),\n",
              " array([2520.24312726, 6518.74933246, 5539.52341472]),\n",
              " array([2520.24715789, 6518.75265576, 5539.51290336]),\n",
              " array([2520.24219823, 6518.75374389, 5539.53943087]),\n",
              " array([2520.25057545, 6518.76640808, 5539.52369476]),\n",
              " array([2520.24339815, 6518.75807854, 5539.4714077 ]),\n",
              " array([2520.2483743 , 6518.75632214, 5539.5301202 ]),\n",
              " array([2520.24326683, 6518.75796985, 5539.52109002]),\n",
              " array([2520.24958169, 6518.75409843, 5539.5213049 ]),\n",
              " array([2520.24005907, 6518.76170771, 5539.45425656]),\n",
              " array([2520.24789621, 6518.75067908, 5539.51888654]),\n",
              " array([2520.24289946, 6518.76118896, 5539.51463367]),\n",
              " array([2520.24876572, 6518.74987682, 5539.50015914]),\n",
              " array([2520.24941658, 6518.75841798, 5539.51599514]),\n",
              " array([2520.24327303, 6518.75676694, 5539.53627142]),\n",
              " array([2520.24257453, 6518.75416974, 5539.53285724]),\n",
              " array([2520.24822373, 6518.75167369, 5539.45415372]),\n",
              " array([2520.24189797, 6518.75902925, 5539.49360206]),\n",
              " array([2520.24971381, 6518.75515054, 5539.45761042]),\n",
              " array([2520.24472087, 6518.76288733, 5539.49338926]),\n",
              " array([2520.2499194 , 6518.75695877, 5539.50130041]),\n",
              " array([2520.24279983, 6518.75972177, 5539.58458047]),\n",
              " array([2520.24392887, 6518.75769587, 5539.51434495]),\n",
              " array([2520.24378518, 6518.75637918, 5539.50766974]),\n",
              " array([2520.24769655, 6518.75887768, 5539.54293297]),\n",
              " array([2520.25152266, 6518.75981462, 5539.47447547]),\n",
              " array([2520.24118566, 6518.75343044, 5539.44614815]),\n",
              " array([2520.24722662, 6518.75304569, 5539.50487612]),\n",
              " array([2520.24526602, 6518.7546014 , 5539.51811377]),\n",
              " array([2520.24664752, 6518.75245207, 5539.50838518]),\n",
              " array([2520.24197957, 6518.75185853, 5539.49253338]),\n",
              " array([2520.2463589 , 6518.75783272, 5539.54682983]),\n",
              " array([2520.24390918, 6518.75948238, 5539.554851  ]),\n",
              " array([2520.24531999, 6518.75551099, 5539.51484843]),\n",
              " array([2520.24610608, 6518.75715812, 5539.49802089]),\n",
              " array([2520.25118208, 6518.75826964, 5539.56004959]),\n",
              " array([2520.24374826, 6518.75825846, 5539.51120314]),\n",
              " array([2520.24396845, 6518.74857589, 5539.53696122]),\n",
              " array([2520.24420009, 6518.7526745 , 5539.53707038]),\n",
              " array([2520.24674093, 6518.75938769, 5539.511464  ]),\n",
              " array([2520.24984792, 6518.76309354, 5539.52760957]),\n",
              " array([2520.24696683, 6518.75384854, 5539.52481226]),\n",
              " array([2520.2367705 , 6518.75806183, 5539.5414799 ]),\n",
              " array([2520.24651816, 6518.75282539, 5539.51687138]),\n",
              " array([2520.24679834, 6518.75552479, 5539.50538043]),\n",
              " array([2520.24736153, 6518.76254735, 5539.51381129]),\n",
              " array([2520.24347236, 6518.75609449, 5539.45837663]),\n",
              " array([2520.24452657, 6518.7497505 , 5539.53893533]),\n",
              " array([2520.24325007, 6518.75138979, 5539.46326132]),\n",
              " array([2520.24909054, 6518.75630886, 5539.56622121]),\n",
              " array([2520.25011051, 6518.75823224, 5539.55867731]),\n",
              " array([2520.24297714, 6518.75174528, 5539.38834282]),\n",
              " array([2520.24658592, 6518.75889676, 5539.47702237]),\n",
              " array([2520.23969951, 6518.75490088, 5539.44587079]),\n",
              " array([2520.25013921, 6518.76091687, 5539.53494625]),\n",
              " array([2520.24869126, 6518.75676345, 5539.58227574]),\n",
              " array([2520.24733461, 6518.75173659, 5539.48846664]),\n",
              " array([2520.24499196, 6518.75828562, 5539.49424593]),\n",
              " array([2520.250244  , 6518.75019895, 5539.48254969]),\n",
              " array([2520.24624649, 6518.75500249, 5539.52337434]),\n",
              " array([2520.24767949, 6518.75295894, 5539.58002147]),\n",
              " array([2520.24416167, 6518.75673326, 5539.47353795]),\n",
              " array([2520.24729777, 6518.75302622, 5539.55556541]),\n",
              " array([2520.24129006, 6518.7606264 , 5539.55516313]),\n",
              " array([2520.24443183, 6518.75604575, 5539.46653616]),\n",
              " array([2520.23847407, 6518.75146168, 5539.57421088]),\n",
              " array([2520.24349805, 6518.75576795, 5539.52266005]),\n",
              " array([2520.24733313, 6518.75817361, 5539.59217792]),\n",
              " array([2520.25203736, 6518.75018432, 5539.52949829]),\n",
              " array([2520.24836946, 6518.75053462, 5539.45810427]),\n",
              " array([2520.25300845, 6518.75754226, 5539.58049042]),\n",
              " array([2520.24459949, 6518.76296476, 5539.47878935]),\n",
              " array([2520.24546443, 6518.75231832, 5539.44969525]),\n",
              " array([2520.24537012, 6518.7574652 , 5539.55787692]),\n",
              " array([2520.24956143, 6518.75258838, 5539.54007944]),\n",
              " array([2520.24858335, 6518.74737287, 5539.46022157]),\n",
              " array([2520.25155519, 6518.7593197 , 5539.50055398]),\n",
              " array([2520.24648816, 6518.75516499, 5539.46048276]),\n",
              " array([2520.24519744, 6518.75547099, 5539.55054776]),\n",
              " array([2520.25423833, 6518.7497072 , 5539.49800876])]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[array([9845.70281756, 6518.75732165, 5539.50301356]),\n",
              " array([9845.69144295, 6518.75507602, 5539.43380359]),\n",
              " array([9845.6989237 , 6518.75576413, 5539.55252133]),\n",
              " array([9845.70088568, 6518.7522811 , 5539.52781744]),\n",
              " array([9845.70578037, 6518.75562625, 5539.44009269]),\n",
              " array([9845.70297198, 6518.75587981, 5539.49594468]),\n",
              " array([9845.70045592, 6518.75333391, 5539.4929031 ]),\n",
              " array([9845.69209239, 6518.75911709, 5539.53820247]),\n",
              " array([9845.70049923, 6518.75963723, 5539.53495941]),\n",
              " array([9845.69813442, 6518.75071615, 5539.51981172]),\n",
              " array([9845.69672108, 6518.75325087, 5539.45620974]),\n",
              " array([9845.69986759, 6518.75957905, 5539.53631913]),\n",
              " array([9845.69538331, 6518.75358893, 5539.56192167]),\n",
              " array([9845.69696635, 6518.75960941, 5539.50665045]),\n",
              " array([9845.70169909, 6518.7638564 , 5539.53438418]),\n",
              " array([9845.70387831, 6518.75638105, 5539.54426849]),\n",
              " array([9845.69928589, 6518.75315094, 5539.52835173]),\n",
              " array([9845.69895024, 6518.75353206, 5539.51141595]),\n",
              " array([9845.69396976, 6518.757827  , 5539.49898417]),\n",
              " array([9845.69486224, 6518.75845932, 5539.515373  ]),\n",
              " array([9845.70031921, 6518.75741028, 5539.53799353]),\n",
              " array([9845.69555624, 6518.75121278, 5539.51887905]),\n",
              " array([9845.69535201, 6518.75794876, 5539.49610915]),\n",
              " array([9845.69821476, 6518.75372345, 5539.57864106]),\n",
              " array([9845.69320569, 6518.7594409 , 5539.51113897]),\n",
              " array([9845.70505526, 6518.75344241, 5539.51767574]),\n",
              " array([9845.70401145, 6518.75107134, 5539.49619331]),\n",
              " array([9845.69109009, 6518.75604773, 5539.54699754]),\n",
              " array([9845.69343604, 6518.75407167, 5539.58060845]),\n",
              " array([9845.70452776, 6518.75882803, 5539.50578122]),\n",
              " array([9845.69652785, 6518.75118475, 5539.50132736]),\n",
              " array([9845.69822478, 6518.75917277, 5539.53657237]),\n",
              " array([9845.70262338, 6518.75417649, 5539.5439103 ]),\n",
              " array([9845.70122298, 6518.75744647, 5539.47562144]),\n",
              " array([9845.69906205, 6518.75586981, 5539.55149506]),\n",
              " array([9845.69242333, 6518.75371569, 5539.51872177]),\n",
              " array([9845.6985138 , 6518.75092768, 5539.50268115]),\n",
              " array([9845.70235249, 6518.75989165, 5539.56363051]),\n",
              " array([9845.69558627, 6518.75665482, 5539.50043106]),\n",
              " array([9845.70088853, 6518.75444234, 5539.44294914]),\n",
              " array([9845.69399217, 6518.75630258, 5539.51926895]),\n",
              " array([9845.70190442, 6518.75265372, 5539.45293203]),\n",
              " array([9845.69614002, 6518.75498145, 5539.51008538]),\n",
              " array([9845.69987315, 6518.75732025, 5539.55422816]),\n",
              " array([9845.70170174, 6518.75290624, 5539.48438249]),\n",
              " array([9845.70119656, 6518.75771096, 5539.48116109]),\n",
              " array([9845.69808749, 6518.75361001, 5539.51444853]),\n",
              " array([9845.70372847, 6518.7616413 , 5539.56749244]),\n",
              " array([9845.70002391, 6518.75066727, 5539.53269084]),\n",
              " array([9845.69730718, 6518.75512773, 5539.48718414]),\n",
              " array([9845.69586104, 6518.75097659, 5539.52100564]),\n",
              " array([9845.70222494, 6518.75770182, 5539.49297578]),\n",
              " array([9845.69752772, 6518.7577556 , 5539.52492964]),\n",
              " array([9845.70178578, 6518.75390429, 5539.48016695]),\n",
              " array([9845.69909537, 6518.75300457, 5539.5497325 ]),\n",
              " array([9845.70172541, 6518.75784146, 5539.48646797]),\n",
              " array([9845.70498686, 6518.75522411, 5539.44600465]),\n",
              " array([9845.69749462, 6518.75422455, 5539.50501926]),\n",
              " array([9845.70120057, 6518.75648655, 5539.48716661]),\n",
              " array([9845.70067799, 6518.75222939, 5539.45383743]),\n",
              " array([9845.70335586, 6518.7568359 , 5539.55394271]),\n",
              " array([9845.70047287, 6518.75339088, 5539.44053353]),\n",
              " array([9845.70064324, 6518.75365236, 5539.53463178]),\n",
              " array([9845.69810352, 6518.75338482, 5539.49579319]),\n",
              " array([9845.69876719, 6518.75731645, 5539.53542771]),\n",
              " array([9845.70382575, 6518.75165083, 5539.51262744]),\n",
              " array([9845.69193499, 6518.75329769, 5539.54654679]),\n",
              " array([9845.70188895, 6518.75475092, 5539.53673918]),\n",
              " array([9845.69877105, 6518.75527731, 5539.53072127]),\n",
              " array([9845.69668595, 6518.75881408, 5539.51742026]),\n",
              " array([9845.69845099, 6518.75319008, 5539.52409861]),\n",
              " array([9845.69913558, 6518.75632135, 5539.49239423]),\n",
              " array([9845.69643377, 6518.76086967, 5539.47491313]),\n",
              " array([9845.70138112, 6518.75847219, 5539.54317233]),\n",
              " array([9845.6951564 , 6518.75176944, 5539.54201127]),\n",
              " array([9845.69301809, 6518.75932194, 5539.5195009 ]),\n",
              " array([9845.70430942, 6518.7515264 , 5539.52049654]),\n",
              " array([9845.69903725, 6518.7540013 , 5539.53791992]),\n",
              " array([9845.69285322, 6518.75568586, 5539.5070364 ]),\n",
              " array([9845.70541188, 6518.75458287, 5539.52564162]),\n",
              " array([9845.69415983, 6518.75565558, 5539.53464446]),\n",
              " array([9845.70231383, 6518.75620208, 5539.50526753]),\n",
              " array([9845.6979418 , 6518.7609123 , 5539.59001033]),\n",
              " array([9845.69204768, 6518.75432948, 5539.55176669]),\n",
              " array([9845.70261968, 6518.75712031, 5539.52814142]),\n",
              " array([9845.69672552, 6518.75364495, 5539.47532186]),\n",
              " array([9845.7026555 , 6518.75460933, 5539.55198301]),\n",
              " array([9845.7030531 , 6518.75497961, 5539.48542653]),\n",
              " array([9845.69771605, 6518.75433377, 5539.54662889]),\n",
              " array([9845.69839286, 6518.75449529, 5539.53263095]),\n",
              " array([9845.69943559, 6518.75424506, 5539.52752342]),\n",
              " array([9845.69886205, 6518.75839442, 5539.54663973]),\n",
              " array([9845.70483027, 6518.75598436, 5539.50978909]),\n",
              " array([9845.69812975, 6518.75359735, 5539.51246038]),\n",
              " array([9845.69852561, 6518.75382399, 5539.52318364]),\n",
              " array([9845.7008659 , 6518.76198711, 5539.49142891]),\n",
              " array([9845.6983574, 6518.750806 , 5539.4404508]),\n",
              " array([9845.70184835, 6518.75528798, 5539.54637642]),\n",
              " array([9845.69672002, 6518.75599029, 5539.53549158]),\n",
              " array([9845.69851421, 6518.75833749, 5539.52633315]),\n",
              " array([9845.69738659, 6518.75421793, 5539.5697664 ]),\n",
              " array([9845.70131453, 6518.75453467, 5539.54821246]),\n",
              " array([9845.69876469, 6518.75248161, 5539.48263458]),\n",
              " array([9845.70109662, 6518.75142659, 5539.54140343]),\n",
              " array([9845.69919798, 6518.7500847 , 5539.50067421]),\n",
              " array([9845.69809675, 6518.75853675, 5539.52093568]),\n",
              " array([9845.6969483 , 6518.75674076, 5539.55337311]),\n",
              " array([9845.7031002 , 6518.75316946, 5539.54161199]),\n",
              " array([9845.70098816, 6518.75366286, 5539.46946943]),\n",
              " array([9845.69371903, 6518.75788667, 5539.54872544]),\n",
              " array([9845.69759458, 6518.75453786, 5539.49561774]),\n",
              " array([9845.70060924, 6518.75091786, 5539.54225193]),\n",
              " array([9845.69604697, 6518.75977692, 5539.49891073]),\n",
              " array([9845.69791953, 6518.75234603, 5539.54210688]),\n",
              " array([9845.7000149 , 6518.7510646 , 5539.53728215]),\n",
              " array([9845.69858574, 6518.76382626, 5539.56678087]),\n",
              " array([9845.69756232, 6518.75544135, 5539.50504581]),\n",
              " array([9845.70107415, 6518.75448142, 5539.56026652]),\n",
              " array([9845.70219127, 6518.75479405, 5539.49050739]),\n",
              " array([9845.69626281, 6518.76041574, 5539.52582254]),\n",
              " array([9845.69802645, 6518.74935688, 5539.54574931]),\n",
              " array([9845.69882   , 6518.75456822, 5539.52026586]),\n",
              " array([9845.70164642, 6518.75436219, 5539.47465292]),\n",
              " array([9845.70027377, 6518.75260413, 5539.54559874]),\n",
              " array([9845.69473455, 6518.76035834, 5539.46743105]),\n",
              " array([9845.69387778, 6518.75126304, 5539.50653344]),\n",
              " array([9845.69498272, 6518.75215096, 5539.50759086]),\n",
              " array([9845.69537633, 6518.7542459 , 5539.53293582]),\n",
              " array([9845.7013533 , 6518.75233336, 5539.5180557 ]),\n",
              " array([9845.69940959, 6518.75159897, 5539.51335988]),\n",
              " array([9845.70139673, 6518.75347635, 5539.49506487]),\n",
              " array([9845.69849231, 6518.74974105, 5539.51356153]),\n",
              " array([9845.69723489, 6518.75161624, 5539.52929004]),\n",
              " array([9845.69893672, 6518.75511778, 5539.48243612]),\n",
              " array([9845.69662887, 6518.75410111, 5539.4953305 ]),\n",
              " array([9845.69139369, 6518.75990066, 5539.48991672]),\n",
              " array([9845.69213227, 6518.74851796, 5539.52776759]),\n",
              " array([9845.70061478, 6518.75679151, 5539.53326351]),\n",
              " array([9845.70138906, 6518.75453044, 5539.52386715]),\n",
              " array([9845.70460179, 6518.75397212, 5539.59135259]),\n",
              " array([9845.69288805, 6518.74471027, 5539.54826534]),\n",
              " array([9845.69758838, 6518.75435344, 5539.47454034]),\n",
              " array([9845.69956104, 6518.75458109, 5539.55331455]),\n",
              " array([9845.69358024, 6518.75170787, 5539.46903134]),\n",
              " array([9845.6943581 , 6518.75429587, 5539.55408129]),\n",
              " array([9845.70184132, 6518.75605457, 5539.52584197]),\n",
              " array([9845.69886892, 6518.75456548, 5539.56821355]),\n",
              " array([9845.70156398, 6518.75854477, 5539.4511729 ]),\n",
              " array([9845.69539981, 6518.75469675, 5539.53558625]),\n",
              " array([9845.69560418, 6518.75378562, 5539.54688181]),\n",
              " array([9845.70094251, 6518.75189871, 5539.61834374]),\n",
              " array([9845.69118804, 6518.7548069 , 5539.47316455]),\n",
              " array([9845.69771157, 6518.75206056, 5539.52831679]),\n",
              " array([9845.69315509, 6518.75417405, 5539.44539881]),\n",
              " array([9845.69708174, 6518.75596077, 5539.50527821]),\n",
              " array([9845.69683877, 6518.74973757, 5539.44771675]),\n",
              " array([9845.69874685, 6518.75210127, 5539.48272414]),\n",
              " array([9845.69379317, 6518.75198635, 5539.54332206]),\n",
              " array([9845.69370876, 6518.75969062, 5539.47716337]),\n",
              " array([9845.6995107 , 6518.75751069, 5539.50043452]),\n",
              " array([9845.70077909, 6518.76087299, 5539.52245952]),\n",
              " array([9845.70181906, 6518.75445615, 5539.50266509]),\n",
              " array([9845.69989486, 6518.75216965, 5539.46653411]),\n",
              " array([9845.69795086, 6518.75511734, 5539.47775829]),\n",
              " array([9845.69370506, 6518.75306562, 5539.52204943]),\n",
              " array([9845.70950608, 6518.74973588, 5539.52873988]),\n",
              " array([9845.70421376, 6518.75415376, 5539.51298234]),\n",
              " array([9845.70234097, 6518.75193998, 5539.52731026]),\n",
              " array([9845.69763981, 6518.75799501, 5539.55708997]),\n",
              " array([9845.70804318, 6518.75733537, 5539.54734509]),\n",
              " array([9845.69426944, 6518.75415594, 5539.41653524]),\n",
              " array([9845.70113948, 6518.75679078, 5539.48177703]),\n",
              " array([9845.69653898, 6518.75126393, 5539.53058667]),\n",
              " array([9845.70100761, 6518.75031317, 5539.55869186]),\n",
              " array([9845.69547804, 6518.75734355, 5539.50048918]),\n",
              " array([9845.70223624, 6518.75600425, 5539.47238079]),\n",
              " array([9845.698246  , 6518.7532141 , 5539.48774614]),\n",
              " array([9845.69800317, 6518.76316501, 5539.48893185]),\n",
              " array([9845.70260364, 6518.75924035, 5539.49190624]),\n",
              " array([9845.69804385, 6518.75696185, 5539.48449179]),\n",
              " array([9845.69652927, 6518.75699405, 5539.50834976]),\n",
              " array([9845.69963861, 6518.75795854, 5539.55774603]),\n",
              " array([9845.69794321, 6518.7551948 , 5539.48568182]),\n",
              " array([9845.70151136, 6518.75678361, 5539.5415225 ]),\n",
              " array([9845.70150636, 6518.75379122, 5539.56258885]),\n",
              " array([9845.69946941, 6518.75716441, 5539.56882173]),\n",
              " array([9845.69791004, 6518.75253702, 5539.46607646]),\n",
              " array([9845.6999037 , 6518.75470822, 5539.52991143]),\n",
              " array([9845.69686752, 6518.76077976, 5539.51804326]),\n",
              " array([9845.70110382, 6518.75751695, 5539.47578665]),\n",
              " array([9845.69556731, 6518.75172116, 5539.47517075]),\n",
              " array([9845.69844577, 6518.759088  , 5539.50700325]),\n",
              " array([9845.70390216, 6518.7556422 , 5539.46532331]),\n",
              " array([9845.69616927, 6518.75213193, 5539.47140733]),\n",
              " array([9845.69840823, 6518.7585632 , 5539.47386514]),\n",
              " array([9845.69842181, 6518.75462144, 5539.5414941 ]),\n",
              " array([9845.6979784 , 6518.75577161, 5539.57657025]),\n",
              " array([9845.69893321, 6518.75446545, 5539.49502176]),\n",
              " array([9845.70118713, 6518.75587335, 5539.51839588]),\n",
              " array([9845.69874099, 6518.75213074, 5539.49074224])]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "shU2I4Khmord",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "5bc4e16d-97fa-4698-cc72-e75de5645272"
      },
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Make sure to run this after each new generation of data\n",
        "# zero mean and unit var\n",
        "x_train2 = StandardScaler().fit_transform(x_train)\n",
        "x_test2 = StandardScaler().fit_transform(x_test)\n",
        "#x_train2 = x_train2[:,:,np.newaxis]\n",
        "#x_test2 = x_test2[:,:,np.newaxis]\n",
        "\n",
        "#x_train2 = x_train2.astype('float32') / 255.\n",
        "#x_test2 = x_test2.astype('float32') / 255.\n",
        "\n",
        "display(x_train2.shape)\n",
        "\n",
        "input_dim = x_train.shape[1]\n",
        "\n",
        "# set size of autoencoder \n",
        "encoding_dim = 6\n",
        "\n",
        "# use elu because it is leaky tried both net and l1 and l2 : net and l1 worked the best \n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "encoder = Dense(encoding_dim, activation=\"elu\",kernel_initializer= 'he_normal', activity_regularizer=regularizers.l1_l2(l1=10e-5, l2=10e-4))(input_layer)\n",
        "#encoder = Dense(encoding_dim, activation=\"elu\",activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "encoder = Dense(int(encoding_dim / 2), activation=\"elu\",kernel_initializer= 'he_normal')(encoder)\n",
        "decoder = Dense(int(encoding_dim / 2), activation='elu',kernel_initializer= 'he_normal')(encoder)\n",
        "decoder = Dense(input_dim, activation='elu',kernel_initializer= 'he_normal')(decoder)\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "\n",
        "autoencoder.summary()  \n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(200, 6)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 3)                 21        \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 6)                 24        \n",
            "=================================================================\n",
            "Total params: 99\n",
            "Trainable params: 99\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0b0rnWT13v-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 28587
        },
        "outputId": "29a729c5-2c9d-4b26-9c87-61d7ceae1176"
      },
      "cell_type": "code",
      "source": [
        "#Results with no anomily \n",
        "# Loss and Val Loss are very close + Accuracy and Val Accuracy are very close \n",
        "# Depending on the params of the net it can hit Accuracy of  1\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "full_anom = 0\n",
        "anom_samples = 0\n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    #loss = 'binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy_with_masking', factor=0.2,\n",
        "                              patience=5,verbose = 1)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "                    validation_split=.1,\n",
        "                    verbose=1,callbacks=[reduce_lr])\n",
        "score = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 180 samples, validate on 20 samples\n",
            "Epoch 1/800\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.5229 - acc: 0.6167 - val_loss: 0.6079 - val_acc: 0.7500\n",
            "Epoch 2/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.5127 - acc: 0.6278 - val_loss: 0.5990 - val_acc: 0.7500\n",
            "Epoch 3/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5022 - acc: 0.6333 - val_loss: 0.5901 - val_acc: 0.7500\n",
            "Epoch 4/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.4927 - acc: 0.6333 - val_loss: 0.5807 - val_acc: 0.7000\n",
            "Epoch 5/800\n",
            " 32/180 [====>.........................] - ETA: 0s - loss: 0.4667 - acc: 0.7500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:972: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_accuracy_with_masking` which is not available. Available metrics are: val_loss,val_acc,loss,acc,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "180/180 [==============================] - 0s 320us/step - loss: 0.4829 - acc: 0.6389 - val_loss: 0.5705 - val_acc: 0.7000\n",
            "Epoch 6/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.4734 - acc: 0.6333 - val_loss: 0.5620 - val_acc: 0.6500\n",
            "Epoch 7/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.4632 - acc: 0.6556 - val_loss: 0.5519 - val_acc: 0.6500\n",
            "Epoch 8/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4528 - acc: 0.6611 - val_loss: 0.5431 - val_acc: 0.6500\n",
            "Epoch 9/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.4432 - acc: 0.6667 - val_loss: 0.5324 - val_acc: 0.6500\n",
            "Epoch 10/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.4334 - acc: 0.6833 - val_loss: 0.5234 - val_acc: 0.6500\n",
            "Epoch 11/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.4246 - acc: 0.7000 - val_loss: 0.5132 - val_acc: 0.7000\n",
            "Epoch 12/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.4155 - acc: 0.7111 - val_loss: 0.5044 - val_acc: 0.7000\n",
            "Epoch 13/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.4059 - acc: 0.7000 - val_loss: 0.4959 - val_acc: 0.7000\n",
            "Epoch 14/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.3971 - acc: 0.7278 - val_loss: 0.4865 - val_acc: 0.7000\n",
            "Epoch 15/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.3878 - acc: 0.7333 - val_loss: 0.4760 - val_acc: 0.7000\n",
            "Epoch 16/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.3799 - acc: 0.7222 - val_loss: 0.4676 - val_acc: 0.7000\n",
            "Epoch 17/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.3712 - acc: 0.7444 - val_loss: 0.4601 - val_acc: 0.7000\n",
            "Epoch 18/800\n",
            "180/180 [==============================] - 0s 335us/step - loss: 0.3631 - acc: 0.7500 - val_loss: 0.4527 - val_acc: 0.7000\n",
            "Epoch 19/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.3552 - acc: 0.7167 - val_loss: 0.4430 - val_acc: 0.7000\n",
            "Epoch 20/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.3472 - acc: 0.7444 - val_loss: 0.4360 - val_acc: 0.7000\n",
            "Epoch 21/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.3397 - acc: 0.7500 - val_loss: 0.4262 - val_acc: 0.7000\n",
            "Epoch 22/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.3327 - acc: 0.7444 - val_loss: 0.4212 - val_acc: 0.7000\n",
            "Epoch 23/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.3249 - acc: 0.7556 - val_loss: 0.4114 - val_acc: 0.7000\n",
            "Epoch 24/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.3184 - acc: 0.7556 - val_loss: 0.4045 - val_acc: 0.7000\n",
            "Epoch 25/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.3118 - acc: 0.7667 - val_loss: 0.3978 - val_acc: 0.7000\n",
            "Epoch 26/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.3056 - acc: 0.7667 - val_loss: 0.3903 - val_acc: 0.7000\n",
            "Epoch 27/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.2995 - acc: 0.7667 - val_loss: 0.3841 - val_acc: 0.7000\n",
            "Epoch 28/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.2931 - acc: 0.7778 - val_loss: 0.3774 - val_acc: 0.7000\n",
            "Epoch 29/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.2876 - acc: 0.7833 - val_loss: 0.3709 - val_acc: 0.7000\n",
            "Epoch 30/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.2823 - acc: 0.7833 - val_loss: 0.3651 - val_acc: 0.7000\n",
            "Epoch 31/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.2768 - acc: 0.7833 - val_loss: 0.3584 - val_acc: 0.7000\n",
            "Epoch 32/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.2711 - acc: 0.7833 - val_loss: 0.3528 - val_acc: 0.7500\n",
            "Epoch 33/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.2665 - acc: 0.7833 - val_loss: 0.3466 - val_acc: 0.7500\n",
            "Epoch 34/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.2609 - acc: 0.7889 - val_loss: 0.3418 - val_acc: 0.7500\n",
            "Epoch 35/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.2564 - acc: 0.7722 - val_loss: 0.3354 - val_acc: 0.8000\n",
            "Epoch 36/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.2518 - acc: 0.7778 - val_loss: 0.3301 - val_acc: 0.8000\n",
            "Epoch 37/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.2472 - acc: 0.7778 - val_loss: 0.3243 - val_acc: 0.8000\n",
            "Epoch 38/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.2427 - acc: 0.7778 - val_loss: 0.3206 - val_acc: 0.8000\n",
            "Epoch 39/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.2386 - acc: 0.7833 - val_loss: 0.3143 - val_acc: 0.8000\n",
            "Epoch 40/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.2341 - acc: 0.7889 - val_loss: 0.3105 - val_acc: 0.8000\n",
            "Epoch 41/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.2307 - acc: 0.7778 - val_loss: 0.3053 - val_acc: 0.8000\n",
            "Epoch 42/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.2266 - acc: 0.7833 - val_loss: 0.2998 - val_acc: 0.8000\n",
            "Epoch 43/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.2232 - acc: 0.7889 - val_loss: 0.2952 - val_acc: 0.8000\n",
            "Epoch 44/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.2193 - acc: 0.7833 - val_loss: 0.2920 - val_acc: 0.8000\n",
            "Epoch 45/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.2158 - acc: 0.7944 - val_loss: 0.2884 - val_acc: 0.8000\n",
            "Epoch 46/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.2119 - acc: 0.7833 - val_loss: 0.2831 - val_acc: 0.8000\n",
            "Epoch 47/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.2087 - acc: 0.7833 - val_loss: 0.2794 - val_acc: 0.8500\n",
            "Epoch 48/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.2056 - acc: 0.7889 - val_loss: 0.2760 - val_acc: 0.8500\n",
            "Epoch 49/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.2028 - acc: 0.7889 - val_loss: 0.2743 - val_acc: 0.8500\n",
            "Epoch 50/800\n",
            "180/180 [==============================] - 0s 408us/step - loss: 0.1997 - acc: 0.7833 - val_loss: 0.2686 - val_acc: 0.8500\n",
            "Epoch 51/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1969 - acc: 0.7944 - val_loss: 0.2654 - val_acc: 0.8500\n",
            "Epoch 52/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1937 - acc: 0.7889 - val_loss: 0.2626 - val_acc: 0.8500\n",
            "Epoch 53/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1913 - acc: 0.8111 - val_loss: 0.2598 - val_acc: 0.9000\n",
            "Epoch 54/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1885 - acc: 0.7944 - val_loss: 0.2563 - val_acc: 0.8500\n",
            "Epoch 55/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1863 - acc: 0.8222 - val_loss: 0.2548 - val_acc: 0.8500\n",
            "Epoch 56/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1842 - acc: 0.8111 - val_loss: 0.2506 - val_acc: 0.8500\n",
            "Epoch 57/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1819 - acc: 0.8167 - val_loss: 0.2487 - val_acc: 0.8500\n",
            "Epoch 58/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1795 - acc: 0.8167 - val_loss: 0.2459 - val_acc: 0.8500\n",
            "Epoch 59/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1774 - acc: 0.8111 - val_loss: 0.2441 - val_acc: 0.8500\n",
            "Epoch 60/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1756 - acc: 0.8167 - val_loss: 0.2421 - val_acc: 0.8500\n",
            "Epoch 61/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1743 - acc: 0.8222 - val_loss: 0.2392 - val_acc: 0.8500\n",
            "Epoch 62/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1716 - acc: 0.8278 - val_loss: 0.2384 - val_acc: 0.8500\n",
            "Epoch 63/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1703 - acc: 0.8333 - val_loss: 0.2355 - val_acc: 0.8500\n",
            "Epoch 64/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1686 - acc: 0.8333 - val_loss: 0.2335 - val_acc: 0.8500\n",
            "Epoch 65/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1670 - acc: 0.8333 - val_loss: 0.2320 - val_acc: 0.8500\n",
            "Epoch 66/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1656 - acc: 0.8278 - val_loss: 0.2303 - val_acc: 0.9500\n",
            "Epoch 67/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1647 - acc: 0.8278 - val_loss: 0.2298 - val_acc: 0.9000\n",
            "Epoch 68/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1624 - acc: 0.8278 - val_loss: 0.2262 - val_acc: 0.9500\n",
            "Epoch 69/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1615 - acc: 0.8278 - val_loss: 0.2282 - val_acc: 0.9000\n",
            "Epoch 70/800\n",
            "180/180 [==============================] - 0s 409us/step - loss: 0.1609 - acc: 0.8278 - val_loss: 0.2269 - val_acc: 0.9000\n",
            "Epoch 71/800\n",
            "180/180 [==============================] - 0s 329us/step - loss: 0.1588 - acc: 0.8333 - val_loss: 0.2225 - val_acc: 0.9500\n",
            "Epoch 72/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1578 - acc: 0.8444 - val_loss: 0.2208 - val_acc: 0.9500\n",
            "Epoch 73/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1568 - acc: 0.8333 - val_loss: 0.2208 - val_acc: 0.9000\n",
            "Epoch 74/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1554 - acc: 0.8333 - val_loss: 0.2211 - val_acc: 0.9500\n",
            "Epoch 75/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1547 - acc: 0.8444 - val_loss: 0.2186 - val_acc: 0.8500\n",
            "Epoch 76/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1536 - acc: 0.8500 - val_loss: 0.2176 - val_acc: 0.9500\n",
            "Epoch 77/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1529 - acc: 0.8389 - val_loss: 0.2157 - val_acc: 0.9500\n",
            "Epoch 78/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1515 - acc: 0.8389 - val_loss: 0.2149 - val_acc: 0.9000\n",
            "Epoch 79/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1506 - acc: 0.8444 - val_loss: 0.2130 - val_acc: 0.9000\n",
            "Epoch 80/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1499 - acc: 0.8222 - val_loss: 0.2123 - val_acc: 0.8500\n",
            "Epoch 81/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1489 - acc: 0.8333 - val_loss: 0.2118 - val_acc: 0.9000\n",
            "Epoch 82/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1481 - acc: 0.8333 - val_loss: 0.2119 - val_acc: 0.9000\n",
            "Epoch 83/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1472 - acc: 0.8333 - val_loss: 0.2106 - val_acc: 0.8000\n",
            "Epoch 84/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1463 - acc: 0.8389 - val_loss: 0.2105 - val_acc: 0.9000\n",
            "Epoch 85/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1456 - acc: 0.8389 - val_loss: 0.2086 - val_acc: 0.8000\n",
            "Epoch 86/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1447 - acc: 0.8389 - val_loss: 0.2085 - val_acc: 0.9000\n",
            "Epoch 87/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1448 - acc: 0.8333 - val_loss: 0.2059 - val_acc: 0.8500\n",
            "Epoch 88/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1434 - acc: 0.8278 - val_loss: 0.2093 - val_acc: 0.9000\n",
            "Epoch 89/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1434 - acc: 0.8278 - val_loss: 0.2069 - val_acc: 0.9000\n",
            "Epoch 90/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1422 - acc: 0.8333 - val_loss: 0.2049 - val_acc: 0.8500\n",
            "Epoch 91/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1418 - acc: 0.8222 - val_loss: 0.2074 - val_acc: 0.8000\n",
            "Epoch 92/800\n",
            "180/180 [==============================] - 0s 336us/step - loss: 0.1415 - acc: 0.8222 - val_loss: 0.2044 - val_acc: 0.8000\n",
            "Epoch 93/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1405 - acc: 0.8333 - val_loss: 0.2039 - val_acc: 0.8000\n",
            "Epoch 94/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1400 - acc: 0.8278 - val_loss: 0.2023 - val_acc: 0.8000\n",
            "Epoch 95/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1393 - acc: 0.8333 - val_loss: 0.2024 - val_acc: 0.8500\n",
            "Epoch 96/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1392 - acc: 0.8333 - val_loss: 0.2022 - val_acc: 0.8500\n",
            "Epoch 97/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1385 - acc: 0.8278 - val_loss: 0.2010 - val_acc: 0.8000\n",
            "Epoch 98/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.1384 - acc: 0.8389 - val_loss: 0.2004 - val_acc: 0.8000\n",
            "Epoch 99/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1373 - acc: 0.8333 - val_loss: 0.1992 - val_acc: 0.8500\n",
            "Epoch 100/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1366 - acc: 0.8222 - val_loss: 0.1989 - val_acc: 0.8500\n",
            "Epoch 101/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1362 - acc: 0.8333 - val_loss: 0.1977 - val_acc: 0.8000\n",
            "Epoch 102/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1360 - acc: 0.8278 - val_loss: 0.1984 - val_acc: 0.8000\n",
            "Epoch 103/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1357 - acc: 0.8278 - val_loss: 0.1980 - val_acc: 0.9000\n",
            "Epoch 104/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1349 - acc: 0.8333 - val_loss: 0.1984 - val_acc: 0.8500\n",
            "Epoch 105/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1346 - acc: 0.8333 - val_loss: 0.1955 - val_acc: 0.8500\n",
            "Epoch 106/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1339 - acc: 0.8389 - val_loss: 0.1954 - val_acc: 0.8500\n",
            "Epoch 107/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1336 - acc: 0.8444 - val_loss: 0.1952 - val_acc: 0.8500\n",
            "Epoch 108/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1333 - acc: 0.8333 - val_loss: 0.1949 - val_acc: 0.8000\n",
            "Epoch 109/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1326 - acc: 0.8278 - val_loss: 0.1952 - val_acc: 0.9000\n",
            "Epoch 110/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1330 - acc: 0.8278 - val_loss: 0.1939 - val_acc: 0.8000\n",
            "Epoch 111/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1327 - acc: 0.8278 - val_loss: 0.1926 - val_acc: 0.8000\n",
            "Epoch 112/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1317 - acc: 0.8389 - val_loss: 0.1937 - val_acc: 0.8000\n",
            "Epoch 113/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.1317 - acc: 0.8333 - val_loss: 0.1933 - val_acc: 0.8000\n",
            "Epoch 114/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1307 - acc: 0.8333 - val_loss: 0.1931 - val_acc: 0.9000\n",
            "Epoch 115/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1316 - acc: 0.8333 - val_loss: 0.1916 - val_acc: 0.8500\n",
            "Epoch 116/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1306 - acc: 0.8278 - val_loss: 0.1910 - val_acc: 0.8500\n",
            "Epoch 117/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1303 - acc: 0.8444 - val_loss: 0.1904 - val_acc: 0.9000\n",
            "Epoch 118/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1298 - acc: 0.8444 - val_loss: 0.1908 - val_acc: 0.8000\n",
            "Epoch 119/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1288 - acc: 0.8500 - val_loss: 0.1897 - val_acc: 0.8000\n",
            "Epoch 120/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1288 - acc: 0.8444 - val_loss: 0.1911 - val_acc: 0.8000\n",
            "Epoch 121/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1284 - acc: 0.8333 - val_loss: 0.1896 - val_acc: 0.8500\n",
            "Epoch 122/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1280 - acc: 0.8444 - val_loss: 0.1895 - val_acc: 0.9000\n",
            "Epoch 123/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1277 - acc: 0.8278 - val_loss: 0.1877 - val_acc: 0.9000\n",
            "Epoch 124/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1277 - acc: 0.8389 - val_loss: 0.1891 - val_acc: 0.9000\n",
            "Epoch 125/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1269 - acc: 0.8333 - val_loss: 0.1877 - val_acc: 0.9000\n",
            "Epoch 126/800\n",
            "180/180 [==============================] - 0s 334us/step - loss: 0.1276 - acc: 0.8278 - val_loss: 0.1862 - val_acc: 0.9000\n",
            "Epoch 127/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1268 - acc: 0.8389 - val_loss: 0.1870 - val_acc: 0.8500\n",
            "Epoch 128/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1265 - acc: 0.8444 - val_loss: 0.1896 - val_acc: 0.8500\n",
            "Epoch 129/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1258 - acc: 0.8333 - val_loss: 0.1863 - val_acc: 0.9500\n",
            "Epoch 130/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1261 - acc: 0.8389 - val_loss: 0.1877 - val_acc: 0.8500\n",
            "Epoch 131/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1256 - acc: 0.8167 - val_loss: 0.1868 - val_acc: 0.8500\n",
            "Epoch 132/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1258 - acc: 0.8500 - val_loss: 0.1861 - val_acc: 0.9500\n",
            "Epoch 133/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.1252 - acc: 0.8333 - val_loss: 0.1855 - val_acc: 0.9000\n",
            "Epoch 134/800\n",
            "180/180 [==============================] - 0s 324us/step - loss: 0.1247 - acc: 0.8389 - val_loss: 0.1867 - val_acc: 0.9000\n",
            "Epoch 135/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1246 - acc: 0.8333 - val_loss: 0.1849 - val_acc: 0.9000\n",
            "Epoch 136/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1244 - acc: 0.8333 - val_loss: 0.1869 - val_acc: 0.8500\n",
            "Epoch 137/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1241 - acc: 0.8278 - val_loss: 0.1870 - val_acc: 0.9000\n",
            "Epoch 138/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1237 - acc: 0.8389 - val_loss: 0.1831 - val_acc: 0.9000\n",
            "Epoch 139/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1236 - acc: 0.8389 - val_loss: 0.1873 - val_acc: 0.9000\n",
            "Epoch 140/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1237 - acc: 0.8222 - val_loss: 0.1839 - val_acc: 0.8500\n",
            "Epoch 141/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1227 - acc: 0.8389 - val_loss: 0.1848 - val_acc: 0.9000\n",
            "Epoch 142/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1232 - acc: 0.8333 - val_loss: 0.1840 - val_acc: 0.8500\n",
            "Epoch 143/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1224 - acc: 0.8333 - val_loss: 0.1860 - val_acc: 0.9000\n",
            "Epoch 144/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1226 - acc: 0.8444 - val_loss: 0.1836 - val_acc: 0.9000\n",
            "Epoch 145/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1226 - acc: 0.8444 - val_loss: 0.1832 - val_acc: 0.9500\n",
            "Epoch 146/800\n",
            "180/180 [==============================] - 0s 328us/step - loss: 0.1220 - acc: 0.8333 - val_loss: 0.1820 - val_acc: 0.9000\n",
            "Epoch 147/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1225 - acc: 0.8167 - val_loss: 0.1828 - val_acc: 0.8500\n",
            "Epoch 148/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1214 - acc: 0.8278 - val_loss: 0.1807 - val_acc: 0.9500\n",
            "Epoch 149/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1214 - acc: 0.8389 - val_loss: 0.1821 - val_acc: 0.9000\n",
            "Epoch 150/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1216 - acc: 0.8333 - val_loss: 0.1809 - val_acc: 0.8500\n",
            "Epoch 151/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1206 - acc: 0.8278 - val_loss: 0.1837 - val_acc: 0.8500\n",
            "Epoch 152/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1211 - acc: 0.8389 - val_loss: 0.1813 - val_acc: 0.9000\n",
            "Epoch 153/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1208 - acc: 0.8444 - val_loss: 0.1804 - val_acc: 0.9000\n",
            "Epoch 154/800\n",
            "180/180 [==============================] - 0s 409us/step - loss: 0.1201 - acc: 0.8389 - val_loss: 0.1819 - val_acc: 0.9500\n",
            "Epoch 155/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1205 - acc: 0.8333 - val_loss: 0.1805 - val_acc: 0.8500\n",
            "Epoch 156/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.1200 - acc: 0.8333 - val_loss: 0.1807 - val_acc: 0.9000\n",
            "Epoch 157/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1197 - acc: 0.8500 - val_loss: 0.1831 - val_acc: 0.8000\n",
            "Epoch 158/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1202 - acc: 0.8278 - val_loss: 0.1808 - val_acc: 0.9000\n",
            "Epoch 159/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1198 - acc: 0.8500 - val_loss: 0.1806 - val_acc: 0.9000\n",
            "Epoch 160/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1190 - acc: 0.8389 - val_loss: 0.1785 - val_acc: 0.9500\n",
            "Epoch 161/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1198 - acc: 0.8500 - val_loss: 0.1799 - val_acc: 0.9000\n",
            "Epoch 162/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1195 - acc: 0.8500 - val_loss: 0.1793 - val_acc: 0.9500\n",
            "Epoch 163/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1189 - acc: 0.8500 - val_loss: 0.1815 - val_acc: 0.9500\n",
            "Epoch 164/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1188 - acc: 0.8444 - val_loss: 0.1790 - val_acc: 0.8000\n",
            "Epoch 165/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1192 - acc: 0.8389 - val_loss: 0.1780 - val_acc: 0.9000\n",
            "Epoch 166/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1190 - acc: 0.8444 - val_loss: 0.1783 - val_acc: 0.9000\n",
            "Epoch 167/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1183 - acc: 0.8500 - val_loss: 0.1787 - val_acc: 0.9500\n",
            "Epoch 168/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1181 - acc: 0.8278 - val_loss: 0.1805 - val_acc: 0.8000\n",
            "Epoch 169/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.1182 - acc: 0.8222 - val_loss: 0.1790 - val_acc: 0.9500\n",
            "Epoch 170/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1183 - acc: 0.8389 - val_loss: 0.1782 - val_acc: 0.9000\n",
            "Epoch 171/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1179 - acc: 0.8444 - val_loss: 0.1769 - val_acc: 0.9500\n",
            "Epoch 172/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1176 - acc: 0.8389 - val_loss: 0.1789 - val_acc: 0.9500\n",
            "Epoch 173/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1175 - acc: 0.8444 - val_loss: 0.1769 - val_acc: 0.9500\n",
            "Epoch 174/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1173 - acc: 0.8444 - val_loss: 0.1777 - val_acc: 0.9000\n",
            "Epoch 175/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1174 - acc: 0.8333 - val_loss: 0.1770 - val_acc: 0.8500\n",
            "Epoch 176/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1170 - acc: 0.8389 - val_loss: 0.1786 - val_acc: 0.8000\n",
            "Epoch 177/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1169 - acc: 0.8278 - val_loss: 0.1783 - val_acc: 0.8000\n",
            "Epoch 178/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.1163 - acc: 0.8333 - val_loss: 0.1768 - val_acc: 0.9000\n",
            "Epoch 179/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1169 - acc: 0.8500 - val_loss: 0.1774 - val_acc: 0.8500\n",
            "Epoch 180/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1164 - acc: 0.8333 - val_loss: 0.1761 - val_acc: 0.9000\n",
            "Epoch 181/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1162 - acc: 0.8556 - val_loss: 0.1754 - val_acc: 0.8000\n",
            "Epoch 182/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1162 - acc: 0.8333 - val_loss: 0.1769 - val_acc: 0.8000\n",
            "Epoch 183/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1160 - acc: 0.8500 - val_loss: 0.1781 - val_acc: 0.8000\n",
            "Epoch 184/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1164 - acc: 0.8444 - val_loss: 0.1767 - val_acc: 0.8000\n",
            "Epoch 185/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1158 - acc: 0.8333 - val_loss: 0.1759 - val_acc: 0.9500\n",
            "Epoch 186/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1155 - acc: 0.8444 - val_loss: 0.1770 - val_acc: 0.9000\n",
            "Epoch 187/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1160 - acc: 0.8444 - val_loss: 0.1760 - val_acc: 0.9000\n",
            "Epoch 188/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1152 - acc: 0.8333 - val_loss: 0.1761 - val_acc: 0.8000\n",
            "Epoch 189/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1152 - acc: 0.8389 - val_loss: 0.1761 - val_acc: 0.8000\n",
            "Epoch 190/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1153 - acc: 0.8444 - val_loss: 0.1746 - val_acc: 0.8500\n",
            "Epoch 191/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1153 - acc: 0.8500 - val_loss: 0.1761 - val_acc: 0.9000\n",
            "Epoch 192/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1153 - acc: 0.8389 - val_loss: 0.1743 - val_acc: 0.9500\n",
            "Epoch 193/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1150 - acc: 0.8278 - val_loss: 0.1756 - val_acc: 0.8500\n",
            "Epoch 194/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1158 - acc: 0.8389 - val_loss: 0.1751 - val_acc: 0.8500\n",
            "Epoch 195/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1146 - acc: 0.8500 - val_loss: 0.1756 - val_acc: 0.8000\n",
            "Epoch 196/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1146 - acc: 0.8333 - val_loss: 0.1752 - val_acc: 0.8000\n",
            "Epoch 197/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1146 - acc: 0.8500 - val_loss: 0.1746 - val_acc: 0.8500\n",
            "Epoch 198/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1144 - acc: 0.8333 - val_loss: 0.1750 - val_acc: 0.8000\n",
            "Epoch 199/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1141 - acc: 0.8389 - val_loss: 0.1766 - val_acc: 0.8000\n",
            "Epoch 200/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1145 - acc: 0.8278 - val_loss: 0.1759 - val_acc: 0.8000\n",
            "Epoch 201/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1142 - acc: 0.8333 - val_loss: 0.1744 - val_acc: 0.8000\n",
            "Epoch 202/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1139 - acc: 0.8444 - val_loss: 0.1731 - val_acc: 0.8500\n",
            "Epoch 203/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1134 - acc: 0.8500 - val_loss: 0.1768 - val_acc: 0.8000\n",
            "Epoch 204/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1137 - acc: 0.8278 - val_loss: 0.1720 - val_acc: 0.9000\n",
            "Epoch 205/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1136 - acc: 0.8333 - val_loss: 0.1741 - val_acc: 0.8000\n",
            "Epoch 206/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1138 - acc: 0.8500 - val_loss: 0.1723 - val_acc: 0.8500\n",
            "Epoch 207/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1132 - acc: 0.8389 - val_loss: 0.1722 - val_acc: 0.8500\n",
            "Epoch 208/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1129 - acc: 0.8389 - val_loss: 0.1734 - val_acc: 0.9000\n",
            "Epoch 209/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1136 - acc: 0.8389 - val_loss: 0.1751 - val_acc: 0.8500\n",
            "Epoch 210/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1136 - acc: 0.8444 - val_loss: 0.1730 - val_acc: 0.9000\n",
            "Epoch 211/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1131 - acc: 0.8500 - val_loss: 0.1751 - val_acc: 0.8500\n",
            "Epoch 212/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.1132 - acc: 0.8333 - val_loss: 0.1736 - val_acc: 0.8500\n",
            "Epoch 213/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1128 - acc: 0.8556 - val_loss: 0.1745 - val_acc: 0.8000\n",
            "Epoch 214/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1126 - acc: 0.8389 - val_loss: 0.1740 - val_acc: 0.8000\n",
            "Epoch 215/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1130 - acc: 0.8333 - val_loss: 0.1724 - val_acc: 0.8500\n",
            "Epoch 216/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.1128 - acc: 0.8500 - val_loss: 0.1726 - val_acc: 0.8000\n",
            "Epoch 217/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1126 - acc: 0.8222 - val_loss: 0.1721 - val_acc: 0.9000\n",
            "Epoch 218/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1123 - acc: 0.8389 - val_loss: 0.1735 - val_acc: 0.8500\n",
            "Epoch 219/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1132 - acc: 0.8333 - val_loss: 0.1734 - val_acc: 0.8000\n",
            "Epoch 220/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1120 - acc: 0.8389 - val_loss: 0.1742 - val_acc: 0.8000\n",
            "Epoch 221/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1125 - acc: 0.8444 - val_loss: 0.1705 - val_acc: 0.9000\n",
            "Epoch 222/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1124 - acc: 0.8389 - val_loss: 0.1723 - val_acc: 0.9500\n",
            "Epoch 223/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1124 - acc: 0.8444 - val_loss: 0.1714 - val_acc: 0.9000\n",
            "Epoch 224/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1114 - acc: 0.8389 - val_loss: 0.1746 - val_acc: 0.8000\n",
            "Epoch 225/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1117 - acc: 0.8500 - val_loss: 0.1728 - val_acc: 0.8500\n",
            "Epoch 226/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1119 - acc: 0.8333 - val_loss: 0.1716 - val_acc: 0.8000\n",
            "Epoch 227/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1116 - acc: 0.8444 - val_loss: 0.1738 - val_acc: 0.8000\n",
            "Epoch 228/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1118 - acc: 0.8278 - val_loss: 0.1718 - val_acc: 0.8000\n",
            "Epoch 229/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1118 - acc: 0.8444 - val_loss: 0.1718 - val_acc: 0.9000\n",
            "Epoch 230/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1110 - acc: 0.8278 - val_loss: 0.1728 - val_acc: 0.8500\n",
            "Epoch 231/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1113 - acc: 0.8667 - val_loss: 0.1710 - val_acc: 0.8500\n",
            "Epoch 232/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1111 - acc: 0.8444 - val_loss: 0.1716 - val_acc: 0.8000\n",
            "Epoch 233/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1111 - acc: 0.8278 - val_loss: 0.1718 - val_acc: 0.8000\n",
            "Epoch 234/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1109 - acc: 0.8333 - val_loss: 0.1718 - val_acc: 0.8500\n",
            "Epoch 235/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1107 - acc: 0.8333 - val_loss: 0.1714 - val_acc: 0.8500\n",
            "Epoch 236/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.1113 - acc: 0.8333 - val_loss: 0.1707 - val_acc: 0.8500\n",
            "Epoch 237/800\n",
            "180/180 [==============================] - 0s 400us/step - loss: 0.1103 - acc: 0.8500 - val_loss: 0.1704 - val_acc: 0.9500\n",
            "Epoch 238/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1104 - acc: 0.8389 - val_loss: 0.1703 - val_acc: 0.8000\n",
            "Epoch 239/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1103 - acc: 0.8389 - val_loss: 0.1696 - val_acc: 0.9000\n",
            "Epoch 240/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1103 - acc: 0.8278 - val_loss: 0.1717 - val_acc: 0.8000\n",
            "Epoch 241/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1107 - acc: 0.8611 - val_loss: 0.1706 - val_acc: 0.9000\n",
            "Epoch 242/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1112 - acc: 0.8389 - val_loss: 0.1708 - val_acc: 0.9000\n",
            "Epoch 243/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1105 - acc: 0.8444 - val_loss: 0.1703 - val_acc: 0.8000\n",
            "Epoch 244/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1114 - acc: 0.8556 - val_loss: 0.1705 - val_acc: 0.9000\n",
            "Epoch 245/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1100 - acc: 0.8389 - val_loss: 0.1698 - val_acc: 0.8500\n",
            "Epoch 246/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1099 - acc: 0.8444 - val_loss: 0.1713 - val_acc: 0.9500\n",
            "Epoch 247/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1103 - acc: 0.8556 - val_loss: 0.1709 - val_acc: 0.9000\n",
            "Epoch 248/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1098 - acc: 0.8444 - val_loss: 0.1696 - val_acc: 0.9500\n",
            "Epoch 249/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1099 - acc: 0.8444 - val_loss: 0.1690 - val_acc: 0.9000\n",
            "Epoch 250/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1104 - acc: 0.8444 - val_loss: 0.1692 - val_acc: 0.9500\n",
            "Epoch 251/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1096 - acc: 0.8389 - val_loss: 0.1699 - val_acc: 0.9000\n",
            "Epoch 252/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1097 - acc: 0.8500 - val_loss: 0.1696 - val_acc: 0.9000\n",
            "Epoch 253/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1094 - acc: 0.8389 - val_loss: 0.1697 - val_acc: 0.8000\n",
            "Epoch 254/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1096 - acc: 0.8444 - val_loss: 0.1683 - val_acc: 0.9000\n",
            "Epoch 255/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1093 - acc: 0.8611 - val_loss: 0.1702 - val_acc: 0.9000\n",
            "Epoch 256/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1096 - acc: 0.8556 - val_loss: 0.1696 - val_acc: 0.9000\n",
            "Epoch 257/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1097 - acc: 0.8500 - val_loss: 0.1705 - val_acc: 0.9000\n",
            "Epoch 258/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.1096 - acc: 0.8556 - val_loss: 0.1692 - val_acc: 1.0000\n",
            "Epoch 259/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1092 - acc: 0.8500 - val_loss: 0.1679 - val_acc: 0.8000\n",
            "Epoch 260/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1093 - acc: 0.8500 - val_loss: 0.1689 - val_acc: 0.9500\n",
            "Epoch 261/800\n",
            "180/180 [==============================] - 0s 323us/step - loss: 0.1090 - acc: 0.8500 - val_loss: 0.1692 - val_acc: 0.8500\n",
            "Epoch 262/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1090 - acc: 0.8444 - val_loss: 0.1702 - val_acc: 1.0000\n",
            "Epoch 263/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1091 - acc: 0.8611 - val_loss: 0.1706 - val_acc: 0.8000\n",
            "Epoch 264/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1093 - acc: 0.8500 - val_loss: 0.1687 - val_acc: 0.9000\n",
            "Epoch 265/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1089 - acc: 0.8556 - val_loss: 0.1701 - val_acc: 0.9500\n",
            "Epoch 266/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1087 - acc: 0.8444 - val_loss: 0.1685 - val_acc: 0.9000\n",
            "Epoch 267/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1087 - acc: 0.8389 - val_loss: 0.1679 - val_acc: 0.9000\n",
            "Epoch 268/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1087 - acc: 0.8389 - val_loss: 0.1691 - val_acc: 0.9000\n",
            "Epoch 269/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1085 - acc: 0.8389 - val_loss: 0.1684 - val_acc: 0.9500\n",
            "Epoch 270/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1683 - val_acc: 0.9000\n",
            "Epoch 271/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1090 - acc: 0.8500 - val_loss: 0.1694 - val_acc: 0.9500\n",
            "Epoch 272/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1091 - acc: 0.8278 - val_loss: 0.1666 - val_acc: 0.9000\n",
            "Epoch 273/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1082 - acc: 0.8444 - val_loss: 0.1696 - val_acc: 0.9500\n",
            "Epoch 274/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1080 - acc: 0.8500 - val_loss: 0.1673 - val_acc: 0.9500\n",
            "Epoch 275/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1081 - acc: 0.8444 - val_loss: 0.1679 - val_acc: 0.9000\n",
            "Epoch 276/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1078 - acc: 0.8444 - val_loss: 0.1676 - val_acc: 0.9000\n",
            "Epoch 277/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1080 - acc: 0.8556 - val_loss: 0.1684 - val_acc: 0.9000\n",
            "Epoch 278/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1075 - acc: 0.8333 - val_loss: 0.1678 - val_acc: 0.8500\n",
            "Epoch 279/800\n",
            "180/180 [==============================] - 0s 408us/step - loss: 0.1085 - acc: 0.8222 - val_loss: 0.1682 - val_acc: 0.9500\n",
            "Epoch 280/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1075 - acc: 0.8389 - val_loss: 0.1682 - val_acc: 0.9000\n",
            "Epoch 281/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.1083 - acc: 0.8333 - val_loss: 0.1690 - val_acc: 0.8500\n",
            "Epoch 282/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.1078 - acc: 0.8500 - val_loss: 0.1682 - val_acc: 0.9000\n",
            "Epoch 283/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1073 - acc: 0.8611 - val_loss: 0.1685 - val_acc: 0.8500\n",
            "Epoch 284/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1074 - acc: 0.8500 - val_loss: 0.1673 - val_acc: 0.9000\n",
            "Epoch 285/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1071 - acc: 0.8389 - val_loss: 0.1685 - val_acc: 0.9500\n",
            "Epoch 286/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1076 - acc: 0.8389 - val_loss: 0.1682 - val_acc: 0.9500\n",
            "Epoch 287/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1076 - acc: 0.8444 - val_loss: 0.1694 - val_acc: 0.8500\n",
            "Epoch 288/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1074 - acc: 0.8667 - val_loss: 0.1701 - val_acc: 0.8500\n",
            "Epoch 289/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.1071 - acc: 0.8556 - val_loss: 0.1671 - val_acc: 0.9000\n",
            "Epoch 290/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1070 - acc: 0.8389 - val_loss: 0.1683 - val_acc: 0.8500\n",
            "Epoch 291/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1087 - acc: 0.8500 - val_loss: 0.1682 - val_acc: 0.9000\n",
            "Epoch 292/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1075 - acc: 0.8389 - val_loss: 0.1666 - val_acc: 0.9000\n",
            "Epoch 293/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1070 - acc: 0.8500 - val_loss: 0.1681 - val_acc: 0.9000\n",
            "Epoch 294/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1072 - acc: 0.8667 - val_loss: 0.1676 - val_acc: 0.9000\n",
            "Epoch 295/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.1070 - acc: 0.8333 - val_loss: 0.1672 - val_acc: 0.8000\n",
            "Epoch 296/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1075 - acc: 0.8500 - val_loss: 0.1685 - val_acc: 0.8500\n",
            "Epoch 297/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1071 - acc: 0.8556 - val_loss: 0.1662 - val_acc: 0.9000\n",
            "Epoch 298/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1071 - acc: 0.8444 - val_loss: 0.1675 - val_acc: 0.9500\n",
            "Epoch 299/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1070 - acc: 0.8556 - val_loss: 0.1695 - val_acc: 0.8500\n",
            "Epoch 300/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1071 - acc: 0.8389 - val_loss: 0.1675 - val_acc: 1.0000\n",
            "Epoch 301/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.1066 - acc: 0.8611 - val_loss: 0.1657 - val_acc: 0.9500\n",
            "Epoch 302/800\n",
            "180/180 [==============================] - 0s 323us/step - loss: 0.1072 - acc: 0.8722 - val_loss: 0.1671 - val_acc: 0.9000\n",
            "Epoch 303/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1064 - acc: 0.8444 - val_loss: 0.1662 - val_acc: 1.0000\n",
            "Epoch 304/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1067 - acc: 0.8500 - val_loss: 0.1661 - val_acc: 0.9500\n",
            "Epoch 305/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1066 - acc: 0.8500 - val_loss: 0.1697 - val_acc: 0.9000\n",
            "Epoch 306/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1067 - acc: 0.8556 - val_loss: 0.1667 - val_acc: 0.9000\n",
            "Epoch 307/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1077 - acc: 0.8722 - val_loss: 0.1675 - val_acc: 0.9000\n",
            "Epoch 308/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1064 - acc: 0.8389 - val_loss: 0.1680 - val_acc: 0.9500\n",
            "Epoch 309/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1062 - acc: 0.8444 - val_loss: 0.1657 - val_acc: 0.9500\n",
            "Epoch 310/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1067 - acc: 0.8611 - val_loss: 0.1657 - val_acc: 0.9500\n",
            "Epoch 311/800\n",
            "180/180 [==============================] - 0s 323us/step - loss: 0.1068 - acc: 0.8444 - val_loss: 0.1684 - val_acc: 0.8500\n",
            "Epoch 312/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1066 - acc: 0.8278 - val_loss: 0.1669 - val_acc: 0.9000\n",
            "Epoch 313/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1077 - acc: 0.8556 - val_loss: 0.1689 - val_acc: 0.9000\n",
            "Epoch 314/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1063 - acc: 0.8500 - val_loss: 0.1658 - val_acc: 0.9500\n",
            "Epoch 315/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1061 - acc: 0.8611 - val_loss: 0.1668 - val_acc: 0.9500\n",
            "Epoch 316/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1061 - acc: 0.8611 - val_loss: 0.1698 - val_acc: 0.8500\n",
            "Epoch 317/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1058 - acc: 0.8611 - val_loss: 0.1660 - val_acc: 0.9000\n",
            "Epoch 318/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1059 - acc: 0.8389 - val_loss: 0.1654 - val_acc: 0.9500\n",
            "Epoch 319/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1060 - acc: 0.8722 - val_loss: 0.1678 - val_acc: 0.9500\n",
            "Epoch 320/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1058 - acc: 0.8389 - val_loss: 0.1661 - val_acc: 0.9500\n",
            "Epoch 321/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.1052 - acc: 0.8500 - val_loss: 0.1691 - val_acc: 0.9000\n",
            "Epoch 322/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1064 - acc: 0.8667 - val_loss: 0.1652 - val_acc: 0.9500\n",
            "Epoch 323/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1054 - acc: 0.8444 - val_loss: 0.1654 - val_acc: 0.9000\n",
            "Epoch 324/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1056 - acc: 0.8611 - val_loss: 0.1661 - val_acc: 0.9500\n",
            "Epoch 325/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1054 - acc: 0.8556 - val_loss: 0.1666 - val_acc: 1.0000\n",
            "Epoch 326/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1058 - acc: 0.8556 - val_loss: 0.1651 - val_acc: 0.9500\n",
            "Epoch 327/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1056 - acc: 0.8556 - val_loss: 0.1657 - val_acc: 0.9000\n",
            "Epoch 328/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1059 - acc: 0.8667 - val_loss: 0.1665 - val_acc: 0.9000\n",
            "Epoch 329/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1056 - acc: 0.8389 - val_loss: 0.1667 - val_acc: 0.9500\n",
            "Epoch 330/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1054 - acc: 0.8500 - val_loss: 0.1664 - val_acc: 0.8500\n",
            "Epoch 331/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1052 - acc: 0.8444 - val_loss: 0.1672 - val_acc: 0.9500\n",
            "Epoch 332/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1052 - acc: 0.8444 - val_loss: 0.1660 - val_acc: 0.9500\n",
            "Epoch 333/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1049 - acc: 0.8444 - val_loss: 0.1648 - val_acc: 0.9500\n",
            "Epoch 334/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1048 - acc: 0.8611 - val_loss: 0.1656 - val_acc: 0.8500\n",
            "Epoch 335/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1052 - acc: 0.8556 - val_loss: 0.1672 - val_acc: 0.9000\n",
            "Epoch 336/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1059 - acc: 0.8444 - val_loss: 0.1638 - val_acc: 0.9500\n",
            "Epoch 337/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1049 - acc: 0.8611 - val_loss: 0.1680 - val_acc: 0.8500\n",
            "Epoch 338/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1049 - acc: 0.8500 - val_loss: 0.1668 - val_acc: 0.8500\n",
            "Epoch 339/800\n",
            "180/180 [==============================] - 0s 330us/step - loss: 0.1058 - acc: 0.8667 - val_loss: 0.1644 - val_acc: 0.9500\n",
            "Epoch 340/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1059 - acc: 0.8500 - val_loss: 0.1652 - val_acc: 0.9500\n",
            "Epoch 341/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1052 - acc: 0.8556 - val_loss: 0.1651 - val_acc: 1.0000\n",
            "Epoch 342/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1061 - acc: 0.8667 - val_loss: 0.1675 - val_acc: 0.8500\n",
            "Epoch 343/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1052 - acc: 0.8556 - val_loss: 0.1647 - val_acc: 0.9500\n",
            "Epoch 344/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.1049 - acc: 0.8611 - val_loss: 0.1661 - val_acc: 0.9500\n",
            "Epoch 345/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1053 - acc: 0.8500 - val_loss: 0.1655 - val_acc: 0.9000\n",
            "Epoch 346/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1046 - acc: 0.8556 - val_loss: 0.1660 - val_acc: 0.9500\n",
            "Epoch 347/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1046 - acc: 0.8667 - val_loss: 0.1671 - val_acc: 0.8500\n",
            "Epoch 348/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1048 - acc: 0.8667 - val_loss: 0.1667 - val_acc: 0.9000\n",
            "Epoch 349/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1046 - acc: 0.8556 - val_loss: 0.1664 - val_acc: 0.9500\n",
            "Epoch 350/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1046 - acc: 0.8333 - val_loss: 0.1660 - val_acc: 0.9000\n",
            "Epoch 351/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1047 - acc: 0.8389 - val_loss: 0.1645 - val_acc: 0.9500\n",
            "Epoch 352/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1049 - acc: 0.8611 - val_loss: 0.1642 - val_acc: 0.9500\n",
            "Epoch 353/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1042 - acc: 0.8667 - val_loss: 0.1650 - val_acc: 0.9000\n",
            "Epoch 354/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1043 - acc: 0.8444 - val_loss: 0.1663 - val_acc: 0.8500\n",
            "Epoch 355/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1051 - acc: 0.8444 - val_loss: 0.1655 - val_acc: 0.9000\n",
            "Epoch 356/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1045 - acc: 0.8556 - val_loss: 0.1646 - val_acc: 0.9500\n",
            "Epoch 357/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1045 - acc: 0.8556 - val_loss: 0.1650 - val_acc: 0.9500\n",
            "Epoch 358/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1052 - acc: 0.8667 - val_loss: 0.1657 - val_acc: 0.9500\n",
            "Epoch 359/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1038 - acc: 0.8500 - val_loss: 0.1655 - val_acc: 0.9500\n",
            "Epoch 360/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1043 - acc: 0.8556 - val_loss: 0.1652 - val_acc: 0.9000\n",
            "Epoch 361/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1043 - acc: 0.8500 - val_loss: 0.1681 - val_acc: 0.8500\n",
            "Epoch 362/800\n",
            "180/180 [==============================] - 0s 335us/step - loss: 0.1049 - acc: 0.8611 - val_loss: 0.1661 - val_acc: 0.8500\n",
            "Epoch 363/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1048 - acc: 0.8611 - val_loss: 0.1666 - val_acc: 0.9500\n",
            "Epoch 364/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1054 - acc: 0.8500 - val_loss: 0.1646 - val_acc: 0.8500\n",
            "Epoch 365/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1041 - acc: 0.8611 - val_loss: 0.1641 - val_acc: 1.0000\n",
            "Epoch 366/800\n",
            "180/180 [==============================] - 0s 329us/step - loss: 0.1039 - acc: 0.8389 - val_loss: 0.1640 - val_acc: 0.9500\n",
            "Epoch 367/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1042 - acc: 0.8444 - val_loss: 0.1651 - val_acc: 0.8500\n",
            "Epoch 368/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1036 - acc: 0.8667 - val_loss: 0.1654 - val_acc: 0.9500\n",
            "Epoch 369/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.1038 - acc: 0.8500 - val_loss: 0.1644 - val_acc: 0.9500\n",
            "Epoch 370/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1035 - acc: 0.8500 - val_loss: 0.1651 - val_acc: 0.9500\n",
            "Epoch 371/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1038 - acc: 0.8667 - val_loss: 0.1643 - val_acc: 0.9000\n",
            "Epoch 372/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1037 - acc: 0.8444 - val_loss: 0.1641 - val_acc: 1.0000\n",
            "Epoch 373/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1041 - acc: 0.8667 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 374/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1041 - acc: 0.8444 - val_loss: 0.1641 - val_acc: 0.9500\n",
            "Epoch 375/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1033 - acc: 0.8444 - val_loss: 0.1648 - val_acc: 0.9500\n",
            "Epoch 376/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1035 - acc: 0.8389 - val_loss: 0.1643 - val_acc: 0.9500\n",
            "Epoch 377/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1033 - acc: 0.8611 - val_loss: 0.1645 - val_acc: 0.9500\n",
            "Epoch 378/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1037 - acc: 0.8667 - val_loss: 0.1658 - val_acc: 0.9000\n",
            "Epoch 379/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1031 - acc: 0.8444 - val_loss: 0.1664 - val_acc: 0.9000\n",
            "Epoch 380/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1033 - acc: 0.8667 - val_loss: 0.1648 - val_acc: 0.9000\n",
            "Epoch 381/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1044 - acc: 0.8778 - val_loss: 0.1652 - val_acc: 0.9500\n",
            "Epoch 382/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1038 - acc: 0.8500 - val_loss: 0.1639 - val_acc: 0.9500\n",
            "Epoch 383/800\n",
            "180/180 [==============================] - 0s 447us/step - loss: 0.1032 - acc: 0.8556 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 384/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1032 - acc: 0.8611 - val_loss: 0.1636 - val_acc: 0.9500\n",
            "Epoch 385/800\n",
            "180/180 [==============================] - 0s 331us/step - loss: 0.1035 - acc: 0.8556 - val_loss: 0.1672 - val_acc: 0.9000\n",
            "Epoch 386/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1034 - acc: 0.8556 - val_loss: 0.1635 - val_acc: 0.9500\n",
            "Epoch 387/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1033 - acc: 0.8667 - val_loss: 0.1624 - val_acc: 0.9500\n",
            "Epoch 388/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.1032 - acc: 0.8722 - val_loss: 0.1663 - val_acc: 1.0000\n",
            "Epoch 389/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1050 - acc: 0.8722 - val_loss: 0.1651 - val_acc: 0.9500\n",
            "Epoch 390/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1031 - acc: 0.8556 - val_loss: 0.1646 - val_acc: 0.9500\n",
            "Epoch 391/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1037 - acc: 0.8444 - val_loss: 0.1660 - val_acc: 0.9500\n",
            "Epoch 392/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1030 - acc: 0.8667 - val_loss: 0.1645 - val_acc: 0.9000\n",
            "Epoch 393/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1029 - acc: 0.8556 - val_loss: 0.1634 - val_acc: 0.9500\n",
            "Epoch 394/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1027 - acc: 0.8389 - val_loss: 0.1652 - val_acc: 0.9500\n",
            "Epoch 395/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1042 - acc: 0.8778 - val_loss: 0.1645 - val_acc: 0.8500\n",
            "Epoch 396/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1032 - acc: 0.8667 - val_loss: 0.1633 - val_acc: 0.9000\n",
            "Epoch 397/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1027 - acc: 0.8556 - val_loss: 0.1642 - val_acc: 0.8500\n",
            "Epoch 398/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1035 - acc: 0.8444 - val_loss: 0.1660 - val_acc: 0.9500\n",
            "Epoch 399/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1031 - acc: 0.8667 - val_loss: 0.1634 - val_acc: 0.9500\n",
            "Epoch 400/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1027 - acc: 0.8611 - val_loss: 0.1624 - val_acc: 0.9500\n",
            "Epoch 401/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1033 - acc: 0.8500 - val_loss: 0.1644 - val_acc: 1.0000\n",
            "Epoch 402/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1028 - acc: 0.8611 - val_loss: 0.1619 - val_acc: 1.0000\n",
            "Epoch 403/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1031 - acc: 0.8444 - val_loss: 0.1629 - val_acc: 0.9500\n",
            "Epoch 404/800\n",
            "180/180 [==============================] - 0s 427us/step - loss: 0.1027 - acc: 0.8778 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 405/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1027 - acc: 0.8556 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 406/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1029 - acc: 0.8500 - val_loss: 0.1639 - val_acc: 0.9000\n",
            "Epoch 407/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1026 - acc: 0.8611 - val_loss: 0.1650 - val_acc: 0.8500\n",
            "Epoch 408/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1026 - acc: 0.8611 - val_loss: 0.1661 - val_acc: 0.9000\n",
            "Epoch 409/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1030 - acc: 0.8556 - val_loss: 0.1622 - val_acc: 0.9500\n",
            "Epoch 410/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.8667 - val_loss: 0.1635 - val_acc: 0.9000\n",
            "Epoch 411/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1026 - acc: 0.8778 - val_loss: 0.1636 - val_acc: 0.9500\n",
            "Epoch 412/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.8556 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 413/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1026 - acc: 0.8556 - val_loss: 0.1633 - val_acc: 0.9500\n",
            "Epoch 414/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1023 - acc: 0.8722 - val_loss: 0.1621 - val_acc: 0.9500\n",
            "Epoch 415/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1022 - acc: 0.8556 - val_loss: 0.1657 - val_acc: 0.8500\n",
            "Epoch 416/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1033 - acc: 0.8611 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 417/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1032 - acc: 0.8500 - val_loss: 0.1622 - val_acc: 0.9500\n",
            "Epoch 418/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1018 - acc: 0.8722 - val_loss: 0.1654 - val_acc: 0.9000\n",
            "Epoch 419/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1031 - acc: 0.8667 - val_loss: 0.1630 - val_acc: 0.9000\n",
            "Epoch 420/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1025 - acc: 0.8667 - val_loss: 0.1678 - val_acc: 0.8500\n",
            "Epoch 421/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1028 - acc: 0.8389 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 422/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1023 - acc: 0.8556 - val_loss: 0.1641 - val_acc: 1.0000\n",
            "Epoch 423/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1032 - acc: 0.8556 - val_loss: 0.1622 - val_acc: 0.9500\n",
            "Epoch 424/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1019 - acc: 0.8556 - val_loss: 0.1636 - val_acc: 0.9500\n",
            "Epoch 425/800\n",
            "180/180 [==============================] - 0s 394us/step - loss: 0.1025 - acc: 0.8500 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 426/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1019 - acc: 0.8611 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 427/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.8556 - val_loss: 0.1639 - val_acc: 0.8500\n",
            "Epoch 428/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1019 - acc: 0.8556 - val_loss: 0.1629 - val_acc: 0.9500\n",
            "Epoch 429/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1019 - acc: 0.8611 - val_loss: 0.1637 - val_acc: 0.8500\n",
            "Epoch 430/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1022 - acc: 0.8611 - val_loss: 0.1650 - val_acc: 0.9500\n",
            "Epoch 431/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1023 - acc: 0.8556 - val_loss: 0.1648 - val_acc: 0.9500\n",
            "Epoch 432/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1031 - acc: 0.8667 - val_loss: 0.1643 - val_acc: 1.0000\n",
            "Epoch 433/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1021 - acc: 0.8722 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 434/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1021 - acc: 0.8667 - val_loss: 0.1624 - val_acc: 0.9500\n",
            "Epoch 435/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1026 - acc: 0.8389 - val_loss: 0.1626 - val_acc: 0.9500\n",
            "Epoch 436/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1016 - acc: 0.8722 - val_loss: 0.1617 - val_acc: 0.9500\n",
            "Epoch 437/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1048 - acc: 0.8500 - val_loss: 0.1653 - val_acc: 0.9500\n",
            "Epoch 438/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1027 - acc: 0.8444 - val_loss: 0.1647 - val_acc: 0.9500\n",
            "Epoch 439/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1023 - acc: 0.8722 - val_loss: 0.1626 - val_acc: 1.0000\n",
            "Epoch 440/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1023 - acc: 0.8722 - val_loss: 0.1621 - val_acc: 0.9500\n",
            "Epoch 441/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1029 - acc: 0.8722 - val_loss: 0.1649 - val_acc: 0.9500\n",
            "Epoch 442/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1024 - acc: 0.8611 - val_loss: 0.1621 - val_acc: 0.9500\n",
            "Epoch 443/800\n",
            "180/180 [==============================] - 0s 329us/step - loss: 0.1016 - acc: 0.8778 - val_loss: 0.1649 - val_acc: 0.9000\n",
            "Epoch 444/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1019 - acc: 0.8500 - val_loss: 0.1609 - val_acc: 0.9500\n",
            "Epoch 445/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1021 - acc: 0.8778 - val_loss: 0.1640 - val_acc: 0.8500\n",
            "Epoch 446/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.1017 - acc: 0.8556 - val_loss: 0.1639 - val_acc: 0.9500\n",
            "Epoch 447/800\n",
            "180/180 [==============================] - 0s 329us/step - loss: 0.1022 - acc: 0.8778 - val_loss: 0.1648 - val_acc: 0.9500\n",
            "Epoch 448/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.1030 - acc: 0.8667 - val_loss: 0.1609 - val_acc: 0.9500\n",
            "Epoch 449/800\n",
            "180/180 [==============================] - 0s 324us/step - loss: 0.1018 - acc: 0.8611 - val_loss: 0.1632 - val_acc: 0.9000\n",
            "Epoch 450/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1019 - acc: 0.8611 - val_loss: 0.1624 - val_acc: 0.9500\n",
            "Epoch 451/800\n",
            "180/180 [==============================] - 0s 324us/step - loss: 0.1018 - acc: 0.8722 - val_loss: 0.1618 - val_acc: 0.9500\n",
            "Epoch 452/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.8556 - val_loss: 0.1638 - val_acc: 0.9500\n",
            "Epoch 453/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1029 - acc: 0.8889 - val_loss: 0.1649 - val_acc: 0.9500\n",
            "Epoch 454/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1016 - acc: 0.8722 - val_loss: 0.1631 - val_acc: 0.9000\n",
            "Epoch 455/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1022 - acc: 0.8667 - val_loss: 0.1637 - val_acc: 0.9500\n",
            "Epoch 456/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1012 - acc: 0.8667 - val_loss: 0.1628 - val_acc: 0.9500\n",
            "Epoch 457/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1019 - acc: 0.8611 - val_loss: 0.1638 - val_acc: 0.9500\n",
            "Epoch 458/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.1017 - acc: 0.8611 - val_loss: 0.1636 - val_acc: 0.9500\n",
            "Epoch 459/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1039 - acc: 0.8556 - val_loss: 0.1615 - val_acc: 0.9500\n",
            "Epoch 460/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1012 - acc: 0.8611 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 461/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1016 - acc: 0.8722 - val_loss: 0.1624 - val_acc: 0.9500\n",
            "Epoch 462/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1017 - acc: 0.8556 - val_loss: 0.1628 - val_acc: 1.0000\n",
            "Epoch 463/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1015 - acc: 0.8778 - val_loss: 0.1629 - val_acc: 0.9500\n",
            "Epoch 464/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1012 - acc: 0.8611 - val_loss: 0.1611 - val_acc: 1.0000\n",
            "Epoch 465/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1013 - acc: 0.8667 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 466/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1011 - acc: 0.8611 - val_loss: 0.1615 - val_acc: 0.9500\n",
            "Epoch 467/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1016 - acc: 0.8611 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 468/800\n",
            "180/180 [==============================] - 0s 324us/step - loss: 0.1033 - acc: 0.8611 - val_loss: 0.1655 - val_acc: 0.9500\n",
            "Epoch 469/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1038 - acc: 0.8611 - val_loss: 0.1642 - val_acc: 0.9500\n",
            "Epoch 470/800\n",
            "180/180 [==============================] - 0s 328us/step - loss: 0.1018 - acc: 0.8778 - val_loss: 0.1638 - val_acc: 0.9500\n",
            "Epoch 471/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1008 - acc: 0.8667 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 472/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1021 - acc: 0.8833 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 473/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1014 - acc: 0.8667 - val_loss: 0.1615 - val_acc: 0.9500\n",
            "Epoch 474/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1012 - acc: 0.8611 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 475/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1011 - acc: 0.8667 - val_loss: 0.1629 - val_acc: 0.9500\n",
            "Epoch 476/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1009 - acc: 0.8722 - val_loss: 0.1617 - val_acc: 0.9500\n",
            "Epoch 477/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1016 - acc: 0.8722 - val_loss: 0.1617 - val_acc: 0.9500\n",
            "Epoch 478/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1012 - acc: 0.8444 - val_loss: 0.1626 - val_acc: 1.0000\n",
            "Epoch 479/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1019 - acc: 0.8667 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 480/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1014 - acc: 0.8556 - val_loss: 0.1619 - val_acc: 0.9500\n",
            "Epoch 481/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1009 - acc: 0.8500 - val_loss: 0.1606 - val_acc: 0.9500\n",
            "Epoch 482/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1010 - acc: 0.8667 - val_loss: 0.1610 - val_acc: 1.0000\n",
            "Epoch 483/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1022 - acc: 0.8667 - val_loss: 0.1633 - val_acc: 0.9500\n",
            "Epoch 484/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1010 - acc: 0.8667 - val_loss: 0.1616 - val_acc: 0.9500\n",
            "Epoch 485/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1006 - acc: 0.8722 - val_loss: 0.1616 - val_acc: 0.9500\n",
            "Epoch 486/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.1009 - acc: 0.8611 - val_loss: 0.1636 - val_acc: 0.9500\n",
            "Epoch 487/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1014 - acc: 0.8556 - val_loss: 0.1608 - val_acc: 0.9500\n",
            "Epoch 488/800\n",
            "180/180 [==============================] - 0s 335us/step - loss: 0.1010 - acc: 0.8611 - val_loss: 0.1604 - val_acc: 1.0000\n",
            "Epoch 489/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1011 - acc: 0.8556 - val_loss: 0.1618 - val_acc: 0.9500\n",
            "Epoch 490/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1008 - acc: 0.8778 - val_loss: 0.1605 - val_acc: 0.9500\n",
            "Epoch 491/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1005 - acc: 0.8556 - val_loss: 0.1619 - val_acc: 0.9500\n",
            "Epoch 492/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1012 - acc: 0.8556 - val_loss: 0.1620 - val_acc: 0.9500\n",
            "Epoch 493/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1008 - acc: 0.8722 - val_loss: 0.1626 - val_acc: 0.9500\n",
            "Epoch 494/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1006 - acc: 0.8611 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 495/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1010 - acc: 0.8667 - val_loss: 0.1633 - val_acc: 0.9500\n",
            "Epoch 496/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.1012 - acc: 0.8722 - val_loss: 0.1643 - val_acc: 1.0000\n",
            "Epoch 497/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1006 - acc: 0.8444 - val_loss: 0.1608 - val_acc: 0.9500\n",
            "Epoch 498/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1001 - acc: 0.8611 - val_loss: 0.1618 - val_acc: 0.9500\n",
            "Epoch 499/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1024 - acc: 0.8722 - val_loss: 0.1610 - val_acc: 0.9500\n",
            "Epoch 500/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1010 - acc: 0.8667 - val_loss: 0.1626 - val_acc: 0.9500\n",
            "Epoch 501/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1009 - acc: 0.8667 - val_loss: 0.1605 - val_acc: 0.9500\n",
            "Epoch 502/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1003 - acc: 0.8611 - val_loss: 0.1611 - val_acc: 0.9500\n",
            "Epoch 503/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1008 - acc: 0.8722 - val_loss: 0.1681 - val_acc: 0.8500\n",
            "Epoch 504/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1013 - acc: 0.8556 - val_loss: 0.1614 - val_acc: 0.9500\n",
            "Epoch 505/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1005 - acc: 0.8611 - val_loss: 0.1616 - val_acc: 0.9500\n",
            "Epoch 506/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1006 - acc: 0.8722 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 507/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1002 - acc: 0.8556 - val_loss: 0.1613 - val_acc: 1.0000\n",
            "Epoch 508/800\n",
            "180/180 [==============================] - 0s 427us/step - loss: 0.1007 - acc: 0.8667 - val_loss: 0.1603 - val_acc: 0.9500\n",
            "Epoch 509/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1003 - acc: 0.8611 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 510/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.1007 - acc: 0.8667 - val_loss: 0.1629 - val_acc: 0.9500\n",
            "Epoch 511/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.1009 - acc: 0.8556 - val_loss: 0.1615 - val_acc: 0.9500\n",
            "Epoch 512/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1006 - acc: 0.8778 - val_loss: 0.1622 - val_acc: 0.9500\n",
            "Epoch 513/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1001 - acc: 0.8444 - val_loss: 0.1612 - val_acc: 1.0000\n",
            "Epoch 514/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1003 - acc: 0.8889 - val_loss: 0.1620 - val_acc: 1.0000\n",
            "Epoch 515/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1004 - acc: 0.8722 - val_loss: 0.1619 - val_acc: 0.9500\n",
            "Epoch 516/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1009 - acc: 0.8500 - val_loss: 0.1618 - val_acc: 0.9500\n",
            "Epoch 517/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1003 - acc: 0.8722 - val_loss: 0.1627 - val_acc: 0.9000\n",
            "Epoch 518/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1011 - acc: 0.8667 - val_loss: 0.1622 - val_acc: 0.9500\n",
            "Epoch 519/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1003 - acc: 0.8611 - val_loss: 0.1616 - val_acc: 0.9500\n",
            "Epoch 520/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1006 - acc: 0.8667 - val_loss: 0.1607 - val_acc: 0.9500\n",
            "Epoch 521/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.0999 - acc: 0.8778 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 522/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0999 - acc: 0.8667 - val_loss: 0.1647 - val_acc: 0.8500\n",
            "Epoch 523/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1010 - acc: 0.8556 - val_loss: 0.1617 - val_acc: 1.0000\n",
            "Epoch 524/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1004 - acc: 0.8500 - val_loss: 0.1603 - val_acc: 0.9500\n",
            "Epoch 525/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1003 - acc: 0.8667 - val_loss: 0.1659 - val_acc: 0.8000\n",
            "Epoch 526/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1008 - acc: 0.8667 - val_loss: 0.1610 - val_acc: 0.9500\n",
            "Epoch 527/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1000 - acc: 0.8611 - val_loss: 0.1616 - val_acc: 0.9500\n",
            "Epoch 528/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1001 - acc: 0.8778 - val_loss: 0.1630 - val_acc: 0.9500\n",
            "Epoch 529/800\n",
            "180/180 [==============================] - 0s 432us/step - loss: 0.1003 - acc: 0.8722 - val_loss: 0.1619 - val_acc: 0.9500\n",
            "Epoch 530/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1002 - acc: 0.8778 - val_loss: 0.1615 - val_acc: 0.9500\n",
            "Epoch 531/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1001 - acc: 0.8556 - val_loss: 0.1610 - val_acc: 0.9500\n",
            "Epoch 532/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1000 - acc: 0.8611 - val_loss: 0.1604 - val_acc: 0.9500\n",
            "Epoch 533/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.0995 - acc: 0.8611 - val_loss: 0.1604 - val_acc: 0.9500\n",
            "Epoch 534/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1013 - acc: 0.8444 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 535/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1008 - acc: 0.8667 - val_loss: 0.1626 - val_acc: 0.9000\n",
            "Epoch 536/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1002 - acc: 0.8611 - val_loss: 0.1608 - val_acc: 1.0000\n",
            "Epoch 537/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.0999 - acc: 0.8722 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 538/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.0998 - acc: 0.8556 - val_loss: 0.1622 - val_acc: 0.9500\n",
            "Epoch 539/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1006 - acc: 0.8778 - val_loss: 0.1640 - val_acc: 0.8500\n",
            "Epoch 540/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1000 - acc: 0.8389 - val_loss: 0.1601 - val_acc: 1.0000\n",
            "Epoch 541/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1002 - acc: 0.8611 - val_loss: 0.1605 - val_acc: 0.9500\n",
            "Epoch 542/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0998 - acc: 0.8667 - val_loss: 0.1614 - val_acc: 0.9500\n",
            "Epoch 543/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.0997 - acc: 0.8722 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 544/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.0998 - acc: 0.8611 - val_loss: 0.1602 - val_acc: 1.0000\n",
            "Epoch 545/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.0997 - acc: 0.8722 - val_loss: 0.1664 - val_acc: 0.9000\n",
            "Epoch 546/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1010 - acc: 0.8500 - val_loss: 0.1672 - val_acc: 0.9500\n",
            "Epoch 547/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1012 - acc: 0.8611 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 548/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0999 - acc: 0.8778 - val_loss: 0.1624 - val_acc: 1.0000\n",
            "Epoch 549/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1008 - acc: 0.8667 - val_loss: 0.1624 - val_acc: 1.0000\n",
            "Epoch 550/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1002 - acc: 0.8611 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 551/800\n",
            "180/180 [==============================] - 0s 331us/step - loss: 0.0999 - acc: 0.8889 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 552/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.0995 - acc: 0.8722 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 553/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.0994 - acc: 0.8778 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 554/800\n",
            "180/180 [==============================] - 0s 330us/step - loss: 0.1004 - acc: 0.8444 - val_loss: 0.1623 - val_acc: 1.0000\n",
            "Epoch 555/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1005 - acc: 0.8556 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 556/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1006 - acc: 0.8778 - val_loss: 0.1607 - val_acc: 0.9500\n",
            "Epoch 557/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1025 - acc: 0.8611 - val_loss: 0.1628 - val_acc: 0.9500\n",
            "Epoch 558/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1003 - acc: 0.8722 - val_loss: 0.1605 - val_acc: 1.0000\n",
            "Epoch 559/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1000 - acc: 0.8667 - val_loss: 0.1608 - val_acc: 0.9000\n",
            "Epoch 560/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.0993 - acc: 0.8722 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 561/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0998 - acc: 0.8667 - val_loss: 0.1607 - val_acc: 1.0000\n",
            "Epoch 562/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1002 - acc: 0.8667 - val_loss: 0.1631 - val_acc: 0.9500\n",
            "Epoch 563/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1004 - acc: 0.8500 - val_loss: 0.1597 - val_acc: 1.0000\n",
            "Epoch 564/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.0994 - acc: 0.8611 - val_loss: 0.1643 - val_acc: 0.9000\n",
            "Epoch 565/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1020 - acc: 0.8611 - val_loss: 0.1624 - val_acc: 0.9500\n",
            "Epoch 566/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1000 - acc: 0.8667 - val_loss: 0.1627 - val_acc: 0.9500\n",
            "Epoch 567/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1010 - acc: 0.8833 - val_loss: 0.1604 - val_acc: 0.9500\n",
            "Epoch 568/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.0995 - acc: 0.8500 - val_loss: 0.1600 - val_acc: 1.0000\n",
            "Epoch 569/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.0998 - acc: 0.8833 - val_loss: 0.1605 - val_acc: 0.9500\n",
            "Epoch 570/800\n",
            "180/180 [==============================] - 0s 337us/step - loss: 0.0995 - acc: 0.8667 - val_loss: 0.1602 - val_acc: 0.9500\n",
            "Epoch 571/800\n",
            "180/180 [==============================] - 0s 403us/step - loss: 0.0997 - acc: 0.8778 - val_loss: 0.1604 - val_acc: 0.9500\n",
            "Epoch 572/800\n",
            "180/180 [==============================] - 0s 329us/step - loss: 0.1002 - acc: 0.8667 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 573/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1000 - acc: 0.8722 - val_loss: 0.1611 - val_acc: 1.0000\n",
            "Epoch 574/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1002 - acc: 0.8778 - val_loss: 0.1624 - val_acc: 1.0000\n",
            "Epoch 575/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1000 - acc: 0.8556 - val_loss: 0.1646 - val_acc: 0.9500\n",
            "Epoch 576/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1004 - acc: 0.8611 - val_loss: 0.1594 - val_acc: 1.0000\n",
            "Epoch 577/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0992 - acc: 0.8778 - val_loss: 0.1632 - val_acc: 0.9000\n",
            "Epoch 578/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.0998 - acc: 0.8722 - val_loss: 0.1610 - val_acc: 0.9500\n",
            "Epoch 579/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1000 - acc: 0.8667 - val_loss: 0.1653 - val_acc: 0.8000\n",
            "Epoch 580/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1004 - acc: 0.8500 - val_loss: 0.1619 - val_acc: 0.9500\n",
            "Epoch 581/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0999 - acc: 0.8611 - val_loss: 0.1592 - val_acc: 0.9500\n",
            "Epoch 582/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.0992 - acc: 0.8722 - val_loss: 0.1617 - val_acc: 0.9000\n",
            "Epoch 583/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.0992 - acc: 0.8556 - val_loss: 0.1604 - val_acc: 0.9500\n",
            "Epoch 584/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.0994 - acc: 0.8556 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 585/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0994 - acc: 0.8722 - val_loss: 0.1605 - val_acc: 0.9500\n",
            "Epoch 586/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0996 - acc: 0.8889 - val_loss: 0.1619 - val_acc: 0.9500\n",
            "Epoch 587/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.0992 - acc: 0.8667 - val_loss: 0.1594 - val_acc: 0.9500\n",
            "Epoch 588/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.0990 - acc: 0.8611 - val_loss: 0.1619 - val_acc: 0.9500\n",
            "Epoch 589/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.0999 - acc: 0.8556 - val_loss: 0.1618 - val_acc: 0.9500\n",
            "Epoch 590/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.0992 - acc: 0.8778 - val_loss: 0.1619 - val_acc: 0.9000\n",
            "Epoch 591/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.0992 - acc: 0.8444 - val_loss: 0.1606 - val_acc: 0.9500\n",
            "Epoch 592/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.0995 - acc: 0.8722 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 593/800\n",
            "180/180 [==============================] - 0s 329us/step - loss: 0.0993 - acc: 0.8778 - val_loss: 0.1631 - val_acc: 0.9000\n",
            "Epoch 594/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.0992 - acc: 0.8611 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 595/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.0995 - acc: 0.8833 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 596/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0996 - acc: 0.8778 - val_loss: 0.1614 - val_acc: 0.9500\n",
            "Epoch 597/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.0994 - acc: 0.8778 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 598/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.0993 - acc: 0.8556 - val_loss: 0.1617 - val_acc: 1.0000\n",
            "Epoch 599/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1003 - acc: 0.8500 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 600/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.0991 - acc: 0.8722 - val_loss: 0.1613 - val_acc: 0.9500\n",
            "Epoch 601/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.0994 - acc: 0.8722 - val_loss: 0.1602 - val_acc: 0.9000\n",
            "Epoch 602/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.0989 - acc: 0.8611 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 603/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.0997 - acc: 0.8444 - val_loss: 0.1603 - val_acc: 1.0000\n",
            "Epoch 604/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.0990 - acc: 0.8722 - val_loss: 0.1613 - val_acc: 0.9000\n",
            "Epoch 605/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0992 - acc: 0.8556 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 606/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.0990 - acc: 0.8556 - val_loss: 0.1590 - val_acc: 0.9500\n",
            "Epoch 607/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.0998 - acc: 0.8611 - val_loss: 0.1606 - val_acc: 0.9500\n",
            "Epoch 608/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.0991 - acc: 0.8889 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 609/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0997 - acc: 0.8778 - val_loss: 0.1641 - val_acc: 0.9000\n",
            "Epoch 610/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.0994 - acc: 0.8556 - val_loss: 0.1597 - val_acc: 0.9500\n",
            "Epoch 611/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.0988 - acc: 0.8667 - val_loss: 0.1612 - val_acc: 0.9500\n",
            "Epoch 612/800\n",
            "180/180 [==============================] - 0s 469us/step - loss: 0.0988 - acc: 0.8611 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 613/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.0991 - acc: 0.8722 - val_loss: 0.1605 - val_acc: 0.9500\n",
            "Epoch 614/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0993 - acc: 0.8778 - val_loss: 0.1600 - val_acc: 1.0000\n",
            "Epoch 615/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1002 - acc: 0.8833 - val_loss: 0.1616 - val_acc: 0.9500\n",
            "Epoch 616/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0991 - acc: 0.8667 - val_loss: 0.1608 - val_acc: 1.0000\n",
            "Epoch 617/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.0988 - acc: 0.8667 - val_loss: 0.1608 - val_acc: 0.9500\n",
            "Epoch 618/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0996 - acc: 0.8444 - val_loss: 0.1590 - val_acc: 0.9500\n",
            "Epoch 619/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.0992 - acc: 0.8556 - val_loss: 0.1621 - val_acc: 0.9000\n",
            "Epoch 620/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.0988 - acc: 0.8722 - val_loss: 0.1599 - val_acc: 0.9500\n",
            "Epoch 621/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.0986 - acc: 0.8722 - val_loss: 0.1592 - val_acc: 1.0000\n",
            "Epoch 622/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1002 - acc: 0.8556 - val_loss: 0.1647 - val_acc: 0.9500\n",
            "Epoch 623/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1000 - acc: 0.8722 - val_loss: 0.1639 - val_acc: 0.8500\n",
            "Epoch 624/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.0989 - acc: 0.8611 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 625/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.0989 - acc: 0.8778 - val_loss: 0.1596 - val_acc: 0.9500\n",
            "Epoch 626/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.0988 - acc: 0.8833 - val_loss: 0.1603 - val_acc: 0.9500\n",
            "Epoch 627/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.0991 - acc: 0.8667 - val_loss: 0.1599 - val_acc: 0.9500\n",
            "Epoch 628/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.0987 - acc: 0.8722 - val_loss: 0.1633 - val_acc: 0.9000\n",
            "Epoch 629/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.0991 - acc: 0.8611 - val_loss: 0.1594 - val_acc: 1.0000\n",
            "Epoch 630/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.0993 - acc: 0.8778 - val_loss: 0.1598 - val_acc: 1.0000\n",
            "Epoch 631/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.0985 - acc: 0.8667 - val_loss: 0.1601 - val_acc: 1.0000\n",
            "Epoch 632/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0987 - acc: 0.8611 - val_loss: 0.1588 - val_acc: 0.9500\n",
            "Epoch 633/800\n",
            "180/180 [==============================] - 0s 394us/step - loss: 0.0992 - acc: 0.8667 - val_loss: 0.1595 - val_acc: 1.0000\n",
            "Epoch 634/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.0990 - acc: 0.8722 - val_loss: 0.1592 - val_acc: 1.0000\n",
            "Epoch 635/800\n",
            "180/180 [==============================] - 0s 333us/step - loss: 0.0991 - acc: 0.8667 - val_loss: 0.1589 - val_acc: 0.9500\n",
            "Epoch 636/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.0993 - acc: 0.8667 - val_loss: 0.1626 - val_acc: 0.9500\n",
            "Epoch 637/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1008 - acc: 0.8500 - val_loss: 0.1616 - val_acc: 0.9500\n",
            "Epoch 638/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.0989 - acc: 0.8833 - val_loss: 0.1599 - val_acc: 1.0000\n",
            "Epoch 639/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.0993 - acc: 0.8722 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 640/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.0988 - acc: 0.8722 - val_loss: 0.1629 - val_acc: 0.9000\n",
            "Epoch 641/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0996 - acc: 0.8778 - val_loss: 0.1605 - val_acc: 0.9000\n",
            "Epoch 642/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.0990 - acc: 0.8722 - val_loss: 0.1635 - val_acc: 0.9000\n",
            "Epoch 643/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.0997 - acc: 0.8833 - val_loss: 0.1597 - val_acc: 0.9500\n",
            "Epoch 644/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0997 - acc: 0.8722 - val_loss: 0.1620 - val_acc: 0.9500\n",
            "Epoch 645/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.0987 - acc: 0.8778 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 646/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.0991 - acc: 0.8722 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 647/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.0994 - acc: 0.8833 - val_loss: 0.1611 - val_acc: 0.9500\n",
            "Epoch 648/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.0998 - acc: 0.8722 - val_loss: 0.1596 - val_acc: 0.9500\n",
            "Epoch 649/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.0990 - acc: 0.8667 - val_loss: 0.1592 - val_acc: 0.9500\n",
            "Epoch 650/800\n",
            "180/180 [==============================] - 0s 337us/step - loss: 0.0994 - acc: 0.8778 - val_loss: 0.1594 - val_acc: 0.9500\n",
            "Epoch 651/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0986 - acc: 0.8667 - val_loss: 0.1599 - val_acc: 0.9500\n",
            "Epoch 652/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.0990 - acc: 0.8778 - val_loss: 0.1596 - val_acc: 0.9500\n",
            "Epoch 653/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0988 - acc: 0.8889 - val_loss: 0.1623 - val_acc: 0.9500\n",
            "Epoch 654/800\n",
            "180/180 [==============================] - 0s 485us/step - loss: 0.0995 - acc: 0.8889 - val_loss: 0.1597 - val_acc: 0.9500\n",
            "Epoch 655/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.0986 - acc: 0.8722 - val_loss: 0.1600 - val_acc: 0.9000\n",
            "Epoch 656/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.0988 - acc: 0.8611 - val_loss: 0.1606 - val_acc: 0.9500\n",
            "Epoch 657/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.0987 - acc: 0.8722 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 658/800\n",
            "180/180 [==============================] - 0s 323us/step - loss: 0.0996 - acc: 0.8611 - val_loss: 0.1638 - val_acc: 0.9500\n",
            "Epoch 659/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0991 - acc: 0.8889 - val_loss: 0.1628 - val_acc: 1.0000\n",
            "Epoch 660/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.0992 - acc: 0.8778 - val_loss: 0.1593 - val_acc: 0.9500\n",
            "Epoch 661/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.0990 - acc: 0.8778 - val_loss: 0.1602 - val_acc: 0.9500\n",
            "Epoch 662/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.0993 - acc: 0.8556 - val_loss: 0.1593 - val_acc: 1.0000\n",
            "Epoch 663/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.0987 - acc: 0.8778 - val_loss: 0.1599 - val_acc: 0.9500\n",
            "Epoch 664/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0985 - acc: 0.8778 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 665/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.0986 - acc: 0.8833 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 666/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.0991 - acc: 0.8667 - val_loss: 0.1608 - val_acc: 0.9500\n",
            "Epoch 667/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.0992 - acc: 0.8722 - val_loss: 0.1595 - val_acc: 1.0000\n",
            "Epoch 668/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.0985 - acc: 0.8556 - val_loss: 0.1609 - val_acc: 0.9500\n",
            "Epoch 669/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0991 - acc: 0.8500 - val_loss: 0.1599 - val_acc: 0.9500\n",
            "Epoch 670/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0988 - acc: 0.8611 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 671/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.0984 - acc: 0.8611 - val_loss: 0.1593 - val_acc: 0.9500\n",
            "Epoch 672/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.0983 - acc: 0.8556 - val_loss: 0.1595 - val_acc: 1.0000\n",
            "Epoch 673/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.0981 - acc: 0.8722 - val_loss: 0.1601 - val_acc: 0.9000\n",
            "Epoch 674/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.0987 - acc: 0.8778 - val_loss: 0.1585 - val_acc: 0.9500\n",
            "Epoch 675/800\n",
            "180/180 [==============================] - 0s 420us/step - loss: 0.0985 - acc: 0.8722 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 676/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.0988 - acc: 0.8722 - val_loss: 0.1588 - val_acc: 1.0000\n",
            "Epoch 677/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.0987 - acc: 0.8556 - val_loss: 0.1604 - val_acc: 0.9500\n",
            "Epoch 678/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0992 - acc: 0.8667 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 679/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0989 - acc: 0.8556 - val_loss: 0.1592 - val_acc: 0.9500\n",
            "Epoch 680/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0983 - acc: 0.8778 - val_loss: 0.1589 - val_acc: 0.9500\n",
            "Epoch 681/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.0989 - acc: 0.8722 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 682/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.0988 - acc: 0.8778 - val_loss: 0.1602 - val_acc: 1.0000\n",
            "Epoch 683/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.0990 - acc: 0.8833 - val_loss: 0.1602 - val_acc: 0.9500\n",
            "Epoch 684/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.0982 - acc: 0.8556 - val_loss: 0.1603 - val_acc: 0.9500\n",
            "Epoch 685/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.0981 - acc: 0.8722 - val_loss: 0.1620 - val_acc: 0.9500\n",
            "Epoch 686/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.0985 - acc: 0.8833 - val_loss: 0.1599 - val_acc: 0.9500\n",
            "Epoch 687/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.0984 - acc: 0.8611 - val_loss: 0.1597 - val_acc: 0.9500\n",
            "Epoch 688/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1005 - acc: 0.8611 - val_loss: 0.1602 - val_acc: 1.0000\n",
            "Epoch 689/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0982 - acc: 0.8667 - val_loss: 0.1592 - val_acc: 0.9500\n",
            "Epoch 690/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0982 - acc: 0.8722 - val_loss: 0.1589 - val_acc: 0.9500\n",
            "Epoch 691/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0983 - acc: 0.8833 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 692/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0984 - acc: 0.8556 - val_loss: 0.1626 - val_acc: 0.9500\n",
            "Epoch 693/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0989 - acc: 0.8611 - val_loss: 0.1597 - val_acc: 0.9500\n",
            "Epoch 694/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.0984 - acc: 0.8722 - val_loss: 0.1608 - val_acc: 0.9500\n",
            "Epoch 695/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.0983 - acc: 0.8722 - val_loss: 0.1599 - val_acc: 1.0000\n",
            "Epoch 696/800\n",
            "180/180 [==============================] - 0s 397us/step - loss: 0.0983 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 0.9500\n",
            "Epoch 697/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0980 - acc: 0.8889 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 698/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.0983 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 0.9500\n",
            "Epoch 699/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.0982 - acc: 0.8833 - val_loss: 0.1602 - val_acc: 0.9500\n",
            "Epoch 700/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.0989 - acc: 0.8778 - val_loss: 0.1602 - val_acc: 1.0000\n",
            "Epoch 701/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0987 - acc: 0.8778 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 702/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0985 - acc: 0.8833 - val_loss: 0.1592 - val_acc: 0.9500\n",
            "Epoch 703/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0986 - acc: 0.8833 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 704/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.0982 - acc: 0.8667 - val_loss: 0.1588 - val_acc: 0.9500\n",
            "Epoch 705/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.0981 - acc: 0.8889 - val_loss: 0.1589 - val_acc: 1.0000\n",
            "Epoch 706/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0984 - acc: 0.8722 - val_loss: 0.1616 - val_acc: 0.9000\n",
            "Epoch 707/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0984 - acc: 0.8833 - val_loss: 0.1598 - val_acc: 1.0000\n",
            "Epoch 708/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.0984 - acc: 0.8611 - val_loss: 0.1598 - val_acc: 1.0000\n",
            "Epoch 709/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0982 - acc: 0.8611 - val_loss: 0.1590 - val_acc: 0.9500\n",
            "Epoch 710/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.0983 - acc: 0.8722 - val_loss: 0.1627 - val_acc: 0.9000\n",
            "Epoch 711/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.0997 - acc: 0.8833 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 712/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.0990 - acc: 0.8778 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 713/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.0986 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 1.0000\n",
            "Epoch 714/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0983 - acc: 0.8778 - val_loss: 0.1587 - val_acc: 1.0000\n",
            "Epoch 715/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.0989 - acc: 0.8722 - val_loss: 0.1596 - val_acc: 0.9500\n",
            "Epoch 716/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0983 - acc: 0.8833 - val_loss: 0.1601 - val_acc: 1.0000\n",
            "Epoch 717/800\n",
            "180/180 [==============================] - 0s 404us/step - loss: 0.0990 - acc: 0.8778 - val_loss: 0.1614 - val_acc: 0.9000\n",
            "Epoch 718/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.0984 - acc: 0.8611 - val_loss: 0.1606 - val_acc: 0.9500\n",
            "Epoch 719/800\n",
            "180/180 [==============================] - 0s 331us/step - loss: 0.0984 - acc: 0.8667 - val_loss: 0.1587 - val_acc: 1.0000\n",
            "Epoch 720/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.0979 - acc: 0.8667 - val_loss: 0.1589 - val_acc: 0.9500\n",
            "Epoch 721/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.0986 - acc: 0.8778 - val_loss: 0.1588 - val_acc: 1.0000\n",
            "Epoch 722/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.0982 - acc: 0.8778 - val_loss: 0.1586 - val_acc: 1.0000\n",
            "Epoch 723/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.0985 - acc: 0.8833 - val_loss: 0.1605 - val_acc: 1.0000\n",
            "Epoch 724/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.0989 - acc: 0.8556 - val_loss: 0.1603 - val_acc: 0.9500\n",
            "Epoch 725/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0992 - acc: 0.8778 - val_loss: 0.1603 - val_acc: 0.9500\n",
            "Epoch 726/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.0984 - acc: 0.8611 - val_loss: 0.1597 - val_acc: 0.9500\n",
            "Epoch 727/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.0983 - acc: 0.8611 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 728/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.0982 - acc: 0.8556 - val_loss: 0.1594 - val_acc: 1.0000\n",
            "Epoch 729/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.0977 - acc: 0.8778 - val_loss: 0.1593 - val_acc: 0.9500\n",
            "Epoch 730/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.0981 - acc: 0.8778 - val_loss: 0.1593 - val_acc: 1.0000\n",
            "Epoch 731/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.0983 - acc: 0.8889 - val_loss: 0.1622 - val_acc: 1.0000\n",
            "Epoch 732/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.0984 - acc: 0.8722 - val_loss: 0.1587 - val_acc: 0.9500\n",
            "Epoch 733/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0986 - acc: 0.8778 - val_loss: 0.1590 - val_acc: 1.0000\n",
            "Epoch 734/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.0982 - acc: 0.8833 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 735/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0979 - acc: 0.8778 - val_loss: 0.1602 - val_acc: 0.9500\n",
            "Epoch 736/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.0979 - acc: 0.8778 - val_loss: 0.1599 - val_acc: 0.9000\n",
            "Epoch 737/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.0983 - acc: 0.8667 - val_loss: 0.1650 - val_acc: 0.9500\n",
            "Epoch 738/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.1006 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 1.0000\n",
            "Epoch 739/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.0987 - acc: 0.8611 - val_loss: 0.1588 - val_acc: 0.9500\n",
            "Epoch 740/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.0979 - acc: 0.8778 - val_loss: 0.1587 - val_acc: 0.9500\n",
            "Epoch 741/800\n",
            "180/180 [==============================] - 0s 330us/step - loss: 0.0983 - acc: 0.8833 - val_loss: 0.1617 - val_acc: 0.9500\n",
            "Epoch 742/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.0990 - acc: 0.8722 - val_loss: 0.1592 - val_acc: 0.9500\n",
            "Epoch 743/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.0983 - acc: 0.8667 - val_loss: 0.1620 - val_acc: 1.0000\n",
            "Epoch 744/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.0984 - acc: 0.8778 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 745/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.0981 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.9500\n",
            "Epoch 746/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.0994 - acc: 0.8722 - val_loss: 0.1592 - val_acc: 0.9500\n",
            "Epoch 747/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.0989 - acc: 0.8722 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 748/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.0982 - acc: 0.8722 - val_loss: 0.1610 - val_acc: 1.0000\n",
            "Epoch 749/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.0985 - acc: 0.8778 - val_loss: 0.1587 - val_acc: 0.9500\n",
            "Epoch 750/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.0977 - acc: 0.8611 - val_loss: 0.1587 - val_acc: 0.9500\n",
            "Epoch 751/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0979 - acc: 0.8722 - val_loss: 0.1588 - val_acc: 0.9500\n",
            "Epoch 752/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.0976 - acc: 0.8722 - val_loss: 0.1610 - val_acc: 0.9500\n",
            "Epoch 753/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0978 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 1.0000\n",
            "Epoch 754/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.0977 - acc: 0.8611 - val_loss: 0.1627 - val_acc: 0.9000\n",
            "Epoch 755/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.0982 - acc: 0.8778 - val_loss: 0.1593 - val_acc: 0.9500\n",
            "Epoch 756/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0983 - acc: 0.8722 - val_loss: 0.1584 - val_acc: 1.0000\n",
            "Epoch 757/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0976 - acc: 0.8722 - val_loss: 0.1589 - val_acc: 0.9500\n",
            "Epoch 758/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.0982 - acc: 0.8778 - val_loss: 0.1615 - val_acc: 1.0000\n",
            "Epoch 759/800\n",
            "180/180 [==============================] - 0s 416us/step - loss: 0.0983 - acc: 0.8833 - val_loss: 0.1585 - val_acc: 1.0000\n",
            "Epoch 760/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.0980 - acc: 0.8722 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 761/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.0976 - acc: 0.8833 - val_loss: 0.1589 - val_acc: 0.9500\n",
            "Epoch 762/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0978 - acc: 0.8611 - val_loss: 0.1580 - val_acc: 1.0000\n",
            "Epoch 763/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.0982 - acc: 0.8667 - val_loss: 0.1596 - val_acc: 1.0000\n",
            "Epoch 764/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0981 - acc: 0.8611 - val_loss: 0.1591 - val_acc: 1.0000\n",
            "Epoch 765/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0980 - acc: 0.8889 - val_loss: 0.1586 - val_acc: 0.9500\n",
            "Epoch 766/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.0979 - acc: 0.8889 - val_loss: 0.1584 - val_acc: 0.9500\n",
            "Epoch 767/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.0977 - acc: 0.8667 - val_loss: 0.1625 - val_acc: 0.9000\n",
            "Epoch 768/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.0979 - acc: 0.8722 - val_loss: 0.1585 - val_acc: 0.9500\n",
            "Epoch 769/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.0979 - acc: 0.8722 - val_loss: 0.1615 - val_acc: 0.9500\n",
            "Epoch 770/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.0980 - acc: 0.8833 - val_loss: 0.1604 - val_acc: 0.9500\n",
            "Epoch 771/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0976 - acc: 0.8944 - val_loss: 0.1590 - val_acc: 0.9500\n",
            "Epoch 772/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.0981 - acc: 0.8944 - val_loss: 0.1600 - val_acc: 1.0000\n",
            "Epoch 773/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.0979 - acc: 0.8722 - val_loss: 0.1590 - val_acc: 0.9500\n",
            "Epoch 774/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.0982 - acc: 0.8667 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 775/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.0977 - acc: 0.8722 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 776/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.0973 - acc: 0.8667 - val_loss: 0.1579 - val_acc: 0.9500\n",
            "Epoch 777/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.0983 - acc: 0.8778 - val_loss: 0.1598 - val_acc: 0.9500\n",
            "Epoch 778/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.0984 - acc: 0.8778 - val_loss: 0.1600 - val_acc: 0.9500\n",
            "Epoch 779/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.0981 - acc: 0.8722 - val_loss: 0.1587 - val_acc: 0.9500\n",
            "Epoch 780/800\n",
            "180/180 [==============================] - 0s 395us/step - loss: 0.0976 - acc: 0.8778 - val_loss: 0.1622 - val_acc: 0.9000\n",
            "Epoch 781/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0990 - acc: 0.8778 - val_loss: 0.1619 - val_acc: 0.9000\n",
            "Epoch 782/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.0982 - acc: 0.8556 - val_loss: 0.1617 - val_acc: 0.9500\n",
            "Epoch 783/800\n",
            "180/180 [==============================] - 0s 335us/step - loss: 0.0982 - acc: 0.8667 - val_loss: 0.1594 - val_acc: 1.0000\n",
            "Epoch 784/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0976 - acc: 0.8722 - val_loss: 0.1591 - val_acc: 0.9500\n",
            "Epoch 785/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.0975 - acc: 0.8667 - val_loss: 0.1596 - val_acc: 1.0000\n",
            "Epoch 786/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.0977 - acc: 0.8611 - val_loss: 0.1591 - val_acc: 1.0000\n",
            "Epoch 787/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.0975 - acc: 0.8833 - val_loss: 0.1590 - val_acc: 0.9500\n",
            "Epoch 788/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0987 - acc: 0.8500 - val_loss: 0.1586 - val_acc: 1.0000\n",
            "Epoch 789/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.0983 - acc: 0.8722 - val_loss: 0.1585 - val_acc: 1.0000\n",
            "Epoch 790/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.0980 - acc: 0.8722 - val_loss: 0.1595 - val_acc: 0.9500\n",
            "Epoch 791/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.0976 - acc: 0.8667 - val_loss: 0.1611 - val_acc: 0.9000\n",
            "Epoch 792/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.0988 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 0.9500\n",
            "Epoch 793/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.0977 - acc: 0.8667 - val_loss: 0.1601 - val_acc: 0.9500\n",
            "Epoch 794/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.0980 - acc: 0.8833 - val_loss: 0.1603 - val_acc: 0.9000\n",
            "Epoch 795/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.0984 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.9500\n",
            "Epoch 796/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.0975 - acc: 0.8778 - val_loss: 0.1589 - val_acc: 0.9500\n",
            "Epoch 797/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.0974 - acc: 0.8778 - val_loss: 0.1599 - val_acc: 0.9500\n",
            "Epoch 798/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.0988 - acc: 0.8556 - val_loss: 0.1583 - val_acc: 0.9500\n",
            "Epoch 799/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.0974 - acc: 0.8833 - val_loss: 0.1581 - val_acc: 0.9500\n",
            "Epoch 800/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.0974 - acc: 0.8833 - val_loss: 0.1594 - val_acc: 0.9500\n",
            "200/200 [==============================] - 0s 99us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0.11783276438713074, 0.945]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "0HjRmdZ2FXk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "e64a42ef-ac2e-494e-91b4-9f1f89e4441d"
      },
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Make sure to run this after each new generation of data\n",
        "# zero mean and unit var\n",
        "x_train2 = StandardScaler().fit_transform(x_train)\n",
        "x_test2 = StandardScaler().fit_transform(x_test)\n",
        "#x_train2 = x_train2[:,:,np.newaxis]\n",
        "#x_test2 = x_test2[:,:,np.newaxis]\n",
        "\n",
        "#x_train2 = x_train2.astype('float32') \n",
        "#x_test2 = x_test2.astype('float32')\n",
        "\n",
        "display(x_train2.shape)\n",
        "\n",
        "input_dim = x_train.shape[1]\n",
        "\n",
        "# set size of autoencoder \n",
        "encoding_dim = 5\n",
        "elu = keras.layers.ELU(alpha=1.2)\n",
        "lrlu= keras.layers.LeakyReLU(alpha=0.3)\n",
        "\n",
        "\n",
        "# use elu because it is leaky tried both net and l1 and l2 : net and l1 worked the best \n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "encoder = Dense(encoding_dim,kernel_initializer= 'he_normal', activity_regularizer=regularizers.l1_l2(l1=10e-5, l2=75.10e-5))(input_layer)\n",
        "encoder = keras.layers.LeakyReLU(alpha=0.011)(encoder)\n",
        "#encoder = Dense(encoding_dim, activation=\"elu\",activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "encoder = Dense(int(encoding_dim / 2),kernel_initializer= 'he_normal')(encoder)\n",
        "encoder = keras.layers.LeakyReLU(alpha=0.011)(encoder)\n",
        "decoder = Dense(int(encoding_dim / 2),kernel_initializer= 'he_normal')(encoder)\n",
        "decoder = keras.layers.LeakyReLU(alpha=0.011)(decoder)\n",
        "decoder = Dense(input_dim,kernel_initializer= 'he_normal')(decoder)\n",
        "decoder = keras.layers.LeakyReLU(alpha=0.011)(decoder)\n",
        "autoencoder2 = Model(inputs=input_layer, outputs=decoder)\n",
        "\n",
        "autoencoder2.summary()  \n"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(300, 6)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 5)                 35        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_92 (LeakyReLU)   (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 2)                 12        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_93 (LeakyReLU)   (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_94 (LeakyReLU)   (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 6)                 18        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_95 (LeakyReLU)   (None, 6)                 0         \n",
            "=================================================================\n",
            "Total params: 71\n",
            "Trainable params: 71\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TGa_7-W3FSLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27353
        },
        "outputId": "c575da05-1a0f-4183-cc77-65616e3c8614"
      },
      "cell_type": "code",
      "source": [
        "#Results with no anomily \n",
        "# Loss and Val Loss are very close + Accuracy and Val Accuracy are very close \n",
        "# Depending on the params of the net it can hit Accuracy of  1\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "full_anom = 0\n",
        "anom_samples = 0\n",
        "batch_size = 32\n",
        "import keras\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "nadam =keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
        "\n",
        "autoencoder2.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    #loss = 'binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
        "                              patience=300,verbose = 1)\n",
        "history = autoencoder2.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "                    validation_split=.1,\n",
        "                    verbose=1,callbacks=[reduce_lr])\n",
        "score = autoencoder2.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 180 samples, validate on 20 samples\n",
            "Epoch 1/800\n",
            "180/180 [==============================] - 7s 38ms/step - loss: 0.6340 - acc: 0.5222 - val_loss: 0.6486 - val_acc: 0.4000\n",
            "Epoch 2/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.6323 - acc: 0.5167 - val_loss: 0.6465 - val_acc: 0.4000\n",
            "Epoch 3/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.6305 - acc: 0.5333 - val_loss: 0.6434 - val_acc: 0.4000\n",
            "Epoch 4/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.6292 - acc: 0.5389 - val_loss: 0.6430 - val_acc: 0.4000\n",
            "Epoch 5/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.6275 - acc: 0.5611 - val_loss: 0.6400 - val_acc: 0.4000\n",
            "Epoch 6/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.6262 - acc: 0.5778 - val_loss: 0.6392 - val_acc: 0.4500\n",
            "Epoch 7/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.6250 - acc: 0.6111 - val_loss: 0.6368 - val_acc: 0.5000\n",
            "Epoch 8/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.6230 - acc: 0.6278 - val_loss: 0.6366 - val_acc: 0.4500\n",
            "Epoch 9/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.6219 - acc: 0.6056 - val_loss: 0.6333 - val_acc: 0.3500\n",
            "Epoch 10/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.6211 - acc: 0.6056 - val_loss: 0.6322 - val_acc: 0.3500\n",
            "Epoch 11/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.6195 - acc: 0.5722 - val_loss: 0.6297 - val_acc: 0.4000\n",
            "Epoch 12/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.6186 - acc: 0.5889 - val_loss: 0.6267 - val_acc: 0.4000\n",
            "Epoch 13/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.6171 - acc: 0.6167 - val_loss: 0.6242 - val_acc: 0.4000\n",
            "Epoch 14/800\n",
            "180/180 [==============================] - 0s 414us/step - loss: 0.6153 - acc: 0.6111 - val_loss: 0.6235 - val_acc: 0.5000\n",
            "Epoch 15/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.6140 - acc: 0.6444 - val_loss: 0.6222 - val_acc: 0.4500\n",
            "Epoch 16/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.6126 - acc: 0.6389 - val_loss: 0.6198 - val_acc: 0.5500\n",
            "Epoch 17/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.6111 - acc: 0.6500 - val_loss: 0.6177 - val_acc: 0.5500\n",
            "Epoch 18/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.6092 - acc: 0.6500 - val_loss: 0.6170 - val_acc: 0.6500\n",
            "Epoch 19/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.6072 - acc: 0.6389 - val_loss: 0.6154 - val_acc: 0.6500\n",
            "Epoch 20/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.6052 - acc: 0.6333 - val_loss: 0.6140 - val_acc: 0.5500\n",
            "Epoch 21/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.6033 - acc: 0.6278 - val_loss: 0.6128 - val_acc: 0.6000\n",
            "Epoch 22/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.6017 - acc: 0.6667 - val_loss: 0.6102 - val_acc: 0.6000\n",
            "Epoch 23/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.5993 - acc: 0.6667 - val_loss: 0.6077 - val_acc: 0.6000\n",
            "Epoch 24/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.5972 - acc: 0.6833 - val_loss: 0.6046 - val_acc: 0.6500\n",
            "Epoch 25/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.5953 - acc: 0.6889 - val_loss: 0.6004 - val_acc: 0.6500\n",
            "Epoch 26/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.5931 - acc: 0.6833 - val_loss: 0.5985 - val_acc: 0.7000\n",
            "Epoch 27/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.5908 - acc: 0.6944 - val_loss: 0.5950 - val_acc: 0.7000\n",
            "Epoch 28/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.5895 - acc: 0.6833 - val_loss: 0.5942 - val_acc: 0.6500\n",
            "Epoch 29/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.5871 - acc: 0.6889 - val_loss: 0.5890 - val_acc: 0.7000\n",
            "Epoch 30/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.5850 - acc: 0.6778 - val_loss: 0.5875 - val_acc: 0.6500\n",
            "Epoch 31/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.5829 - acc: 0.6833 - val_loss: 0.5843 - val_acc: 0.6500\n",
            "Epoch 32/800\n",
            "180/180 [==============================] - 0s 480us/step - loss: 0.5812 - acc: 0.6889 - val_loss: 0.5801 - val_acc: 0.7000\n",
            "Epoch 33/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.5805 - acc: 0.7056 - val_loss: 0.5771 - val_acc: 0.7000\n",
            "Epoch 34/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.5776 - acc: 0.7000 - val_loss: 0.5727 - val_acc: 0.7000\n",
            "Epoch 35/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.5755 - acc: 0.6889 - val_loss: 0.5697 - val_acc: 0.7000\n",
            "Epoch 36/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.5731 - acc: 0.6833 - val_loss: 0.5663 - val_acc: 0.7000\n",
            "Epoch 37/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.5715 - acc: 0.6889 - val_loss: 0.5633 - val_acc: 0.7000\n",
            "Epoch 38/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.5700 - acc: 0.6833 - val_loss: 0.5601 - val_acc: 0.7000\n",
            "Epoch 39/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.5677 - acc: 0.6833 - val_loss: 0.5567 - val_acc: 0.7000\n",
            "Epoch 40/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.5655 - acc: 0.6889 - val_loss: 0.5524 - val_acc: 0.7000\n",
            "Epoch 41/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.5638 - acc: 0.7056 - val_loss: 0.5492 - val_acc: 0.7000\n",
            "Epoch 42/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.5618 - acc: 0.7000 - val_loss: 0.5439 - val_acc: 0.7500\n",
            "Epoch 43/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.5589 - acc: 0.7000 - val_loss: 0.5411 - val_acc: 0.8000\n",
            "Epoch 44/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.5569 - acc: 0.7056 - val_loss: 0.5370 - val_acc: 0.8000\n",
            "Epoch 45/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.5540 - acc: 0.7222 - val_loss: 0.5328 - val_acc: 0.9000\n",
            "Epoch 46/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.5525 - acc: 0.7389 - val_loss: 0.5278 - val_acc: 0.8500\n",
            "Epoch 47/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.5489 - acc: 0.7556 - val_loss: 0.5248 - val_acc: 0.8500\n",
            "Epoch 48/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.5458 - acc: 0.7556 - val_loss: 0.5214 - val_acc: 0.9000\n",
            "Epoch 49/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.5435 - acc: 0.7556 - val_loss: 0.5185 - val_acc: 0.9000\n",
            "Epoch 50/800\n",
            "180/180 [==============================] - 0s 455us/step - loss: 0.5420 - acc: 0.7722 - val_loss: 0.5159 - val_acc: 0.9000\n",
            "Epoch 51/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.5393 - acc: 0.7611 - val_loss: 0.5138 - val_acc: 0.9000\n",
            "Epoch 52/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.5374 - acc: 0.7722 - val_loss: 0.5100 - val_acc: 0.9500\n",
            "Epoch 53/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.5352 - acc: 0.7778 - val_loss: 0.5079 - val_acc: 0.9000\n",
            "Epoch 54/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.5332 - acc: 0.7833 - val_loss: 0.5053 - val_acc: 0.9500\n",
            "Epoch 55/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.5321 - acc: 0.7889 - val_loss: 0.5032 - val_acc: 0.9500\n",
            "Epoch 56/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.5296 - acc: 0.7944 - val_loss: 0.5013 - val_acc: 0.9500\n",
            "Epoch 57/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.5277 - acc: 0.7944 - val_loss: 0.4986 - val_acc: 0.9000\n",
            "Epoch 58/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.5262 - acc: 0.7889 - val_loss: 0.4976 - val_acc: 0.9500\n",
            "Epoch 59/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.5247 - acc: 0.7944 - val_loss: 0.4949 - val_acc: 0.9500\n",
            "Epoch 60/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.5232 - acc: 0.8000 - val_loss: 0.4935 - val_acc: 0.9500\n",
            "Epoch 61/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.5216 - acc: 0.8000 - val_loss: 0.4921 - val_acc: 0.9500\n",
            "Epoch 62/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.5204 - acc: 0.7944 - val_loss: 0.4904 - val_acc: 0.9500\n",
            "Epoch 63/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.5193 - acc: 0.8000 - val_loss: 0.4896 - val_acc: 0.9000\n",
            "Epoch 64/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.5181 - acc: 0.7889 - val_loss: 0.4879 - val_acc: 0.9000\n",
            "Epoch 65/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.5173 - acc: 0.7944 - val_loss: 0.4866 - val_acc: 0.8500\n",
            "Epoch 66/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.5161 - acc: 0.7778 - val_loss: 0.4862 - val_acc: 0.9000\n",
            "Epoch 67/800\n",
            "180/180 [==============================] - 0s 475us/step - loss: 0.5147 - acc: 0.7944 - val_loss: 0.4857 - val_acc: 0.8000\n",
            "Epoch 68/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.5142 - acc: 0.7722 - val_loss: 0.4836 - val_acc: 0.8500\n",
            "Epoch 69/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.5134 - acc: 0.7889 - val_loss: 0.4833 - val_acc: 0.8500\n",
            "Epoch 70/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.5120 - acc: 0.7833 - val_loss: 0.4820 - val_acc: 0.8500\n",
            "Epoch 71/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.5107 - acc: 0.8056 - val_loss: 0.4831 - val_acc: 0.8000\n",
            "Epoch 72/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.5102 - acc: 0.8056 - val_loss: 0.4805 - val_acc: 0.8000\n",
            "Epoch 73/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.5089 - acc: 0.8056 - val_loss: 0.4802 - val_acc: 0.8000\n",
            "Epoch 74/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.5075 - acc: 0.8056 - val_loss: 0.4795 - val_acc: 0.8000\n",
            "Epoch 75/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.5066 - acc: 0.8167 - val_loss: 0.4788 - val_acc: 0.8500\n",
            "Epoch 76/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.5058 - acc: 0.7889 - val_loss: 0.4787 - val_acc: 0.8000\n",
            "Epoch 77/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.5047 - acc: 0.7944 - val_loss: 0.4784 - val_acc: 0.8000\n",
            "Epoch 78/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.5035 - acc: 0.8111 - val_loss: 0.4775 - val_acc: 0.8500\n",
            "Epoch 79/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.5031 - acc: 0.8000 - val_loss: 0.4763 - val_acc: 0.8000\n",
            "Epoch 80/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.5016 - acc: 0.8056 - val_loss: 0.4760 - val_acc: 0.8500\n",
            "Epoch 81/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.5007 - acc: 0.8167 - val_loss: 0.4756 - val_acc: 0.8000\n",
            "Epoch 82/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.5000 - acc: 0.8167 - val_loss: 0.4754 - val_acc: 0.8500\n",
            "Epoch 83/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.4990 - acc: 0.8167 - val_loss: 0.4749 - val_acc: 0.8000\n",
            "Epoch 84/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.4984 - acc: 0.8222 - val_loss: 0.4742 - val_acc: 0.8000\n",
            "Epoch 85/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.4980 - acc: 0.8167 - val_loss: 0.4742 - val_acc: 0.8000\n",
            "Epoch 86/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4970 - acc: 0.8111 - val_loss: 0.4739 - val_acc: 0.8500\n",
            "Epoch 87/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4963 - acc: 0.8056 - val_loss: 0.4734 - val_acc: 0.8500\n",
            "Epoch 88/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4961 - acc: 0.8167 - val_loss: 0.4731 - val_acc: 0.8500\n",
            "Epoch 89/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4953 - acc: 0.8222 - val_loss: 0.4728 - val_acc: 0.8000\n",
            "Epoch 90/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4949 - acc: 0.8222 - val_loss: 0.4727 - val_acc: 0.8500\n",
            "Epoch 91/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4941 - acc: 0.8056 - val_loss: 0.4726 - val_acc: 0.8000\n",
            "Epoch 92/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4936 - acc: 0.8111 - val_loss: 0.4720 - val_acc: 0.8500\n",
            "Epoch 93/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4931 - acc: 0.8278 - val_loss: 0.4711 - val_acc: 0.8000\n",
            "Epoch 94/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4926 - acc: 0.8278 - val_loss: 0.4709 - val_acc: 0.8500\n",
            "Epoch 95/800\n",
            "180/180 [==============================] - 0s 399us/step - loss: 0.4923 - acc: 0.8111 - val_loss: 0.4707 - val_acc: 0.8000\n",
            "Epoch 96/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4916 - acc: 0.8167 - val_loss: 0.4703 - val_acc: 0.8500\n",
            "Epoch 97/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4914 - acc: 0.8167 - val_loss: 0.4696 - val_acc: 0.8500\n",
            "Epoch 98/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4913 - acc: 0.8389 - val_loss: 0.4696 - val_acc: 0.8500\n",
            "Epoch 99/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4906 - acc: 0.8333 - val_loss: 0.4695 - val_acc: 0.8500\n",
            "Epoch 100/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4905 - acc: 0.8111 - val_loss: 0.4687 - val_acc: 0.8500\n",
            "Epoch 101/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4899 - acc: 0.8111 - val_loss: 0.4688 - val_acc: 0.8000\n",
            "Epoch 102/800\n",
            "180/180 [==============================] - 0s 497us/step - loss: 0.4895 - acc: 0.8222 - val_loss: 0.4685 - val_acc: 0.8500\n",
            "Epoch 103/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4893 - acc: 0.8333 - val_loss: 0.4686 - val_acc: 0.8000\n",
            "Epoch 104/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4889 - acc: 0.8278 - val_loss: 0.4685 - val_acc: 0.8500\n",
            "Epoch 105/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4887 - acc: 0.8167 - val_loss: 0.4679 - val_acc: 0.8500\n",
            "Epoch 106/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4883 - acc: 0.8111 - val_loss: 0.4682 - val_acc: 0.8500\n",
            "Epoch 107/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4881 - acc: 0.8167 - val_loss: 0.4690 - val_acc: 0.8500\n",
            "Epoch 108/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.4879 - acc: 0.8444 - val_loss: 0.4680 - val_acc: 0.8500\n",
            "Epoch 109/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4876 - acc: 0.8167 - val_loss: 0.4677 - val_acc: 0.8000\n",
            "Epoch 110/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4872 - acc: 0.8444 - val_loss: 0.4679 - val_acc: 0.8000\n",
            "Epoch 111/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4871 - acc: 0.8222 - val_loss: 0.4681 - val_acc: 0.8500\n",
            "Epoch 112/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4869 - acc: 0.8389 - val_loss: 0.4674 - val_acc: 0.9000\n",
            "Epoch 113/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4866 - acc: 0.8500 - val_loss: 0.4676 - val_acc: 0.9500\n",
            "Epoch 114/800\n",
            "180/180 [==============================] - 0s 401us/step - loss: 0.4863 - acc: 0.8389 - val_loss: 0.4670 - val_acc: 0.9500\n",
            "Epoch 115/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4862 - acc: 0.8778 - val_loss: 0.4673 - val_acc: 1.0000\n",
            "Epoch 116/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4859 - acc: 0.8722 - val_loss: 0.4674 - val_acc: 1.0000\n",
            "Epoch 117/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4859 - acc: 0.9056 - val_loss: 0.4668 - val_acc: 0.9500\n",
            "Epoch 118/800\n",
            "180/180 [==============================] - 0s 393us/step - loss: 0.4856 - acc: 0.8944 - val_loss: 0.4670 - val_acc: 1.0000\n",
            "Epoch 119/800\n",
            "180/180 [==============================] - 0s 472us/step - loss: 0.4854 - acc: 0.9000 - val_loss: 0.4665 - val_acc: 1.0000\n",
            "Epoch 120/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4852 - acc: 0.9222 - val_loss: 0.4666 - val_acc: 1.0000\n",
            "Epoch 121/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4850 - acc: 0.9000 - val_loss: 0.4665 - val_acc: 1.0000\n",
            "Epoch 122/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4849 - acc: 0.9222 - val_loss: 0.4666 - val_acc: 1.0000\n",
            "Epoch 123/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.4850 - acc: 0.9278 - val_loss: 0.4665 - val_acc: 1.0000\n",
            "Epoch 124/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.4846 - acc: 0.9389 - val_loss: 0.4664 - val_acc: 1.0000\n",
            "Epoch 125/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4846 - acc: 0.9222 - val_loss: 0.4660 - val_acc: 1.0000\n",
            "Epoch 126/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.4842 - acc: 0.9389 - val_loss: 0.4663 - val_acc: 1.0000\n",
            "Epoch 127/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.4840 - acc: 0.9056 - val_loss: 0.4665 - val_acc: 1.0000\n",
            "Epoch 128/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.4840 - acc: 0.9389 - val_loss: 0.4665 - val_acc: 1.0000\n",
            "Epoch 129/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4838 - acc: 0.9444 - val_loss: 0.4667 - val_acc: 1.0000\n",
            "Epoch 130/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.4841 - acc: 0.9389 - val_loss: 0.4657 - val_acc: 1.0000\n",
            "Epoch 131/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4838 - acc: 0.9278 - val_loss: 0.4664 - val_acc: 1.0000\n",
            "Epoch 132/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4834 - acc: 0.9222 - val_loss: 0.4658 - val_acc: 1.0000\n",
            "Epoch 133/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4833 - acc: 0.9389 - val_loss: 0.4661 - val_acc: 1.0000\n",
            "Epoch 134/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4832 - acc: 0.9444 - val_loss: 0.4656 - val_acc: 1.0000\n",
            "Epoch 135/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4830 - acc: 0.8667 - val_loss: 0.4657 - val_acc: 1.0000\n",
            "Epoch 136/800\n",
            "180/180 [==============================] - 0s 431us/step - loss: 0.4832 - acc: 0.8778 - val_loss: 0.4658 - val_acc: 1.0000\n",
            "Epoch 137/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.4827 - acc: 0.9167 - val_loss: 0.4659 - val_acc: 0.9500\n",
            "Epoch 138/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.4829 - acc: 0.9167 - val_loss: 0.4651 - val_acc: 1.0000\n",
            "Epoch 139/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4824 - acc: 0.9111 - val_loss: 0.4668 - val_acc: 1.0000\n",
            "Epoch 140/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4825 - acc: 0.9222 - val_loss: 0.4654 - val_acc: 1.0000\n",
            "Epoch 141/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4830 - acc: 0.9056 - val_loss: 0.4657 - val_acc: 1.0000\n",
            "Epoch 142/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4821 - acc: 0.9056 - val_loss: 0.4649 - val_acc: 1.0000\n",
            "Epoch 143/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4827 - acc: 0.9222 - val_loss: 0.4656 - val_acc: 1.0000\n",
            "Epoch 144/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4821 - acc: 0.9278 - val_loss: 0.4649 - val_acc: 1.0000\n",
            "Epoch 145/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.4823 - acc: 0.9222 - val_loss: 0.4660 - val_acc: 1.0000\n",
            "Epoch 146/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4818 - acc: 0.9333 - val_loss: 0.4650 - val_acc: 1.0000\n",
            "Epoch 147/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4816 - acc: 0.9167 - val_loss: 0.4648 - val_acc: 1.0000\n",
            "Epoch 148/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4819 - acc: 0.9278 - val_loss: 0.4653 - val_acc: 1.0000\n",
            "Epoch 149/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4817 - acc: 0.9222 - val_loss: 0.4644 - val_acc: 1.0000\n",
            "Epoch 150/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4815 - acc: 0.9333 - val_loss: 0.4643 - val_acc: 1.0000\n",
            "Epoch 151/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4812 - acc: 0.9222 - val_loss: 0.4641 - val_acc: 1.0000\n",
            "Epoch 152/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4813 - acc: 0.9222 - val_loss: 0.4648 - val_acc: 1.0000\n",
            "Epoch 153/800\n",
            "180/180 [==============================] - 0s 398us/step - loss: 0.4813 - acc: 0.9444 - val_loss: 0.4647 - val_acc: 1.0000\n",
            "Epoch 154/800\n",
            "180/180 [==============================] - 0s 399us/step - loss: 0.4812 - acc: 0.9278 - val_loss: 0.4642 - val_acc: 1.0000\n",
            "Epoch 155/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4811 - acc: 0.9444 - val_loss: 0.4647 - val_acc: 1.0000\n",
            "Epoch 156/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4809 - acc: 0.9278 - val_loss: 0.4651 - val_acc: 1.0000\n",
            "Epoch 157/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4817 - acc: 0.9167 - val_loss: 0.4644 - val_acc: 1.0000\n",
            "Epoch 158/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4807 - acc: 0.9389 - val_loss: 0.4641 - val_acc: 1.0000\n",
            "Epoch 159/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4806 - acc: 0.9444 - val_loss: 0.4637 - val_acc: 1.0000\n",
            "Epoch 160/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4806 - acc: 0.9056 - val_loss: 0.4636 - val_acc: 1.0000\n",
            "Epoch 161/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4803 - acc: 0.9333 - val_loss: 0.4639 - val_acc: 1.0000\n",
            "Epoch 162/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4804 - acc: 0.9111 - val_loss: 0.4637 - val_acc: 0.9500\n",
            "Epoch 163/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4807 - acc: 0.9111 - val_loss: 0.4641 - val_acc: 1.0000\n",
            "Epoch 164/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4804 - acc: 0.8889 - val_loss: 0.4640 - val_acc: 1.0000\n",
            "Epoch 165/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4800 - acc: 0.9111 - val_loss: 0.4652 - val_acc: 1.0000\n",
            "Epoch 166/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4814 - acc: 0.9000 - val_loss: 0.4635 - val_acc: 1.0000\n",
            "Epoch 167/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4803 - acc: 0.9333 - val_loss: 0.4636 - val_acc: 1.0000\n",
            "Epoch 168/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4801 - acc: 0.9111 - val_loss: 0.4641 - val_acc: 1.0000\n",
            "Epoch 169/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4799 - acc: 0.9333 - val_loss: 0.4638 - val_acc: 1.0000\n",
            "Epoch 170/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.4797 - acc: 0.9167 - val_loss: 0.4638 - val_acc: 1.0000\n",
            "Epoch 171/800\n",
            "180/180 [==============================] - 0s 412us/step - loss: 0.4798 - acc: 0.9278 - val_loss: 0.4630 - val_acc: 1.0000\n",
            "Epoch 172/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4798 - acc: 0.9167 - val_loss: 0.4636 - val_acc: 1.0000\n",
            "Epoch 173/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4795 - acc: 0.9333 - val_loss: 0.4639 - val_acc: 1.0000\n",
            "Epoch 174/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.4795 - acc: 0.9389 - val_loss: 0.4631 - val_acc: 1.0000\n",
            "Epoch 175/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4796 - acc: 0.9222 - val_loss: 0.4631 - val_acc: 1.0000\n",
            "Epoch 176/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4795 - acc: 0.9333 - val_loss: 0.4634 - val_acc: 1.0000\n",
            "Epoch 177/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4792 - acc: 0.9111 - val_loss: 0.4634 - val_acc: 1.0000\n",
            "Epoch 178/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4792 - acc: 0.9222 - val_loss: 0.4633 - val_acc: 1.0000\n",
            "Epoch 179/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4792 - acc: 0.9278 - val_loss: 0.4629 - val_acc: 1.0000\n",
            "Epoch 180/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4790 - acc: 0.9333 - val_loss: 0.4634 - val_acc: 1.0000\n",
            "Epoch 181/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4791 - acc: 0.9278 - val_loss: 0.4643 - val_acc: 1.0000\n",
            "Epoch 182/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4792 - acc: 0.9333 - val_loss: 0.4670 - val_acc: 1.0000\n",
            "Epoch 183/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.4797 - acc: 0.9111 - val_loss: 0.4637 - val_acc: 1.0000\n",
            "Epoch 184/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4787 - acc: 0.9389 - val_loss: 0.4631 - val_acc: 1.0000\n",
            "Epoch 185/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.4785 - acc: 0.9389 - val_loss: 0.4640 - val_acc: 1.0000\n",
            "Epoch 186/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.4786 - acc: 0.9556 - val_loss: 0.4638 - val_acc: 1.0000\n",
            "Epoch 187/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4787 - acc: 0.9056 - val_loss: 0.4632 - val_acc: 1.0000\n",
            "Epoch 188/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.4786 - acc: 0.9222 - val_loss: 0.4647 - val_acc: 1.0000\n",
            "Epoch 189/800\n",
            "180/180 [==============================] - 0s 443us/step - loss: 0.4790 - acc: 0.9444 - val_loss: 0.4637 - val_acc: 1.0000\n",
            "Epoch 190/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4783 - acc: 0.9167 - val_loss: 0.4626 - val_acc: 1.0000\n",
            "Epoch 191/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4782 - acc: 0.9333 - val_loss: 0.4631 - val_acc: 1.0000\n",
            "Epoch 192/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4785 - acc: 0.9444 - val_loss: 0.4628 - val_acc: 1.0000\n",
            "Epoch 193/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4781 - acc: 0.9333 - val_loss: 0.4633 - val_acc: 1.0000\n",
            "Epoch 194/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4782 - acc: 0.9167 - val_loss: 0.4631 - val_acc: 1.0000\n",
            "Epoch 195/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4779 - acc: 0.9389 - val_loss: 0.4642 - val_acc: 1.0000\n",
            "Epoch 196/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.4798 - acc: 0.9222 - val_loss: 0.4625 - val_acc: 1.0000\n",
            "Epoch 197/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.4779 - acc: 0.9444 - val_loss: 0.4624 - val_acc: 1.0000\n",
            "Epoch 198/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4780 - acc: 0.9333 - val_loss: 0.4627 - val_acc: 1.0000\n",
            "Epoch 199/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4782 - acc: 0.9389 - val_loss: 0.4622 - val_acc: 1.0000\n",
            "Epoch 200/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4775 - acc: 0.9333 - val_loss: 0.4629 - val_acc: 1.0000\n",
            "Epoch 201/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4775 - acc: 0.9167 - val_loss: 0.4618 - val_acc: 1.0000\n",
            "Epoch 202/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4773 - acc: 0.9167 - val_loss: 0.4617 - val_acc: 1.0000\n",
            "Epoch 203/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4772 - acc: 0.9333 - val_loss: 0.4621 - val_acc: 1.0000\n",
            "Epoch 204/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4773 - acc: 0.9222 - val_loss: 0.4620 - val_acc: 1.0000\n",
            "Epoch 205/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4778 - acc: 0.9222 - val_loss: 0.4630 - val_acc: 1.0000\n",
            "Epoch 206/800\n",
            "180/180 [==============================] - 0s 393us/step - loss: 0.4772 - acc: 0.9389 - val_loss: 0.4616 - val_acc: 1.0000\n",
            "Epoch 207/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4773 - acc: 0.9500 - val_loss: 0.4621 - val_acc: 0.9500\n",
            "Epoch 208/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4770 - acc: 0.9222 - val_loss: 0.4620 - val_acc: 1.0000\n",
            "Epoch 209/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4770 - acc: 0.9167 - val_loss: 0.4617 - val_acc: 1.0000\n",
            "Epoch 210/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4768 - acc: 0.9222 - val_loss: 0.4610 - val_acc: 1.0000\n",
            "Epoch 211/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4774 - acc: 0.9278 - val_loss: 0.4616 - val_acc: 1.0000\n",
            "Epoch 212/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4765 - acc: 0.9278 - val_loss: 0.4612 - val_acc: 1.0000\n",
            "Epoch 213/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4767 - acc: 0.9222 - val_loss: 0.4615 - val_acc: 1.0000\n",
            "Epoch 214/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.4769 - acc: 0.9333 - val_loss: 0.4611 - val_acc: 1.0000\n",
            "Epoch 215/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4767 - acc: 0.9111 - val_loss: 0.4608 - val_acc: 1.0000\n",
            "Epoch 216/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4767 - acc: 0.9056 - val_loss: 0.4611 - val_acc: 0.9500\n",
            "Epoch 217/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4763 - acc: 0.9389 - val_loss: 0.4612 - val_acc: 1.0000\n",
            "Epoch 218/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4770 - acc: 0.9333 - val_loss: 0.4606 - val_acc: 1.0000\n",
            "Epoch 219/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4760 - acc: 0.9333 - val_loss: 0.4605 - val_acc: 1.0000\n",
            "Epoch 220/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.4760 - acc: 0.9389 - val_loss: 0.4608 - val_acc: 1.0000\n",
            "Epoch 221/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4761 - acc: 0.9222 - val_loss: 0.4611 - val_acc: 1.0000\n",
            "Epoch 222/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.4759 - acc: 0.9278 - val_loss: 0.4601 - val_acc: 1.0000\n",
            "Epoch 223/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4761 - acc: 0.9056 - val_loss: 0.4610 - val_acc: 1.0000\n",
            "Epoch 224/800\n",
            "180/180 [==============================] - 0s 456us/step - loss: 0.4760 - acc: 0.9389 - val_loss: 0.4602 - val_acc: 1.0000\n",
            "Epoch 225/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4756 - acc: 0.9111 - val_loss: 0.4602 - val_acc: 1.0000\n",
            "Epoch 226/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4758 - acc: 0.9278 - val_loss: 0.4598 - val_acc: 1.0000\n",
            "Epoch 227/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4753 - acc: 0.9167 - val_loss: 0.4598 - val_acc: 1.0000\n",
            "Epoch 228/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4756 - acc: 0.9333 - val_loss: 0.4605 - val_acc: 1.0000\n",
            "Epoch 229/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4764 - acc: 0.9111 - val_loss: 0.4597 - val_acc: 1.0000\n",
            "Epoch 230/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4752 - acc: 0.9500 - val_loss: 0.4600 - val_acc: 1.0000\n",
            "Epoch 231/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4781 - acc: 0.9167 - val_loss: 0.4609 - val_acc: 1.0000\n",
            "Epoch 232/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4763 - acc: 0.9222 - val_loss: 0.4607 - val_acc: 0.9500\n",
            "Epoch 233/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4754 - acc: 0.9222 - val_loss: 0.4590 - val_acc: 1.0000\n",
            "Epoch 234/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4749 - acc: 0.9389 - val_loss: 0.4592 - val_acc: 1.0000\n",
            "Epoch 235/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4749 - acc: 0.9222 - val_loss: 0.4614 - val_acc: 0.9500\n",
            "Epoch 236/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4754 - acc: 0.9278 - val_loss: 0.4590 - val_acc: 1.0000\n",
            "Epoch 237/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4743 - acc: 0.9333 - val_loss: 0.4589 - val_acc: 1.0000\n",
            "Epoch 238/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.4748 - acc: 0.9500 - val_loss: 0.4586 - val_acc: 1.0000\n",
            "Epoch 239/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4742 - acc: 0.9444 - val_loss: 0.4587 - val_acc: 1.0000\n",
            "Epoch 240/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4741 - acc: 0.9111 - val_loss: 0.4581 - val_acc: 1.0000\n",
            "Epoch 241/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.4740 - acc: 0.9333 - val_loss: 0.4581 - val_acc: 1.0000\n",
            "Epoch 242/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4740 - acc: 0.9444 - val_loss: 0.4581 - val_acc: 1.0000\n",
            "Epoch 243/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4736 - acc: 0.9222 - val_loss: 0.4583 - val_acc: 0.9500\n",
            "Epoch 244/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4737 - acc: 0.9278 - val_loss: 0.4582 - val_acc: 1.0000\n",
            "Epoch 245/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4743 - acc: 0.9333 - val_loss: 0.4591 - val_acc: 1.0000\n",
            "Epoch 246/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4742 - acc: 0.9167 - val_loss: 0.4580 - val_acc: 0.9500\n",
            "Epoch 247/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4734 - acc: 0.9222 - val_loss: 0.4574 - val_acc: 1.0000\n",
            "Epoch 248/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4735 - acc: 0.9222 - val_loss: 0.4579 - val_acc: 1.0000\n",
            "Epoch 249/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4732 - acc: 0.9444 - val_loss: 0.4573 - val_acc: 1.0000\n",
            "Epoch 250/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4736 - acc: 0.9111 - val_loss: 0.4576 - val_acc: 1.0000\n",
            "Epoch 251/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4732 - acc: 0.9333 - val_loss: 0.4570 - val_acc: 1.0000\n",
            "Epoch 252/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.4728 - acc: 0.9278 - val_loss: 0.4576 - val_acc: 1.0000\n",
            "Epoch 253/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4729 - acc: 0.9278 - val_loss: 0.4574 - val_acc: 1.0000\n",
            "Epoch 254/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4735 - acc: 0.8667 - val_loss: 0.4567 - val_acc: 0.9500\n",
            "Epoch 255/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4727 - acc: 0.9222 - val_loss: 0.4566 - val_acc: 1.0000\n",
            "Epoch 256/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4721 - acc: 0.9056 - val_loss: 0.4564 - val_acc: 1.0000\n",
            "Epoch 257/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4723 - acc: 0.9222 - val_loss: 0.4566 - val_acc: 1.0000\n",
            "Epoch 258/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.4720 - acc: 0.9333 - val_loss: 0.4567 - val_acc: 1.0000\n",
            "Epoch 259/800\n",
            "180/180 [==============================] - 0s 501us/step - loss: 0.4718 - acc: 0.9278 - val_loss: 0.4572 - val_acc: 1.0000\n",
            "Epoch 260/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.4730 - acc: 0.9222 - val_loss: 0.4565 - val_acc: 1.0000\n",
            "Epoch 261/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4723 - acc: 0.9167 - val_loss: 0.4564 - val_acc: 1.0000\n",
            "Epoch 262/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.4728 - acc: 0.9167 - val_loss: 0.4567 - val_acc: 1.0000\n",
            "Epoch 263/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4717 - acc: 0.8944 - val_loss: 0.4573 - val_acc: 1.0000\n",
            "Epoch 264/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4715 - acc: 0.8722 - val_loss: 0.4552 - val_acc: 1.0000\n",
            "Epoch 265/800\n",
            "180/180 [==============================] - 0s 398us/step - loss: 0.4714 - acc: 0.9222 - val_loss: 0.4558 - val_acc: 1.0000\n",
            "Epoch 266/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4714 - acc: 0.9111 - val_loss: 0.4548 - val_acc: 0.9500\n",
            "Epoch 267/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4712 - acc: 0.9278 - val_loss: 0.4553 - val_acc: 1.0000\n",
            "Epoch 268/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4708 - acc: 0.9389 - val_loss: 0.4556 - val_acc: 1.0000\n",
            "Epoch 269/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4706 - acc: 0.9111 - val_loss: 0.4555 - val_acc: 0.9500\n",
            "Epoch 270/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4717 - acc: 0.8944 - val_loss: 0.4558 - val_acc: 0.9500\n",
            "Epoch 271/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.4726 - acc: 0.9056 - val_loss: 0.4552 - val_acc: 0.9500\n",
            "Epoch 272/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4702 - acc: 0.9278 - val_loss: 0.4540 - val_acc: 1.0000\n",
            "Epoch 273/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4698 - acc: 0.9389 - val_loss: 0.4545 - val_acc: 0.9500\n",
            "Epoch 274/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4701 - acc: 0.9278 - val_loss: 0.4542 - val_acc: 0.9500\n",
            "Epoch 275/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4706 - acc: 0.8667 - val_loss: 0.4555 - val_acc: 1.0000\n",
            "Epoch 276/800\n",
            "180/180 [==============================] - 0s 484us/step - loss: 0.4718 - acc: 0.8722 - val_loss: 0.4528 - val_acc: 1.0000\n",
            "Epoch 277/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4702 - acc: 0.9056 - val_loss: 0.4539 - val_acc: 0.9500\n",
            "Epoch 278/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4693 - acc: 0.9111 - val_loss: 0.4528 - val_acc: 0.9500\n",
            "Epoch 279/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4689 - acc: 0.9111 - val_loss: 0.4523 - val_acc: 1.0000\n",
            "Epoch 280/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.4689 - acc: 0.9111 - val_loss: 0.4524 - val_acc: 1.0000\n",
            "Epoch 281/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4684 - acc: 0.9167 - val_loss: 0.4522 - val_acc: 1.0000\n",
            "Epoch 282/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.4683 - acc: 0.9056 - val_loss: 0.4528 - val_acc: 0.9500\n",
            "Epoch 283/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4692 - acc: 0.9444 - val_loss: 0.4531 - val_acc: 1.0000\n",
            "Epoch 284/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.4681 - acc: 0.9333 - val_loss: 0.4531 - val_acc: 1.0000\n",
            "Epoch 285/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4680 - acc: 0.9222 - val_loss: 0.4516 - val_acc: 1.0000\n",
            "Epoch 286/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.4677 - acc: 0.9167 - val_loss: 0.4521 - val_acc: 0.9500\n",
            "Epoch 287/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4679 - acc: 0.9111 - val_loss: 0.4510 - val_acc: 1.0000\n",
            "Epoch 288/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4667 - acc: 0.9278 - val_loss: 0.4504 - val_acc: 0.9500\n",
            "Epoch 289/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4667 - acc: 0.9222 - val_loss: 0.4519 - val_acc: 0.9500\n",
            "Epoch 290/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4672 - acc: 0.9000 - val_loss: 0.4506 - val_acc: 0.9500\n",
            "Epoch 291/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4669 - acc: 0.9333 - val_loss: 0.4498 - val_acc: 0.9500\n",
            "Epoch 292/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4661 - acc: 0.9389 - val_loss: 0.4509 - val_acc: 0.9500\n",
            "Epoch 293/800\n",
            "180/180 [==============================] - 0s 495us/step - loss: 0.4664 - acc: 0.9000 - val_loss: 0.4496 - val_acc: 1.0000\n",
            "Epoch 294/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4660 - acc: 0.9333 - val_loss: 0.4494 - val_acc: 1.0000\n",
            "Epoch 295/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4655 - acc: 0.9333 - val_loss: 0.4489 - val_acc: 0.9500\n",
            "Epoch 296/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4654 - acc: 0.9167 - val_loss: 0.4495 - val_acc: 0.9500\n",
            "Epoch 297/800\n",
            "180/180 [==============================] - 0s 395us/step - loss: 0.4658 - acc: 0.9000 - val_loss: 0.4482 - val_acc: 1.0000\n",
            "Epoch 298/800\n",
            "180/180 [==============================] - 0s 408us/step - loss: 0.4644 - acc: 0.9278 - val_loss: 0.4476 - val_acc: 1.0000\n",
            "Epoch 299/800\n",
            "180/180 [==============================] - 0s 394us/step - loss: 0.4656 - acc: 0.9056 - val_loss: 0.4482 - val_acc: 0.9500\n",
            "Epoch 300/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4646 - acc: 0.9111 - val_loss: 0.4475 - val_acc: 1.0000\n",
            "Epoch 301/800\n",
            "180/180 [==============================] - 0s 400us/step - loss: 0.4643 - acc: 0.9056 - val_loss: 0.4471 - val_acc: 0.9000\n",
            "Epoch 302/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.4638 - acc: 0.9389 - val_loss: 0.4485 - val_acc: 1.0000\n",
            "Epoch 303/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4636 - acc: 0.8889 - val_loss: 0.4471 - val_acc: 0.9500\n",
            "Epoch 304/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.4632 - acc: 0.9056 - val_loss: 0.4458 - val_acc: 1.0000\n",
            "Epoch 305/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4622 - acc: 0.9222 - val_loss: 0.4451 - val_acc: 1.0000\n",
            "Epoch 306/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4622 - acc: 0.9056 - val_loss: 0.4477 - val_acc: 0.9500\n",
            "Epoch 307/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4626 - acc: 0.9000 - val_loss: 0.4461 - val_acc: 0.9500\n",
            "Epoch 308/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4615 - acc: 0.9444 - val_loss: 0.4450 - val_acc: 0.9500\n",
            "Epoch 309/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4625 - acc: 0.9167 - val_loss: 0.4466 - val_acc: 1.0000\n",
            "Epoch 310/800\n",
            "180/180 [==============================] - 0s 495us/step - loss: 0.4719 - acc: 0.8444 - val_loss: 0.4438 - val_acc: 0.9500\n",
            "Epoch 311/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4603 - acc: 0.9056 - val_loss: 0.4437 - val_acc: 1.0000\n",
            "Epoch 312/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4613 - acc: 0.9111 - val_loss: 0.4439 - val_acc: 0.9500\n",
            "Epoch 313/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4605 - acc: 0.8889 - val_loss: 0.4435 - val_acc: 0.9500\n",
            "Epoch 314/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4596 - acc: 0.9278 - val_loss: 0.4417 - val_acc: 1.0000\n",
            "Epoch 315/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4589 - acc: 0.9056 - val_loss: 0.4424 - val_acc: 0.9500\n",
            "Epoch 316/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4592 - acc: 0.9056 - val_loss: 0.4415 - val_acc: 0.9500\n",
            "Epoch 317/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4580 - acc: 0.9000 - val_loss: 0.4407 - val_acc: 0.9500\n",
            "Epoch 318/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4598 - acc: 0.9000 - val_loss: 0.4405 - val_acc: 1.0000\n",
            "Epoch 319/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4587 - acc: 0.9056 - val_loss: 0.4405 - val_acc: 0.9000\n",
            "Epoch 320/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4570 - acc: 0.9056 - val_loss: 0.4423 - val_acc: 1.0000\n",
            "Epoch 321/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4570 - acc: 0.9056 - val_loss: 0.4413 - val_acc: 0.9500\n",
            "Epoch 322/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.4576 - acc: 0.8944 - val_loss: 0.4391 - val_acc: 0.9500\n",
            "Epoch 323/800\n",
            "180/180 [==============================] - 0s 394us/step - loss: 0.4569 - acc: 0.8944 - val_loss: 0.4395 - val_acc: 0.8500\n",
            "Epoch 324/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4555 - acc: 0.9278 - val_loss: 0.4378 - val_acc: 0.9500\n",
            "Epoch 325/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4571 - acc: 0.8833 - val_loss: 0.4384 - val_acc: 1.0000\n",
            "Epoch 326/800\n",
            "180/180 [==============================] - 0s 395us/step - loss: 0.4555 - acc: 0.9056 - val_loss: 0.4371 - val_acc: 1.0000\n",
            "Epoch 327/800\n",
            "180/180 [==============================] - 0s 479us/step - loss: 0.4553 - acc: 0.8889 - val_loss: 0.4386 - val_acc: 0.9500\n",
            "Epoch 328/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4570 - acc: 0.8833 - val_loss: 0.4356 - val_acc: 0.9500\n",
            "Epoch 329/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4533 - acc: 0.9167 - val_loss: 0.4345 - val_acc: 1.0000\n",
            "Epoch 330/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4533 - acc: 0.9167 - val_loss: 0.4351 - val_acc: 0.9500\n",
            "Epoch 331/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4521 - acc: 0.9000 - val_loss: 0.4359 - val_acc: 0.9500\n",
            "Epoch 332/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4520 - acc: 0.8889 - val_loss: 0.4342 - val_acc: 0.9500\n",
            "Epoch 333/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4511 - acc: 0.9167 - val_loss: 0.4329 - val_acc: 0.9500\n",
            "Epoch 334/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4502 - acc: 0.9056 - val_loss: 0.4333 - val_acc: 0.9000\n",
            "Epoch 335/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4541 - acc: 0.8889 - val_loss: 0.4355 - val_acc: 0.9500\n",
            "Epoch 336/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4512 - acc: 0.8722 - val_loss: 0.4328 - val_acc: 0.9500\n",
            "Epoch 337/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4490 - acc: 0.8889 - val_loss: 0.4303 - val_acc: 1.0000\n",
            "Epoch 338/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4484 - acc: 0.8889 - val_loss: 0.4309 - val_acc: 1.0000\n",
            "Epoch 339/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4496 - acc: 0.9056 - val_loss: 0.4310 - val_acc: 1.0000\n",
            "Epoch 340/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.4487 - acc: 0.9222 - val_loss: 0.4297 - val_acc: 0.9000\n",
            "Epoch 341/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4481 - acc: 0.9056 - val_loss: 0.4286 - val_acc: 0.9500\n",
            "Epoch 342/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4473 - acc: 0.8833 - val_loss: 0.4282 - val_acc: 1.0000\n",
            "Epoch 343/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4463 - acc: 0.9000 - val_loss: 0.4272 - val_acc: 0.9500\n",
            "Epoch 344/800\n",
            "180/180 [==============================] - 0s 417us/step - loss: 0.4468 - acc: 0.9000 - val_loss: 0.4276 - val_acc: 0.9500\n",
            "Epoch 345/800\n",
            "180/180 [==============================] - 0s 399us/step - loss: 0.4452 - acc: 0.8833 - val_loss: 0.4273 - val_acc: 0.9500\n",
            "Epoch 346/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4510 - acc: 0.8667 - val_loss: 0.4265 - val_acc: 1.0000\n",
            "Epoch 347/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4478 - acc: 0.9000 - val_loss: 0.4271 - val_acc: 0.9500\n",
            "Epoch 348/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4457 - acc: 0.8667 - val_loss: 0.4270 - val_acc: 0.9000\n",
            "Epoch 349/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4445 - acc: 0.9111 - val_loss: 0.4252 - val_acc: 0.9500\n",
            "Epoch 350/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4429 - acc: 0.9056 - val_loss: 0.4245 - val_acc: 1.0000\n",
            "Epoch 351/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4429 - acc: 0.8944 - val_loss: 0.4249 - val_acc: 0.9500\n",
            "Epoch 352/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4420 - acc: 0.8944 - val_loss: 0.4245 - val_acc: 0.9500\n",
            "Epoch 353/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.4418 - acc: 0.9000 - val_loss: 0.4230 - val_acc: 0.9500\n",
            "Epoch 354/800\n",
            "180/180 [==============================] - 0s 403us/step - loss: 0.4417 - acc: 0.8778 - val_loss: 0.4220 - val_acc: 0.9500\n",
            "Epoch 355/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4406 - acc: 0.8778 - val_loss: 0.4215 - val_acc: 1.0000\n",
            "Epoch 356/800\n",
            "180/180 [==============================] - 0s 392us/step - loss: 0.4400 - acc: 0.9056 - val_loss: 0.4214 - val_acc: 0.9500\n",
            "Epoch 357/800\n",
            "180/180 [==============================] - 0s 396us/step - loss: 0.4405 - acc: 0.8889 - val_loss: 0.4215 - val_acc: 1.0000\n",
            "Epoch 358/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4403 - acc: 0.8889 - val_loss: 0.4216 - val_acc: 0.9000\n",
            "Epoch 359/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4398 - acc: 0.8722 - val_loss: 0.4207 - val_acc: 0.9500\n",
            "Epoch 360/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4390 - acc: 0.8889 - val_loss: 0.4202 - val_acc: 0.9500\n",
            "Epoch 361/800\n",
            "180/180 [==============================] - 0s 499us/step - loss: 0.4383 - acc: 0.8833 - val_loss: 0.4185 - val_acc: 0.9500\n",
            "Epoch 362/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4384 - acc: 0.9167 - val_loss: 0.4188 - val_acc: 0.9000\n",
            "Epoch 363/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4375 - acc: 0.9056 - val_loss: 0.4173 - val_acc: 1.0000\n",
            "Epoch 364/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.4368 - acc: 0.8833 - val_loss: 0.4166 - val_acc: 1.0000\n",
            "Epoch 365/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4364 - acc: 0.9000 - val_loss: 0.4182 - val_acc: 0.9000\n",
            "Epoch 366/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4369 - acc: 0.8944 - val_loss: 0.4156 - val_acc: 0.9500\n",
            "Epoch 367/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4364 - acc: 0.8889 - val_loss: 0.4150 - val_acc: 1.0000\n",
            "Epoch 368/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4361 - acc: 0.8944 - val_loss: 0.4181 - val_acc: 0.9500\n",
            "Epoch 369/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4364 - acc: 0.8611 - val_loss: 0.4144 - val_acc: 1.0000\n",
            "Epoch 370/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4351 - acc: 0.8944 - val_loss: 0.4149 - val_acc: 1.0000\n",
            "Epoch 371/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4344 - acc: 0.8778 - val_loss: 0.4140 - val_acc: 0.9000\n",
            "Epoch 372/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4341 - acc: 0.8944 - val_loss: 0.4129 - val_acc: 1.0000\n",
            "Epoch 373/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.4337 - acc: 0.8944 - val_loss: 0.4129 - val_acc: 1.0000\n",
            "Epoch 374/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4338 - acc: 0.8944 - val_loss: 0.4128 - val_acc: 1.0000\n",
            "Epoch 375/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4336 - acc: 0.8889 - val_loss: 0.4125 - val_acc: 1.0000\n",
            "Epoch 376/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4349 - acc: 0.8833 - val_loss: 0.4129 - val_acc: 1.0000\n",
            "Epoch 377/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4329 - acc: 0.9000 - val_loss: 0.4117 - val_acc: 1.0000\n",
            "Epoch 378/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4330 - acc: 0.9167 - val_loss: 0.4122 - val_acc: 0.9500\n",
            "Epoch 379/800\n",
            "180/180 [==============================] - 0s 498us/step - loss: 0.4335 - acc: 0.9000 - val_loss: 0.4104 - val_acc: 1.0000\n",
            "Epoch 380/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4319 - acc: 0.8833 - val_loss: 0.4103 - val_acc: 0.9500\n",
            "Epoch 381/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4318 - acc: 0.9167 - val_loss: 0.4092 - val_acc: 1.0000\n",
            "Epoch 382/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.4310 - acc: 0.8833 - val_loss: 0.4092 - val_acc: 1.0000\n",
            "Epoch 383/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4309 - acc: 0.9056 - val_loss: 0.4104 - val_acc: 0.9500\n",
            "Epoch 384/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4319 - acc: 0.8778 - val_loss: 0.4121 - val_acc: 1.0000\n",
            "Epoch 385/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.4339 - acc: 0.8889 - val_loss: 0.4082 - val_acc: 0.9500\n",
            "Epoch 386/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4303 - acc: 0.9056 - val_loss: 0.4075 - val_acc: 1.0000\n",
            "Epoch 387/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.4294 - acc: 0.9000 - val_loss: 0.4071 - val_acc: 1.0000\n",
            "Epoch 388/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4282 - acc: 0.8833 - val_loss: 0.4059 - val_acc: 1.0000\n",
            "Epoch 389/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4285 - acc: 0.9111 - val_loss: 0.4062 - val_acc: 0.9500\n",
            "Epoch 390/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4278 - acc: 0.8889 - val_loss: 0.4078 - val_acc: 0.9500\n",
            "Epoch 391/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4299 - acc: 0.8944 - val_loss: 0.4054 - val_acc: 1.0000\n",
            "Epoch 392/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4275 - acc: 0.9056 - val_loss: 0.4117 - val_acc: 1.0000\n",
            "Epoch 393/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4339 - acc: 0.8556 - val_loss: 0.4068 - val_acc: 1.0000\n",
            "Epoch 394/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4283 - acc: 0.8944 - val_loss: 0.4048 - val_acc: 0.9500\n",
            "Epoch 395/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4270 - acc: 0.9278 - val_loss: 0.4043 - val_acc: 1.0000\n",
            "Epoch 396/800\n",
            "180/180 [==============================] - 0s 465us/step - loss: 0.4262 - acc: 0.9000 - val_loss: 0.4048 - val_acc: 1.0000\n",
            "Epoch 397/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4285 - acc: 0.9056 - val_loss: 0.4056 - val_acc: 1.0000\n",
            "Epoch 398/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4270 - acc: 0.9167 - val_loss: 0.4049 - val_acc: 1.0000\n",
            "Epoch 399/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4262 - acc: 0.8833 - val_loss: 0.4031 - val_acc: 1.0000\n",
            "Epoch 400/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4273 - acc: 0.8722 - val_loss: 0.4028 - val_acc: 1.0000\n",
            "Epoch 401/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4254 - acc: 0.9167 - val_loss: 0.4029 - val_acc: 1.0000\n",
            "Epoch 402/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4262 - acc: 0.9056 - val_loss: 0.4023 - val_acc: 1.0000\n",
            "Epoch 403/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4277 - acc: 0.9111 - val_loss: 0.4044 - val_acc: 1.0000\n",
            "Epoch 404/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4265 - acc: 0.8889 - val_loss: 0.4021 - val_acc: 0.9500\n",
            "Epoch 405/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.4252 - acc: 0.9167 - val_loss: 0.4026 - val_acc: 0.9500\n",
            "Epoch 406/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.4247 - acc: 0.9000 - val_loss: 0.4009 - val_acc: 1.0000\n",
            "Epoch 407/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4243 - acc: 0.8833 - val_loss: 0.4022 - val_acc: 1.0000\n",
            "Epoch 408/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4241 - acc: 0.8944 - val_loss: 0.4009 - val_acc: 0.9500\n",
            "Epoch 409/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4235 - acc: 0.9167 - val_loss: 0.4023 - val_acc: 1.0000\n",
            "Epoch 410/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4243 - acc: 0.8778 - val_loss: 0.4012 - val_acc: 1.0000\n",
            "Epoch 411/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4233 - acc: 0.8833 - val_loss: 0.4007 - val_acc: 0.9500\n",
            "Epoch 412/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4233 - acc: 0.9056 - val_loss: 0.4003 - val_acc: 1.0000\n",
            "Epoch 413/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4232 - acc: 0.9000 - val_loss: 0.3996 - val_acc: 1.0000\n",
            "Epoch 414/800\n",
            "180/180 [==============================] - 0s 437us/step - loss: 0.4233 - acc: 0.8833 - val_loss: 0.3993 - val_acc: 0.9500\n",
            "Epoch 415/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4225 - acc: 0.9000 - val_loss: 0.3994 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00415: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 416/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4221 - acc: 0.9000 - val_loss: 0.3991 - val_acc: 1.0000\n",
            "Epoch 417/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4218 - acc: 0.9111 - val_loss: 0.3991 - val_acc: 1.0000\n",
            "Epoch 418/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.4221 - acc: 0.9056 - val_loss: 0.3990 - val_acc: 1.0000\n",
            "Epoch 419/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4219 - acc: 0.9111 - val_loss: 0.3990 - val_acc: 1.0000\n",
            "Epoch 420/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4219 - acc: 0.9000 - val_loss: 0.3989 - val_acc: 1.0000\n",
            "Epoch 421/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4218 - acc: 0.8667 - val_loss: 0.3989 - val_acc: 1.0000\n",
            "Epoch 422/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4218 - acc: 0.8722 - val_loss: 0.3989 - val_acc: 1.0000\n",
            "Epoch 423/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4218 - acc: 0.8944 - val_loss: 0.3988 - val_acc: 1.0000\n",
            "Epoch 424/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.4219 - acc: 0.9167 - val_loss: 0.3987 - val_acc: 1.0000\n",
            "Epoch 425/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.4215 - acc: 0.9222 - val_loss: 0.3987 - val_acc: 1.0000\n",
            "Epoch 426/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4213 - acc: 0.9167 - val_loss: 0.3987 - val_acc: 1.0000\n",
            "Epoch 427/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4214 - acc: 0.9167 - val_loss: 0.3986 - val_acc: 1.0000\n",
            "Epoch 428/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4215 - acc: 0.9111 - val_loss: 0.3986 - val_acc: 1.0000\n",
            "Epoch 429/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.4215 - acc: 0.8889 - val_loss: 0.3986 - val_acc: 1.0000\n",
            "Epoch 430/800\n",
            "180/180 [==============================] - 0s 464us/step - loss: 0.4216 - acc: 0.8667 - val_loss: 0.3985 - val_acc: 1.0000\n",
            "Epoch 431/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4217 - acc: 0.8778 - val_loss: 0.3984 - val_acc: 1.0000\n",
            "Epoch 432/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4213 - acc: 0.8778 - val_loss: 0.3984 - val_acc: 1.0000\n",
            "Epoch 433/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4212 - acc: 0.8833 - val_loss: 0.3984 - val_acc: 1.0000\n",
            "Epoch 434/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4211 - acc: 0.9167 - val_loss: 0.3983 - val_acc: 1.0000\n",
            "Epoch 435/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.4215 - acc: 0.9222 - val_loss: 0.3983 - val_acc: 1.0000\n",
            "Epoch 436/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4212 - acc: 0.9056 - val_loss: 0.3983 - val_acc: 1.0000\n",
            "Epoch 437/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4212 - acc: 0.9056 - val_loss: 0.3983 - val_acc: 1.0000\n",
            "Epoch 438/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.4213 - acc: 0.9056 - val_loss: 0.3983 - val_acc: 1.0000\n",
            "Epoch 439/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.4206 - acc: 0.9056 - val_loss: 0.3982 - val_acc: 1.0000\n",
            "Epoch 440/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4209 - acc: 0.9167 - val_loss: 0.3981 - val_acc: 1.0000\n",
            "Epoch 441/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4209 - acc: 0.9111 - val_loss: 0.3981 - val_acc: 1.0000\n",
            "Epoch 442/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4212 - acc: 0.9167 - val_loss: 0.3980 - val_acc: 1.0000\n",
            "Epoch 443/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4211 - acc: 0.9167 - val_loss: 0.3980 - val_acc: 1.0000\n",
            "Epoch 444/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4210 - acc: 0.9111 - val_loss: 0.3979 - val_acc: 1.0000\n",
            "Epoch 445/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4206 - acc: 0.9222 - val_loss: 0.3979 - val_acc: 1.0000\n",
            "Epoch 446/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4206 - acc: 0.9000 - val_loss: 0.3979 - val_acc: 1.0000\n",
            "Epoch 447/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4208 - acc: 0.9111 - val_loss: 0.3978 - val_acc: 1.0000\n",
            "Epoch 448/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4205 - acc: 0.9167 - val_loss: 0.3978 - val_acc: 1.0000\n",
            "Epoch 449/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4209 - acc: 0.9167 - val_loss: 0.3978 - val_acc: 1.0000\n",
            "Epoch 450/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4206 - acc: 0.9111 - val_loss: 0.3978 - val_acc: 1.0000\n",
            "Epoch 451/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4206 - acc: 0.9167 - val_loss: 0.3978 - val_acc: 1.0000\n",
            "Epoch 452/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.4205 - acc: 0.9167 - val_loss: 0.3977 - val_acc: 1.0000\n",
            "Epoch 453/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4203 - acc: 0.9111 - val_loss: 0.3976 - val_acc: 1.0000\n",
            "Epoch 454/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4204 - acc: 0.9056 - val_loss: 0.3976 - val_acc: 1.0000\n",
            "Epoch 455/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.4206 - acc: 0.9111 - val_loss: 0.3975 - val_acc: 1.0000\n",
            "Epoch 456/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4206 - acc: 0.9111 - val_loss: 0.3974 - val_acc: 1.0000\n",
            "Epoch 457/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4204 - acc: 0.9167 - val_loss: 0.3974 - val_acc: 1.0000\n",
            "Epoch 458/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4203 - acc: 0.9167 - val_loss: 0.3974 - val_acc: 1.0000\n",
            "Epoch 459/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4203 - acc: 0.9167 - val_loss: 0.3974 - val_acc: 1.0000\n",
            "Epoch 460/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4203 - acc: 0.9222 - val_loss: 0.3974 - val_acc: 1.0000\n",
            "Epoch 461/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4203 - acc: 0.9111 - val_loss: 0.3973 - val_acc: 1.0000\n",
            "Epoch 462/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4204 - acc: 0.9111 - val_loss: 0.3973 - val_acc: 1.0000\n",
            "Epoch 463/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4199 - acc: 0.9167 - val_loss: 0.3972 - val_acc: 1.0000\n",
            "Epoch 464/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4203 - acc: 0.9167 - val_loss: 0.3972 - val_acc: 1.0000\n",
            "Epoch 465/800\n",
            "180/180 [==============================] - 0s 469us/step - loss: 0.4200 - acc: 0.9056 - val_loss: 0.3972 - val_acc: 1.0000\n",
            "Epoch 466/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4202 - acc: 0.8667 - val_loss: 0.3972 - val_acc: 1.0000\n",
            "Epoch 467/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4202 - acc: 0.8833 - val_loss: 0.3971 - val_acc: 1.0000\n",
            "Epoch 468/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4200 - acc: 0.8889 - val_loss: 0.3971 - val_acc: 1.0000\n",
            "Epoch 469/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4200 - acc: 0.9111 - val_loss: 0.3971 - val_acc: 1.0000\n",
            "Epoch 470/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4201 - acc: 0.9333 - val_loss: 0.3970 - val_acc: 1.0000\n",
            "Epoch 471/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.4199 - acc: 0.9333 - val_loss: 0.3969 - val_acc: 1.0000\n",
            "Epoch 472/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4201 - acc: 0.9167 - val_loss: 0.3969 - val_acc: 1.0000\n",
            "Epoch 473/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4195 - acc: 0.9111 - val_loss: 0.3969 - val_acc: 1.0000\n",
            "Epoch 474/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.4198 - acc: 0.9222 - val_loss: 0.3968 - val_acc: 1.0000\n",
            "Epoch 475/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4197 - acc: 0.9000 - val_loss: 0.3968 - val_acc: 1.0000\n",
            "Epoch 476/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4197 - acc: 0.8778 - val_loss: 0.3969 - val_acc: 1.0000\n",
            "Epoch 477/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4198 - acc: 0.8889 - val_loss: 0.3968 - val_acc: 1.0000\n",
            "Epoch 478/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4196 - acc: 0.9111 - val_loss: 0.3967 - val_acc: 1.0000\n",
            "Epoch 479/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4199 - acc: 0.9056 - val_loss: 0.3967 - val_acc: 1.0000\n",
            "Epoch 480/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4194 - acc: 0.9111 - val_loss: 0.3967 - val_acc: 1.0000\n",
            "Epoch 481/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4193 - acc: 0.9111 - val_loss: 0.3966 - val_acc: 1.0000\n",
            "Epoch 482/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4196 - acc: 0.9167 - val_loss: 0.3966 - val_acc: 1.0000\n",
            "Epoch 483/800\n",
            "180/180 [==============================] - 0s 417us/step - loss: 0.4198 - acc: 0.9167 - val_loss: 0.3966 - val_acc: 1.0000\n",
            "Epoch 484/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4193 - acc: 0.9167 - val_loss: 0.3966 - val_acc: 1.0000\n",
            "Epoch 485/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4194 - acc: 0.9167 - val_loss: 0.3965 - val_acc: 1.0000\n",
            "Epoch 486/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.4197 - acc: 0.9167 - val_loss: 0.3965 - val_acc: 1.0000\n",
            "Epoch 487/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4194 - acc: 0.9222 - val_loss: 0.3964 - val_acc: 1.0000\n",
            "Epoch 488/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4192 - acc: 0.9111 - val_loss: 0.3964 - val_acc: 1.0000\n",
            "Epoch 489/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4191 - acc: 0.9222 - val_loss: 0.3965 - val_acc: 1.0000\n",
            "Epoch 490/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4193 - acc: 0.9167 - val_loss: 0.3964 - val_acc: 1.0000\n",
            "Epoch 491/800\n",
            "180/180 [==============================] - 0s 392us/step - loss: 0.4193 - acc: 0.9222 - val_loss: 0.3964 - val_acc: 1.0000\n",
            "Epoch 492/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4194 - acc: 0.9167 - val_loss: 0.3963 - val_acc: 1.0000\n",
            "Epoch 493/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4191 - acc: 0.9167 - val_loss: 0.3963 - val_acc: 1.0000\n",
            "Epoch 494/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4189 - acc: 0.9222 - val_loss: 0.3963 - val_acc: 1.0000\n",
            "Epoch 495/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4193 - acc: 0.8944 - val_loss: 0.3962 - val_acc: 1.0000\n",
            "Epoch 496/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4191 - acc: 0.8667 - val_loss: 0.3962 - val_acc: 1.0000\n",
            "Epoch 497/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4191 - acc: 0.8833 - val_loss: 0.3962 - val_acc: 1.0000\n",
            "Epoch 498/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4192 - acc: 0.9000 - val_loss: 0.3961 - val_acc: 1.0000\n",
            "Epoch 499/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4190 - acc: 0.9056 - val_loss: 0.3960 - val_acc: 1.0000\n",
            "Epoch 500/800\n",
            "180/180 [==============================] - 0s 519us/step - loss: 0.4191 - acc: 0.9167 - val_loss: 0.3960 - val_acc: 1.0000\n",
            "Epoch 501/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4191 - acc: 0.9222 - val_loss: 0.3960 - val_acc: 1.0000\n",
            "Epoch 502/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4190 - acc: 0.9222 - val_loss: 0.3959 - val_acc: 1.0000\n",
            "Epoch 503/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4188 - acc: 0.9111 - val_loss: 0.3960 - val_acc: 1.0000\n",
            "Epoch 504/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4186 - acc: 0.9222 - val_loss: 0.3958 - val_acc: 1.0000\n",
            "Epoch 505/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4189 - acc: 0.9111 - val_loss: 0.3959 - val_acc: 1.0000\n",
            "Epoch 506/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4190 - acc: 0.9167 - val_loss: 0.3958 - val_acc: 1.0000\n",
            "Epoch 507/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4189 - acc: 0.9222 - val_loss: 0.3958 - val_acc: 1.0000\n",
            "Epoch 508/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4189 - acc: 0.9222 - val_loss: 0.3958 - val_acc: 1.0000\n",
            "Epoch 509/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4188 - acc: 0.9278 - val_loss: 0.3957 - val_acc: 1.0000\n",
            "Epoch 510/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.4184 - acc: 0.9111 - val_loss: 0.3958 - val_acc: 1.0000\n",
            "Epoch 511/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.4186 - acc: 0.9222 - val_loss: 0.3957 - val_acc: 1.0000\n",
            "Epoch 512/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4186 - acc: 0.9222 - val_loss: 0.3957 - val_acc: 1.0000\n",
            "Epoch 513/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4185 - acc: 0.9167 - val_loss: 0.3956 - val_acc: 1.0000\n",
            "Epoch 514/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4182 - acc: 0.9111 - val_loss: 0.3956 - val_acc: 1.0000\n",
            "Epoch 515/800\n",
            "180/180 [==============================] - 0s 409us/step - loss: 0.4186 - acc: 0.8778 - val_loss: 0.3955 - val_acc: 1.0000\n",
            "Epoch 516/800\n",
            "180/180 [==============================] - 0s 392us/step - loss: 0.4182 - acc: 0.8944 - val_loss: 0.3955 - val_acc: 1.0000\n",
            "Epoch 517/800\n",
            "180/180 [==============================] - 0s 505us/step - loss: 0.4185 - acc: 0.9222 - val_loss: 0.3955 - val_acc: 1.0000\n",
            "Epoch 518/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4184 - acc: 0.9222 - val_loss: 0.3954 - val_acc: 1.0000\n",
            "Epoch 519/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4186 - acc: 0.9333 - val_loss: 0.3955 - val_acc: 1.0000\n",
            "Epoch 520/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4182 - acc: 0.9167 - val_loss: 0.3954 - val_acc: 1.0000\n",
            "Epoch 521/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4184 - acc: 0.9167 - val_loss: 0.3954 - val_acc: 1.0000\n",
            "Epoch 522/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4183 - acc: 0.9111 - val_loss: 0.3953 - val_acc: 1.0000\n",
            "Epoch 523/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.4183 - acc: 0.9167 - val_loss: 0.3953 - val_acc: 1.0000\n",
            "Epoch 524/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.4180 - acc: 0.9167 - val_loss: 0.3953 - val_acc: 1.0000\n",
            "Epoch 525/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4183 - acc: 0.9167 - val_loss: 0.3952 - val_acc: 1.0000\n",
            "Epoch 526/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4182 - acc: 0.9111 - val_loss: 0.3952 - val_acc: 1.0000\n",
            "Epoch 527/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4182 - acc: 0.9111 - val_loss: 0.3951 - val_acc: 1.0000\n",
            "Epoch 528/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4181 - acc: 0.9111 - val_loss: 0.3951 - val_acc: 1.0000\n",
            "Epoch 529/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4180 - acc: 0.9222 - val_loss: 0.3951 - val_acc: 1.0000\n",
            "Epoch 530/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4180 - acc: 0.9056 - val_loss: 0.3950 - val_acc: 1.0000\n",
            "Epoch 531/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4181 - acc: 0.9000 - val_loss: 0.3950 - val_acc: 1.0000\n",
            "Epoch 532/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4180 - acc: 0.9111 - val_loss: 0.3950 - val_acc: 1.0000\n",
            "Epoch 533/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4179 - acc: 0.9222 - val_loss: 0.3949 - val_acc: 1.0000\n",
            "Epoch 534/800\n",
            "180/180 [==============================] - 0s 459us/step - loss: 0.4180 - acc: 0.9111 - val_loss: 0.3949 - val_acc: 1.0000\n",
            "Epoch 535/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.4179 - acc: 0.9167 - val_loss: 0.3949 - val_acc: 1.0000\n",
            "Epoch 536/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4180 - acc: 0.9056 - val_loss: 0.3949 - val_acc: 1.0000\n",
            "Epoch 537/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.4178 - acc: 0.9056 - val_loss: 0.3949 - val_acc: 1.0000\n",
            "Epoch 538/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4178 - acc: 0.9056 - val_loss: 0.3948 - val_acc: 1.0000\n",
            "Epoch 539/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4177 - acc: 0.9167 - val_loss: 0.3948 - val_acc: 1.0000\n",
            "Epoch 540/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4180 - acc: 0.9222 - val_loss: 0.3948 - val_acc: 1.0000\n",
            "Epoch 541/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4176 - acc: 0.9111 - val_loss: 0.3948 - val_acc: 1.0000\n",
            "Epoch 542/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4176 - acc: 0.9056 - val_loss: 0.3947 - val_acc: 1.0000\n",
            "Epoch 543/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4173 - acc: 0.9222 - val_loss: 0.3947 - val_acc: 1.0000\n",
            "Epoch 544/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4177 - acc: 0.9167 - val_loss: 0.3946 - val_acc: 1.0000\n",
            "Epoch 545/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4176 - acc: 0.9222 - val_loss: 0.3947 - val_acc: 1.0000\n",
            "Epoch 546/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4173 - acc: 0.9056 - val_loss: 0.3945 - val_acc: 1.0000\n",
            "Epoch 547/800\n",
            "180/180 [==============================] - 0s 411us/step - loss: 0.4175 - acc: 0.9111 - val_loss: 0.3946 - val_acc: 1.0000\n",
            "Epoch 548/800\n",
            "180/180 [==============================] - 0s 396us/step - loss: 0.4171 - acc: 0.9111 - val_loss: 0.3946 - val_acc: 1.0000\n",
            "Epoch 549/800\n",
            "180/180 [==============================] - 0s 402us/step - loss: 0.4173 - acc: 0.9111 - val_loss: 0.3945 - val_acc: 1.0000\n",
            "Epoch 550/800\n",
            "180/180 [==============================] - 0s 411us/step - loss: 0.4174 - acc: 0.9167 - val_loss: 0.3944 - val_acc: 1.0000\n",
            "Epoch 551/800\n",
            "180/180 [==============================] - 0s 493us/step - loss: 0.4174 - acc: 0.9222 - val_loss: 0.3944 - val_acc: 1.0000\n",
            "Epoch 552/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4174 - acc: 0.9111 - val_loss: 0.3944 - val_acc: 1.0000\n",
            "Epoch 553/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4174 - acc: 0.9111 - val_loss: 0.3943 - val_acc: 1.0000\n",
            "Epoch 554/800\n",
            "180/180 [==============================] - 0s 395us/step - loss: 0.4172 - acc: 0.9111 - val_loss: 0.3943 - val_acc: 1.0000\n",
            "Epoch 555/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4174 - acc: 0.9056 - val_loss: 0.3943 - val_acc: 1.0000\n",
            "Epoch 556/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4172 - acc: 0.9056 - val_loss: 0.3943 - val_acc: 1.0000\n",
            "Epoch 557/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4169 - acc: 0.9056 - val_loss: 0.3942 - val_acc: 1.0000\n",
            "Epoch 558/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4172 - acc: 0.9111 - val_loss: 0.3942 - val_acc: 1.0000\n",
            "Epoch 559/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4170 - acc: 0.9111 - val_loss: 0.3942 - val_acc: 1.0000\n",
            "Epoch 560/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4169 - acc: 0.9222 - val_loss: 0.3942 - val_acc: 1.0000\n",
            "Epoch 561/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4171 - acc: 0.9167 - val_loss: 0.3942 - val_acc: 1.0000\n",
            "Epoch 562/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4172 - acc: 0.9167 - val_loss: 0.3940 - val_acc: 1.0000\n",
            "Epoch 563/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4170 - acc: 0.9111 - val_loss: 0.3940 - val_acc: 1.0000\n",
            "Epoch 564/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4167 - acc: 0.9000 - val_loss: 0.3940 - val_acc: 1.0000\n",
            "Epoch 565/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4170 - acc: 0.9056 - val_loss: 0.3940 - val_acc: 1.0000\n",
            "Epoch 566/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4171 - acc: 0.9111 - val_loss: 0.3940 - val_acc: 1.0000\n",
            "Epoch 567/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4172 - acc: 0.9111 - val_loss: 0.3940 - val_acc: 1.0000\n",
            "Epoch 568/800\n",
            "180/180 [==============================] - 0s 473us/step - loss: 0.4169 - acc: 0.9167 - val_loss: 0.3938 - val_acc: 1.0000\n",
            "Epoch 569/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4167 - acc: 0.9056 - val_loss: 0.3938 - val_acc: 1.0000\n",
            "Epoch 570/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4169 - acc: 0.9111 - val_loss: 0.3939 - val_acc: 1.0000\n",
            "Epoch 571/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4167 - acc: 0.9111 - val_loss: 0.3939 - val_acc: 1.0000\n",
            "Epoch 572/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4166 - acc: 0.9167 - val_loss: 0.3939 - val_acc: 1.0000\n",
            "Epoch 573/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4165 - acc: 0.9000 - val_loss: 0.3937 - val_acc: 1.0000\n",
            "Epoch 574/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4167 - acc: 0.8722 - val_loss: 0.3937 - val_acc: 1.0000\n",
            "Epoch 575/800\n",
            "180/180 [==============================] - 0s 392us/step - loss: 0.4165 - acc: 0.8722 - val_loss: 0.3937 - val_acc: 1.0000\n",
            "Epoch 576/800\n",
            "180/180 [==============================] - 0s 432us/step - loss: 0.4166 - acc: 0.9167 - val_loss: 0.3937 - val_acc: 1.0000\n",
            "Epoch 577/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4168 - acc: 0.9222 - val_loss: 0.3937 - val_acc: 1.0000\n",
            "Epoch 578/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4165 - acc: 0.9389 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 579/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4164 - acc: 0.9333 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 580/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4164 - acc: 0.9278 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 581/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4164 - acc: 0.9222 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 582/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4165 - acc: 0.9167 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 583/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4166 - acc: 0.9056 - val_loss: 0.3934 - val_acc: 1.0000\n",
            "Epoch 584/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4165 - acc: 0.9167 - val_loss: 0.3933 - val_acc: 1.0000\n",
            "Epoch 585/800\n",
            "180/180 [==============================] - 0s 529us/step - loss: 0.4165 - acc: 0.9167 - val_loss: 0.3934 - val_acc: 1.0000\n",
            "Epoch 586/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.4162 - acc: 0.9167 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 587/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.4161 - acc: 0.9167 - val_loss: 0.3935 - val_acc: 1.0000\n",
            "Epoch 588/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.4163 - acc: 0.9111 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 589/800\n",
            "180/180 [==============================] - 0s 389us/step - loss: 0.4163 - acc: 0.9111 - val_loss: 0.3935 - val_acc: 1.0000\n",
            "Epoch 590/800\n",
            "180/180 [==============================] - 0s 394us/step - loss: 0.4160 - acc: 0.9167 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 591/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.4161 - acc: 0.9056 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 592/800\n",
            "180/180 [==============================] - 0s 400us/step - loss: 0.4159 - acc: 0.9111 - val_loss: 0.3935 - val_acc: 1.0000\n",
            "Epoch 593/800\n",
            "180/180 [==============================] - 0s 393us/step - loss: 0.4160 - acc: 0.9056 - val_loss: 0.3936 - val_acc: 1.0000\n",
            "Epoch 594/800\n",
            "180/180 [==============================] - 0s 401us/step - loss: 0.4162 - acc: 0.9167 - val_loss: 0.3935 - val_acc: 1.0000\n",
            "Epoch 595/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4161 - acc: 0.9056 - val_loss: 0.3935 - val_acc: 1.0000\n",
            "Epoch 596/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4158 - acc: 0.9056 - val_loss: 0.3934 - val_acc: 1.0000\n",
            "Epoch 597/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4159 - acc: 0.9056 - val_loss: 0.3934 - val_acc: 1.0000\n",
            "Epoch 598/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4158 - acc: 0.8889 - val_loss: 0.3933 - val_acc: 1.0000\n",
            "Epoch 599/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4158 - acc: 0.8722 - val_loss: 0.3933 - val_acc: 1.0000\n",
            "Epoch 600/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4160 - acc: 0.8944 - val_loss: 0.3932 - val_acc: 1.0000\n",
            "Epoch 601/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4157 - acc: 0.9167 - val_loss: 0.3933 - val_acc: 1.0000\n",
            "Epoch 602/800\n",
            "180/180 [==============================] - 0s 483us/step - loss: 0.4157 - acc: 0.9167 - val_loss: 0.3933 - val_acc: 1.0000\n",
            "Epoch 603/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4157 - acc: 0.9167 - val_loss: 0.3932 - val_acc: 1.0000\n",
            "Epoch 604/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.4155 - acc: 0.9167 - val_loss: 0.3933 - val_acc: 1.0000\n",
            "Epoch 605/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4156 - acc: 0.9000 - val_loss: 0.3931 - val_acc: 1.0000\n",
            "Epoch 606/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4156 - acc: 0.8833 - val_loss: 0.3930 - val_acc: 1.0000\n",
            "Epoch 607/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4154 - acc: 0.8833 - val_loss: 0.3930 - val_acc: 1.0000\n",
            "Epoch 608/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4155 - acc: 0.8944 - val_loss: 0.3930 - val_acc: 1.0000\n",
            "Epoch 609/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.4155 - acc: 0.9167 - val_loss: 0.3930 - val_acc: 1.0000\n",
            "Epoch 610/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4154 - acc: 0.9111 - val_loss: 0.3929 - val_acc: 1.0000\n",
            "Epoch 611/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4154 - acc: 0.9111 - val_loss: 0.3929 - val_acc: 1.0000\n",
            "Epoch 612/800\n",
            "180/180 [==============================] - 0s 470us/step - loss: 0.4155 - acc: 0.8944 - val_loss: 0.3930 - val_acc: 1.0000\n",
            "Epoch 613/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.4154 - acc: 0.9056 - val_loss: 0.3929 - val_acc: 1.0000\n",
            "Epoch 614/800\n",
            "180/180 [==============================] - 0s 407us/step - loss: 0.4152 - acc: 0.8833 - val_loss: 0.3929 - val_acc: 1.0000\n",
            "Epoch 615/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4154 - acc: 0.8889 - val_loss: 0.3929 - val_acc: 1.0000\n",
            "Epoch 616/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.4154 - acc: 0.8833 - val_loss: 0.3927 - val_acc: 1.0000\n",
            "Epoch 617/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4152 - acc: 0.9000 - val_loss: 0.3926 - val_acc: 1.0000\n",
            "Epoch 618/800\n",
            "180/180 [==============================] - 0s 497us/step - loss: 0.4155 - acc: 0.9111 - val_loss: 0.3928 - val_acc: 1.0000\n",
            "Epoch 619/800\n",
            "180/180 [==============================] - 0s 398us/step - loss: 0.4152 - acc: 0.9111 - val_loss: 0.3926 - val_acc: 1.0000\n",
            "Epoch 620/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4151 - acc: 0.9000 - val_loss: 0.3927 - val_acc: 1.0000\n",
            "Epoch 621/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4153 - acc: 0.9000 - val_loss: 0.3926 - val_acc: 1.0000\n",
            "Epoch 622/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4148 - acc: 0.9167 - val_loss: 0.3926 - val_acc: 1.0000\n",
            "Epoch 623/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4152 - acc: 0.9111 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 624/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4152 - acc: 0.9167 - val_loss: 0.3924 - val_acc: 1.0000\n",
            "Epoch 625/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4150 - acc: 0.9167 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 626/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4150 - acc: 0.9167 - val_loss: 0.3926 - val_acc: 1.0000\n",
            "Epoch 627/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4149 - acc: 0.9167 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 628/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4151 - acc: 0.9167 - val_loss: 0.3926 - val_acc: 1.0000\n",
            "Epoch 629/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4148 - acc: 0.9222 - val_loss: 0.3924 - val_acc: 1.0000\n",
            "Epoch 630/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.4150 - acc: 0.9167 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 631/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4150 - acc: 0.9167 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 632/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4147 - acc: 0.9111 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 633/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4149 - acc: 0.9222 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 634/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4146 - acc: 0.9278 - val_loss: 0.3925 - val_acc: 1.0000\n",
            "Epoch 635/800\n",
            "180/180 [==============================] - 0s 467us/step - loss: 0.4148 - acc: 0.9111 - val_loss: 0.3923 - val_acc: 1.0000\n",
            "Epoch 636/800\n",
            "180/180 [==============================] - 0s 405us/step - loss: 0.4149 - acc: 0.9278 - val_loss: 0.3923 - val_acc: 1.0000\n",
            "Epoch 637/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4148 - acc: 0.9333 - val_loss: 0.3923 - val_acc: 1.0000\n",
            "Epoch 638/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4149 - acc: 0.9278 - val_loss: 0.3921 - val_acc: 1.0000\n",
            "Epoch 639/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4146 - acc: 0.9222 - val_loss: 0.3923 - val_acc: 1.0000\n",
            "Epoch 640/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4145 - acc: 0.9111 - val_loss: 0.3923 - val_acc: 1.0000\n",
            "Epoch 641/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4146 - acc: 0.8889 - val_loss: 0.3922 - val_acc: 1.0000\n",
            "Epoch 642/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4144 - acc: 0.8833 - val_loss: 0.3921 - val_acc: 1.0000\n",
            "Epoch 643/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4145 - acc: 0.8889 - val_loss: 0.3922 - val_acc: 1.0000\n",
            "Epoch 644/800\n",
            "180/180 [==============================] - 0s 411us/step - loss: 0.4145 - acc: 0.9167 - val_loss: 0.3922 - val_acc: 1.0000\n",
            "Epoch 645/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.4144 - acc: 0.9222 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 646/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4145 - acc: 0.9167 - val_loss: 0.3921 - val_acc: 1.0000\n",
            "Epoch 647/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4144 - acc: 0.9111 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 648/800\n",
            "180/180 [==============================] - 0s 409us/step - loss: 0.4145 - acc: 0.9278 - val_loss: 0.3920 - val_acc: 1.0000\n",
            "Epoch 649/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4145 - acc: 0.9389 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 650/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4146 - acc: 0.9222 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 651/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4143 - acc: 0.9222 - val_loss: 0.3918 - val_acc: 1.0000\n",
            "Epoch 652/800\n",
            "180/180 [==============================] - 0s 478us/step - loss: 0.4143 - acc: 0.9167 - val_loss: 0.3918 - val_acc: 1.0000\n",
            "Epoch 653/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4144 - acc: 0.9278 - val_loss: 0.3918 - val_acc: 1.0000\n",
            "Epoch 654/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4143 - acc: 0.9167 - val_loss: 0.3918 - val_acc: 1.0000\n",
            "Epoch 655/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4145 - acc: 0.9167 - val_loss: 0.3918 - val_acc: 1.0000\n",
            "Epoch 656/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.4145 - acc: 0.9222 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 657/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4142 - acc: 0.9278 - val_loss: 0.3920 - val_acc: 1.0000\n",
            "Epoch 658/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4141 - acc: 0.9278 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 659/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.4141 - acc: 0.9167 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 660/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.4142 - acc: 0.9167 - val_loss: 0.3917 - val_acc: 1.0000\n",
            "Epoch 661/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4144 - acc: 0.9167 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 662/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4140 - acc: 0.9167 - val_loss: 0.3917 - val_acc: 1.0000\n",
            "Epoch 663/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4141 - acc: 0.9167 - val_loss: 0.3917 - val_acc: 1.0000\n",
            "Epoch 664/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4141 - acc: 0.9111 - val_loss: 0.3919 - val_acc: 1.0000\n",
            "Epoch 665/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4140 - acc: 0.9111 - val_loss: 0.3917 - val_acc: 1.0000\n",
            "Epoch 666/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4140 - acc: 0.9056 - val_loss: 0.3915 - val_acc: 1.0000\n",
            "Epoch 667/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4141 - acc: 0.9056 - val_loss: 0.3915 - val_acc: 1.0000\n",
            "Epoch 668/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.4140 - acc: 0.9111 - val_loss: 0.3916 - val_acc: 1.0000\n",
            "Epoch 669/800\n",
            "180/180 [==============================] - 0s 487us/step - loss: 0.4140 - acc: 0.9111 - val_loss: 0.3916 - val_acc: 1.0000\n",
            "Epoch 670/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.4138 - acc: 0.9333 - val_loss: 0.3916 - val_acc: 1.0000\n",
            "Epoch 671/800\n",
            "180/180 [==============================] - 0s 393us/step - loss: 0.4139 - acc: 0.9222 - val_loss: 0.3915 - val_acc: 1.0000\n",
            "Epoch 672/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4138 - acc: 0.9111 - val_loss: 0.3916 - val_acc: 1.0000\n",
            "Epoch 673/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4139 - acc: 0.9056 - val_loss: 0.3914 - val_acc: 1.0000\n",
            "Epoch 674/800\n",
            "180/180 [==============================] - 0s 412us/step - loss: 0.4139 - acc: 0.9167 - val_loss: 0.3914 - val_acc: 1.0000\n",
            "Epoch 675/800\n",
            "180/180 [==============================] - 0s 404us/step - loss: 0.4140 - acc: 0.9056 - val_loss: 0.3912 - val_acc: 1.0000\n",
            "Epoch 676/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.4139 - acc: 0.9056 - val_loss: 0.3913 - val_acc: 1.0000\n",
            "Epoch 677/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4140 - acc: 0.9278 - val_loss: 0.3912 - val_acc: 1.0000\n",
            "Epoch 678/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4139 - acc: 0.9167 - val_loss: 0.3915 - val_acc: 1.0000\n",
            "Epoch 679/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4137 - acc: 0.9278 - val_loss: 0.3913 - val_acc: 1.0000\n",
            "Epoch 680/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4137 - acc: 0.9278 - val_loss: 0.3913 - val_acc: 1.0000\n",
            "Epoch 681/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4136 - acc: 0.9167 - val_loss: 0.3912 - val_acc: 1.0000\n",
            "Epoch 682/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4136 - acc: 0.9222 - val_loss: 0.3914 - val_acc: 1.0000\n",
            "Epoch 683/800\n",
            "180/180 [==============================] - 0s 395us/step - loss: 0.4136 - acc: 0.9056 - val_loss: 0.3913 - val_acc: 1.0000\n",
            "Epoch 684/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4136 - acc: 0.9056 - val_loss: 0.3912 - val_acc: 1.0000\n",
            "Epoch 685/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.4136 - acc: 0.9167 - val_loss: 0.3913 - val_acc: 1.0000\n",
            "Epoch 686/800\n",
            "180/180 [==============================] - 0s 527us/step - loss: 0.4134 - acc: 0.9167 - val_loss: 0.3911 - val_acc: 1.0000\n",
            "Epoch 687/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4134 - acc: 0.9056 - val_loss: 0.3913 - val_acc: 1.0000\n",
            "Epoch 688/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4135 - acc: 0.9111 - val_loss: 0.3911 - val_acc: 1.0000\n",
            "Epoch 689/800\n",
            "180/180 [==============================] - 0s 389us/step - loss: 0.4134 - acc: 0.9056 - val_loss: 0.3911 - val_acc: 1.0000\n",
            "Epoch 690/800\n",
            "180/180 [==============================] - 0s 412us/step - loss: 0.4136 - acc: 0.9111 - val_loss: 0.3910 - val_acc: 1.0000\n",
            "Epoch 691/800\n",
            "180/180 [==============================] - 0s 405us/step - loss: 0.4132 - acc: 0.9111 - val_loss: 0.3912 - val_acc: 1.0000\n",
            "Epoch 692/800\n",
            "180/180 [==============================] - 0s 416us/step - loss: 0.4134 - acc: 0.9056 - val_loss: 0.3909 - val_acc: 1.0000\n",
            "Epoch 693/800\n",
            "180/180 [==============================] - 0s 409us/step - loss: 0.4135 - acc: 0.9167 - val_loss: 0.3910 - val_acc: 1.0000\n",
            "Epoch 694/800\n",
            "180/180 [==============================] - 0s 410us/step - loss: 0.4132 - acc: 0.9222 - val_loss: 0.3909 - val_acc: 1.0000\n",
            "Epoch 695/800\n",
            "180/180 [==============================] - 0s 402us/step - loss: 0.4132 - acc: 0.9111 - val_loss: 0.3910 - val_acc: 1.0000\n",
            "Epoch 696/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.4134 - acc: 0.9111 - val_loss: 0.3909 - val_acc: 1.0000\n",
            "Epoch 697/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4134 - acc: 0.9111 - val_loss: 0.3909 - val_acc: 1.0000\n",
            "Epoch 698/800\n",
            "180/180 [==============================] - 0s 396us/step - loss: 0.4130 - acc: 0.9111 - val_loss: 0.3910 - val_acc: 1.0000\n",
            "Epoch 699/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4131 - acc: 0.9167 - val_loss: 0.3909 - val_acc: 1.0000\n",
            "Epoch 700/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4132 - acc: 0.9111 - val_loss: 0.3907 - val_acc: 1.0000\n",
            "Epoch 701/800\n",
            "180/180 [==============================] - 0s 414us/step - loss: 0.4130 - acc: 0.9111 - val_loss: 0.3909 - val_acc: 1.0000\n",
            "Epoch 702/800\n",
            "180/180 [==============================] - 0s 513us/step - loss: 0.4132 - acc: 0.9111 - val_loss: 0.3908 - val_acc: 1.0000\n",
            "Epoch 703/800\n",
            "180/180 [==============================] - 0s 393us/step - loss: 0.4131 - acc: 0.9111 - val_loss: 0.3908 - val_acc: 1.0000\n",
            "Epoch 704/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4130 - acc: 0.9111 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 705/800\n",
            "180/180 [==============================] - 0s 389us/step - loss: 0.4131 - acc: 0.9056 - val_loss: 0.3909 - val_acc: 1.0000\n",
            "Epoch 706/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4130 - acc: 0.9222 - val_loss: 0.3906 - val_acc: 1.0000\n",
            "Epoch 707/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4130 - acc: 0.9056 - val_loss: 0.3907 - val_acc: 1.0000\n",
            "Epoch 708/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4131 - acc: 0.9167 - val_loss: 0.3906 - val_acc: 1.0000\n",
            "Epoch 709/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.4131 - acc: 0.9278 - val_loss: 0.3907 - val_acc: 1.0000\n",
            "Epoch 710/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4131 - acc: 0.9389 - val_loss: 0.3907 - val_acc: 1.0000\n",
            "Epoch 711/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.4128 - acc: 0.9278 - val_loss: 0.3906 - val_acc: 1.0000\n",
            "Epoch 712/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.4128 - acc: 0.9333 - val_loss: 0.3906 - val_acc: 1.0000\n",
            "Epoch 713/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4128 - acc: 0.9056 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 714/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4126 - acc: 0.9056 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 715/800\n",
            "180/180 [==============================] - 0s 389us/step - loss: 0.4129 - acc: 0.9056 - val_loss: 0.3906 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00715: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 716/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4128 - acc: 0.9000 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 717/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4129 - acc: 0.9056 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 718/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4126 - acc: 0.9111 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 719/800\n",
            "180/180 [==============================] - 0s 512us/step - loss: 0.4128 - acc: 0.9056 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 720/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4128 - acc: 0.9056 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 721/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4128 - acc: 0.9056 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 722/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4129 - acc: 0.9167 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 723/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.4127 - acc: 0.9167 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 724/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4127 - acc: 0.9167 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 725/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4127 - acc: 0.9167 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 726/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4126 - acc: 0.9222 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 727/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4128 - acc: 0.9167 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 728/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4129 - acc: 0.9222 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 729/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4125 - acc: 0.9222 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 730/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4126 - acc: 0.9222 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 731/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4128 - acc: 0.9222 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 732/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4128 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 733/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.4128 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 734/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4127 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 735/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4129 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 736/800\n",
            "180/180 [==============================] - 0s 491us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 737/800\n",
            "180/180 [==============================] - 0s 336us/step - loss: 0.4128 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 738/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4126 - acc: 0.9333 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 739/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.4127 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 740/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4128 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 741/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4129 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 742/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4128 - acc: 0.9278 - val_loss: 0.3905 - val_acc: 1.0000\n",
            "Epoch 743/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.4128 - acc: 0.9333 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 744/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4125 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 745/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.4127 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 746/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4125 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 747/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4126 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 748/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 749/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4127 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 750/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.4126 - acc: 0.9333 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 751/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.4126 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 752/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.4126 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 753/800\n",
            "180/180 [==============================] - 0s 393us/step - loss: 0.4126 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 754/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4125 - acc: 0.9222 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 755/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4128 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 756/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 757/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4125 - acc: 0.9333 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 758/800\n",
            "180/180 [==============================] - 0s 405us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 759/800\n",
            "180/180 [==============================] - 0s 409us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 760/800\n",
            "180/180 [==============================] - 0s 413us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 761/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.4127 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 762/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 763/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4123 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 764/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 765/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 766/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3904 - val_acc: 1.0000\n",
            "Epoch 767/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 768/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 769/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 770/800\n",
            "180/180 [==============================] - 0s 522us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 771/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 772/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 773/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4123 - acc: 0.9333 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 774/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.4123 - acc: 0.9333 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 775/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 776/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 777/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 778/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 779/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.4123 - acc: 0.9333 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 780/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4123 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 781/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 782/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 783/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 784/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4125 - acc: 0.9333 - val_loss: 0.3903 - val_acc: 1.0000\n",
            "Epoch 785/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4126 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 786/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 787/800\n",
            "180/180 [==============================] - 0s 408us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 788/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.4125 - acc: 0.9333 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 789/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 790/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 791/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 792/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4125 - acc: 0.9333 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 793/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 794/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 795/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.4122 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 796/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 797/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4123 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 798/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.4125 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 799/800\n",
            "180/180 [==============================] - 0s 407us/step - loss: 0.4123 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "Epoch 800/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.4124 - acc: 0.9278 - val_loss: 0.3902 - val_acc: 1.0000\n",
            "200/200 [==============================] - 0s 125us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0.43619103610515597, 0.945]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NpgVvVhsi6_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27977
        },
        "outputId": "08358b2d-e158-4cd1-a0f5-16ec9c7639a0"
      },
      "cell_type": "code",
      "source": [
        "#Results with no anomily \n",
        "# Loss and Val Loss are very close + Accuracy and Val Accuracy are very close \n",
        "# Depending on the params of the net it can hit Accuracy of  1\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "full_anom = 0\n",
        "anom_samples = 0\n",
        "batch_size = 32\n",
        "import keras\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "nadam =keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
        "\n",
        "autoencoder2.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    #loss = 'binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
        "                              patience=200,verbose = 1)\n",
        "history = autoencoder2.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "                    validation_split=.1,\n",
        "                    verbose=1,callbacks=[reduce_lr])\n",
        "score = autoencoder2.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 180 samples, validate on 20 samples\n",
            "Epoch 1/800\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 0.5234 - acc: 0.8222 - val_loss: 0.3367 - val_acc: 0.8500\n",
            "Epoch 2/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5223 - acc: 0.8667 - val_loss: 0.3346 - val_acc: 0.8500\n",
            "Epoch 3/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5219 - acc: 0.8556 - val_loss: 0.3369 - val_acc: 0.8500\n",
            "Epoch 4/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5224 - acc: 0.8556 - val_loss: 0.3338 - val_acc: 0.8500\n",
            "Epoch 5/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5214 - acc: 0.8556 - val_loss: 0.3348 - val_acc: 0.8500\n",
            "Epoch 6/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5219 - acc: 0.8500 - val_loss: 0.3343 - val_acc: 0.8000\n",
            "Epoch 7/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5220 - acc: 0.8556 - val_loss: 0.3337 - val_acc: 0.8500\n",
            "Epoch 8/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5217 - acc: 0.8611 - val_loss: 0.3345 - val_acc: 0.8500\n",
            "Epoch 9/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5217 - acc: 0.8667 - val_loss: 0.3357 - val_acc: 0.8500\n",
            "Epoch 10/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5222 - acc: 0.8611 - val_loss: 0.3337 - val_acc: 0.8500\n",
            "Epoch 11/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5213 - acc: 0.8611 - val_loss: 0.3352 - val_acc: 0.8500\n",
            "Epoch 12/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5215 - acc: 0.8667 - val_loss: 0.3337 - val_acc: 0.8500\n",
            "Epoch 13/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5210 - acc: 0.8500 - val_loss: 0.3338 - val_acc: 0.8500\n",
            "Epoch 14/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5217 - acc: 0.8556 - val_loss: 0.3335 - val_acc: 0.8500\n",
            "Epoch 15/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5214 - acc: 0.8611 - val_loss: 0.3342 - val_acc: 0.8000\n",
            "Epoch 16/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5211 - acc: 0.8389 - val_loss: 0.3345 - val_acc: 0.8500\n",
            "Epoch 17/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5209 - acc: 0.8556 - val_loss: 0.3336 - val_acc: 0.8500\n",
            "Epoch 18/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5214 - acc: 0.8722 - val_loss: 0.3341 - val_acc: 0.8500\n",
            "Epoch 19/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5219 - acc: 0.8667 - val_loss: 0.3335 - val_acc: 0.8500\n",
            "Epoch 20/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5206 - acc: 0.8611 - val_loss: 0.3346 - val_acc: 0.8000\n",
            "Epoch 21/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5215 - acc: 0.8556 - val_loss: 0.3332 - val_acc: 0.8500\n",
            "Epoch 22/800\n",
            "180/180 [==============================] - 0s 432us/step - loss: 0.5209 - acc: 0.8556 - val_loss: 0.3344 - val_acc: 0.8000\n",
            "Epoch 23/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5220 - acc: 0.8444 - val_loss: 0.3341 - val_acc: 0.8500\n",
            "Epoch 24/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5210 - acc: 0.8611 - val_loss: 0.3400 - val_acc: 0.8500\n",
            "Epoch 25/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.5231 - acc: 0.8667 - val_loss: 0.3352 - val_acc: 0.8500\n",
            "Epoch 26/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5207 - acc: 0.8611 - val_loss: 0.3336 - val_acc: 0.8500\n",
            "Epoch 27/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5205 - acc: 0.8500 - val_loss: 0.3337 - val_acc: 0.8000\n",
            "Epoch 28/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5219 - acc: 0.8389 - val_loss: 0.3343 - val_acc: 0.8500\n",
            "Epoch 29/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5204 - acc: 0.8556 - val_loss: 0.3330 - val_acc: 0.8500\n",
            "Epoch 30/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5201 - acc: 0.8500 - val_loss: 0.3337 - val_acc: 0.8500\n",
            "Epoch 31/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5206 - acc: 0.8611 - val_loss: 0.3331 - val_acc: 0.8500\n",
            "Epoch 32/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5206 - acc: 0.8444 - val_loss: 0.3368 - val_acc: 0.8500\n",
            "Epoch 33/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5212 - acc: 0.8611 - val_loss: 0.3337 - val_acc: 0.8500\n",
            "Epoch 34/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5203 - acc: 0.8722 - val_loss: 0.3343 - val_acc: 0.8500\n",
            "Epoch 35/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.5202 - acc: 0.8722 - val_loss: 0.3343 - val_acc: 0.8500\n",
            "Epoch 36/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5202 - acc: 0.8833 - val_loss: 0.3331 - val_acc: 0.8500\n",
            "Epoch 37/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5202 - acc: 0.8778 - val_loss: 0.3342 - val_acc: 0.8500\n",
            "Epoch 38/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5220 - acc: 0.8500 - val_loss: 0.3337 - val_acc: 0.8000\n",
            "Epoch 39/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5202 - acc: 0.8556 - val_loss: 0.3359 - val_acc: 0.8500\n",
            "Epoch 40/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5205 - acc: 0.8444 - val_loss: 0.3338 - val_acc: 0.8500\n",
            "Epoch 41/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5202 - acc: 0.8444 - val_loss: 0.3330 - val_acc: 0.8500\n",
            "Epoch 42/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5198 - acc: 0.8722 - val_loss: 0.3332 - val_acc: 0.8500\n",
            "Epoch 43/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.5206 - acc: 0.8389 - val_loss: 0.3332 - val_acc: 0.8500\n",
            "Epoch 44/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5199 - acc: 0.8667 - val_loss: 0.3326 - val_acc: 0.8500\n",
            "Epoch 45/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.5203 - acc: 0.8889 - val_loss: 0.3329 - val_acc: 0.8000\n",
            "Epoch 46/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5202 - acc: 0.8500 - val_loss: 0.3328 - val_acc: 0.8500\n",
            "Epoch 47/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5199 - acc: 0.8722 - val_loss: 0.3339 - val_acc: 0.8500\n",
            "Epoch 48/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5213 - acc: 0.8389 - val_loss: 0.3342 - val_acc: 0.8500\n",
            "Epoch 49/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5200 - acc: 0.8667 - val_loss: 0.3343 - val_acc: 0.8500\n",
            "Epoch 50/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5199 - acc: 0.8889 - val_loss: 0.3345 - val_acc: 0.8000\n",
            "Epoch 51/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5209 - acc: 0.8722 - val_loss: 0.3330 - val_acc: 0.8500\n",
            "Epoch 52/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5196 - acc: 0.9056 - val_loss: 0.3335 - val_acc: 0.8500\n",
            "Epoch 53/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5205 - acc: 0.8944 - val_loss: 0.3330 - val_acc: 0.8500\n",
            "Epoch 54/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5195 - acc: 0.9278 - val_loss: 0.3346 - val_acc: 0.8500\n",
            "Epoch 55/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.5208 - acc: 0.9000 - val_loss: 0.3331 - val_acc: 0.8500\n",
            "Epoch 56/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5200 - acc: 0.8778 - val_loss: 0.3364 - val_acc: 0.8500\n",
            "Epoch 57/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5203 - acc: 0.8833 - val_loss: 0.3328 - val_acc: 0.8500\n",
            "Epoch 58/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5205 - acc: 0.8556 - val_loss: 0.3338 - val_acc: 0.8000\n",
            "Epoch 59/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5198 - acc: 0.8500 - val_loss: 0.3328 - val_acc: 0.8000\n",
            "Epoch 60/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5196 - acc: 0.9000 - val_loss: 0.3344 - val_acc: 0.8500\n",
            "Epoch 61/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5198 - acc: 0.9000 - val_loss: 0.3328 - val_acc: 0.8500\n",
            "Epoch 62/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5195 - acc: 0.9000 - val_loss: 0.3329 - val_acc: 0.8500\n",
            "Epoch 63/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.5192 - acc: 0.9056 - val_loss: 0.3323 - val_acc: 0.8500\n",
            "Epoch 64/800\n",
            "180/180 [==============================] - 0s 337us/step - loss: 0.5193 - acc: 0.8944 - val_loss: 0.3334 - val_acc: 0.8000\n",
            "Epoch 65/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5215 - acc: 0.8944 - val_loss: 0.3335 - val_acc: 0.8500\n",
            "Epoch 66/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5193 - acc: 0.8833 - val_loss: 0.3336 - val_acc: 0.8500\n",
            "Epoch 67/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5200 - acc: 0.9000 - val_loss: 0.3331 - val_acc: 0.8500\n",
            "Epoch 68/800\n",
            "180/180 [==============================] - 0s 324us/step - loss: 0.5202 - acc: 0.8722 - val_loss: 0.3332 - val_acc: 0.8500\n",
            "Epoch 69/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.5198 - acc: 0.9167 - val_loss: 0.3325 - val_acc: 0.8500\n",
            "Epoch 70/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5194 - acc: 0.8833 - val_loss: 0.3328 - val_acc: 0.8500\n",
            "Epoch 71/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.5191 - acc: 0.9278 - val_loss: 0.3325 - val_acc: 0.8500\n",
            "Epoch 72/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5197 - acc: 0.9389 - val_loss: 0.3327 - val_acc: 0.8500\n",
            "Epoch 73/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5196 - acc: 0.9389 - val_loss: 0.3352 - val_acc: 0.8000\n",
            "Epoch 74/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5217 - acc: 0.9111 - val_loss: 0.3397 - val_acc: 0.8500\n",
            "Epoch 75/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5264 - acc: 0.8889 - val_loss: 0.3325 - val_acc: 0.8000\n",
            "Epoch 76/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5194 - acc: 0.9278 - val_loss: 0.3331 - val_acc: 0.9000\n",
            "Epoch 77/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5191 - acc: 0.9222 - val_loss: 0.3325 - val_acc: 0.9000\n",
            "Epoch 78/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.5189 - acc: 0.9500 - val_loss: 0.3338 - val_acc: 0.8000\n",
            "Epoch 79/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.5192 - acc: 0.9444 - val_loss: 0.3346 - val_acc: 0.8500\n",
            "Epoch 80/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5191 - acc: 0.9278 - val_loss: 0.3341 - val_acc: 0.8500\n",
            "Epoch 81/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5192 - acc: 0.9500 - val_loss: 0.3324 - val_acc: 0.8500\n",
            "Epoch 82/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5192 - acc: 0.9500 - val_loss: 0.3325 - val_acc: 0.8500\n",
            "Epoch 83/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5188 - acc: 0.9278 - val_loss: 0.3337 - val_acc: 0.8000\n",
            "Epoch 84/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5191 - acc: 0.9500 - val_loss: 0.3327 - val_acc: 0.8500\n",
            "Epoch 85/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5194 - acc: 0.9111 - val_loss: 0.3334 - val_acc: 0.8000\n",
            "Epoch 86/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.5188 - acc: 0.9389 - val_loss: 0.3345 - val_acc: 0.8500\n",
            "Epoch 87/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5189 - acc: 0.9333 - val_loss: 0.3328 - val_acc: 0.8500\n",
            "Epoch 88/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5186 - acc: 0.9444 - val_loss: 0.3326 - val_acc: 0.8500\n",
            "Epoch 89/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5189 - acc: 0.9556 - val_loss: 0.3331 - val_acc: 0.8500\n",
            "Epoch 90/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5187 - acc: 0.9389 - val_loss: 0.3345 - val_acc: 0.8000\n",
            "Epoch 91/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.5189 - acc: 0.9222 - val_loss: 0.3343 - val_acc: 0.8500\n",
            "Epoch 92/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5186 - acc: 0.9500 - val_loss: 0.3360 - val_acc: 0.8500\n",
            "Epoch 93/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5190 - acc: 0.9389 - val_loss: 0.3334 - val_acc: 0.8500\n",
            "Epoch 94/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.5186 - acc: 0.9556 - val_loss: 0.3318 - val_acc: 0.8500\n",
            "Epoch 95/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5190 - acc: 0.9444 - val_loss: 0.3363 - val_acc: 0.8500\n",
            "Epoch 96/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5199 - acc: 0.9111 - val_loss: 0.3329 - val_acc: 0.9000\n",
            "Epoch 97/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5184 - acc: 0.9500 - val_loss: 0.3327 - val_acc: 0.9000\n",
            "Epoch 98/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5184 - acc: 0.9389 - val_loss: 0.3333 - val_acc: 0.9000\n",
            "Epoch 99/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5183 - acc: 0.9444 - val_loss: 0.3326 - val_acc: 0.9000\n",
            "Epoch 100/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5188 - acc: 0.9389 - val_loss: 0.3321 - val_acc: 0.9000\n",
            "Epoch 101/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5191 - acc: 0.9333 - val_loss: 0.3327 - val_acc: 0.9000\n",
            "Epoch 102/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5183 - acc: 0.9556 - val_loss: 0.3320 - val_acc: 0.9000\n",
            "Epoch 103/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5184 - acc: 0.9333 - val_loss: 0.3325 - val_acc: 0.9000\n",
            "Epoch 104/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5183 - acc: 0.9444 - val_loss: 0.3330 - val_acc: 0.9000\n",
            "Epoch 105/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5185 - acc: 0.9500 - val_loss: 0.3322 - val_acc: 0.9000\n",
            "Epoch 106/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5183 - acc: 0.9444 - val_loss: 0.3327 - val_acc: 0.8500\n",
            "Epoch 107/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5184 - acc: 0.9389 - val_loss: 0.3322 - val_acc: 0.9000\n",
            "Epoch 108/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.5184 - acc: 0.9333 - val_loss: 0.3341 - val_acc: 0.9000\n",
            "Epoch 109/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5179 - acc: 0.9444 - val_loss: 0.3354 - val_acc: 0.9000\n",
            "Epoch 110/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5190 - acc: 0.9500 - val_loss: 0.3330 - val_acc: 0.9000\n",
            "Epoch 111/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5183 - acc: 0.9500 - val_loss: 0.3343 - val_acc: 0.9000\n",
            "Epoch 112/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5182 - acc: 0.9444 - val_loss: 0.3324 - val_acc: 0.9000\n",
            "Epoch 113/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5184 - acc: 0.9333 - val_loss: 0.3327 - val_acc: 0.9000\n",
            "Epoch 114/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5179 - acc: 0.9389 - val_loss: 0.3319 - val_acc: 0.8500\n",
            "Epoch 115/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5178 - acc: 0.9556 - val_loss: 0.3316 - val_acc: 0.9000\n",
            "Epoch 116/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5179 - acc: 0.9444 - val_loss: 0.3329 - val_acc: 0.8500\n",
            "Epoch 117/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5180 - acc: 0.9500 - val_loss: 0.3329 - val_acc: 0.8500\n",
            "Epoch 118/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5183 - acc: 0.9444 - val_loss: 0.3318 - val_acc: 0.9000\n",
            "Epoch 119/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5181 - acc: 0.9500 - val_loss: 0.3319 - val_acc: 0.9000\n",
            "Epoch 120/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5181 - acc: 0.9389 - val_loss: 0.3334 - val_acc: 0.9000\n",
            "Epoch 121/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5193 - acc: 0.9389 - val_loss: 0.3329 - val_acc: 0.9000\n",
            "Epoch 122/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.5181 - acc: 0.9556 - val_loss: 0.3336 - val_acc: 0.8500\n",
            "Epoch 123/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5181 - acc: 0.9500 - val_loss: 0.3369 - val_acc: 0.9000\n",
            "Epoch 124/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5196 - acc: 0.9389 - val_loss: 0.3326 - val_acc: 0.9000\n",
            "Epoch 125/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5178 - acc: 0.9389 - val_loss: 0.3333 - val_acc: 0.9000\n",
            "Epoch 126/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5179 - acc: 0.9500 - val_loss: 0.3324 - val_acc: 0.9000\n",
            "Epoch 127/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5176 - acc: 0.9389 - val_loss: 0.3316 - val_acc: 0.9000\n",
            "Epoch 128/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5177 - acc: 0.9111 - val_loss: 0.3323 - val_acc: 0.8500\n",
            "Epoch 129/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5184 - acc: 0.9333 - val_loss: 0.3361 - val_acc: 0.9000\n",
            "Epoch 130/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.5204 - acc: 0.9278 - val_loss: 0.3322 - val_acc: 0.9000\n",
            "Epoch 131/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.5176 - acc: 0.9222 - val_loss: 0.3346 - val_acc: 0.9000\n",
            "Epoch 132/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5188 - acc: 0.9389 - val_loss: 0.3339 - val_acc: 0.9000\n",
            "Epoch 133/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5191 - acc: 0.9333 - val_loss: 0.3323 - val_acc: 0.9000\n",
            "Epoch 134/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5175 - acc: 0.9556 - val_loss: 0.3324 - val_acc: 0.9000\n",
            "Epoch 135/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5178 - acc: 0.9444 - val_loss: 0.3318 - val_acc: 0.9000\n",
            "Epoch 136/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5182 - acc: 0.9389 - val_loss: 0.3326 - val_acc: 0.9000\n",
            "Epoch 137/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.5172 - acc: 0.9500 - val_loss: 0.3322 - val_acc: 0.9000\n",
            "Epoch 138/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5181 - acc: 0.9389 - val_loss: 0.3324 - val_acc: 0.9000\n",
            "Epoch 139/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5176 - acc: 0.9444 - val_loss: 0.3316 - val_acc: 0.8500\n",
            "Epoch 140/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5174 - acc: 0.9333 - val_loss: 0.3336 - val_acc: 0.9500\n",
            "Epoch 141/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5175 - acc: 0.9333 - val_loss: 0.3314 - val_acc: 0.9000\n",
            "Epoch 142/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5179 - acc: 0.9444 - val_loss: 0.3332 - val_acc: 0.9000\n",
            "Epoch 143/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5177 - acc: 0.9556 - val_loss: 0.3343 - val_acc: 0.9500\n",
            "Epoch 144/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5174 - acc: 0.9500 - val_loss: 0.3324 - val_acc: 0.8500\n",
            "Epoch 145/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5177 - acc: 0.9556 - val_loss: 0.3326 - val_acc: 0.9500\n",
            "Epoch 146/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5173 - acc: 0.9667 - val_loss: 0.3341 - val_acc: 0.9500\n",
            "Epoch 147/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5175 - acc: 0.9333 - val_loss: 0.3319 - val_acc: 0.9500\n",
            "Epoch 148/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5175 - acc: 0.9556 - val_loss: 0.3326 - val_acc: 0.9000\n",
            "Epoch 149/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.5183 - acc: 0.9278 - val_loss: 0.3333 - val_acc: 0.9500\n",
            "Epoch 150/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5174 - acc: 0.9444 - val_loss: 0.3313 - val_acc: 0.9000\n",
            "Epoch 151/800\n",
            "180/180 [==============================] - 0s 328us/step - loss: 0.5174 - acc: 0.9389 - val_loss: 0.3320 - val_acc: 0.9500\n",
            "Epoch 152/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.5171 - acc: 0.9556 - val_loss: 0.3315 - val_acc: 0.9500\n",
            "Epoch 153/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.5174 - acc: 0.9556 - val_loss: 0.3317 - val_acc: 0.9500\n",
            "Epoch 154/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5177 - acc: 0.9444 - val_loss: 0.3334 - val_acc: 0.9500\n",
            "Epoch 155/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5176 - acc: 0.9389 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 156/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5173 - acc: 0.9500 - val_loss: 0.3315 - val_acc: 0.9000\n",
            "Epoch 157/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5173 - acc: 0.9500 - val_loss: 0.3336 - val_acc: 0.9500\n",
            "Epoch 158/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5174 - acc: 0.9333 - val_loss: 0.3315 - val_acc: 0.9500\n",
            "Epoch 159/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5177 - acc: 0.9500 - val_loss: 0.3314 - val_acc: 0.9500\n",
            "Epoch 160/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5171 - acc: 0.9444 - val_loss: 0.3309 - val_acc: 0.9500\n",
            "Epoch 161/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5180 - acc: 0.9278 - val_loss: 0.3319 - val_acc: 0.9500\n",
            "Epoch 162/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5170 - acc: 0.9500 - val_loss: 0.3329 - val_acc: 0.9500\n",
            "Epoch 163/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5170 - acc: 0.9278 - val_loss: 0.3319 - val_acc: 0.9500\n",
            "Epoch 164/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5177 - acc: 0.9444 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 165/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5168 - acc: 0.9500 - val_loss: 0.3320 - val_acc: 0.9500\n",
            "Epoch 166/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5171 - acc: 0.9500 - val_loss: 0.3335 - val_acc: 0.9500\n",
            "Epoch 167/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5172 - acc: 0.9556 - val_loss: 0.3334 - val_acc: 0.9500\n",
            "Epoch 168/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5174 - acc: 0.9333 - val_loss: 0.3316 - val_acc: 0.9500\n",
            "Epoch 169/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5172 - acc: 0.9333 - val_loss: 0.3322 - val_acc: 0.9500\n",
            "Epoch 170/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5168 - acc: 0.9611 - val_loss: 0.3317 - val_acc: 0.9500\n",
            "Epoch 171/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5170 - acc: 0.9556 - val_loss: 0.3325 - val_acc: 0.9500\n",
            "Epoch 172/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5175 - acc: 0.9444 - val_loss: 0.3367 - val_acc: 0.9500\n",
            "Epoch 173/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.5178 - acc: 0.9556 - val_loss: 0.3331 - val_acc: 0.9500\n",
            "Epoch 174/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5182 - acc: 0.9444 - val_loss: 0.3332 - val_acc: 0.9500\n",
            "Epoch 175/800\n",
            "180/180 [==============================] - 0s 324us/step - loss: 0.5169 - acc: 0.9444 - val_loss: 0.3323 - val_acc: 0.9500\n",
            "Epoch 176/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5172 - acc: 0.9611 - val_loss: 0.3322 - val_acc: 0.9000\n",
            "Epoch 177/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5168 - acc: 0.9556 - val_loss: 0.3333 - val_acc: 0.9000\n",
            "Epoch 178/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5181 - acc: 0.9389 - val_loss: 0.3337 - val_acc: 0.9000\n",
            "Epoch 179/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5177 - acc: 0.9278 - val_loss: 0.3318 - val_acc: 0.9000\n",
            "Epoch 180/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5172 - acc: 0.9444 - val_loss: 0.3327 - val_acc: 0.9500\n",
            "Epoch 181/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5167 - acc: 0.9444 - val_loss: 0.3328 - val_acc: 0.9500\n",
            "Epoch 182/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5175 - acc: 0.9389 - val_loss: 0.3331 - val_acc: 0.9000\n",
            "Epoch 183/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5181 - acc: 0.9333 - val_loss: 0.3334 - val_acc: 0.9500\n",
            "Epoch 184/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5164 - acc: 0.9611 - val_loss: 0.3306 - val_acc: 0.9500\n",
            "Epoch 185/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5169 - acc: 0.9556 - val_loss: 0.3308 - val_acc: 0.9500\n",
            "Epoch 186/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.5165 - acc: 0.9556 - val_loss: 0.3332 - val_acc: 0.9000\n",
            "Epoch 187/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5178 - acc: 0.9222 - val_loss: 0.3309 - val_acc: 0.9500\n",
            "Epoch 188/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5169 - acc: 0.9389 - val_loss: 0.3324 - val_acc: 0.9000\n",
            "Epoch 189/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5173 - acc: 0.9556 - val_loss: 0.3318 - val_acc: 0.9500\n",
            "Epoch 190/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5172 - acc: 0.9556 - val_loss: 0.3312 - val_acc: 0.9500\n",
            "Epoch 191/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5178 - acc: 0.9556 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 192/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5181 - acc: 0.9556 - val_loss: 0.3315 - val_acc: 0.9500\n",
            "Epoch 193/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5162 - acc: 0.9556 - val_loss: 0.3311 - val_acc: 0.9500\n",
            "Epoch 194/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5168 - acc: 0.9500 - val_loss: 0.3325 - val_acc: 0.9500\n",
            "Epoch 195/800\n",
            "180/180 [==============================] - 0s 412us/step - loss: 0.5177 - acc: 0.9389 - val_loss: 0.3377 - val_acc: 0.9000\n",
            "Epoch 196/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5175 - acc: 0.9500 - val_loss: 0.3308 - val_acc: 0.9500\n",
            "Epoch 197/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5168 - acc: 0.9444 - val_loss: 0.3322 - val_acc: 0.9500\n",
            "Epoch 198/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.5165 - acc: 0.9667 - val_loss: 0.3317 - val_acc: 0.9500\n",
            "Epoch 199/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5171 - acc: 0.9500 - val_loss: 0.3322 - val_acc: 0.9500\n",
            "Epoch 200/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5170 - acc: 0.9556 - val_loss: 0.3314 - val_acc: 1.0000\n",
            "Epoch 201/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5165 - acc: 0.9278 - val_loss: 0.3320 - val_acc: 0.9000\n",
            "Epoch 202/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5170 - acc: 0.9500 - val_loss: 0.3309 - val_acc: 0.9000\n",
            "Epoch 203/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5164 - acc: 0.9611 - val_loss: 0.3324 - val_acc: 0.9000\n",
            "Epoch 204/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.5165 - acc: 0.9444 - val_loss: 0.3327 - val_acc: 0.9500\n",
            "Epoch 205/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5161 - acc: 0.9500 - val_loss: 0.3307 - val_acc: 0.9500\n",
            "Epoch 206/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5177 - acc: 0.9333 - val_loss: 0.3365 - val_acc: 0.9500\n",
            "Epoch 207/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5175 - acc: 0.9444 - val_loss: 0.3300 - val_acc: 0.9500\n",
            "Epoch 208/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5164 - acc: 0.9611 - val_loss: 0.3308 - val_acc: 0.9500\n",
            "Epoch 209/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.5162 - acc: 0.9556 - val_loss: 0.3300 - val_acc: 0.9500\n",
            "Epoch 210/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5164 - acc: 0.9556 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 211/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5168 - acc: 0.9444 - val_loss: 0.3327 - val_acc: 0.9000\n",
            "Epoch 212/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5171 - acc: 0.9444 - val_loss: 0.3320 - val_acc: 0.9500\n",
            "Epoch 213/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5162 - acc: 0.9556 - val_loss: 0.3318 - val_acc: 1.0000\n",
            "Epoch 214/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5167 - acc: 0.9500 - val_loss: 0.3346 - val_acc: 0.9000\n",
            "Epoch 215/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5168 - acc: 0.9444 - val_loss: 0.3327 - val_acc: 0.9500\n",
            "Epoch 216/800\n",
            "180/180 [==============================] - 0s 328us/step - loss: 0.5162 - acc: 0.9556 - val_loss: 0.3305 - val_acc: 0.9500\n",
            "Epoch 217/800\n",
            "180/180 [==============================] - 0s 334us/step - loss: 0.5162 - acc: 0.9611 - val_loss: 0.3405 - val_acc: 0.9000\n",
            "Epoch 218/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5191 - acc: 0.9444 - val_loss: 0.3352 - val_acc: 0.9000\n",
            "Epoch 219/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5169 - acc: 0.9500 - val_loss: 0.3307 - val_acc: 0.9500\n",
            "Epoch 220/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5172 - acc: 0.9500 - val_loss: 0.3326 - val_acc: 0.9500\n",
            "Epoch 221/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5169 - acc: 0.9556 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 222/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5162 - acc: 0.9556 - val_loss: 0.3319 - val_acc: 0.9500\n",
            "Epoch 223/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5174 - acc: 0.9556 - val_loss: 0.3303 - val_acc: 0.9000\n",
            "Epoch 224/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5167 - acc: 0.9556 - val_loss: 0.3311 - val_acc: 0.9500\n",
            "Epoch 225/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5159 - acc: 0.9556 - val_loss: 0.3317 - val_acc: 0.9000\n",
            "Epoch 226/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5165 - acc: 0.9556 - val_loss: 0.3318 - val_acc: 0.9000\n",
            "Epoch 227/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5167 - acc: 0.9611 - val_loss: 0.3321 - val_acc: 0.9500\n",
            "Epoch 228/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5161 - acc: 0.9611 - val_loss: 0.3308 - val_acc: 0.9500\n",
            "Epoch 229/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.5155 - acc: 0.9611 - val_loss: 0.3310 - val_acc: 0.9000\n",
            "Epoch 230/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5157 - acc: 0.9500 - val_loss: 0.3298 - val_acc: 0.9500\n",
            "Epoch 231/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5163 - acc: 0.9667 - val_loss: 0.3301 - val_acc: 0.9500\n",
            "Epoch 232/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5167 - acc: 0.9500 - val_loss: 0.3320 - val_acc: 0.9500\n",
            "Epoch 233/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5159 - acc: 0.9611 - val_loss: 0.3303 - val_acc: 0.9500\n",
            "Epoch 234/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5157 - acc: 0.9778 - val_loss: 0.3325 - val_acc: 0.9500\n",
            "Epoch 235/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5163 - acc: 0.9722 - val_loss: 0.3304 - val_acc: 0.9500\n",
            "Epoch 236/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5163 - acc: 0.9611 - val_loss: 0.3304 - val_acc: 0.8500\n",
            "Epoch 237/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5171 - acc: 0.9444 - val_loss: 0.3318 - val_acc: 0.9500\n",
            "Epoch 238/800\n",
            "180/180 [==============================] - 0s 410us/step - loss: 0.5167 - acc: 0.9444 - val_loss: 0.3310 - val_acc: 0.9500\n",
            "Epoch 239/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5157 - acc: 0.9611 - val_loss: 0.3318 - val_acc: 0.9500\n",
            "Epoch 240/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.5165 - acc: 0.9611 - val_loss: 0.3309 - val_acc: 0.9500\n",
            "Epoch 241/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5159 - acc: 0.9500 - val_loss: 0.3298 - val_acc: 0.9000\n",
            "Epoch 242/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5158 - acc: 0.9611 - val_loss: 0.3340 - val_acc: 0.9000\n",
            "Epoch 243/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5158 - acc: 0.9556 - val_loss: 0.3327 - val_acc: 0.9000\n",
            "Epoch 244/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5163 - acc: 0.9500 - val_loss: 0.3303 - val_acc: 0.9500\n",
            "Epoch 245/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5181 - acc: 0.9444 - val_loss: 0.3305 - val_acc: 0.9000\n",
            "Epoch 246/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5161 - acc: 0.9722 - val_loss: 0.3300 - val_acc: 0.9500\n",
            "Epoch 247/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5157 - acc: 0.9500 - val_loss: 0.3306 - val_acc: 1.0000\n",
            "Epoch 248/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5157 - acc: 0.9667 - val_loss: 0.3327 - val_acc: 0.9500\n",
            "Epoch 249/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5189 - acc: 0.9389 - val_loss: 0.3298 - val_acc: 0.9500\n",
            "Epoch 250/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5157 - acc: 0.9611 - val_loss: 0.3307 - val_acc: 0.9500\n",
            "Epoch 251/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5169 - acc: 0.9500 - val_loss: 0.3303 - val_acc: 0.9500\n",
            "Epoch 252/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5156 - acc: 0.9556 - val_loss: 0.3296 - val_acc: 0.9500\n",
            "Epoch 253/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5165 - acc: 0.9667 - val_loss: 0.3296 - val_acc: 0.9500\n",
            "Epoch 254/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5156 - acc: 0.9778 - val_loss: 0.3321 - val_acc: 0.9500\n",
            "Epoch 255/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5162 - acc: 0.9444 - val_loss: 0.3333 - val_acc: 0.9000\n",
            "Epoch 256/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5156 - acc: 0.9556 - val_loss: 0.3327 - val_acc: 0.9000\n",
            "Epoch 257/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5162 - acc: 0.9389 - val_loss: 0.3311 - val_acc: 0.9000\n",
            "Epoch 258/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5158 - acc: 0.9667 - val_loss: 0.3327 - val_acc: 0.9500\n",
            "Epoch 259/800\n",
            "180/180 [==============================] - 0s 335us/step - loss: 0.5151 - acc: 0.9722 - val_loss: 0.3315 - val_acc: 0.9500\n",
            "Epoch 260/800\n",
            "180/180 [==============================] - 0s 337us/step - loss: 0.5158 - acc: 0.9500 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 261/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5157 - acc: 0.9556 - val_loss: 0.3302 - val_acc: 1.0000\n",
            "Epoch 262/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5154 - acc: 0.9500 - val_loss: 0.3301 - val_acc: 0.9500\n",
            "Epoch 263/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5163 - acc: 0.9556 - val_loss: 0.3302 - val_acc: 0.9500\n",
            "Epoch 264/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5154 - acc: 0.9611 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 265/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5152 - acc: 0.9556 - val_loss: 0.3312 - val_acc: 0.9500\n",
            "Epoch 266/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5168 - acc: 0.9500 - val_loss: 0.3372 - val_acc: 0.9000\n",
            "Epoch 267/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.5182 - acc: 0.9222 - val_loss: 0.3305 - val_acc: 0.9500\n",
            "Epoch 268/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5155 - acc: 0.9611 - val_loss: 0.3295 - val_acc: 1.0000\n",
            "Epoch 269/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5153 - acc: 0.9556 - val_loss: 0.3299 - val_acc: 1.0000\n",
            "Epoch 270/800\n",
            "180/180 [==============================] - 0s 314us/step - loss: 0.5148 - acc: 0.9722 - val_loss: 0.3308 - val_acc: 0.9500\n",
            "Epoch 271/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5154 - acc: 0.9389 - val_loss: 0.3316 - val_acc: 0.9000\n",
            "Epoch 272/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5155 - acc: 0.9722 - val_loss: 0.3336 - val_acc: 0.9000\n",
            "Epoch 273/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5155 - acc: 0.9556 - val_loss: 0.3303 - val_acc: 1.0000\n",
            "Epoch 274/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5150 - acc: 0.9722 - val_loss: 0.3305 - val_acc: 0.9500\n",
            "Epoch 275/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5155 - acc: 0.9611 - val_loss: 0.3294 - val_acc: 1.0000\n",
            "Epoch 276/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5154 - acc: 0.9444 - val_loss: 0.3302 - val_acc: 1.0000\n",
            "Epoch 277/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5149 - acc: 0.9611 - val_loss: 0.3302 - val_acc: 0.9500\n",
            "Epoch 278/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5155 - acc: 0.9500 - val_loss: 0.3298 - val_acc: 0.9000\n",
            "Epoch 279/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.5154 - acc: 0.9500 - val_loss: 0.3314 - val_acc: 0.9500\n",
            "Epoch 280/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5152 - acc: 0.9611 - val_loss: 0.3297 - val_acc: 0.9500\n",
            "Epoch 281/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.5158 - acc: 0.9611 - val_loss: 0.3304 - val_acc: 0.9000\n",
            "Epoch 282/800\n",
            "180/180 [==============================] - 0s 323us/step - loss: 0.5154 - acc: 0.9611 - val_loss: 0.3297 - val_acc: 0.9500\n",
            "Epoch 283/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5152 - acc: 0.9722 - val_loss: 0.3302 - val_acc: 0.9500\n",
            "Epoch 284/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5147 - acc: 0.9611 - val_loss: 0.3309 - val_acc: 0.9500\n",
            "Epoch 285/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.5150 - acc: 0.9611 - val_loss: 0.3298 - val_acc: 0.9500\n",
            "Epoch 286/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5149 - acc: 0.9556 - val_loss: 0.3299 - val_acc: 0.9500\n",
            "Epoch 287/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5157 - acc: 0.9667 - val_loss: 0.3317 - val_acc: 0.9000\n",
            "Epoch 288/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5154 - acc: 0.9444 - val_loss: 0.3309 - val_acc: 0.9500\n",
            "Epoch 289/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5154 - acc: 0.9444 - val_loss: 0.3318 - val_acc: 0.9000\n",
            "Epoch 290/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5163 - acc: 0.9444 - val_loss: 0.3303 - val_acc: 0.9500\n",
            "Epoch 291/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5154 - acc: 0.9444 - val_loss: 0.3302 - val_acc: 0.9500\n",
            "Epoch 292/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5148 - acc: 0.9667 - val_loss: 0.3333 - val_acc: 0.9000\n",
            "Epoch 293/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.5153 - acc: 0.9611 - val_loss: 0.3316 - val_acc: 0.9500\n",
            "Epoch 294/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5162 - acc: 0.9722 - val_loss: 0.3319 - val_acc: 0.9500\n",
            "Epoch 295/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5154 - acc: 0.9611 - val_loss: 0.3310 - val_acc: 0.9500\n",
            "Epoch 296/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5149 - acc: 0.9500 - val_loss: 0.3347 - val_acc: 0.9500\n",
            "Epoch 297/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5162 - acc: 0.9444 - val_loss: 0.3299 - val_acc: 0.9000\n",
            "Epoch 298/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5147 - acc: 0.9556 - val_loss: 0.3305 - val_acc: 0.9000\n",
            "Epoch 299/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5151 - acc: 0.9556 - val_loss: 0.3311 - val_acc: 0.9500\n",
            "Epoch 300/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5156 - acc: 0.9667 - val_loss: 0.3311 - val_acc: 0.9500\n",
            "Epoch 301/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.5157 - acc: 0.9278 - val_loss: 0.3322 - val_acc: 0.9500\n",
            "Epoch 302/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.5160 - acc: 0.9500 - val_loss: 0.3306 - val_acc: 0.9500\n",
            "Epoch 303/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.5151 - acc: 0.9611 - val_loss: 0.3288 - val_acc: 0.9500\n",
            "Epoch 304/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.5148 - acc: 0.9611 - val_loss: 0.3285 - val_acc: 0.9500\n",
            "Epoch 305/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5148 - acc: 0.9556 - val_loss: 0.3290 - val_acc: 1.0000\n",
            "Epoch 306/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5148 - acc: 0.9500 - val_loss: 0.3319 - val_acc: 1.0000\n",
            "Epoch 307/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5157 - acc: 0.9556 - val_loss: 0.3303 - val_acc: 0.9500\n",
            "Epoch 308/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5149 - acc: 0.9722 - val_loss: 0.3305 - val_acc: 1.0000\n",
            "Epoch 309/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5146 - acc: 0.9667 - val_loss: 0.3301 - val_acc: 0.9000\n",
            "Epoch 310/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5171 - acc: 0.9611 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 311/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5147 - acc: 0.9389 - val_loss: 0.3299 - val_acc: 0.9500\n",
            "Epoch 312/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5146 - acc: 0.9500 - val_loss: 0.3300 - val_acc: 0.9500\n",
            "Epoch 313/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.5146 - acc: 0.9611 - val_loss: 0.3288 - val_acc: 1.0000\n",
            "Epoch 314/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5145 - acc: 0.9500 - val_loss: 0.3290 - val_acc: 0.9500\n",
            "Epoch 315/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5148 - acc: 0.9500 - val_loss: 0.3294 - val_acc: 1.0000\n",
            "Epoch 316/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5153 - acc: 0.9389 - val_loss: 0.3285 - val_acc: 0.9500\n",
            "Epoch 317/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5143 - acc: 0.9500 - val_loss: 0.3294 - val_acc: 1.0000\n",
            "Epoch 318/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5149 - acc: 0.9667 - val_loss: 0.3304 - val_acc: 0.9500\n",
            "Epoch 319/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5145 - acc: 0.9611 - val_loss: 0.3290 - val_acc: 0.9500\n",
            "Epoch 320/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.5143 - acc: 0.9556 - val_loss: 0.3300 - val_acc: 0.9500\n",
            "Epoch 321/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5151 - acc: 0.9389 - val_loss: 0.3300 - val_acc: 0.9000\n",
            "Epoch 322/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5146 - acc: 0.9556 - val_loss: 0.3294 - val_acc: 0.9500\n",
            "Epoch 323/800\n",
            "180/180 [==============================] - 0s 414us/step - loss: 0.5147 - acc: 0.9667 - val_loss: 0.3287 - val_acc: 1.0000\n",
            "Epoch 324/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.5146 - acc: 0.9611 - val_loss: 0.3294 - val_acc: 0.9000\n",
            "Epoch 325/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5141 - acc: 0.9722 - val_loss: 0.3285 - val_acc: 0.9500\n",
            "Epoch 326/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.5150 - acc: 0.9667 - val_loss: 0.3284 - val_acc: 1.0000\n",
            "Epoch 327/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.5148 - acc: 0.9500 - val_loss: 0.3301 - val_acc: 0.9500\n",
            "Epoch 328/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5147 - acc: 0.9611 - val_loss: 0.3293 - val_acc: 0.9500\n",
            "Epoch 329/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.5139 - acc: 0.9611 - val_loss: 0.3316 - val_acc: 0.9000\n",
            "Epoch 330/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5153 - acc: 0.9611 - val_loss: 0.3306 - val_acc: 0.9500\n",
            "Epoch 331/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5145 - acc: 0.9333 - val_loss: 0.3313 - val_acc: 0.9000\n",
            "Epoch 332/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5149 - acc: 0.9611 - val_loss: 0.3304 - val_acc: 0.9500\n",
            "Epoch 333/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5148 - acc: 0.9722 - val_loss: 0.3320 - val_acc: 0.9500\n",
            "Epoch 334/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5155 - acc: 0.9667 - val_loss: 0.3285 - val_acc: 1.0000\n",
            "Epoch 335/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5142 - acc: 0.9722 - val_loss: 0.3286 - val_acc: 1.0000\n",
            "Epoch 336/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5137 - acc: 0.9667 - val_loss: 0.3281 - val_acc: 0.9500\n",
            "Epoch 337/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5137 - acc: 0.9556 - val_loss: 0.3291 - val_acc: 1.0000\n",
            "Epoch 338/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5147 - acc: 0.9667 - val_loss: 0.3278 - val_acc: 1.0000\n",
            "Epoch 339/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5145 - acc: 0.9556 - val_loss: 0.3290 - val_acc: 0.9500\n",
            "Epoch 340/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5150 - acc: 0.9389 - val_loss: 0.3335 - val_acc: 0.9000\n",
            "Epoch 341/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5145 - acc: 0.9611 - val_loss: 0.3302 - val_acc: 0.9000\n",
            "Epoch 342/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5140 - acc: 0.9333 - val_loss: 0.3301 - val_acc: 0.9500\n",
            "Epoch 343/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5144 - acc: 0.9611 - val_loss: 0.3297 - val_acc: 0.9500\n",
            "Epoch 344/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.5141 - acc: 0.9722 - val_loss: 0.3301 - val_acc: 0.9500\n",
            "Epoch 345/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5142 - acc: 0.9667 - val_loss: 0.3288 - val_acc: 1.0000\n",
            "Epoch 346/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5144 - acc: 0.9500 - val_loss: 0.3285 - val_acc: 1.0000\n",
            "Epoch 347/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5143 - acc: 0.9556 - val_loss: 0.3299 - val_acc: 0.9500\n",
            "Epoch 348/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5140 - acc: 0.9667 - val_loss: 0.3285 - val_acc: 0.9500\n",
            "Epoch 349/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5151 - acc: 0.9556 - val_loss: 0.3285 - val_acc: 1.0000\n",
            "Epoch 350/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5138 - acc: 0.9611 - val_loss: 0.3313 - val_acc: 0.9500\n",
            "Epoch 351/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5144 - acc: 0.9389 - val_loss: 0.3322 - val_acc: 0.9000\n",
            "Epoch 352/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.5154 - acc: 0.9444 - val_loss: 0.3321 - val_acc: 0.9500\n",
            "Epoch 353/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5152 - acc: 0.9778 - val_loss: 0.3286 - val_acc: 0.9500\n",
            "Epoch 354/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5140 - acc: 0.9556 - val_loss: 0.3310 - val_acc: 0.9500\n",
            "Epoch 355/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5145 - acc: 0.9333 - val_loss: 0.3286 - val_acc: 1.0000\n",
            "Epoch 356/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5143 - acc: 0.9611 - val_loss: 0.3306 - val_acc: 0.9000\n",
            "Epoch 357/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5144 - acc: 0.9444 - val_loss: 0.3291 - val_acc: 0.9500\n",
            "Epoch 358/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5141 - acc: 0.9778 - val_loss: 0.3299 - val_acc: 0.9000\n",
            "Epoch 359/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5142 - acc: 0.9500 - val_loss: 0.3296 - val_acc: 0.9500\n",
            "Epoch 360/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5140 - acc: 0.9500 - val_loss: 0.3293 - val_acc: 1.0000\n",
            "Epoch 361/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5145 - acc: 0.9500 - val_loss: 0.3297 - val_acc: 0.9500\n",
            "Epoch 362/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5134 - acc: 0.9778 - val_loss: 0.3296 - val_acc: 0.9500\n",
            "Epoch 363/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5137 - acc: 0.9722 - val_loss: 0.3279 - val_acc: 1.0000\n",
            "Epoch 364/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5135 - acc: 0.9667 - val_loss: 0.3291 - val_acc: 0.9500\n",
            "Epoch 365/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.5138 - acc: 0.9722 - val_loss: 0.3305 - val_acc: 0.9500\n",
            "Epoch 366/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.5141 - acc: 0.9667 - val_loss: 0.3301 - val_acc: 0.9000\n",
            "Epoch 367/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.5150 - acc: 0.9722 - val_loss: 0.3298 - val_acc: 0.9500\n",
            "Epoch 368/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5138 - acc: 0.9667 - val_loss: 0.3315 - val_acc: 0.9000\n",
            "Epoch 369/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5148 - acc: 0.9556 - val_loss: 0.3276 - val_acc: 0.9500\n",
            "Epoch 370/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5138 - acc: 0.9611 - val_loss: 0.3288 - val_acc: 0.9000\n",
            "Epoch 371/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5136 - acc: 0.9667 - val_loss: 0.3302 - val_acc: 0.9500\n",
            "Epoch 372/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5135 - acc: 0.9556 - val_loss: 0.3286 - val_acc: 0.9500\n",
            "Epoch 373/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5132 - acc: 0.9722 - val_loss: 0.3288 - val_acc: 0.9500\n",
            "Epoch 374/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5132 - acc: 0.9611 - val_loss: 0.3280 - val_acc: 1.0000\n",
            "Epoch 375/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5135 - acc: 0.9778 - val_loss: 0.3286 - val_acc: 0.9000\n",
            "Epoch 376/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5136 - acc: 0.9611 - val_loss: 0.3285 - val_acc: 0.9500\n",
            "Epoch 377/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5151 - acc: 0.9389 - val_loss: 0.3278 - val_acc: 1.0000\n",
            "Epoch 378/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5153 - acc: 0.9389 - val_loss: 0.3294 - val_acc: 1.0000\n",
            "Epoch 379/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5137 - acc: 0.9722 - val_loss: 0.3290 - val_acc: 1.0000\n",
            "Epoch 380/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5133 - acc: 0.9611 - val_loss: 0.3306 - val_acc: 0.9500\n",
            "Epoch 381/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5138 - acc: 0.9556 - val_loss: 0.3289 - val_acc: 1.0000\n",
            "Epoch 382/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5131 - acc: 0.9556 - val_loss: 0.3279 - val_acc: 0.9500\n",
            "Epoch 383/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5126 - acc: 0.9611 - val_loss: 0.3292 - val_acc: 0.9500\n",
            "Epoch 384/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5127 - acc: 0.9500 - val_loss: 0.3284 - val_acc: 1.0000\n",
            "Epoch 385/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5128 - acc: 0.9167 - val_loss: 0.3279 - val_acc: 0.9000\n",
            "Epoch 386/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5131 - acc: 0.9333 - val_loss: 0.3273 - val_acc: 1.0000\n",
            "Epoch 387/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.5124 - acc: 0.9444 - val_loss: 0.3287 - val_acc: 0.9000\n",
            "Epoch 388/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5123 - acc: 0.9556 - val_loss: 0.3300 - val_acc: 0.9500\n",
            "Epoch 389/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5120 - acc: 0.9500 - val_loss: 0.3285 - val_acc: 0.9000\n",
            "Epoch 390/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.5124 - acc: 0.9667 - val_loss: 0.3259 - val_acc: 1.0000\n",
            "Epoch 391/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5121 - acc: 0.9556 - val_loss: 0.3296 - val_acc: 0.9500\n",
            "Epoch 392/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5142 - acc: 0.9278 - val_loss: 0.3263 - val_acc: 1.0000\n",
            "Epoch 393/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5121 - acc: 0.9444 - val_loss: 0.3273 - val_acc: 1.0000\n",
            "Epoch 394/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5119 - acc: 0.9500 - val_loss: 0.3260 - val_acc: 1.0000\n",
            "Epoch 395/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5123 - acc: 0.9500 - val_loss: 0.3371 - val_acc: 0.9000\n",
            "Epoch 396/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5147 - acc: 0.9389 - val_loss: 0.3262 - val_acc: 0.9000\n",
            "Epoch 397/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5119 - acc: 0.9556 - val_loss: 0.3260 - val_acc: 0.9500\n",
            "Epoch 398/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5121 - acc: 0.9278 - val_loss: 0.3262 - val_acc: 0.9500\n",
            "Epoch 399/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5115 - acc: 0.9389 - val_loss: 0.3260 - val_acc: 0.9000\n",
            "Epoch 400/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5116 - acc: 0.9278 - val_loss: 0.3263 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00400: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 401/800\n",
            "180/180 [==============================] - 0s 399us/step - loss: 0.5110 - acc: 0.9444 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 402/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.5106 - acc: 0.9611 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 403/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5105 - acc: 0.9611 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 404/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5105 - acc: 0.9556 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 405/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5105 - acc: 0.9556 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 406/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5105 - acc: 0.9611 - val_loss: 0.3254 - val_acc: 1.0000\n",
            "Epoch 407/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5104 - acc: 0.9556 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 408/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5104 - acc: 0.9667 - val_loss: 0.3254 - val_acc: 1.0000\n",
            "Epoch 409/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5104 - acc: 0.9500 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 410/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5104 - acc: 0.9556 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 411/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5104 - acc: 0.9611 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 412/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5104 - acc: 0.9611 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 413/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5104 - acc: 0.9556 - val_loss: 0.3253 - val_acc: 1.0000\n",
            "Epoch 414/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5103 - acc: 0.9611 - val_loss: 0.3253 - val_acc: 1.0000\n",
            "Epoch 415/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5103 - acc: 0.9500 - val_loss: 0.3251 - val_acc: 0.9500\n",
            "Epoch 416/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5103 - acc: 0.9556 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 417/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5103 - acc: 0.9444 - val_loss: 0.3250 - val_acc: 1.0000\n",
            "Epoch 418/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5103 - acc: 0.9611 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 419/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.5103 - acc: 0.9556 - val_loss: 0.3250 - val_acc: 1.0000\n",
            "Epoch 420/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5103 - acc: 0.9556 - val_loss: 0.3250 - val_acc: 1.0000\n",
            "Epoch 421/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5103 - acc: 0.9611 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 422/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.5103 - acc: 0.9500 - val_loss: 0.3252 - val_acc: 1.0000\n",
            "Epoch 423/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.5102 - acc: 0.9556 - val_loss: 0.3250 - val_acc: 1.0000\n",
            "Epoch 424/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5102 - acc: 0.9722 - val_loss: 0.3249 - val_acc: 1.0000\n",
            "Epoch 425/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5102 - acc: 0.9667 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 426/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5102 - acc: 0.9667 - val_loss: 0.3250 - val_acc: 1.0000\n",
            "Epoch 427/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5102 - acc: 0.9667 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 428/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.5102 - acc: 0.9611 - val_loss: 0.3250 - val_acc: 1.0000\n",
            "Epoch 429/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.5101 - acc: 0.9667 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 430/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5101 - acc: 0.9611 - val_loss: 0.3251 - val_acc: 1.0000\n",
            "Epoch 431/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5101 - acc: 0.9667 - val_loss: 0.3250 - val_acc: 1.0000\n",
            "Epoch 432/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5101 - acc: 0.9667 - val_loss: 0.3249 - val_acc: 1.0000\n",
            "Epoch 433/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5100 - acc: 0.9667 - val_loss: 0.3249 - val_acc: 1.0000\n",
            "Epoch 434/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.5101 - acc: 0.9611 - val_loss: 0.3249 - val_acc: 1.0000\n",
            "Epoch 435/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5100 - acc: 0.9667 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 436/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5100 - acc: 0.9667 - val_loss: 0.3249 - val_acc: 1.0000\n",
            "Epoch 437/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5100 - acc: 0.9611 - val_loss: 0.3249 - val_acc: 1.0000\n",
            "Epoch 438/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5100 - acc: 0.9556 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 439/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5100 - acc: 0.9611 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 440/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5100 - acc: 0.9667 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 441/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5100 - acc: 0.9611 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 442/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5099 - acc: 0.9611 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 443/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5100 - acc: 0.9667 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 444/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5099 - acc: 0.9611 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 445/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.5100 - acc: 0.9722 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 446/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.5099 - acc: 0.9611 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 447/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5099 - acc: 0.9667 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 448/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5099 - acc: 0.9611 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 449/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5099 - acc: 0.9667 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 450/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5098 - acc: 0.9667 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 451/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5098 - acc: 0.9556 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 452/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5098 - acc: 0.9611 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 453/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5098 - acc: 0.9611 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 454/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5098 - acc: 0.9667 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 455/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5098 - acc: 0.9667 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 456/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5098 - acc: 0.9556 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 457/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5097 - acc: 0.9667 - val_loss: 0.3248 - val_acc: 1.0000\n",
            "Epoch 458/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5097 - acc: 0.9611 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 459/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.5097 - acc: 0.9611 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 460/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5097 - acc: 0.9667 - val_loss: 0.3247 - val_acc: 1.0000\n",
            "Epoch 461/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5097 - acc: 0.9556 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 462/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5097 - acc: 0.9667 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 463/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5097 - acc: 0.9611 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 464/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5096 - acc: 0.9667 - val_loss: 0.3245 - val_acc: 0.9500\n",
            "Epoch 465/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5097 - acc: 0.9667 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 466/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.5097 - acc: 0.9611 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 467/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.5096 - acc: 0.9500 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 468/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.5097 - acc: 0.9667 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 469/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5096 - acc: 0.9611 - val_loss: 0.3244 - val_acc: 1.0000\n",
            "Epoch 470/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5096 - acc: 0.9611 - val_loss: 0.3244 - val_acc: 1.0000\n",
            "Epoch 471/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5095 - acc: 0.9667 - val_loss: 0.3244 - val_acc: 0.9500\n",
            "Epoch 472/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5096 - acc: 0.9667 - val_loss: 0.3244 - val_acc: 0.9500\n",
            "Epoch 473/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5096 - acc: 0.9556 - val_loss: 0.3245 - val_acc: 0.9500\n",
            "Epoch 474/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5095 - acc: 0.9667 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 475/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5096 - acc: 0.9611 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 476/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5095 - acc: 0.9667 - val_loss: 0.3244 - val_acc: 1.0000\n",
            "Epoch 477/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5095 - acc: 0.9611 - val_loss: 0.3244 - val_acc: 0.9500\n",
            "Epoch 478/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5094 - acc: 0.9611 - val_loss: 0.3244 - val_acc: 0.9500\n",
            "Epoch 479/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5095 - acc: 0.9667 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 480/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5095 - acc: 0.9667 - val_loss: 0.3246 - val_acc: 1.0000\n",
            "Epoch 481/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5095 - acc: 0.9556 - val_loss: 0.3244 - val_acc: 1.0000\n",
            "Epoch 482/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5094 - acc: 0.9611 - val_loss: 0.3243 - val_acc: 0.9500\n",
            "Epoch 483/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5093 - acc: 0.9667 - val_loss: 0.3244 - val_acc: 1.0000\n",
            "Epoch 484/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5094 - acc: 0.9611 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 485/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5094 - acc: 0.9611 - val_loss: 0.3245 - val_acc: 1.0000\n",
            "Epoch 486/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5094 - acc: 0.9611 - val_loss: 0.3243 - val_acc: 1.0000\n",
            "Epoch 487/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5094 - acc: 0.9611 - val_loss: 0.3243 - val_acc: 0.9500\n",
            "Epoch 488/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5094 - acc: 0.9556 - val_loss: 0.3243 - val_acc: 1.0000\n",
            "Epoch 489/800\n",
            "180/180 [==============================] - 0s 398us/step - loss: 0.5092 - acc: 0.9556 - val_loss: 0.3243 - val_acc: 0.9500\n",
            "Epoch 490/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5093 - acc: 0.9667 - val_loss: 0.3243 - val_acc: 0.9500\n",
            "Epoch 491/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5092 - acc: 0.9611 - val_loss: 0.3244 - val_acc: 1.0000\n",
            "Epoch 492/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.5093 - acc: 0.9611 - val_loss: 0.3243 - val_acc: 1.0000\n",
            "Epoch 493/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5092 - acc: 0.9500 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 494/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5093 - acc: 0.9611 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 495/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5093 - acc: 0.9667 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 496/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5092 - acc: 0.9556 - val_loss: 0.3242 - val_acc: 0.9500\n",
            "Epoch 497/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5092 - acc: 0.9556 - val_loss: 0.3242 - val_acc: 0.9500\n",
            "Epoch 498/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5092 - acc: 0.9667 - val_loss: 0.3242 - val_acc: 0.9500\n",
            "Epoch 499/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5092 - acc: 0.9667 - val_loss: 0.3242 - val_acc: 0.9500\n",
            "Epoch 500/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5092 - acc: 0.9722 - val_loss: 0.3242 - val_acc: 1.0000\n",
            "Epoch 501/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5092 - acc: 0.9611 - val_loss: 0.3242 - val_acc: 0.9500\n",
            "Epoch 502/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5092 - acc: 0.9667 - val_loss: 0.3242 - val_acc: 0.9500\n",
            "Epoch 503/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5091 - acc: 0.9611 - val_loss: 0.3242 - val_acc: 1.0000\n",
            "Epoch 504/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5091 - acc: 0.9611 - val_loss: 0.3241 - val_acc: 0.9500\n",
            "Epoch 505/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5091 - acc: 0.9556 - val_loss: 0.3240 - val_acc: 0.9500\n",
            "Epoch 506/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5091 - acc: 0.9667 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 507/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5091 - acc: 0.9611 - val_loss: 0.3240 - val_acc: 0.9500\n",
            "Epoch 508/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5090 - acc: 0.9611 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 509/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5091 - acc: 0.9611 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 510/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.5091 - acc: 0.9611 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 511/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5091 - acc: 0.9556 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 512/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.5089 - acc: 0.9611 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 513/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5090 - acc: 0.9667 - val_loss: 0.3239 - val_acc: 1.0000\n",
            "Epoch 514/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5090 - acc: 0.9556 - val_loss: 0.3240 - val_acc: 1.0000\n",
            "Epoch 515/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5090 - acc: 0.9500 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 516/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5089 - acc: 0.9611 - val_loss: 0.3240 - val_acc: 1.0000\n",
            "Epoch 517/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5090 - acc: 0.9500 - val_loss: 0.3240 - val_acc: 1.0000\n",
            "Epoch 518/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5089 - acc: 0.9667 - val_loss: 0.3241 - val_acc: 1.0000\n",
            "Epoch 519/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.5089 - acc: 0.9556 - val_loss: 0.3240 - val_acc: 1.0000\n",
            "Epoch 520/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5089 - acc: 0.9667 - val_loss: 0.3239 - val_acc: 1.0000\n",
            "Epoch 521/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5089 - acc: 0.9611 - val_loss: 0.3240 - val_acc: 1.0000\n",
            "Epoch 522/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.5089 - acc: 0.9667 - val_loss: 0.3239 - val_acc: 1.0000\n",
            "Epoch 523/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5089 - acc: 0.9667 - val_loss: 0.3239 - val_acc: 1.0000\n",
            "Epoch 524/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5089 - acc: 0.9611 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 525/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5088 - acc: 0.9611 - val_loss: 0.3239 - val_acc: 1.0000\n",
            "Epoch 526/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5089 - acc: 0.9556 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 527/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5087 - acc: 0.9556 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 528/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5088 - acc: 0.9611 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 529/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5088 - acc: 0.9556 - val_loss: 0.3239 - val_acc: 1.0000\n",
            "Epoch 530/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5088 - acc: 0.9556 - val_loss: 0.3238 - val_acc: 0.9500\n",
            "Epoch 531/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.5087 - acc: 0.9611 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 532/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.5087 - acc: 0.9500 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 533/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5087 - acc: 0.9611 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 534/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5087 - acc: 0.9667 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 535/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5086 - acc: 0.9611 - val_loss: 0.3239 - val_acc: 1.0000\n",
            "Epoch 536/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5087 - acc: 0.9556 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 537/800\n",
            "180/180 [==============================] - 0s 321us/step - loss: 0.5087 - acc: 0.9556 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 538/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5087 - acc: 0.9611 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 539/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5086 - acc: 0.9667 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 540/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5086 - acc: 0.9556 - val_loss: 0.3236 - val_acc: 0.9500\n",
            "Epoch 541/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.5086 - acc: 0.9667 - val_loss: 0.3238 - val_acc: 0.9500\n",
            "Epoch 542/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5086 - acc: 0.9611 - val_loss: 0.3238 - val_acc: 0.9500\n",
            "Epoch 543/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5085 - acc: 0.9667 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 544/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5086 - acc: 0.9611 - val_loss: 0.3238 - val_acc: 1.0000\n",
            "Epoch 545/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5086 - acc: 0.9667 - val_loss: 0.3236 - val_acc: 1.0000\n",
            "Epoch 546/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5085 - acc: 0.9556 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 547/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5085 - acc: 0.9611 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 548/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5085 - acc: 0.9556 - val_loss: 0.3236 - val_acc: 1.0000\n",
            "Epoch 549/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5085 - acc: 0.9556 - val_loss: 0.3236 - val_acc: 1.0000\n",
            "Epoch 550/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5084 - acc: 0.9667 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 551/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5084 - acc: 0.9556 - val_loss: 0.3236 - val_acc: 1.0000\n",
            "Epoch 552/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5085 - acc: 0.9556 - val_loss: 0.3235 - val_acc: 1.0000\n",
            "Epoch 553/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.5085 - acc: 0.9556 - val_loss: 0.3235 - val_acc: 1.0000\n",
            "Epoch 554/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5084 - acc: 0.9611 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 555/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5083 - acc: 0.9444 - val_loss: 0.3235 - val_acc: 0.9500\n",
            "Epoch 556/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5084 - acc: 0.9667 - val_loss: 0.3237 - val_acc: 1.0000\n",
            "Epoch 557/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5084 - acc: 0.9556 - val_loss: 0.3236 - val_acc: 1.0000\n",
            "Epoch 558/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5084 - acc: 0.9444 - val_loss: 0.3235 - val_acc: 1.0000\n",
            "Epoch 559/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5083 - acc: 0.9611 - val_loss: 0.3234 - val_acc: 1.0000\n",
            "Epoch 560/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5083 - acc: 0.9556 - val_loss: 0.3235 - val_acc: 1.0000\n",
            "Epoch 561/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5083 - acc: 0.9556 - val_loss: 0.3236 - val_acc: 1.0000\n",
            "Epoch 562/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5083 - acc: 0.9444 - val_loss: 0.3235 - val_acc: 1.0000\n",
            "Epoch 563/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5083 - acc: 0.9611 - val_loss: 0.3234 - val_acc: 1.0000\n",
            "Epoch 564/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.5082 - acc: 0.9611 - val_loss: 0.3234 - val_acc: 1.0000\n",
            "Epoch 565/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5082 - acc: 0.9556 - val_loss: 0.3233 - val_acc: 1.0000\n",
            "Epoch 566/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5082 - acc: 0.9667 - val_loss: 0.3234 - val_acc: 1.0000\n",
            "Epoch 567/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5082 - acc: 0.9500 - val_loss: 0.3233 - val_acc: 1.0000\n",
            "Epoch 568/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5082 - acc: 0.9556 - val_loss: 0.3233 - val_acc: 0.9500\n",
            "Epoch 569/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5082 - acc: 0.9611 - val_loss: 0.3233 - val_acc: 1.0000\n",
            "Epoch 570/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5082 - acc: 0.9611 - val_loss: 0.3234 - val_acc: 1.0000\n",
            "Epoch 571/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5082 - acc: 0.9611 - val_loss: 0.3234 - val_acc: 1.0000\n",
            "Epoch 572/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5081 - acc: 0.9611 - val_loss: 0.3233 - val_acc: 1.0000\n",
            "Epoch 573/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5081 - acc: 0.9667 - val_loss: 0.3233 - val_acc: 1.0000\n",
            "Epoch 574/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.5082 - acc: 0.9667 - val_loss: 0.3234 - val_acc: 1.0000\n",
            "Epoch 575/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.5081 - acc: 0.9500 - val_loss: 0.3232 - val_acc: 0.9500\n",
            "Epoch 576/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5081 - acc: 0.9556 - val_loss: 0.3231 - val_acc: 0.9500\n",
            "Epoch 577/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5081 - acc: 0.9556 - val_loss: 0.3232 - val_acc: 1.0000\n",
            "Epoch 578/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5081 - acc: 0.9611 - val_loss: 0.3232 - val_acc: 1.0000\n",
            "Epoch 579/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.5079 - acc: 0.9556 - val_loss: 0.3232 - val_acc: 0.9500\n",
            "Epoch 580/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5080 - acc: 0.9611 - val_loss: 0.3233 - val_acc: 0.9500\n",
            "Epoch 581/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5080 - acc: 0.9611 - val_loss: 0.3233 - val_acc: 1.0000\n",
            "Epoch 582/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5080 - acc: 0.9556 - val_loss: 0.3231 - val_acc: 1.0000\n",
            "Epoch 583/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5080 - acc: 0.9556 - val_loss: 0.3231 - val_acc: 1.0000\n",
            "Epoch 584/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.5079 - acc: 0.9500 - val_loss: 0.3231 - val_acc: 0.9500\n",
            "Epoch 585/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5080 - acc: 0.9667 - val_loss: 0.3231 - val_acc: 1.0000\n",
            "Epoch 586/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5080 - acc: 0.9556 - val_loss: 0.3231 - val_acc: 1.0000\n",
            "Epoch 587/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5079 - acc: 0.9500 - val_loss: 0.3231 - val_acc: 0.9500\n",
            "Epoch 588/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5080 - acc: 0.9611 - val_loss: 0.3231 - val_acc: 0.9500\n",
            "Epoch 589/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5079 - acc: 0.9611 - val_loss: 0.3231 - val_acc: 0.9500\n",
            "Epoch 590/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5079 - acc: 0.9611 - val_loss: 0.3230 - val_acc: 0.9500\n",
            "Epoch 591/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5079 - acc: 0.9611 - val_loss: 0.3230 - val_acc: 1.0000\n",
            "Epoch 592/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5078 - acc: 0.9556 - val_loss: 0.3231 - val_acc: 1.0000\n",
            "Epoch 593/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5078 - acc: 0.9611 - val_loss: 0.3230 - val_acc: 1.0000\n",
            "Epoch 594/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5078 - acc: 0.9556 - val_loss: 0.3230 - val_acc: 1.0000\n",
            "Epoch 595/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5078 - acc: 0.9611 - val_loss: 0.3231 - val_acc: 1.0000\n",
            "Epoch 596/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.5077 - acc: 0.9500 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 597/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5077 - acc: 0.9611 - val_loss: 0.3230 - val_acc: 1.0000\n",
            "Epoch 598/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5077 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 599/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5077 - acc: 0.9556 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 600/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5077 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00600: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 601/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5076 - acc: 0.9556 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 602/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5076 - acc: 0.9556 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 603/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.5076 - acc: 0.9667 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 604/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5076 - acc: 0.9667 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 605/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 606/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5076 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 607/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5076 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 608/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5076 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 609/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5076 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 610/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5076 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 611/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 612/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 613/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 614/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 615/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5075 - acc: 0.9667 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 616/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 617/800\n",
            "180/180 [==============================] - 0s 415us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 618/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 619/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 620/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 621/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5075 - acc: 0.9667 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 622/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3229 - val_acc: 1.0000\n",
            "Epoch 623/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 624/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 625/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 626/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 627/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 628/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 629/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 630/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 631/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 632/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 633/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 634/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 635/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 636/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 637/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 638/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 639/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 640/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 641/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 642/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 643/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 644/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 645/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 646/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 647/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 648/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 649/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 650/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 651/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 652/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5075 - acc: 0.9611 - val_loss: 0.3228 - val_acc: 1.0000\n",
            "Epoch 653/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 654/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 655/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 656/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 657/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.5074 - acc: 0.9556 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 658/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 659/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 660/800\n",
            "180/180 [==============================] - 0s 406us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 661/800\n",
            "180/180 [==============================] - 0s 312us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 662/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5074 - acc: 0.9667 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 663/800\n",
            "180/180 [==============================] - 0s 335us/step - loss: 0.5074 - acc: 0.9556 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 664/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 665/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 666/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 667/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 668/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 669/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 670/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 671/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 672/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 673/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 674/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 675/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 676/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 677/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 678/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 679/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 680/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5073 - acc: 0.9667 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 681/800\n",
            "180/180 [==============================] - 0s 427us/step - loss: 0.5074 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 682/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 683/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 684/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3227 - val_acc: 1.0000\n",
            "Epoch 685/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 686/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 687/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 688/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 689/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 690/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 691/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 692/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 693/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 694/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 695/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 696/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 697/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5073 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 698/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 699/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 700/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 701/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 702/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 703/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 704/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.5072 - acc: 0.9667 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 705/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 706/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5073 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 707/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 708/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 709/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 710/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 711/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 712/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 713/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 714/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 715/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 716/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 717/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 718/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 719/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 720/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3226 - val_acc: 1.0000\n",
            "Epoch 721/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 722/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 723/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 724/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 725/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 726/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 727/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 728/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5072 - acc: 0.9611 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 729/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 730/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 731/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 732/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 733/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 734/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 735/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 736/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 737/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 738/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.5072 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 739/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 740/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 741/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 742/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 743/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 744/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3225 - val_acc: 1.0000\n",
            "Epoch 745/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 746/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 747/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 748/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 749/800\n",
            "180/180 [==============================] - 0s 310us/step - loss: 0.5070 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 750/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 751/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 752/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 753/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 754/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 755/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 756/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 757/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 758/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.5071 - acc: 0.9500 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 759/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 760/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.5071 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 761/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 762/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 763/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 764/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 765/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 766/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 767/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 768/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 769/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.5071 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 770/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5070 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 771/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 772/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5070 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 773/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 774/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 775/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 776/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5070 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 777/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 778/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 779/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 780/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 781/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.5069 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 782/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.5070 - acc: 0.9611 - val_loss: 0.3224 - val_acc: 1.0000\n",
            "Epoch 783/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 784/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 785/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 786/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 787/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 788/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 789/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.5070 - acc: 0.9611 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 790/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.5070 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 791/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.5069 - acc: 0.9611 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 792/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.5069 - acc: 0.9611 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 793/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.5069 - acc: 0.9611 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 794/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.5068 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 795/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 796/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 797/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 798/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.5069 - acc: 0.9611 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 799/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.5069 - acc: 0.9611 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "Epoch 800/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.5069 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00800: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
            "200/200 [==============================] - 0s 105us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0.491057288646698, 0.93]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2OYghoPPjUKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "3fe09fa2-e4ac-4497-fd9f-1a2b90e5bae2"
      },
      "cell_type": "code",
      "source": [
        "score2 = autoencoder2.predict( x_test2, batch_size=32, verbose=1,  steps=None)\n",
        "display('[test_loss, test_acc]')\n",
        "display(score2)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 0s 74us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[-3.8262815e-03,  5.2551866e-02,  6.3689315e-01, -3.9367224e-03,\n",
              "        -1.9887458e-03, -5.4442916e-02],\n",
              "       [-5.1220238e-02,  1.1607015e-01,  5.2193403e-03, -5.1724304e-02,\n",
              "        -2.7074758e-03, -2.4022104e-02],\n",
              "       [-1.6899738e-02, -9.9430894e-03,  8.9939630e-01, -1.7122829e-02,\n",
              "         8.6482787e-01, -6.3293010e-02],\n",
              "       ...,\n",
              "       [ 6.5779042e-01, -1.3897435e-02, -4.3334248e-03,  6.5602982e-01,\n",
              "         1.2824008e+00, -1.2700321e-02],\n",
              "       [ 2.3217554e+00, -5.3286506e-03,  1.0894061e+00,  2.3337369e+00,\n",
              "         4.0560138e-01, -7.5490735e-02],\n",
              "       [ 5.7478356e-01, -8.4188534e-03, -8.7396456e-03,  5.7256198e-01,\n",
              "         7.4112201e-01,  3.1248784e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NV95xokhjZ_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "50d8e9c9-3eb0-4d64-c1fe-2cc614810850"
      },
      "cell_type": "code",
      "source": [
        "display(score2[19,:])\n",
        "display(x_test2[19,:])\n",
        "display(x_train2[2,:])\n",
        "display(x_train[3,:])\n",
        "display(x_test[0,:])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([-0.00767877, -0.00466669, -0.01181935, -0.00781828,  0.36902094,\n",
              "        1.4584022 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([-0.24763037, -0.4292751 , -1.4694093 , -0.2507984 ,  0.43348488,\n",
              "        1.4690304 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([ 0.03809295, -0.21452783, -1.0977932 ,  0.03475823,  0.21923955,\n",
              "        1.0976255 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([8.53335151e+01, 7.88288937e+01, 7.13779116e+00, 9.84570089e+03,\n",
              "       6.51875228e+03, 5.53952782e+03])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([8.53334978e+01, 7.88288768e+01, 7.14071248e+00, 9.84569969e+03,\n",
              "       6.51875426e+03, 5.53948052e+03])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Xc2dLdYL3nV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 28047
        },
        "outputId": "75761474-e04a-4cae-cb72-9e39bb853381"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Results with no anomily \n",
        "full_anom = 0\n",
        "anom_samples = 0\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,min_lr=1e-6,min_delta=0.0001,\n",
        "                              patience=150,verbose = 1)\n",
        "# history = autoencoder.fit(x_train2, x_train2,\n",
        "#                     epochs=nb_epoch,\n",
        "#                     batch_size=batch_size,\n",
        "#                     #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "#                     validation_split=.1,\n",
        "#                     verbose=1,callbacks=[reduce_lr])\n",
        "\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
        "                               verbose=0,\n",
        "                               save_best_only=True)\n",
        "tensorboard = TensorBoard(log_dir='./logs',\n",
        "                          histogram_freq=0,\n",
        "                          write_graph=True,\n",
        "                          write_images=True)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2, x_test2),\n",
        "                    validation_split=.1,\n",
        "                    shuffle=True,\n",
        "                    verbose=1,callbacks=[reduce_lr, checkpointer, tensorboard]).history \n",
        "\n",
        "score = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 270 samples, validate on 30 samples\n",
            "Epoch 1/800\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1077 - acc: 0.9296 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 2/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1038 - acc: 0.9259 - val_loss: 0.1416 - val_acc: 0.9000\n",
            "Epoch 3/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1030 - acc: 0.9519 - val_loss: 0.1424 - val_acc: 0.8667\n",
            "Epoch 4/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1052 - acc: 0.9296 - val_loss: 0.1444 - val_acc: 0.9000\n",
            "Epoch 5/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1060 - acc: 0.9370 - val_loss: 0.1407 - val_acc: 0.9000\n",
            "Epoch 6/800\n",
            "270/270 [==============================] - 0s 370us/step - loss: 0.1037 - acc: 0.9370 - val_loss: 0.1406 - val_acc: 0.9000\n",
            "Epoch 7/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1033 - acc: 0.9407 - val_loss: 0.1423 - val_acc: 0.9000\n",
            "Epoch 8/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1037 - acc: 0.9481 - val_loss: 0.1399 - val_acc: 0.9000\n",
            "Epoch 9/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1029 - acc: 0.9407 - val_loss: 0.1419 - val_acc: 0.8667\n",
            "Epoch 10/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1036 - acc: 0.9407 - val_loss: 0.1418 - val_acc: 0.9000\n",
            "Epoch 11/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1049 - acc: 0.9333 - val_loss: 0.1452 - val_acc: 0.8667\n",
            "Epoch 12/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1052 - acc: 0.9259 - val_loss: 0.1492 - val_acc: 0.8667\n",
            "Epoch 13/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1052 - acc: 0.9333 - val_loss: 0.1408 - val_acc: 0.9333\n",
            "Epoch 14/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1036 - acc: 0.9444 - val_loss: 0.1414 - val_acc: 0.9000\n",
            "Epoch 15/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1036 - acc: 0.9407 - val_loss: 0.1436 - val_acc: 0.8667\n",
            "Epoch 16/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1055 - acc: 0.9444 - val_loss: 0.1401 - val_acc: 0.9000\n",
            "Epoch 17/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1036 - acc: 0.9333 - val_loss: 0.1416 - val_acc: 0.9000\n",
            "Epoch 18/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1050 - acc: 0.9370 - val_loss: 0.1394 - val_acc: 0.9000\n",
            "Epoch 19/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1042 - acc: 0.9556 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 20/800\n",
            "270/270 [==============================] - 0s 367us/step - loss: 0.1041 - acc: 0.9444 - val_loss: 0.1406 - val_acc: 0.9000\n",
            "Epoch 21/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1034 - acc: 0.9407 - val_loss: 0.1402 - val_acc: 0.8667\n",
            "Epoch 22/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1036 - acc: 0.9185 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 23/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1044 - acc: 0.9407 - val_loss: 0.1455 - val_acc: 0.9333\n",
            "Epoch 24/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1042 - acc: 0.9444 - val_loss: 0.1404 - val_acc: 0.9000\n",
            "Epoch 25/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1035 - acc: 0.9333 - val_loss: 0.1405 - val_acc: 0.9000\n",
            "Epoch 26/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1032 - acc: 0.9370 - val_loss: 0.1412 - val_acc: 0.9000\n",
            "Epoch 27/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1032 - acc: 0.9519 - val_loss: 0.1435 - val_acc: 0.8667\n",
            "Epoch 28/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1038 - acc: 0.9519 - val_loss: 0.1415 - val_acc: 0.8333\n",
            "Epoch 29/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1039 - acc: 0.9444 - val_loss: 0.1430 - val_acc: 0.9000\n",
            "Epoch 30/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1049 - acc: 0.9370 - val_loss: 0.1438 - val_acc: 0.9000\n",
            "Epoch 31/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1036 - acc: 0.9444 - val_loss: 0.1433 - val_acc: 0.9667\n",
            "Epoch 32/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1037 - acc: 0.9519 - val_loss: 0.1517 - val_acc: 0.8667\n",
            "Epoch 33/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1053 - acc: 0.9481 - val_loss: 0.1398 - val_acc: 0.8667\n",
            "Epoch 34/800\n",
            "270/270 [==============================] - 0s 360us/step - loss: 0.1041 - acc: 0.9444 - val_loss: 0.1419 - val_acc: 0.9000\n",
            "Epoch 35/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1036 - acc: 0.9593 - val_loss: 0.1394 - val_acc: 0.9333\n",
            "Epoch 36/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1030 - acc: 0.9370 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 37/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1040 - acc: 0.9370 - val_loss: 0.1411 - val_acc: 0.9000\n",
            "Epoch 38/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1038 - acc: 0.9333 - val_loss: 0.1409 - val_acc: 0.9000\n",
            "Epoch 39/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1033 - acc: 0.9407 - val_loss: 0.1399 - val_acc: 0.9333\n",
            "Epoch 40/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1037 - acc: 0.9481 - val_loss: 0.1441 - val_acc: 0.8333\n",
            "Epoch 41/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1039 - acc: 0.9370 - val_loss: 0.1399 - val_acc: 0.9000\n",
            "Epoch 42/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1045 - acc: 0.9481 - val_loss: 0.1454 - val_acc: 0.9333\n",
            "Epoch 43/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1070 - acc: 0.9444 - val_loss: 0.1406 - val_acc: 0.9000\n",
            "Epoch 44/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1051 - acc: 0.9370 - val_loss: 0.1434 - val_acc: 0.9000\n",
            "Epoch 45/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1045 - acc: 0.9296 - val_loss: 0.1406 - val_acc: 0.9000\n",
            "Epoch 46/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1040 - acc: 0.9556 - val_loss: 0.1409 - val_acc: 0.9000\n",
            "Epoch 47/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1035 - acc: 0.9407 - val_loss: 0.1414 - val_acc: 0.8667\n",
            "Epoch 48/800\n",
            "270/270 [==============================] - 0s 347us/step - loss: 0.1043 - acc: 0.9407 - val_loss: 0.1397 - val_acc: 0.9000\n",
            "Epoch 49/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1037 - acc: 0.9370 - val_loss: 0.1450 - val_acc: 0.9000\n",
            "Epoch 50/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1038 - acc: 0.9519 - val_loss: 0.1399 - val_acc: 0.9333\n",
            "Epoch 51/800\n",
            "270/270 [==============================] - 0s 271us/step - loss: 0.1057 - acc: 0.9333 - val_loss: 0.1429 - val_acc: 0.9000\n",
            "Epoch 52/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1034 - acc: 0.9481 - val_loss: 0.1418 - val_acc: 0.9333\n",
            "Epoch 53/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1039 - acc: 0.9444 - val_loss: 0.1409 - val_acc: 0.9333\n",
            "Epoch 54/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1045 - acc: 0.9333 - val_loss: 0.1451 - val_acc: 0.8333\n",
            "Epoch 55/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1043 - acc: 0.9444 - val_loss: 0.1396 - val_acc: 0.9000\n",
            "Epoch 56/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1035 - acc: 0.9481 - val_loss: 0.1406 - val_acc: 0.9000\n",
            "Epoch 57/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1038 - acc: 0.9444 - val_loss: 0.1407 - val_acc: 0.9000\n",
            "Epoch 58/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1033 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 59/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1032 - acc: 0.9519 - val_loss: 0.1415 - val_acc: 0.8667\n",
            "Epoch 60/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1045 - acc: 0.9556 - val_loss: 0.1397 - val_acc: 0.9000\n",
            "Epoch 61/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1051 - acc: 0.9259 - val_loss: 0.1614 - val_acc: 0.7667\n",
            "Epoch 62/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1088 - acc: 0.9407 - val_loss: 0.1447 - val_acc: 0.9333\n",
            "Epoch 63/800\n",
            "270/270 [==============================] - 0s 345us/step - loss: 0.1049 - acc: 0.9333 - val_loss: 0.1411 - val_acc: 0.8667\n",
            "Epoch 64/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1031 - acc: 0.9593 - val_loss: 0.1446 - val_acc: 0.8667\n",
            "Epoch 65/800\n",
            "270/270 [==============================] - 0s 279us/step - loss: 0.1098 - acc: 0.9074 - val_loss: 0.1431 - val_acc: 0.8667\n",
            "Epoch 66/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1042 - acc: 0.9407 - val_loss: 0.1398 - val_acc: 0.9333\n",
            "Epoch 67/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1041 - acc: 0.9407 - val_loss: 0.1395 - val_acc: 0.9333\n",
            "Epoch 68/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1032 - acc: 0.9630 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 69/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1050 - acc: 0.9481 - val_loss: 0.1413 - val_acc: 0.9000\n",
            "Epoch 70/800\n",
            "270/270 [==============================] - 0s 278us/step - loss: 0.1040 - acc: 0.9296 - val_loss: 0.1399 - val_acc: 0.9000\n",
            "Epoch 71/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1042 - acc: 0.9407 - val_loss: 0.1475 - val_acc: 0.8667\n",
            "Epoch 72/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1072 - acc: 0.9481 - val_loss: 0.1404 - val_acc: 0.9333\n",
            "Epoch 73/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1030 - acc: 0.9519 - val_loss: 0.1406 - val_acc: 0.8667\n",
            "Epoch 74/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1032 - acc: 0.9481 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 75/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1035 - acc: 0.9593 - val_loss: 0.1400 - val_acc: 0.9000\n",
            "Epoch 76/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1032 - acc: 0.9519 - val_loss: 0.1423 - val_acc: 0.9000\n",
            "Epoch 77/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1043 - acc: 0.9444 - val_loss: 0.1443 - val_acc: 0.8667\n",
            "Epoch 78/800\n",
            "270/270 [==============================] - 0s 346us/step - loss: 0.1034 - acc: 0.9481 - val_loss: 0.1396 - val_acc: 0.8667\n",
            "Epoch 79/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1031 - acc: 0.9481 - val_loss: 0.1402 - val_acc: 0.9333\n",
            "Epoch 80/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1031 - acc: 0.9481 - val_loss: 0.1406 - val_acc: 0.9000\n",
            "Epoch 81/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1029 - acc: 0.9481 - val_loss: 0.1411 - val_acc: 0.9000\n",
            "Epoch 82/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1046 - acc: 0.9370 - val_loss: 0.1422 - val_acc: 0.8667\n",
            "Epoch 83/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1035 - acc: 0.9519 - val_loss: 0.1396 - val_acc: 0.9000\n",
            "Epoch 84/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1029 - acc: 0.9481 - val_loss: 0.1397 - val_acc: 0.9000\n",
            "Epoch 85/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1032 - acc: 0.9593 - val_loss: 0.1418 - val_acc: 0.8667\n",
            "Epoch 86/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1030 - acc: 0.9519 - val_loss: 0.1395 - val_acc: 0.9333\n",
            "Epoch 87/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1029 - acc: 0.9519 - val_loss: 0.1396 - val_acc: 0.9000\n",
            "Epoch 88/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1032 - acc: 0.9407 - val_loss: 0.1397 - val_acc: 0.9333\n",
            "Epoch 89/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1041 - acc: 0.9333 - val_loss: 0.1411 - val_acc: 0.9333\n",
            "Epoch 90/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1050 - acc: 0.9333 - val_loss: 0.1543 - val_acc: 0.8667\n",
            "Epoch 91/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1099 - acc: 0.9444 - val_loss: 0.1415 - val_acc: 0.9000\n",
            "Epoch 92/800\n",
            "270/270 [==============================] - 0s 360us/step - loss: 0.1036 - acc: 0.9481 - val_loss: 0.1401 - val_acc: 0.9333\n",
            "Epoch 93/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1038 - acc: 0.9444 - val_loss: 0.1433 - val_acc: 0.9000\n",
            "Epoch 94/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1033 - acc: 0.9556 - val_loss: 0.1417 - val_acc: 0.9000\n",
            "Epoch 95/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1038 - acc: 0.9333 - val_loss: 0.1404 - val_acc: 0.9000\n",
            "Epoch 96/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1034 - acc: 0.9481 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 97/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1034 - acc: 0.9481 - val_loss: 0.1406 - val_acc: 0.9333\n",
            "Epoch 98/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1036 - acc: 0.9444 - val_loss: 0.1399 - val_acc: 0.9333\n",
            "Epoch 99/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1040 - acc: 0.9519 - val_loss: 0.1412 - val_acc: 0.9000\n",
            "Epoch 100/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1046 - acc: 0.9370 - val_loss: 0.1407 - val_acc: 0.9000\n",
            "Epoch 101/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1031 - acc: 0.9481 - val_loss: 0.1417 - val_acc: 0.8667\n",
            "Epoch 102/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1032 - acc: 0.9444 - val_loss: 0.1395 - val_acc: 0.9000\n",
            "Epoch 103/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1038 - acc: 0.9444 - val_loss: 0.1397 - val_acc: 0.8667\n",
            "Epoch 104/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1033 - acc: 0.9370 - val_loss: 0.1426 - val_acc: 0.9000\n",
            "Epoch 105/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1040 - acc: 0.9519 - val_loss: 0.1397 - val_acc: 0.9000\n",
            "Epoch 106/800\n",
            "270/270 [==============================] - 0s 350us/step - loss: 0.1036 - acc: 0.9259 - val_loss: 0.1413 - val_acc: 0.9333\n",
            "Epoch 107/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1047 - acc: 0.9444 - val_loss: 0.1412 - val_acc: 0.9333\n",
            "Epoch 108/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1038 - acc: 0.9481 - val_loss: 0.1399 - val_acc: 0.9333\n",
            "Epoch 109/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1035 - acc: 0.9407 - val_loss: 0.1399 - val_acc: 0.9000\n",
            "Epoch 110/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1028 - acc: 0.9519 - val_loss: 0.1407 - val_acc: 0.8667\n",
            "Epoch 111/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1037 - acc: 0.9407 - val_loss: 0.1441 - val_acc: 0.9333\n",
            "Epoch 112/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1044 - acc: 0.9444 - val_loss: 0.1404 - val_acc: 0.9333\n",
            "Epoch 113/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1030 - acc: 0.9481 - val_loss: 0.1408 - val_acc: 0.9000\n",
            "Epoch 114/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1037 - acc: 0.9444 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 115/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1030 - acc: 0.9519 - val_loss: 0.1402 - val_acc: 0.8667\n",
            "Epoch 116/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1030 - acc: 0.9444 - val_loss: 0.1413 - val_acc: 0.9000\n",
            "Epoch 117/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1036 - acc: 0.9296 - val_loss: 0.1398 - val_acc: 0.8667\n",
            "Epoch 118/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1033 - acc: 0.9481 - val_loss: 0.1440 - val_acc: 0.9333\n",
            "Epoch 119/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1045 - acc: 0.9481 - val_loss: 0.1402 - val_acc: 0.9000\n",
            "Epoch 120/800\n",
            "270/270 [==============================] - 0s 369us/step - loss: 0.1031 - acc: 0.9519 - val_loss: 0.1421 - val_acc: 0.8000\n",
            "Epoch 121/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1042 - acc: 0.9370 - val_loss: 0.1414 - val_acc: 0.9000\n",
            "Epoch 122/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1041 - acc: 0.9444 - val_loss: 0.1410 - val_acc: 0.9333\n",
            "Epoch 123/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1031 - acc: 0.9481 - val_loss: 0.1411 - val_acc: 0.9000\n",
            "Epoch 124/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1033 - acc: 0.9519 - val_loss: 0.1396 - val_acc: 0.9333\n",
            "Epoch 125/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1037 - acc: 0.9556 - val_loss: 0.1421 - val_acc: 0.9000\n",
            "Epoch 126/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1043 - acc: 0.9333 - val_loss: 0.1401 - val_acc: 0.9333\n",
            "Epoch 127/800\n",
            "270/270 [==============================] - 0s 324us/step - loss: 0.1032 - acc: 0.9444 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 128/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1036 - acc: 0.9444 - val_loss: 0.1410 - val_acc: 0.9333\n",
            "Epoch 129/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1039 - acc: 0.9333 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 130/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1036 - acc: 0.9519 - val_loss: 0.1396 - val_acc: 0.9000\n",
            "Epoch 131/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1032 - acc: 0.9444 - val_loss: 0.1413 - val_acc: 0.9333\n",
            "Epoch 132/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1039 - acc: 0.9407 - val_loss: 0.1400 - val_acc: 0.9000\n",
            "Epoch 133/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1037 - acc: 0.9444 - val_loss: 0.1463 - val_acc: 0.9000\n",
            "Epoch 134/800\n",
            "270/270 [==============================] - 0s 357us/step - loss: 0.1049 - acc: 0.9296 - val_loss: 0.1397 - val_acc: 0.9000\n",
            "Epoch 135/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1037 - acc: 0.9407 - val_loss: 0.1409 - val_acc: 0.9000\n",
            "Epoch 136/800\n",
            "270/270 [==============================] - 0s 325us/step - loss: 0.1032 - acc: 0.9519 - val_loss: 0.1398 - val_acc: 0.9000\n",
            "Epoch 137/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1031 - acc: 0.9481 - val_loss: 0.1394 - val_acc: 0.9333\n",
            "Epoch 138/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1030 - acc: 0.9519 - val_loss: 0.1400 - val_acc: 0.8667\n",
            "Epoch 139/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1034 - acc: 0.9370 - val_loss: 0.1404 - val_acc: 0.9000\n",
            "Epoch 140/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1029 - acc: 0.9519 - val_loss: 0.1399 - val_acc: 0.9000\n",
            "Epoch 141/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1045 - acc: 0.9259 - val_loss: 0.1470 - val_acc: 0.8667\n",
            "Epoch 142/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1045 - acc: 0.9222 - val_loss: 0.1403 - val_acc: 0.8667\n",
            "Epoch 143/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1032 - acc: 0.9481 - val_loss: 0.1396 - val_acc: 0.9333\n",
            "Epoch 144/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1035 - acc: 0.9481 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 145/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1042 - acc: 0.9333 - val_loss: 0.1462 - val_acc: 0.9333\n",
            "Epoch 146/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1073 - acc: 0.9259 - val_loss: 0.1398 - val_acc: 0.8667\n",
            "Epoch 147/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1036 - acc: 0.9481 - val_loss: 0.1394 - val_acc: 0.9333\n",
            "Epoch 148/800\n",
            "270/270 [==============================] - 0s 376us/step - loss: 0.1033 - acc: 0.9593 - val_loss: 0.1458 - val_acc: 0.9333\n",
            "Epoch 149/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1050 - acc: 0.9407 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 150/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1031 - acc: 0.9519 - val_loss: 0.1424 - val_acc: 0.8667\n",
            "Epoch 151/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1030 - acc: 0.9556 - val_loss: 0.1405 - val_acc: 0.9333\n",
            "Epoch 152/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1032 - acc: 0.9519 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 153/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1033 - acc: 0.9481 - val_loss: 0.1456 - val_acc: 0.9000\n",
            "Epoch 154/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1038 - acc: 0.9444 - val_loss: 0.1430 - val_acc: 0.9000\n",
            "Epoch 155/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1038 - acc: 0.9481 - val_loss: 0.1403 - val_acc: 0.9000\n",
            "Epoch 156/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1034 - acc: 0.9444 - val_loss: 0.1405 - val_acc: 0.9000\n",
            "Epoch 157/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1037 - acc: 0.9481 - val_loss: 0.1402 - val_acc: 0.9333\n",
            "Epoch 158/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1034 - acc: 0.9407 - val_loss: 0.1396 - val_acc: 0.9333\n",
            "Epoch 159/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1033 - acc: 0.9444 - val_loss: 0.1433 - val_acc: 0.8667\n",
            "Epoch 160/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1040 - acc: 0.9481 - val_loss: 0.1406 - val_acc: 0.9000\n",
            "Epoch 161/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1032 - acc: 0.9407 - val_loss: 0.1401 - val_acc: 0.9000\n",
            "Epoch 162/800\n",
            "270/270 [==============================] - 0s 348us/step - loss: 0.1037 - acc: 0.9481 - val_loss: 0.1424 - val_acc: 0.8667\n",
            "Epoch 163/800\n",
            "270/270 [==============================] - 0s 327us/step - loss: 0.1042 - acc: 0.9370 - val_loss: 0.1395 - val_acc: 0.8667\n",
            "Epoch 164/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1029 - acc: 0.9556 - val_loss: 0.1410 - val_acc: 0.9000\n",
            "Epoch 165/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1030 - acc: 0.9556 - val_loss: 0.1404 - val_acc: 0.9333\n",
            "Epoch 166/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1036 - acc: 0.9444 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 167/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1051 - acc: 0.9222 - val_loss: 0.1404 - val_acc: 0.9333\n",
            "Epoch 168/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1049 - acc: 0.9370 - val_loss: 0.1427 - val_acc: 0.9000\n",
            "Epoch 169/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1037 - acc: 0.9444 - val_loss: 0.1402 - val_acc: 0.9333\n",
            "Epoch 170/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1038 - acc: 0.9370 - val_loss: 0.1439 - val_acc: 0.8667\n",
            "Epoch 171/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1035 - acc: 0.9481 - val_loss: 0.1411 - val_acc: 0.8667\n",
            "Epoch 172/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1038 - acc: 0.9519 - val_loss: 0.1405 - val_acc: 0.9000\n",
            "Epoch 173/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1030 - acc: 0.9519 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 174/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1033 - acc: 0.9444 - val_loss: 0.1394 - val_acc: 0.8667\n",
            "Epoch 175/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1038 - acc: 0.9370 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 176/800\n",
            "270/270 [==============================] - 0s 342us/step - loss: 0.1028 - acc: 0.9481 - val_loss: 0.1398 - val_acc: 0.9333\n",
            "Epoch 177/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1029 - acc: 0.9556 - val_loss: 0.1394 - val_acc: 0.9333\n",
            "Epoch 178/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1030 - acc: 0.9444 - val_loss: 0.1469 - val_acc: 0.8000\n",
            "Epoch 179/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1048 - acc: 0.9333 - val_loss: 0.1420 - val_acc: 0.9000\n",
            "Epoch 180/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1032 - acc: 0.9481 - val_loss: 0.1402 - val_acc: 0.9333\n",
            "Epoch 181/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1038 - acc: 0.9370 - val_loss: 0.1398 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00181: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 182/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1025 - acc: 0.9556 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 183/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1394 - val_acc: 0.9000\n",
            "Epoch 184/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 185/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 186/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 187/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 188/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 189/800\n",
            "270/270 [==============================] - 0s 333us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 190/800\n",
            "270/270 [==============================] - 0s 348us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 191/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 192/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 193/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 194/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 195/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1393 - val_acc: 0.9333\n",
            "Epoch 196/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 197/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 198/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1394 - val_acc: 0.9000\n",
            "Epoch 199/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 200/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 201/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 202/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 203/800\n",
            "270/270 [==============================] - 0s 366us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 204/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1395 - val_acc: 0.9000\n",
            "Epoch 205/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 206/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 207/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 208/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 209/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 210/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 211/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 212/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1023 - acc: 0.9519 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 213/800\n",
            "270/270 [==============================] - 0s 328us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1393 - val_acc: 0.9333\n",
            "Epoch 214/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 215/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1394 - val_acc: 0.9000\n",
            "Epoch 216/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1023 - acc: 0.9481 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 217/800\n",
            "270/270 [==============================] - 0s 377us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 218/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 219/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 220/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 221/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1395 - val_acc: 0.9000\n",
            "Epoch 222/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 223/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 224/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 225/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 226/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 227/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 228/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 229/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 230/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1394 - val_acc: 0.8667\n",
            "Epoch 231/800\n",
            "270/270 [==============================] - 0s 373us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 232/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 233/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 234/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 235/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 236/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 237/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 238/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 239/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1023 - acc: 0.9519 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 240/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 241/800\n",
            "270/270 [==============================] - 0s 330us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 242/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 243/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1023 - acc: 0.9519 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 244/800\n",
            "270/270 [==============================] - 0s 323us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 245/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 246/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 247/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 248/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 249/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 250/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 251/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 252/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 253/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 254/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1394 - val_acc: 0.9333\n",
            "Epoch 255/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 256/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1023 - acc: 0.9481 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 257/800\n",
            "270/270 [==============================] - 0s 278us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 258/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 259/800\n",
            "270/270 [==============================] - 0s 330us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 260/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 261/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 262/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 263/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 264/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 265/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 266/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 267/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.8667\n",
            "Epoch 268/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1024 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 269/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1386 - val_acc: 0.9000\n",
            "Epoch 270/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 271/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1392 - val_acc: 0.8667\n",
            "Epoch 272/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 273/800\n",
            "270/270 [==============================] - 0s 354us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 274/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1393 - val_acc: 0.8667\n",
            "Epoch 275/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1387 - val_acc: 0.9000\n",
            "Epoch 276/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 277/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1023 - acc: 0.9519 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 278/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 279/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.8667\n",
            "Epoch 280/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9333\n",
            "Epoch 281/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 282/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 283/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 284/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 285/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 286/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1023 - acc: 0.9593 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 287/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 288/800\n",
            "270/270 [==============================] - 0s 358us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 289/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 290/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 291/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1387 - val_acc: 0.9333\n",
            "Epoch 292/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1387 - val_acc: 0.9000\n",
            "Epoch 293/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 294/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1023 - acc: 0.9481 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 295/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 296/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 297/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1023 - acc: 0.9519 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 298/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9333\n",
            "Epoch 299/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 300/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 301/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 302/800\n",
            "270/270 [==============================] - 0s 357us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 303/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 304/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1387 - val_acc: 0.9333\n",
            "Epoch 305/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1387 - val_acc: 0.9000\n",
            "Epoch 306/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1022 - acc: 0.9630 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 307/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 308/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1384 - val_acc: 0.9333\n",
            "Epoch 309/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 310/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 311/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1390 - val_acc: 0.9000\n",
            "Epoch 312/800\n",
            "270/270 [==============================] - 0s 324us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 313/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 314/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1393 - val_acc: 0.9000\n",
            "Epoch 315/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1023 - acc: 0.9519 - val_loss: 0.1394 - val_acc: 0.9000\n",
            "Epoch 316/800\n",
            "270/270 [==============================] - 0s 395us/step - loss: 0.1023 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 317/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1392 - val_acc: 0.9000\n",
            "Epoch 318/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1021 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 319/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 320/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1022 - acc: 0.9519 - val_loss: 0.1386 - val_acc: 0.9000\n",
            "Epoch 321/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 322/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 323/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1023 - acc: 0.9519 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 324/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1387 - val_acc: 0.9000\n",
            "Epoch 325/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1021 - acc: 0.9519 - val_loss: 0.1387 - val_acc: 0.9333\n",
            "Epoch 326/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1386 - val_acc: 0.9333\n",
            "Epoch 327/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1021 - acc: 0.9519 - val_loss: 0.1392 - val_acc: 0.9333\n",
            "Epoch 328/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 329/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1022 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9333\n",
            "Epoch 330/800\n",
            "270/270 [==============================] - 0s 361us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9000\n",
            "Epoch 331/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1022 - acc: 0.9556 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00331: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 332/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 333/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 334/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 335/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 336/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 337/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 338/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 339/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 340/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 341/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 342/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 343/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 344/800\n",
            "270/270 [==============================] - 0s 367us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 345/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 346/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 347/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 348/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 349/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 350/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 351/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 352/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 353/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 354/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 355/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 356/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 357/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 358/800\n",
            "270/270 [==============================] - 0s 372us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 359/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1021 - acc: 0.9556 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 360/800\n",
            "270/270 [==============================] - 0s 324us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 361/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 362/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 363/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 364/800\n",
            "270/270 [==============================] - 0s 323us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 365/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 366/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 367/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 368/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 369/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 370/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 371/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 372/800\n",
            "270/270 [==============================] - 0s 360us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 373/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 374/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 375/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 376/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 377/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 378/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 379/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 380/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 381/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 382/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 383/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 384/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 385/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 386/800\n",
            "270/270 [==============================] - 0s 384us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 387/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 388/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 389/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 390/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 391/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 392/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 393/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 394/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 395/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 396/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 397/800\n",
            "270/270 [==============================] - 0s 325us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 398/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 399/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 400/800\n",
            "270/270 [==============================] - 0s 386us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 401/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 402/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 403/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 404/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 405/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 406/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 407/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 408/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 409/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 410/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 411/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 412/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 413/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 414/800\n",
            "270/270 [==============================] - 0s 371us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 415/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 416/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 417/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 418/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 419/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 420/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1387 - val_acc: 0.9000\n",
            "Epoch 421/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1387 - val_acc: 0.9000\n",
            "Epoch 422/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 423/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 424/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 425/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 426/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 427/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 428/800\n",
            "270/270 [==============================] - 0s 358us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 429/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 430/800\n",
            "270/270 [==============================] - 0s 331us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 431/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 432/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 433/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 434/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 435/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 436/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 437/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 438/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 439/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 440/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1021 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 441/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 442/800\n",
            "270/270 [==============================] - 0s 348us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 443/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 444/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 445/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 446/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 447/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 448/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 449/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 450/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 451/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 452/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1387 - val_acc: 0.9000\n",
            "Epoch 453/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 454/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 455/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 456/800\n",
            "270/270 [==============================] - 0s 338us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 457/800\n",
            "270/270 [==============================] - 0s 337us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 458/800\n",
            "270/270 [==============================] - 0s 338us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 459/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 460/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 461/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 462/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 463/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 464/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 465/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 466/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 467/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1389 - val_acc: 0.9000\n",
            "Epoch 468/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 469/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 470/800\n",
            "270/270 [==============================] - 0s 276us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 471/800\n",
            "270/270 [==============================] - 0s 324us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 472/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 473/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 474/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 475/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 476/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 477/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 478/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 479/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 480/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 481/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00481: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
            "Epoch 482/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9333\n",
            "Epoch 483/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 484/800\n",
            "270/270 [==============================] - 0s 276us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 485/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 486/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 487/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 488/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 489/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 490/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 491/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 492/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 493/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 494/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 495/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 496/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 497/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 498/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 499/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 500/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 501/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 502/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 503/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 504/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 505/800\n",
            "270/270 [==============================] - 0s 274us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 506/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 507/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 508/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 509/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 510/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 511/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 512/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 513/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 514/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 515/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 516/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 517/800\n",
            "270/270 [==============================] - 0s 276us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 518/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 519/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 520/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 521/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 522/800\n",
            "270/270 [==============================] - 0s 275us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 523/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 524/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 525/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 526/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 527/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 528/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 529/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 530/800\n",
            "270/270 [==============================] - 0s 370us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 531/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 532/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 533/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 534/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 535/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 536/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 537/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 538/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 539/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 540/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 541/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 542/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 543/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 544/800\n",
            "270/270 [==============================] - 0s 341us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 545/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 546/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 547/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 548/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 549/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 550/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 551/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 552/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 553/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 554/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 555/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 556/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 557/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 558/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 559/800\n",
            "270/270 [==============================] - 0s 345us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 560/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 561/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 562/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 563/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 564/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 565/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 566/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 567/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 568/800\n",
            "270/270 [==============================] - 0s 323us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 569/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 570/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 571/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 572/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 573/800\n",
            "270/270 [==============================] - 0s 327us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 574/800\n",
            "270/270 [==============================] - 0s 329us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 575/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 576/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 577/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 578/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 579/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 580/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 581/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 582/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 583/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 584/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 585/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 586/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 587/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 588/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 589/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 590/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 591/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 592/800\n",
            "270/270 [==============================] - 0s 342us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 593/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 594/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 595/800\n",
            "270/270 [==============================] - 0s 322us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 596/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 597/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 598/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 599/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 600/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 601/800\n",
            "270/270 [==============================] - 0s 345us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 602/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 603/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 604/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 605/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 606/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 607/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 608/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 609/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 610/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 611/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 612/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 613/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 614/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 615/800\n",
            "270/270 [==============================] - 0s 366us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 616/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 617/800\n",
            "270/270 [==============================] - 0s 334us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 618/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 619/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 620/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 621/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 622/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 623/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 624/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 625/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 626/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 627/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 628/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 629/800\n",
            "270/270 [==============================] - 0s 362us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 630/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 631/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00631: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
            "Epoch 632/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 633/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 634/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 635/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 636/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 637/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 638/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 639/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 640/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 641/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 642/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 643/800\n",
            "270/270 [==============================] - 0s 372us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 644/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 645/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 646/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 647/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 648/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 649/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 650/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 651/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 652/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 653/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 654/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 655/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 656/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 657/800\n",
            "270/270 [==============================] - 0s 374us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 658/800\n",
            "270/270 [==============================] - 0s 327us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 659/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 660/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 661/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 662/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 663/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 664/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 665/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 666/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 667/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 668/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 669/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 670/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 671/800\n",
            "270/270 [==============================] - 0s 376us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 672/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 673/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 674/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 675/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 676/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 677/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 678/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 679/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 680/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 681/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 682/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 683/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 684/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 685/800\n",
            "270/270 [==============================] - 0s 378us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 686/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 687/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 688/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 689/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 690/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 691/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 692/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 693/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 694/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 695/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 696/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 697/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 698/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 699/800\n",
            "270/270 [==============================] - 0s 369us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 700/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 701/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 702/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 703/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 704/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 705/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 706/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 707/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 708/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 709/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 710/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 711/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 712/800\n",
            "270/270 [==============================] - 0s 275us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 713/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 714/800\n",
            "270/270 [==============================] - 0s 348us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 715/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 716/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 717/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 718/800\n",
            "270/270 [==============================] - 0s 273us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 719/800\n",
            "270/270 [==============================] - 0s 278us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 720/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 721/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 722/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 723/800\n",
            "270/270 [==============================] - 0s 268us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 724/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 725/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 726/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 727/800\n",
            "270/270 [==============================] - 0s 273us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 728/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 729/800\n",
            "270/270 [==============================] - 0s 339us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 730/800\n",
            "270/270 [==============================] - 0s 279us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 731/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 732/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 733/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 734/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 735/800\n",
            "270/270 [==============================] - 0s 279us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 736/800\n",
            "270/270 [==============================] - 0s 276us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 737/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 738/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 739/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 740/800\n",
            "270/270 [==============================] - 0s 279us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 741/800\n",
            "270/270 [==============================] - 0s 271us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 742/800\n",
            "270/270 [==============================] - 0s 276us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 743/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 744/800\n",
            "270/270 [==============================] - 0s 343us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 745/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 746/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 747/800\n",
            "270/270 [==============================] - 0s 329us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 748/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 749/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 750/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 751/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 752/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 753/800\n",
            "270/270 [==============================] - 0s 272us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 754/800\n",
            "270/270 [==============================] - 0s 275us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 755/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 756/800\n",
            "270/270 [==============================] - 0s 275us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 757/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 758/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 759/800\n",
            "270/270 [==============================] - 0s 359us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 760/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 761/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 762/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 763/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 764/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 765/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 766/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 767/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 768/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 769/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 770/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 771/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 772/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 773/800\n",
            "270/270 [==============================] - 0s 371us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 774/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 775/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 776/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 777/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 778/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 779/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 780/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 781/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00781: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "Epoch 782/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 783/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 784/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 785/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 786/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 787/800\n",
            "270/270 [==============================] - 0s 344us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 788/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 789/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 790/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 791/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 792/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 793/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 794/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 795/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 796/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 797/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 798/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 799/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "Epoch 800/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1020 - acc: 0.9593 - val_loss: 0.1388 - val_acc: 0.9000\n",
            "300/300 [==============================] - 0s 102us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0.1051254536708196, 0.9566666666666667]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "PS6_4zgF4mGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27943
        },
        "outputId": "2bfe821c-279b-48f0-b32a-9da5a34af09b"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Results with full anomily \n",
        "full_anom = 1\n",
        "anom_samples = 0\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,min_lr=1e-6,min_delta=0.0001,\n",
        "                              patience=150,verbose = 1)\n",
        "# history = autoencoder.fit(x_train2, x_train2,\n",
        "#                     epochs=nb_epoch,\n",
        "#                     batch_size=batch_size,\n",
        "#                     #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "#                     validation_split=.1,\n",
        "#                     verbose=1,callbacks=[reduce_lr])\n",
        "\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
        "                               verbose=0,\n",
        "                               save_best_only=True)\n",
        "tensorboard = TensorBoard(log_dir='./logs',\n",
        "                          histogram_freq=0,\n",
        "                          write_graph=True,\n",
        "                          write_images=True)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2, x_test2),\n",
        "                    validation_split=.1,\n",
        "                    shuffle=True,\n",
        "                    verbose=1,callbacks=[reduce_lr, checkpointer, tensorboard]).history \n",
        "\n",
        "score = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 270 samples, validate on 30 samples\n",
            "Epoch 1/800\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.3057 - acc: 0.7222 - val_loss: 0.3381 - val_acc: 0.6667\n",
            "Epoch 2/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.3016 - acc: 0.7370 - val_loss: 0.3398 - val_acc: 0.6000\n",
            "Epoch 3/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.3022 - acc: 0.7593 - val_loss: 0.3379 - val_acc: 0.6333\n",
            "Epoch 4/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.3009 - acc: 0.7370 - val_loss: 0.3390 - val_acc: 0.6000\n",
            "Epoch 5/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.3007 - acc: 0.7556 - val_loss: 0.3504 - val_acc: 0.5000\n",
            "Epoch 6/800\n",
            "270/270 [==============================] - 0s 272us/step - loss: 0.3013 - acc: 0.7296 - val_loss: 0.3375 - val_acc: 0.6333\n",
            "Epoch 7/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2999 - acc: 0.7444 - val_loss: 0.3343 - val_acc: 0.6667\n",
            "Epoch 8/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.3000 - acc: 0.7519 - val_loss: 0.3365 - val_acc: 0.6000\n",
            "Epoch 9/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2994 - acc: 0.7222 - val_loss: 0.3328 - val_acc: 0.7333\n",
            "Epoch 10/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.3005 - acc: 0.7444 - val_loss: 0.3354 - val_acc: 0.7000\n",
            "Epoch 11/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.2992 - acc: 0.7556 - val_loss: 0.3353 - val_acc: 0.6000\n",
            "Epoch 12/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.2985 - acc: 0.7259 - val_loss: 0.3330 - val_acc: 0.6667\n",
            "Epoch 13/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.2965 - acc: 0.7481 - val_loss: 0.3409 - val_acc: 0.6667\n",
            "Epoch 14/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.2978 - acc: 0.7296 - val_loss: 0.3333 - val_acc: 0.6333\n",
            "Epoch 15/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2962 - acc: 0.7519 - val_loss: 0.3362 - val_acc: 0.6667\n",
            "Epoch 16/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.2959 - acc: 0.7370 - val_loss: 0.3322 - val_acc: 0.6667\n",
            "Epoch 17/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.2960 - acc: 0.7444 - val_loss: 0.3307 - val_acc: 0.7000\n",
            "Epoch 18/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.2953 - acc: 0.7407 - val_loss: 0.3325 - val_acc: 0.7000\n",
            "Epoch 19/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.2939 - acc: 0.7481 - val_loss: 0.3509 - val_acc: 0.5000\n",
            "Epoch 20/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.2962 - acc: 0.7185 - val_loss: 0.3439 - val_acc: 0.5667\n",
            "Epoch 21/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.2942 - acc: 0.7444 - val_loss: 0.3319 - val_acc: 0.7000\n",
            "Epoch 22/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.2919 - acc: 0.7667 - val_loss: 0.3262 - val_acc: 0.7000\n",
            "Epoch 23/800\n",
            "270/270 [==============================] - 0s 372us/step - loss: 0.2933 - acc: 0.7593 - val_loss: 0.3280 - val_acc: 0.6333\n",
            "Epoch 24/800\n",
            "270/270 [==============================] - 0s 340us/step - loss: 0.2915 - acc: 0.7185 - val_loss: 0.3284 - val_acc: 0.6333\n",
            "Epoch 25/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.2943 - acc: 0.7333 - val_loss: 0.3271 - val_acc: 0.6667\n",
            "Epoch 26/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.2924 - acc: 0.7370 - val_loss: 0.3263 - val_acc: 0.6667\n",
            "Epoch 27/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.2901 - acc: 0.7593 - val_loss: 0.3260 - val_acc: 0.6667\n",
            "Epoch 28/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.2896 - acc: 0.7481 - val_loss: 0.3237 - val_acc: 0.7000\n",
            "Epoch 29/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.2903 - acc: 0.7370 - val_loss: 0.3264 - val_acc: 0.7000\n",
            "Epoch 30/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.2905 - acc: 0.7667 - val_loss: 0.3225 - val_acc: 0.7000\n",
            "Epoch 31/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.2884 - acc: 0.7593 - val_loss: 0.3287 - val_acc: 0.6667\n",
            "Epoch 32/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.2890 - acc: 0.7444 - val_loss: 0.3283 - val_acc: 0.6667\n",
            "Epoch 33/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.2920 - acc: 0.7111 - val_loss: 0.3244 - val_acc: 0.6333\n",
            "Epoch 34/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.2884 - acc: 0.7259 - val_loss: 0.3287 - val_acc: 0.6333\n",
            "Epoch 35/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.2876 - acc: 0.7556 - val_loss: 0.3212 - val_acc: 0.7000\n",
            "Epoch 36/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.2879 - acc: 0.7370 - val_loss: 0.3193 - val_acc: 0.7000\n",
            "Epoch 37/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.2874 - acc: 0.7704 - val_loss: 0.3182 - val_acc: 0.7000\n",
            "Epoch 38/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.2852 - acc: 0.7556 - val_loss: 0.3275 - val_acc: 0.6000\n",
            "Epoch 39/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.2865 - acc: 0.7222 - val_loss: 0.3203 - val_acc: 0.7000\n",
            "Epoch 40/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2852 - acc: 0.7556 - val_loss: 0.3186 - val_acc: 0.7000\n",
            "Epoch 41/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.2844 - acc: 0.7556 - val_loss: 0.3153 - val_acc: 0.7000\n",
            "Epoch 42/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.2854 - acc: 0.7407 - val_loss: 0.3156 - val_acc: 0.7333\n",
            "Epoch 43/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.2832 - acc: 0.7556 - val_loss: 0.3237 - val_acc: 0.6000\n",
            "Epoch 44/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2832 - acc: 0.7370 - val_loss: 0.3141 - val_acc: 0.7000\n",
            "Epoch 45/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.2832 - acc: 0.7481 - val_loss: 0.3157 - val_acc: 0.7000\n",
            "Epoch 46/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.2822 - acc: 0.7519 - val_loss: 0.3149 - val_acc: 0.7000\n",
            "Epoch 47/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2819 - acc: 0.7556 - val_loss: 0.3146 - val_acc: 0.7000\n",
            "Epoch 48/800\n",
            "270/270 [==============================] - 0s 327us/step - loss: 0.2822 - acc: 0.7630 - val_loss: 0.3200 - val_acc: 0.6667\n",
            "Epoch 49/800\n",
            "270/270 [==============================] - 0s 339us/step - loss: 0.2836 - acc: 0.7370 - val_loss: 0.3131 - val_acc: 0.7333\n",
            "Epoch 50/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2807 - acc: 0.7667 - val_loss: 0.3177 - val_acc: 0.7000\n",
            "Epoch 51/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.2816 - acc: 0.7444 - val_loss: 0.3163 - val_acc: 0.6333\n",
            "Epoch 52/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.2803 - acc: 0.7481 - val_loss: 0.3136 - val_acc: 0.7000\n",
            "Epoch 53/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.2796 - acc: 0.7630 - val_loss: 0.3232 - val_acc: 0.6000\n",
            "Epoch 54/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.2825 - acc: 0.7481 - val_loss: 0.3159 - val_acc: 0.6667\n",
            "Epoch 55/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.2790 - acc: 0.7370 - val_loss: 0.3094 - val_acc: 0.6667\n",
            "Epoch 56/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2814 - acc: 0.7333 - val_loss: 0.3084 - val_acc: 0.7333\n",
            "Epoch 57/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.2777 - acc: 0.7593 - val_loss: 0.3184 - val_acc: 0.6333\n",
            "Epoch 58/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.2784 - acc: 0.7407 - val_loss: 0.3118 - val_acc: 0.6667\n",
            "Epoch 59/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2771 - acc: 0.7593 - val_loss: 0.3182 - val_acc: 0.6000\n",
            "Epoch 60/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.2790 - acc: 0.7333 - val_loss: 0.3152 - val_acc: 0.6667\n",
            "Epoch 61/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.2773 - acc: 0.7481 - val_loss: 0.3079 - val_acc: 0.6667\n",
            "Epoch 62/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.2770 - acc: 0.7481 - val_loss: 0.3075 - val_acc: 0.7333\n",
            "Epoch 63/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.2782 - acc: 0.7630 - val_loss: 0.3119 - val_acc: 0.6667\n",
            "Epoch 64/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.2765 - acc: 0.7519 - val_loss: 0.3044 - val_acc: 0.7000\n",
            "Epoch 65/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2748 - acc: 0.7593 - val_loss: 0.3089 - val_acc: 0.7000\n",
            "Epoch 66/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.2753 - acc: 0.7407 - val_loss: 0.3076 - val_acc: 0.6667\n",
            "Epoch 67/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.2760 - acc: 0.7444 - val_loss: 0.3042 - val_acc: 0.7333\n",
            "Epoch 68/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.2733 - acc: 0.7593 - val_loss: 0.3232 - val_acc: 0.6000\n",
            "Epoch 69/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2751 - acc: 0.7667 - val_loss: 0.3056 - val_acc: 0.7333\n",
            "Epoch 70/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2726 - acc: 0.7593 - val_loss: 0.3032 - val_acc: 0.7000\n",
            "Epoch 71/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.2725 - acc: 0.7481 - val_loss: 0.3036 - val_acc: 0.7000\n",
            "Epoch 72/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.2715 - acc: 0.7481 - val_loss: 0.3059 - val_acc: 0.7667\n",
            "Epoch 73/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.2717 - acc: 0.7519 - val_loss: 0.2993 - val_acc: 0.7000\n",
            "Epoch 74/800\n",
            "270/270 [==============================] - 0s 399us/step - loss: 0.2708 - acc: 0.7556 - val_loss: 0.3025 - val_acc: 0.6667\n",
            "Epoch 75/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.2711 - acc: 0.7519 - val_loss: 0.2996 - val_acc: 0.7000\n",
            "Epoch 76/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.2705 - acc: 0.7556 - val_loss: 0.3012 - val_acc: 0.6667\n",
            "Epoch 77/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.2707 - acc: 0.7481 - val_loss: 0.3016 - val_acc: 0.6333\n",
            "Epoch 78/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.2705 - acc: 0.7370 - val_loss: 0.3025 - val_acc: 0.7000\n",
            "Epoch 79/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.2688 - acc: 0.7519 - val_loss: 0.3037 - val_acc: 0.6333\n",
            "Epoch 80/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.2695 - acc: 0.7481 - val_loss: 0.2983 - val_acc: 0.7333\n",
            "Epoch 81/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.2687 - acc: 0.7630 - val_loss: 0.2985 - val_acc: 0.7000\n",
            "Epoch 82/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.2674 - acc: 0.7593 - val_loss: 0.3023 - val_acc: 0.7000\n",
            "Epoch 83/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2682 - acc: 0.7444 - val_loss: 0.2987 - val_acc: 0.7333\n",
            "Epoch 84/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.2670 - acc: 0.7519 - val_loss: 0.2962 - val_acc: 0.7000\n",
            "Epoch 85/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.2674 - acc: 0.7481 - val_loss: 0.2967 - val_acc: 0.6667\n",
            "Epoch 86/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.2669 - acc: 0.7519 - val_loss: 0.3038 - val_acc: 0.6333\n",
            "Epoch 87/800\n",
            "270/270 [==============================] - 0s 335us/step - loss: 0.2665 - acc: 0.7556 - val_loss: 0.2969 - val_acc: 0.6667\n",
            "Epoch 88/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.2663 - acc: 0.7444 - val_loss: 0.2955 - val_acc: 0.7000\n",
            "Epoch 89/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2655 - acc: 0.7444 - val_loss: 0.2944 - val_acc: 0.7000\n",
            "Epoch 90/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.2647 - acc: 0.7519 - val_loss: 0.2940 - val_acc: 0.6667\n",
            "Epoch 91/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.2643 - acc: 0.7444 - val_loss: 0.2913 - val_acc: 0.7000\n",
            "Epoch 92/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.2639 - acc: 0.7444 - val_loss: 0.2982 - val_acc: 0.6667\n",
            "Epoch 93/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.2642 - acc: 0.7296 - val_loss: 0.2907 - val_acc: 0.7000\n",
            "Epoch 94/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2635 - acc: 0.7444 - val_loss: 0.2910 - val_acc: 0.6667\n",
            "Epoch 95/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.2629 - acc: 0.7630 - val_loss: 0.2922 - val_acc: 0.7000\n",
            "Epoch 96/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.2621 - acc: 0.7444 - val_loss: 0.2888 - val_acc: 0.7000\n",
            "Epoch 97/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.2619 - acc: 0.7556 - val_loss: 0.2876 - val_acc: 0.7000\n",
            "Epoch 98/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.2621 - acc: 0.7630 - val_loss: 0.2896 - val_acc: 0.7000\n",
            "Epoch 99/800\n",
            "270/270 [==============================] - 0s 362us/step - loss: 0.2618 - acc: 0.7519 - val_loss: 0.2918 - val_acc: 0.7333\n",
            "Epoch 100/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.2636 - acc: 0.7556 - val_loss: 0.2877 - val_acc: 0.7333\n",
            "Epoch 101/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.2605 - acc: 0.7630 - val_loss: 0.2916 - val_acc: 0.7000\n",
            "Epoch 102/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.2608 - acc: 0.7630 - val_loss: 0.2858 - val_acc: 0.7333\n",
            "Epoch 103/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.2588 - acc: 0.7556 - val_loss: 0.2887 - val_acc: 0.6667\n",
            "Epoch 104/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2597 - acc: 0.7630 - val_loss: 0.2859 - val_acc: 0.7000\n",
            "Epoch 105/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.2589 - acc: 0.7481 - val_loss: 0.2915 - val_acc: 0.7000\n",
            "Epoch 106/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.2594 - acc: 0.7519 - val_loss: 0.2842 - val_acc: 0.7333\n",
            "Epoch 107/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2579 - acc: 0.7444 - val_loss: 0.2847 - val_acc: 0.7333\n",
            "Epoch 108/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.2570 - acc: 0.7704 - val_loss: 0.2852 - val_acc: 0.7000\n",
            "Epoch 109/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.2571 - acc: 0.7519 - val_loss: 0.2834 - val_acc: 0.7000\n",
            "Epoch 110/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.2564 - acc: 0.7481 - val_loss: 0.2831 - val_acc: 0.7333\n",
            "Epoch 111/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.2560 - acc: 0.7593 - val_loss: 0.2836 - val_acc: 0.6667\n",
            "Epoch 112/800\n",
            "270/270 [==============================] - 0s 365us/step - loss: 0.2573 - acc: 0.7407 - val_loss: 0.2822 - val_acc: 0.7000\n",
            "Epoch 113/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.2554 - acc: 0.7481 - val_loss: 0.2834 - val_acc: 0.7333\n",
            "Epoch 114/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.2556 - acc: 0.7630 - val_loss: 0.2789 - val_acc: 0.7333\n",
            "Epoch 115/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.2541 - acc: 0.7593 - val_loss: 0.2798 - val_acc: 0.7000\n",
            "Epoch 116/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2542 - acc: 0.7519 - val_loss: 0.2769 - val_acc: 0.7000\n",
            "Epoch 117/800\n",
            "270/270 [==============================] - 0s 324us/step - loss: 0.2547 - acc: 0.7593 - val_loss: 0.2807 - val_acc: 0.7000\n",
            "Epoch 118/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.2533 - acc: 0.7556 - val_loss: 0.2787 - val_acc: 0.7333\n",
            "Epoch 119/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2537 - acc: 0.7556 - val_loss: 0.3166 - val_acc: 0.6000\n",
            "Epoch 120/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.2568 - acc: 0.7370 - val_loss: 0.2794 - val_acc: 0.7000\n",
            "Epoch 121/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.2522 - acc: 0.7519 - val_loss: 0.2758 - val_acc: 0.7333\n",
            "Epoch 122/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.2526 - acc: 0.7556 - val_loss: 0.2757 - val_acc: 0.7333\n",
            "Epoch 123/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.2517 - acc: 0.7593 - val_loss: 0.2835 - val_acc: 0.6333\n",
            "Epoch 124/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2514 - acc: 0.7333 - val_loss: 0.2759 - val_acc: 0.7000\n",
            "Epoch 125/800\n",
            "270/270 [==============================] - 0s 378us/step - loss: 0.2511 - acc: 0.7407 - val_loss: 0.2754 - val_acc: 0.6667\n",
            "Epoch 126/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2505 - acc: 0.7444 - val_loss: 0.2841 - val_acc: 0.7000\n",
            "Epoch 127/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.2527 - acc: 0.7481 - val_loss: 0.2750 - val_acc: 0.7333\n",
            "Epoch 128/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.2488 - acc: 0.7556 - val_loss: 0.2724 - val_acc: 0.7000\n",
            "Epoch 129/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.2485 - acc: 0.7667 - val_loss: 0.2716 - val_acc: 0.7000\n",
            "Epoch 130/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.2487 - acc: 0.7667 - val_loss: 0.2802 - val_acc: 0.7000\n",
            "Epoch 131/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.2495 - acc: 0.7519 - val_loss: 0.2744 - val_acc: 0.7000\n",
            "Epoch 132/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.2492 - acc: 0.7481 - val_loss: 0.2709 - val_acc: 0.7333\n",
            "Epoch 133/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.2476 - acc: 0.7667 - val_loss: 0.2739 - val_acc: 0.6667\n",
            "Epoch 134/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.2471 - acc: 0.7593 - val_loss: 0.2678 - val_acc: 0.7333\n",
            "Epoch 135/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.2461 - acc: 0.7667 - val_loss: 0.2678 - val_acc: 0.7333\n",
            "Epoch 136/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.2457 - acc: 0.7444 - val_loss: 0.2686 - val_acc: 0.7000\n",
            "Epoch 137/800\n",
            "270/270 [==============================] - 0s 362us/step - loss: 0.2457 - acc: 0.7407 - val_loss: 0.2669 - val_acc: 0.7000\n",
            "Epoch 138/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.2458 - acc: 0.7519 - val_loss: 0.2700 - val_acc: 0.7000\n",
            "Epoch 139/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2446 - acc: 0.7519 - val_loss: 0.2681 - val_acc: 0.7333\n",
            "Epoch 140/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.2454 - acc: 0.7630 - val_loss: 0.2668 - val_acc: 0.7333\n",
            "Epoch 141/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.2441 - acc: 0.7519 - val_loss: 0.2662 - val_acc: 0.7333\n",
            "Epoch 142/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.2437 - acc: 0.7593 - val_loss: 0.2640 - val_acc: 0.7000\n",
            "Epoch 143/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.2428 - acc: 0.7407 - val_loss: 0.2696 - val_acc: 0.7000\n",
            "Epoch 144/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.2429 - acc: 0.7519 - val_loss: 0.2661 - val_acc: 0.7000\n",
            "Epoch 145/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.2433 - acc: 0.7481 - val_loss: 0.2649 - val_acc: 0.7333\n",
            "Epoch 146/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.2415 - acc: 0.7630 - val_loss: 0.2697 - val_acc: 0.6333\n",
            "Epoch 147/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.2421 - acc: 0.7444 - val_loss: 0.2639 - val_acc: 0.7000\n",
            "Epoch 148/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.2409 - acc: 0.7519 - val_loss: 0.2659 - val_acc: 0.7000\n",
            "Epoch 149/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.2417 - acc: 0.7519 - val_loss: 0.2635 - val_acc: 0.7333\n",
            "Epoch 150/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.2409 - acc: 0.7519 - val_loss: 0.2614 - val_acc: 0.7333\n",
            "Epoch 151/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.2412 - acc: 0.7741 - val_loss: 0.2723 - val_acc: 0.7000\n",
            "Epoch 152/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.2402 - acc: 0.7593 - val_loss: 0.2610 - val_acc: 0.7000\n",
            "Epoch 153/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.2391 - acc: 0.7593 - val_loss: 0.2600 - val_acc: 0.7000\n",
            "Epoch 154/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.2382 - acc: 0.7593 - val_loss: 0.2644 - val_acc: 0.7000\n",
            "Epoch 155/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.2388 - acc: 0.7556 - val_loss: 0.2584 - val_acc: 0.7000\n",
            "Epoch 156/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.2376 - acc: 0.7444 - val_loss: 0.2604 - val_acc: 0.6667\n",
            "Epoch 157/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.2376 - acc: 0.7593 - val_loss: 0.2588 - val_acc: 0.7333\n",
            "Epoch 158/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.2364 - acc: 0.7444 - val_loss: 0.2621 - val_acc: 0.6667\n",
            "Epoch 159/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2373 - acc: 0.7556 - val_loss: 0.2589 - val_acc: 0.7000\n",
            "Epoch 160/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.2357 - acc: 0.7407 - val_loss: 0.2624 - val_acc: 0.6333\n",
            "Epoch 161/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.2361 - acc: 0.7519 - val_loss: 0.2543 - val_acc: 0.7333\n",
            "Epoch 162/800\n",
            "270/270 [==============================] - 0s 354us/step - loss: 0.2349 - acc: 0.7556 - val_loss: 0.2557 - val_acc: 0.7000\n",
            "Epoch 163/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.2340 - acc: 0.7593 - val_loss: 0.2592 - val_acc: 0.7333\n",
            "Epoch 164/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.2349 - acc: 0.7481 - val_loss: 0.2566 - val_acc: 0.7000\n",
            "Epoch 165/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.2341 - acc: 0.7444 - val_loss: 0.2618 - val_acc: 0.7000\n",
            "Epoch 166/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.2338 - acc: 0.7556 - val_loss: 0.2546 - val_acc: 0.7000\n",
            "Epoch 167/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.2333 - acc: 0.7481 - val_loss: 0.2548 - val_acc: 0.7000\n",
            "Epoch 168/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.2328 - acc: 0.7333 - val_loss: 0.2537 - val_acc: 0.7000\n",
            "Epoch 169/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.2323 - acc: 0.7630 - val_loss: 0.2566 - val_acc: 0.7000\n",
            "Epoch 170/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.2316 - acc: 0.7593 - val_loss: 0.2517 - val_acc: 0.7333\n",
            "Epoch 171/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.2313 - acc: 0.7704 - val_loss: 0.2503 - val_acc: 0.7333\n",
            "Epoch 172/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.2309 - acc: 0.7519 - val_loss: 0.2499 - val_acc: 0.7333\n",
            "Epoch 173/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.2300 - acc: 0.7593 - val_loss: 0.2512 - val_acc: 0.7000\n",
            "Epoch 174/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.2297 - acc: 0.7556 - val_loss: 0.2493 - val_acc: 0.6667\n",
            "Epoch 175/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.2291 - acc: 0.7630 - val_loss: 0.2481 - val_acc: 0.6667\n",
            "Epoch 176/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2294 - acc: 0.7593 - val_loss: 0.2469 - val_acc: 0.6667\n",
            "Epoch 177/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2290 - acc: 0.7481 - val_loss: 0.2463 - val_acc: 0.7000\n",
            "Epoch 178/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.2283 - acc: 0.7704 - val_loss: 0.2596 - val_acc: 0.6667\n",
            "Epoch 179/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2306 - acc: 0.7519 - val_loss: 0.2527 - val_acc: 0.6667\n",
            "Epoch 180/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.2280 - acc: 0.7519 - val_loss: 0.2456 - val_acc: 0.7333\n",
            "Epoch 181/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.2263 - acc: 0.7593 - val_loss: 0.2509 - val_acc: 0.7000\n",
            "Epoch 182/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.2273 - acc: 0.7630 - val_loss: 0.2468 - val_acc: 0.7333\n",
            "Epoch 183/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.2267 - acc: 0.7667 - val_loss: 0.2425 - val_acc: 0.7333\n",
            "Epoch 184/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2250 - acc: 0.7593 - val_loss: 0.2437 - val_acc: 0.7333\n",
            "Epoch 185/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.2251 - acc: 0.7556 - val_loss: 0.2421 - val_acc: 0.7333\n",
            "Epoch 186/800\n",
            "270/270 [==============================] - 0s 278us/step - loss: 0.2240 - acc: 0.7667 - val_loss: 0.2420 - val_acc: 0.7000\n",
            "Epoch 187/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.2245 - acc: 0.7667 - val_loss: 0.2425 - val_acc: 0.7000\n",
            "Epoch 188/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.2237 - acc: 0.7667 - val_loss: 0.2422 - val_acc: 0.7333\n",
            "Epoch 189/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.2236 - acc: 0.7593 - val_loss: 0.2416 - val_acc: 0.7000\n",
            "Epoch 190/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.2233 - acc: 0.7704 - val_loss: 0.2400 - val_acc: 0.7667\n",
            "Epoch 191/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.2223 - acc: 0.7556 - val_loss: 0.2412 - val_acc: 0.7667\n",
            "Epoch 192/800\n",
            "270/270 [==============================] - 0s 279us/step - loss: 0.2219 - acc: 0.7667 - val_loss: 0.2437 - val_acc: 0.6667\n",
            "Epoch 193/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.2228 - acc: 0.7630 - val_loss: 0.2422 - val_acc: 0.7667\n",
            "Epoch 194/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.2211 - acc: 0.7667 - val_loss: 0.2388 - val_acc: 0.7667\n",
            "Epoch 195/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.2205 - acc: 0.7593 - val_loss: 0.2385 - val_acc: 0.7667\n",
            "Epoch 196/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.2208 - acc: 0.7556 - val_loss: 0.2375 - val_acc: 0.6667\n",
            "Epoch 197/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.2193 - acc: 0.7519 - val_loss: 0.2406 - val_acc: 0.6667\n",
            "Epoch 198/800\n",
            "270/270 [==============================] - 0s 275us/step - loss: 0.2192 - acc: 0.7704 - val_loss: 0.2350 - val_acc: 0.7000\n",
            "Epoch 199/800\n",
            "270/270 [==============================] - 0s 334us/step - loss: 0.2188 - acc: 0.7519 - val_loss: 0.2353 - val_acc: 0.7667\n",
            "Epoch 200/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.2182 - acc: 0.7667 - val_loss: 0.2337 - val_acc: 0.7000\n",
            "Epoch 201/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.2170 - acc: 0.7667 - val_loss: 0.2365 - val_acc: 0.7333\n",
            "Epoch 202/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.2179 - acc: 0.7593 - val_loss: 0.2451 - val_acc: 0.7000\n",
            "Epoch 203/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.2187 - acc: 0.7889 - val_loss: 0.2334 - val_acc: 0.7333\n",
            "Epoch 204/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.2166 - acc: 0.7593 - val_loss: 0.2334 - val_acc: 0.7667\n",
            "Epoch 205/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.2156 - acc: 0.7667 - val_loss: 0.2320 - val_acc: 0.6667\n",
            "Epoch 206/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.2154 - acc: 0.7667 - val_loss: 0.2317 - val_acc: 0.7000\n",
            "Epoch 207/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.2149 - acc: 0.7630 - val_loss: 0.2331 - val_acc: 0.7667\n",
            "Epoch 208/800\n",
            "270/270 [==============================] - 0s 269us/step - loss: 0.2149 - acc: 0.7667 - val_loss: 0.2323 - val_acc: 0.7000\n",
            "Epoch 209/800\n",
            "270/270 [==============================] - 0s 276us/step - loss: 0.2143 - acc: 0.7704 - val_loss: 0.2302 - val_acc: 0.7000\n",
            "Epoch 210/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.2138 - acc: 0.7593 - val_loss: 0.2290 - val_acc: 0.7333\n",
            "Epoch 211/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.2129 - acc: 0.7667 - val_loss: 0.2283 - val_acc: 0.8000\n",
            "Epoch 212/800\n",
            "270/270 [==============================] - 0s 338us/step - loss: 0.2134 - acc: 0.7556 - val_loss: 0.2286 - val_acc: 0.7000\n",
            "Epoch 213/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.2117 - acc: 0.7630 - val_loss: 0.2280 - val_acc: 0.7000\n",
            "Epoch 214/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.2125 - acc: 0.7667 - val_loss: 0.2258 - val_acc: 0.7333\n",
            "Epoch 215/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.2108 - acc: 0.7704 - val_loss: 0.2277 - val_acc: 0.7000\n",
            "Epoch 216/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.2118 - acc: 0.7556 - val_loss: 0.2264 - val_acc: 0.7667\n",
            "Epoch 217/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.2109 - acc: 0.7815 - val_loss: 0.2246 - val_acc: 0.6667\n",
            "Epoch 218/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.2109 - acc: 0.7741 - val_loss: 0.2247 - val_acc: 0.7333\n",
            "Epoch 219/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.2098 - acc: 0.7741 - val_loss: 0.2225 - val_acc: 0.7333\n",
            "Epoch 220/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.2097 - acc: 0.7667 - val_loss: 0.2237 - val_acc: 0.7333\n",
            "Epoch 221/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.2094 - acc: 0.7815 - val_loss: 0.2297 - val_acc: 0.7000\n",
            "Epoch 222/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.2098 - acc: 0.7815 - val_loss: 0.2237 - val_acc: 0.7000\n",
            "Epoch 223/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.2079 - acc: 0.7630 - val_loss: 0.2391 - val_acc: 0.7000\n",
            "Epoch 224/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.2096 - acc: 0.7704 - val_loss: 0.2209 - val_acc: 0.7333\n",
            "Epoch 225/800\n",
            "270/270 [==============================] - 0s 373us/step - loss: 0.2069 - acc: 0.7704 - val_loss: 0.2201 - val_acc: 0.7333\n",
            "Epoch 226/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.2069 - acc: 0.7778 - val_loss: 0.2188 - val_acc: 0.7333\n",
            "Epoch 227/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.2061 - acc: 0.7741 - val_loss: 0.2184 - val_acc: 0.7667\n",
            "Epoch 228/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.2061 - acc: 0.7778 - val_loss: 0.2181 - val_acc: 0.7667\n",
            "Epoch 229/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.2046 - acc: 0.7741 - val_loss: 0.2170 - val_acc: 0.7333\n",
            "Epoch 230/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2044 - acc: 0.7704 - val_loss: 0.2196 - val_acc: 0.7000\n",
            "Epoch 231/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.2051 - acc: 0.7852 - val_loss: 0.2179 - val_acc: 0.7000\n",
            "Epoch 232/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2044 - acc: 0.7889 - val_loss: 0.2161 - val_acc: 0.7333\n",
            "Epoch 233/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.2038 - acc: 0.7852 - val_loss: 0.2162 - val_acc: 0.7667\n",
            "Epoch 234/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.2034 - acc: 0.7667 - val_loss: 0.2162 - val_acc: 0.7000\n",
            "Epoch 235/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.2028 - acc: 0.7704 - val_loss: 0.2168 - val_acc: 0.7333\n",
            "Epoch 236/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.2030 - acc: 0.7852 - val_loss: 0.2158 - val_acc: 0.7333\n",
            "Epoch 237/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.2015 - acc: 0.7704 - val_loss: 0.2154 - val_acc: 0.7000\n",
            "Epoch 238/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.2011 - acc: 0.7852 - val_loss: 0.2122 - val_acc: 0.7333\n",
            "Epoch 239/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.2007 - acc: 0.7852 - val_loss: 0.2144 - val_acc: 0.7333\n",
            "Epoch 240/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.2010 - acc: 0.7852 - val_loss: 0.2114 - val_acc: 0.7667\n",
            "Epoch 241/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1991 - acc: 0.7667 - val_loss: 0.2129 - val_acc: 0.8000\n",
            "Epoch 242/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1993 - acc: 0.7852 - val_loss: 0.2104 - val_acc: 0.7000\n",
            "Epoch 243/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1999 - acc: 0.7741 - val_loss: 0.2122 - val_acc: 0.8000\n",
            "Epoch 244/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1986 - acc: 0.7778 - val_loss: 0.2107 - val_acc: 0.7000\n",
            "Epoch 245/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1982 - acc: 0.7741 - val_loss: 0.2099 - val_acc: 0.7333\n",
            "Epoch 246/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1983 - acc: 0.7741 - val_loss: 0.2142 - val_acc: 0.7333\n",
            "Epoch 247/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1976 - acc: 0.7778 - val_loss: 0.2076 - val_acc: 0.7000\n",
            "Epoch 248/800\n",
            "270/270 [==============================] - 0s 338us/step - loss: 0.1971 - acc: 0.7704 - val_loss: 0.2075 - val_acc: 0.7000\n",
            "Epoch 249/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1964 - acc: 0.7778 - val_loss: 0.2059 - val_acc: 0.7667\n",
            "Epoch 250/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1956 - acc: 0.7889 - val_loss: 0.2097 - val_acc: 0.7667\n",
            "Epoch 251/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1957 - acc: 0.7852 - val_loss: 0.2064 - val_acc: 0.7667\n",
            "Epoch 252/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1954 - acc: 0.7852 - val_loss: 0.2055 - val_acc: 0.7333\n",
            "Epoch 253/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1945 - acc: 0.7778 - val_loss: 0.2061 - val_acc: 0.7667\n",
            "Epoch 254/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1949 - acc: 0.7815 - val_loss: 0.2040 - val_acc: 0.7333\n",
            "Epoch 255/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1943 - acc: 0.7815 - val_loss: 0.2026 - val_acc: 0.7333\n",
            "Epoch 256/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1933 - acc: 0.7889 - val_loss: 0.2037 - val_acc: 0.7000\n",
            "Epoch 257/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1933 - acc: 0.7815 - val_loss: 0.2024 - val_acc: 0.7667\n",
            "Epoch 258/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1925 - acc: 0.7963 - val_loss: 0.2061 - val_acc: 0.7000\n",
            "Epoch 259/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1926 - acc: 0.7815 - val_loss: 0.2025 - val_acc: 0.7000\n",
            "Epoch 260/800\n",
            "270/270 [==============================] - 0s 329us/step - loss: 0.1912 - acc: 0.7778 - val_loss: 0.2026 - val_acc: 0.7333\n",
            "Epoch 261/800\n",
            "270/270 [==============================] - 0s 360us/step - loss: 0.1910 - acc: 0.7926 - val_loss: 0.2005 - val_acc: 0.7667\n",
            "Epoch 262/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1910 - acc: 0.7889 - val_loss: 0.1991 - val_acc: 0.7000\n",
            "Epoch 263/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1904 - acc: 0.7778 - val_loss: 0.2033 - val_acc: 0.7333\n",
            "Epoch 264/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1907 - acc: 0.7815 - val_loss: 0.1970 - val_acc: 0.7667\n",
            "Epoch 265/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1896 - acc: 0.7926 - val_loss: 0.1962 - val_acc: 0.7667\n",
            "Epoch 266/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1884 - acc: 0.8037 - val_loss: 0.1964 - val_acc: 0.7667\n",
            "Epoch 267/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1883 - acc: 0.7815 - val_loss: 0.1995 - val_acc: 0.7000\n",
            "Epoch 268/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1878 - acc: 0.7926 - val_loss: 0.1965 - val_acc: 0.7333\n",
            "Epoch 269/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1879 - acc: 0.7815 - val_loss: 0.1949 - val_acc: 0.7333\n",
            "Epoch 270/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1871 - acc: 0.7889 - val_loss: 0.1984 - val_acc: 0.7667\n",
            "Epoch 271/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1873 - acc: 0.7815 - val_loss: 0.1922 - val_acc: 0.7333\n",
            "Epoch 272/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1861 - acc: 0.7852 - val_loss: 0.1939 - val_acc: 0.7000\n",
            "Epoch 273/800\n",
            "270/270 [==============================] - 0s 348us/step - loss: 0.1856 - acc: 0.7815 - val_loss: 0.1933 - val_acc: 0.7000\n",
            "Epoch 274/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1860 - acc: 0.7741 - val_loss: 0.1927 - val_acc: 0.7000\n",
            "Epoch 275/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1851 - acc: 0.7889 - val_loss: 0.1990 - val_acc: 0.7667\n",
            "Epoch 276/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1848 - acc: 0.8074 - val_loss: 0.1922 - val_acc: 0.7667\n",
            "Epoch 277/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1841 - acc: 0.7963 - val_loss: 0.1907 - val_acc: 0.7333\n",
            "Epoch 278/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1834 - acc: 0.7926 - val_loss: 0.1897 - val_acc: 0.7333\n",
            "Epoch 279/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1828 - acc: 0.7926 - val_loss: 0.1894 - val_acc: 0.7333\n",
            "Epoch 280/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1823 - acc: 0.7926 - val_loss: 0.1895 - val_acc: 0.7333\n",
            "Epoch 281/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1826 - acc: 0.7963 - val_loss: 0.1881 - val_acc: 0.8000\n",
            "Epoch 282/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1823 - acc: 0.8111 - val_loss: 0.1892 - val_acc: 0.7000\n",
            "Epoch 283/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1817 - acc: 0.7926 - val_loss: 0.1877 - val_acc: 0.7000\n",
            "Epoch 284/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1813 - acc: 0.8000 - val_loss: 0.1882 - val_acc: 0.7000\n",
            "Epoch 285/800\n",
            "270/270 [==============================] - 0s 346us/step - loss: 0.1809 - acc: 0.7852 - val_loss: 0.1860 - val_acc: 0.7333\n",
            "Epoch 286/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1803 - acc: 0.7926 - val_loss: 0.1845 - val_acc: 0.7333\n",
            "Epoch 287/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1797 - acc: 0.7926 - val_loss: 0.1840 - val_acc: 0.7667\n",
            "Epoch 288/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1796 - acc: 0.7963 - val_loss: 0.1854 - val_acc: 0.8000\n",
            "Epoch 289/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1786 - acc: 0.7926 - val_loss: 0.1827 - val_acc: 0.7333\n",
            "Epoch 290/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1789 - acc: 0.7852 - val_loss: 0.1851 - val_acc: 0.7667\n",
            "Epoch 291/800\n",
            "270/270 [==============================] - 0s 325us/step - loss: 0.1784 - acc: 0.8111 - val_loss: 0.1890 - val_acc: 0.7000\n",
            "Epoch 292/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1783 - acc: 0.8000 - val_loss: 0.1822 - val_acc: 0.7333\n",
            "Epoch 293/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1771 - acc: 0.7926 - val_loss: 0.1819 - val_acc: 0.7333\n",
            "Epoch 294/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1774 - acc: 0.7852 - val_loss: 0.1812 - val_acc: 0.7333\n",
            "Epoch 295/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1766 - acc: 0.7889 - val_loss: 0.1794 - val_acc: 0.7667\n",
            "Epoch 296/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1758 - acc: 0.7852 - val_loss: 0.1806 - val_acc: 0.7667\n",
            "Epoch 297/800\n",
            "270/270 [==============================] - 0s 324us/step - loss: 0.1752 - acc: 0.7963 - val_loss: 0.1792 - val_acc: 0.7667\n",
            "Epoch 298/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1755 - acc: 0.7926 - val_loss: 0.1827 - val_acc: 0.7667\n",
            "Epoch 299/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1755 - acc: 0.8037 - val_loss: 0.1839 - val_acc: 0.8000\n",
            "Epoch 300/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1750 - acc: 0.8111 - val_loss: 0.1786 - val_acc: 0.7000\n",
            "Epoch 301/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1740 - acc: 0.7963 - val_loss: 0.1803 - val_acc: 0.7333\n",
            "Epoch 302/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1739 - acc: 0.8074 - val_loss: 0.1767 - val_acc: 0.7333\n",
            "Epoch 303/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1734 - acc: 0.7963 - val_loss: 0.1769 - val_acc: 0.7667\n",
            "Epoch 304/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1732 - acc: 0.7926 - val_loss: 0.1761 - val_acc: 0.7667\n",
            "Epoch 305/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1728 - acc: 0.7963 - val_loss: 0.1740 - val_acc: 0.7333\n",
            "Epoch 306/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1717 - acc: 0.8000 - val_loss: 0.1758 - val_acc: 0.8333\n",
            "Epoch 307/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1722 - acc: 0.8000 - val_loss: 0.1753 - val_acc: 0.7333\n",
            "Epoch 308/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1713 - acc: 0.7963 - val_loss: 0.1727 - val_acc: 0.7333\n",
            "Epoch 309/800\n",
            "270/270 [==============================] - 0s 371us/step - loss: 0.1709 - acc: 0.7889 - val_loss: 0.1820 - val_acc: 0.8000\n",
            "Epoch 310/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1719 - acc: 0.8074 - val_loss: 0.1727 - val_acc: 0.7667\n",
            "Epoch 311/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1697 - acc: 0.8037 - val_loss: 0.1770 - val_acc: 0.7667\n",
            "Epoch 312/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1706 - acc: 0.8037 - val_loss: 0.1732 - val_acc: 0.7333\n",
            "Epoch 313/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1695 - acc: 0.8037 - val_loss: 0.1703 - val_acc: 0.7667\n",
            "Epoch 314/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1689 - acc: 0.8000 - val_loss: 0.1696 - val_acc: 0.7333\n",
            "Epoch 315/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1686 - acc: 0.8000 - val_loss: 0.1690 - val_acc: 0.7333\n",
            "Epoch 316/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1684 - acc: 0.7926 - val_loss: 0.1696 - val_acc: 0.7667\n",
            "Epoch 317/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1683 - acc: 0.8000 - val_loss: 0.1697 - val_acc: 0.7333\n",
            "Epoch 318/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1669 - acc: 0.8000 - val_loss: 0.1684 - val_acc: 0.8000\n",
            "Epoch 319/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1667 - acc: 0.8148 - val_loss: 0.1684 - val_acc: 0.8333\n",
            "Epoch 320/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1662 - acc: 0.8111 - val_loss: 0.1690 - val_acc: 0.7000\n",
            "Epoch 321/800\n",
            "270/270 [==============================] - 0s 344us/step - loss: 0.1663 - acc: 0.7963 - val_loss: 0.1684 - val_acc: 0.8000\n",
            "Epoch 322/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1664 - acc: 0.7852 - val_loss: 0.1679 - val_acc: 0.8000\n",
            "Epoch 323/800\n",
            "270/270 [==============================] - 0s 274us/step - loss: 0.1663 - acc: 0.8074 - val_loss: 0.1685 - val_acc: 0.7333\n",
            "Epoch 324/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1657 - acc: 0.8000 - val_loss: 0.1664 - val_acc: 0.8000\n",
            "Epoch 325/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1649 - acc: 0.7963 - val_loss: 0.1660 - val_acc: 0.8333\n",
            "Epoch 326/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1652 - acc: 0.8074 - val_loss: 0.1646 - val_acc: 0.8000\n",
            "Epoch 327/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1640 - acc: 0.8074 - val_loss: 0.1647 - val_acc: 0.7667\n",
            "Epoch 328/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1634 - acc: 0.8000 - val_loss: 0.1648 - val_acc: 0.7333\n",
            "Epoch 329/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1637 - acc: 0.8185 - val_loss: 0.1667 - val_acc: 0.7667\n",
            "Epoch 330/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1631 - acc: 0.7852 - val_loss: 0.1659 - val_acc: 0.8667\n",
            "Epoch 331/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1626 - acc: 0.7963 - val_loss: 0.1624 - val_acc: 0.7667\n",
            "Epoch 332/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1620 - acc: 0.8074 - val_loss: 0.1617 - val_acc: 0.8667\n",
            "Epoch 333/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1621 - acc: 0.8037 - val_loss: 0.1610 - val_acc: 0.8000\n",
            "Epoch 334/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1615 - acc: 0.8074 - val_loss: 0.1600 - val_acc: 0.8000\n",
            "Epoch 335/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1612 - acc: 0.8074 - val_loss: 0.1607 - val_acc: 0.7667\n",
            "Epoch 336/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1613 - acc: 0.8037 - val_loss: 0.1601 - val_acc: 0.7667\n",
            "Epoch 337/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1604 - acc: 0.8111 - val_loss: 0.1622 - val_acc: 0.8333\n",
            "Epoch 338/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1602 - acc: 0.8148 - val_loss: 0.1588 - val_acc: 0.8000\n",
            "Epoch 339/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1601 - acc: 0.8000 - val_loss: 0.1638 - val_acc: 0.8333\n",
            "Epoch 340/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1602 - acc: 0.8037 - val_loss: 0.1575 - val_acc: 0.7667\n",
            "Epoch 341/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1593 - acc: 0.8111 - val_loss: 0.1578 - val_acc: 0.7333\n",
            "Epoch 342/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1598 - acc: 0.8148 - val_loss: 0.1579 - val_acc: 0.7333\n",
            "Epoch 343/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1596 - acc: 0.8111 - val_loss: 0.1567 - val_acc: 0.8000\n",
            "Epoch 344/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1578 - acc: 0.7963 - val_loss: 0.1600 - val_acc: 0.8333\n",
            "Epoch 345/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1581 - acc: 0.8111 - val_loss: 0.1577 - val_acc: 0.8000\n",
            "Epoch 346/800\n",
            "270/270 [==============================] - 0s 374us/step - loss: 0.1575 - acc: 0.8037 - val_loss: 0.1562 - val_acc: 0.8667\n",
            "Epoch 347/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1569 - acc: 0.7963 - val_loss: 0.1569 - val_acc: 0.7333\n",
            "Epoch 348/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1570 - acc: 0.7963 - val_loss: 0.1554 - val_acc: 0.8000\n",
            "Epoch 349/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1563 - acc: 0.8111 - val_loss: 0.1553 - val_acc: 0.8667\n",
            "Epoch 350/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1563 - acc: 0.8074 - val_loss: 0.1535 - val_acc: 0.7667\n",
            "Epoch 351/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1561 - acc: 0.8185 - val_loss: 0.1520 - val_acc: 0.8000\n",
            "Epoch 352/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1556 - acc: 0.8185 - val_loss: 0.1526 - val_acc: 0.8667\n",
            "Epoch 353/800\n",
            "270/270 [==============================] - 0s 322us/step - loss: 0.1548 - acc: 0.8148 - val_loss: 0.1520 - val_acc: 0.8000\n",
            "Epoch 354/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1542 - acc: 0.7963 - val_loss: 0.1502 - val_acc: 0.8667\n",
            "Epoch 355/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1547 - acc: 0.8037 - val_loss: 0.1507 - val_acc: 0.7667\n",
            "Epoch 356/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1540 - acc: 0.8111 - val_loss: 0.1493 - val_acc: 0.8333\n",
            "Epoch 357/800\n",
            "270/270 [==============================] - 0s 331us/step - loss: 0.1534 - acc: 0.8074 - val_loss: 0.1498 - val_acc: 0.7667\n",
            "Epoch 358/800\n",
            "270/270 [==============================] - 0s 336us/step - loss: 0.1536 - acc: 0.8037 - val_loss: 0.1486 - val_acc: 0.8667\n",
            "Epoch 359/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1528 - acc: 0.8148 - val_loss: 0.1494 - val_acc: 0.7667\n",
            "Epoch 360/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1531 - acc: 0.8074 - val_loss: 0.1492 - val_acc: 0.8667\n",
            "Epoch 361/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1521 - acc: 0.8037 - val_loss: 0.1508 - val_acc: 0.7333\n",
            "Epoch 362/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1521 - acc: 0.8148 - val_loss: 0.1488 - val_acc: 0.8667\n",
            "Epoch 363/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1517 - acc: 0.8148 - val_loss: 0.1509 - val_acc: 0.8667\n",
            "Epoch 364/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1529 - acc: 0.8074 - val_loss: 0.1471 - val_acc: 0.8667\n",
            "Epoch 365/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1518 - acc: 0.8037 - val_loss: 0.1478 - val_acc: 0.7333\n",
            "Epoch 366/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1510 - acc: 0.8185 - val_loss: 0.1469 - val_acc: 0.8000\n",
            "Epoch 367/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1508 - acc: 0.8000 - val_loss: 0.1453 - val_acc: 0.8000\n",
            "Epoch 368/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1501 - acc: 0.8111 - val_loss: 0.1516 - val_acc: 0.8667\n",
            "Epoch 369/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1509 - acc: 0.8037 - val_loss: 0.1451 - val_acc: 0.8667\n",
            "Epoch 370/800\n",
            "270/270 [==============================] - 0s 370us/step - loss: 0.1497 - acc: 0.8148 - val_loss: 0.1435 - val_acc: 0.8667\n",
            "Epoch 371/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1491 - acc: 0.8185 - val_loss: 0.1468 - val_acc: 0.8667\n",
            "Epoch 372/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1489 - acc: 0.8148 - val_loss: 0.1430 - val_acc: 0.8667\n",
            "Epoch 373/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1485 - acc: 0.8148 - val_loss: 0.1427 - val_acc: 0.8667\n",
            "Epoch 374/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1491 - acc: 0.8222 - val_loss: 0.1424 - val_acc: 0.8667\n",
            "Epoch 375/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1479 - acc: 0.8111 - val_loss: 0.1430 - val_acc: 0.8000\n",
            "Epoch 376/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1478 - acc: 0.8000 - val_loss: 0.1439 - val_acc: 0.8667\n",
            "Epoch 377/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1482 - acc: 0.8074 - val_loss: 0.1440 - val_acc: 0.8667\n",
            "Epoch 378/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1472 - acc: 0.8185 - val_loss: 0.1421 - val_acc: 0.8000\n",
            "Epoch 379/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1470 - acc: 0.8222 - val_loss: 0.1496 - val_acc: 0.8667\n",
            "Epoch 380/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1481 - acc: 0.8185 - val_loss: 0.1406 - val_acc: 0.8667\n",
            "Epoch 381/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1461 - acc: 0.8185 - val_loss: 0.1405 - val_acc: 0.7667\n",
            "Epoch 382/800\n",
            "270/270 [==============================] - 0s 331us/step - loss: 0.1459 - acc: 0.8037 - val_loss: 0.1412 - val_acc: 0.8333\n",
            "Epoch 383/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1458 - acc: 0.8074 - val_loss: 0.1397 - val_acc: 0.8667\n",
            "Epoch 384/800\n",
            "270/270 [==============================] - 0s 278us/step - loss: 0.1451 - acc: 0.8148 - val_loss: 0.1390 - val_acc: 0.8667\n",
            "Epoch 385/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1451 - acc: 0.8333 - val_loss: 0.1389 - val_acc: 0.8667\n",
            "Epoch 386/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1447 - acc: 0.8259 - val_loss: 0.1398 - val_acc: 0.8667\n",
            "Epoch 387/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1445 - acc: 0.8222 - val_loss: 0.1413 - val_acc: 0.8667\n",
            "Epoch 388/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1448 - acc: 0.8333 - val_loss: 0.1391 - val_acc: 0.8667\n",
            "Epoch 389/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1441 - acc: 0.8333 - val_loss: 0.1379 - val_acc: 0.8667\n",
            "Epoch 390/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1435 - acc: 0.8222 - val_loss: 0.1372 - val_acc: 0.8667\n",
            "Epoch 391/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1438 - acc: 0.8259 - val_loss: 0.1399 - val_acc: 0.8667\n",
            "Epoch 392/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1448 - acc: 0.8148 - val_loss: 0.1364 - val_acc: 0.8667\n",
            "Epoch 393/800\n",
            "270/270 [==============================] - 0s 278us/step - loss: 0.1429 - acc: 0.8185 - val_loss: 0.1377 - val_acc: 0.8667\n",
            "Epoch 394/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1427 - acc: 0.8111 - val_loss: 0.1388 - val_acc: 0.8667\n",
            "Epoch 395/800\n",
            "270/270 [==============================] - 0s 362us/step - loss: 0.1426 - acc: 0.8259 - val_loss: 0.1368 - val_acc: 0.8000\n",
            "Epoch 396/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1421 - acc: 0.8333 - val_loss: 0.1350 - val_acc: 0.8667\n",
            "Epoch 397/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1416 - acc: 0.8222 - val_loss: 0.1360 - val_acc: 0.8333\n",
            "Epoch 398/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1418 - acc: 0.8259 - val_loss: 0.1356 - val_acc: 0.8667\n",
            "Epoch 399/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1423 - acc: 0.8148 - val_loss: 0.1335 - val_acc: 0.8667\n",
            "Epoch 400/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1413 - acc: 0.8296 - val_loss: 0.1351 - val_acc: 0.8667\n",
            "Epoch 401/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1411 - acc: 0.8259 - val_loss: 0.1348 - val_acc: 0.8333\n",
            "Epoch 402/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1406 - acc: 0.8185 - val_loss: 0.1329 - val_acc: 0.8667\n",
            "Epoch 403/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1405 - acc: 0.8222 - val_loss: 0.1344 - val_acc: 0.8667\n",
            "Epoch 404/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1410 - acc: 0.8148 - val_loss: 0.1330 - val_acc: 0.8667\n",
            "Epoch 405/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1401 - acc: 0.8185 - val_loss: 0.1315 - val_acc: 0.8667\n",
            "Epoch 406/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1398 - acc: 0.8185 - val_loss: 0.1344 - val_acc: 0.8000\n",
            "Epoch 407/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1393 - acc: 0.8148 - val_loss: 0.1313 - val_acc: 0.8667\n",
            "Epoch 408/800\n",
            "270/270 [==============================] - 0s 367us/step - loss: 0.1393 - acc: 0.8259 - val_loss: 0.1344 - val_acc: 0.7667\n",
            "Epoch 409/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1391 - acc: 0.8148 - val_loss: 0.1298 - val_acc: 0.8667\n",
            "Epoch 410/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1387 - acc: 0.8222 - val_loss: 0.1322 - val_acc: 0.8000\n",
            "Epoch 411/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1384 - acc: 0.8148 - val_loss: 0.1294 - val_acc: 0.8667\n",
            "Epoch 412/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1378 - acc: 0.8259 - val_loss: 0.1303 - val_acc: 0.8333\n",
            "Epoch 413/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1381 - acc: 0.8222 - val_loss: 0.1288 - val_acc: 0.8667\n",
            "Epoch 414/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1379 - acc: 0.8185 - val_loss: 0.1349 - val_acc: 0.8000\n",
            "Epoch 415/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1382 - acc: 0.8148 - val_loss: 0.1347 - val_acc: 0.9000\n",
            "Epoch 416/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1387 - acc: 0.8370 - val_loss: 0.1304 - val_acc: 0.8667\n",
            "Epoch 417/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1372 - acc: 0.8407 - val_loss: 0.1313 - val_acc: 0.7667\n",
            "Epoch 418/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1371 - acc: 0.8185 - val_loss: 0.1276 - val_acc: 0.8667\n",
            "Epoch 419/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1364 - acc: 0.8185 - val_loss: 0.1266 - val_acc: 0.8667\n",
            "Epoch 420/800\n",
            "270/270 [==============================] - 0s 279us/step - loss: 0.1364 - acc: 0.8185 - val_loss: 0.1286 - val_acc: 0.8667\n",
            "Epoch 421/800\n",
            "270/270 [==============================] - 0s 346us/step - loss: 0.1361 - acc: 0.8222 - val_loss: 0.1317 - val_acc: 0.8333\n",
            "Epoch 422/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1361 - acc: 0.8074 - val_loss: 0.1314 - val_acc: 0.8333\n",
            "Epoch 423/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1364 - acc: 0.8185 - val_loss: 0.1273 - val_acc: 0.8667\n",
            "Epoch 424/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1354 - acc: 0.8333 - val_loss: 0.1260 - val_acc: 0.8333\n",
            "Epoch 425/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1347 - acc: 0.8111 - val_loss: 0.1253 - val_acc: 0.8667\n",
            "Epoch 426/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1346 - acc: 0.8259 - val_loss: 0.1248 - val_acc: 0.8667\n",
            "Epoch 427/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1348 - acc: 0.8185 - val_loss: 0.1250 - val_acc: 0.8667\n",
            "Epoch 428/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1347 - acc: 0.8333 - val_loss: 0.1257 - val_acc: 0.9000\n",
            "Epoch 429/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1343 - acc: 0.8259 - val_loss: 0.1249 - val_acc: 0.8667\n",
            "Epoch 430/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1338 - acc: 0.8148 - val_loss: 0.1250 - val_acc: 0.8667\n",
            "Epoch 431/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1341 - acc: 0.8296 - val_loss: 0.1244 - val_acc: 0.8667\n",
            "Epoch 432/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1340 - acc: 0.8370 - val_loss: 0.1254 - val_acc: 0.8667\n",
            "Epoch 433/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1338 - acc: 0.8185 - val_loss: 0.1236 - val_acc: 0.8667\n",
            "Epoch 434/800\n",
            "270/270 [==============================] - 0s 336us/step - loss: 0.1330 - acc: 0.8259 - val_loss: 0.1228 - val_acc: 0.8667\n",
            "Epoch 435/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1330 - acc: 0.8296 - val_loss: 0.1243 - val_acc: 0.8667\n",
            "Epoch 436/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1334 - acc: 0.8148 - val_loss: 0.1221 - val_acc: 0.8667\n",
            "Epoch 437/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1328 - acc: 0.8222 - val_loss: 0.1231 - val_acc: 0.8667\n",
            "Epoch 438/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1322 - acc: 0.8185 - val_loss: 0.1231 - val_acc: 0.8667\n",
            "Epoch 439/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1321 - acc: 0.8222 - val_loss: 0.1215 - val_acc: 0.8667\n",
            "Epoch 440/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1325 - acc: 0.8111 - val_loss: 0.1243 - val_acc: 0.9000\n",
            "Epoch 441/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1321 - acc: 0.8296 - val_loss: 0.1226 - val_acc: 0.8667\n",
            "Epoch 442/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1313 - acc: 0.8259 - val_loss: 0.1222 - val_acc: 0.9000\n",
            "Epoch 443/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1314 - acc: 0.8259 - val_loss: 0.1233 - val_acc: 0.8667\n",
            "Epoch 444/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1308 - acc: 0.8370 - val_loss: 0.1241 - val_acc: 0.8333\n",
            "Epoch 445/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1319 - acc: 0.8148 - val_loss: 0.1207 - val_acc: 0.8333\n",
            "Epoch 446/800\n",
            "270/270 [==============================] - 0s 322us/step - loss: 0.1318 - acc: 0.8259 - val_loss: 0.1201 - val_acc: 0.8667\n",
            "Epoch 447/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1304 - acc: 0.8222 - val_loss: 0.1226 - val_acc: 0.8333\n",
            "Epoch 448/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1310 - acc: 0.8333 - val_loss: 0.1199 - val_acc: 0.8667\n",
            "Epoch 449/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1309 - acc: 0.8148 - val_loss: 0.1204 - val_acc: 0.8667\n",
            "Epoch 450/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1308 - acc: 0.8259 - val_loss: 0.1210 - val_acc: 0.9000\n",
            "Epoch 451/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1300 - acc: 0.8185 - val_loss: 0.1239 - val_acc: 0.9000\n",
            "Epoch 452/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1304 - acc: 0.8222 - val_loss: 0.1202 - val_acc: 0.9000\n",
            "Epoch 453/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1294 - acc: 0.8333 - val_loss: 0.1199 - val_acc: 0.9000\n",
            "Epoch 454/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1292 - acc: 0.8370 - val_loss: 0.1184 - val_acc: 0.8667\n",
            "Epoch 455/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1291 - acc: 0.8370 - val_loss: 0.1171 - val_acc: 0.8667\n",
            "Epoch 456/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1290 - acc: 0.8296 - val_loss: 0.1174 - val_acc: 0.9000\n",
            "Epoch 457/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1286 - acc: 0.8259 - val_loss: 0.1172 - val_acc: 0.9000\n",
            "Epoch 458/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1289 - acc: 0.8333 - val_loss: 0.1193 - val_acc: 0.9000\n",
            "Epoch 459/800\n",
            "270/270 [==============================] - 0s 368us/step - loss: 0.1286 - acc: 0.8333 - val_loss: 0.1171 - val_acc: 0.8667\n",
            "Epoch 460/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1281 - acc: 0.8185 - val_loss: 0.1177 - val_acc: 0.9000\n",
            "Epoch 461/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1285 - acc: 0.8296 - val_loss: 0.1169 - val_acc: 0.8333\n",
            "Epoch 462/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1279 - acc: 0.8185 - val_loss: 0.1191 - val_acc: 0.9000\n",
            "Epoch 463/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1281 - acc: 0.8185 - val_loss: 0.1169 - val_acc: 0.8333\n",
            "Epoch 464/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1276 - acc: 0.8259 - val_loss: 0.1163 - val_acc: 0.9000\n",
            "Epoch 465/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1271 - acc: 0.8333 - val_loss: 0.1174 - val_acc: 0.9000\n",
            "Epoch 466/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1272 - acc: 0.8259 - val_loss: 0.1152 - val_acc: 0.9000\n",
            "Epoch 467/800\n",
            "270/270 [==============================] - 0s 325us/step - loss: 0.1269 - acc: 0.8296 - val_loss: 0.1181 - val_acc: 0.8667\n",
            "Epoch 468/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1275 - acc: 0.8370 - val_loss: 0.1163 - val_acc: 0.8667\n",
            "Epoch 469/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1273 - acc: 0.8407 - val_loss: 0.1158 - val_acc: 0.9000\n",
            "Epoch 470/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1266 - acc: 0.8333 - val_loss: 0.1155 - val_acc: 0.8667\n",
            "Epoch 471/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1265 - acc: 0.8370 - val_loss: 0.1160 - val_acc: 0.8333\n",
            "Epoch 472/800\n",
            "270/270 [==============================] - 0s 385us/step - loss: 0.1260 - acc: 0.8370 - val_loss: 0.1172 - val_acc: 0.8667\n",
            "Epoch 473/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1265 - acc: 0.8296 - val_loss: 0.1148 - val_acc: 0.8667\n",
            "Epoch 474/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1262 - acc: 0.8259 - val_loss: 0.1149 - val_acc: 0.8667\n",
            "Epoch 475/800\n",
            "270/270 [==============================] - 0s 325us/step - loss: 0.1257 - acc: 0.8259 - val_loss: 0.1161 - val_acc: 0.8333\n",
            "Epoch 476/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1254 - acc: 0.8333 - val_loss: 0.1169 - val_acc: 0.8667\n",
            "Epoch 477/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1256 - acc: 0.8296 - val_loss: 0.1144 - val_acc: 0.9000\n",
            "Epoch 478/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1252 - acc: 0.8296 - val_loss: 0.1142 - val_acc: 0.8667\n",
            "Epoch 479/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1253 - acc: 0.8185 - val_loss: 0.1173 - val_acc: 0.9000\n",
            "Epoch 480/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1250 - acc: 0.8407 - val_loss: 0.1124 - val_acc: 0.9000\n",
            "Epoch 481/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1247 - acc: 0.8259 - val_loss: 0.1143 - val_acc: 0.8667\n",
            "Epoch 482/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1245 - acc: 0.8296 - val_loss: 0.1117 - val_acc: 0.8667\n",
            "Epoch 483/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1247 - acc: 0.8259 - val_loss: 0.1128 - val_acc: 0.9000\n",
            "Epoch 484/800\n",
            "270/270 [==============================] - 0s 349us/step - loss: 0.1247 - acc: 0.8444 - val_loss: 0.1134 - val_acc: 0.8667\n",
            "Epoch 485/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1242 - acc: 0.8333 - val_loss: 0.1127 - val_acc: 0.9000\n",
            "Epoch 486/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1237 - acc: 0.8222 - val_loss: 0.1120 - val_acc: 0.9000\n",
            "Epoch 487/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1238 - acc: 0.8259 - val_loss: 0.1112 - val_acc: 0.9000\n",
            "Epoch 488/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1235 - acc: 0.8296 - val_loss: 0.1146 - val_acc: 0.8667\n",
            "Epoch 489/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1239 - acc: 0.8370 - val_loss: 0.1119 - val_acc: 0.9000\n",
            "Epoch 490/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1240 - acc: 0.8407 - val_loss: 0.1125 - val_acc: 0.8333\n",
            "Epoch 491/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1236 - acc: 0.8333 - val_loss: 0.1115 - val_acc: 0.9000\n",
            "Epoch 492/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1234 - acc: 0.8296 - val_loss: 0.1108 - val_acc: 0.9000\n",
            "Epoch 493/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1230 - acc: 0.8481 - val_loss: 0.1105 - val_acc: 0.9000\n",
            "Epoch 494/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1232 - acc: 0.8296 - val_loss: 0.1122 - val_acc: 0.9000\n",
            "Epoch 495/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1230 - acc: 0.8333 - val_loss: 0.1118 - val_acc: 0.8667\n",
            "Epoch 496/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1224 - acc: 0.8444 - val_loss: 0.1107 - val_acc: 0.9000\n",
            "Epoch 497/800\n",
            "270/270 [==============================] - 0s 346us/step - loss: 0.1228 - acc: 0.8370 - val_loss: 0.1102 - val_acc: 0.9000\n",
            "Epoch 498/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1226 - acc: 0.8370 - val_loss: 0.1115 - val_acc: 0.8667\n",
            "Epoch 499/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1222 - acc: 0.8333 - val_loss: 0.1102 - val_acc: 0.9000\n",
            "Epoch 500/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1222 - acc: 0.8407 - val_loss: 0.1116 - val_acc: 0.8333\n",
            "Epoch 501/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1221 - acc: 0.8333 - val_loss: 0.1104 - val_acc: 0.8667\n",
            "Epoch 502/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1215 - acc: 0.8370 - val_loss: 0.1118 - val_acc: 0.9000\n",
            "Epoch 503/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1219 - acc: 0.8407 - val_loss: 0.1096 - val_acc: 0.8667\n",
            "Epoch 504/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1213 - acc: 0.8444 - val_loss: 0.1096 - val_acc: 0.9000\n",
            "Epoch 505/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1220 - acc: 0.8407 - val_loss: 0.1087 - val_acc: 0.9000\n",
            "Epoch 506/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1210 - acc: 0.8370 - val_loss: 0.1148 - val_acc: 0.9000\n",
            "Epoch 507/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1222 - acc: 0.8407 - val_loss: 0.1086 - val_acc: 0.9000\n",
            "Epoch 508/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1209 - acc: 0.8519 - val_loss: 0.1084 - val_acc: 0.9000\n",
            "Epoch 509/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1211 - acc: 0.8370 - val_loss: 0.1115 - val_acc: 0.9000\n",
            "Epoch 510/800\n",
            "270/270 [==============================] - 0s 356us/step - loss: 0.1209 - acc: 0.8481 - val_loss: 0.1090 - val_acc: 0.9000\n",
            "Epoch 511/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1207 - acc: 0.8333 - val_loss: 0.1082 - val_acc: 0.9000\n",
            "Epoch 512/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1203 - acc: 0.8593 - val_loss: 0.1094 - val_acc: 0.8667\n",
            "Epoch 513/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1207 - acc: 0.8407 - val_loss: 0.1075 - val_acc: 0.9000\n",
            "Epoch 514/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1200 - acc: 0.8407 - val_loss: 0.1109 - val_acc: 0.9000\n",
            "Epoch 515/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1202 - acc: 0.8519 - val_loss: 0.1081 - val_acc: 0.9000\n",
            "Epoch 516/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1203 - acc: 0.8407 - val_loss: 0.1074 - val_acc: 0.9000\n",
            "Epoch 517/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1197 - acc: 0.8444 - val_loss: 0.1089 - val_acc: 0.8667\n",
            "Epoch 518/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1205 - acc: 0.8481 - val_loss: 0.1095 - val_acc: 0.8667\n",
            "Epoch 519/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1199 - acc: 0.8222 - val_loss: 0.1062 - val_acc: 0.8667\n",
            "Epoch 520/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1197 - acc: 0.8481 - val_loss: 0.1082 - val_acc: 0.9000\n",
            "Epoch 521/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1194 - acc: 0.8407 - val_loss: 0.1092 - val_acc: 0.9000\n",
            "Epoch 522/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1194 - acc: 0.8444 - val_loss: 0.1073 - val_acc: 0.8667\n",
            "Epoch 523/800\n",
            "270/270 [==============================] - 0s 359us/step - loss: 0.1191 - acc: 0.8481 - val_loss: 0.1072 - val_acc: 0.9000\n",
            "Epoch 524/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1198 - acc: 0.8370 - val_loss: 0.1061 - val_acc: 0.8667\n",
            "Epoch 525/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1190 - acc: 0.8444 - val_loss: 0.1058 - val_acc: 0.9000\n",
            "Epoch 526/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1189 - acc: 0.8333 - val_loss: 0.1060 - val_acc: 0.9000\n",
            "Epoch 527/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1192 - acc: 0.8556 - val_loss: 0.1061 - val_acc: 0.9000\n",
            "Epoch 528/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1187 - acc: 0.8444 - val_loss: 0.1065 - val_acc: 0.9000\n",
            "Epoch 529/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1190 - acc: 0.8444 - val_loss: 0.1055 - val_acc: 0.9000\n",
            "Epoch 530/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1185 - acc: 0.8407 - val_loss: 0.1057 - val_acc: 0.9000\n",
            "Epoch 531/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1182 - acc: 0.8444 - val_loss: 0.1061 - val_acc: 0.9000\n",
            "Epoch 532/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1185 - acc: 0.8407 - val_loss: 0.1054 - val_acc: 0.9000\n",
            "Epoch 533/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1181 - acc: 0.8407 - val_loss: 0.1064 - val_acc: 0.9000\n",
            "Epoch 534/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1183 - acc: 0.8481 - val_loss: 0.1051 - val_acc: 0.9000\n",
            "Epoch 535/800\n",
            "270/270 [==============================] - 0s 346us/step - loss: 0.1187 - acc: 0.8444 - val_loss: 0.1054 - val_acc: 0.9000\n",
            "Epoch 536/800\n",
            "270/270 [==============================] - 0s 335us/step - loss: 0.1175 - acc: 0.8556 - val_loss: 0.1112 - val_acc: 0.9000\n",
            "Epoch 537/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1186 - acc: 0.8519 - val_loss: 0.1083 - val_acc: 0.9000\n",
            "Epoch 538/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1178 - acc: 0.8407 - val_loss: 0.1060 - val_acc: 0.9000\n",
            "Epoch 539/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1175 - acc: 0.8444 - val_loss: 0.1040 - val_acc: 0.9000\n",
            "Epoch 540/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1175 - acc: 0.8481 - val_loss: 0.1074 - val_acc: 0.9000\n",
            "Epoch 541/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1176 - acc: 0.8481 - val_loss: 0.1044 - val_acc: 0.9000\n",
            "Epoch 542/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1178 - acc: 0.8593 - val_loss: 0.1059 - val_acc: 0.9000\n",
            "Epoch 543/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1175 - acc: 0.8519 - val_loss: 0.1059 - val_acc: 0.9000\n",
            "Epoch 544/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1179 - acc: 0.8407 - val_loss: 0.1040 - val_acc: 0.9000\n",
            "Epoch 545/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1168 - acc: 0.8630 - val_loss: 0.1052 - val_acc: 0.9000\n",
            "Epoch 546/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1171 - acc: 0.8370 - val_loss: 0.1050 - val_acc: 0.8667\n",
            "Epoch 547/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1169 - acc: 0.8519 - val_loss: 0.1031 - val_acc: 0.9000\n",
            "Epoch 548/800\n",
            "270/270 [==============================] - 0s 348us/step - loss: 0.1162 - acc: 0.8407 - val_loss: 0.1048 - val_acc: 0.8667\n",
            "Epoch 549/800\n",
            "270/270 [==============================] - 0s 337us/step - loss: 0.1171 - acc: 0.8481 - val_loss: 0.1042 - val_acc: 0.8667\n",
            "Epoch 550/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1163 - acc: 0.8630 - val_loss: 0.1049 - val_acc: 0.9000\n",
            "Epoch 551/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1165 - acc: 0.8407 - val_loss: 0.1051 - val_acc: 0.8667\n",
            "Epoch 552/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1161 - acc: 0.8556 - val_loss: 0.1062 - val_acc: 0.9000\n",
            "Epoch 553/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1162 - acc: 0.8519 - val_loss: 0.1025 - val_acc: 0.9000\n",
            "Epoch 554/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1161 - acc: 0.8407 - val_loss: 0.1044 - val_acc: 0.8667\n",
            "Epoch 555/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1164 - acc: 0.8333 - val_loss: 0.1035 - val_acc: 0.9000\n",
            "Epoch 556/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1160 - acc: 0.8556 - val_loss: 0.1035 - val_acc: 0.9000\n",
            "Epoch 557/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1155 - acc: 0.8370 - val_loss: 0.1038 - val_acc: 0.9000\n",
            "Epoch 558/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1155 - acc: 0.8519 - val_loss: 0.1039 - val_acc: 0.9000\n",
            "Epoch 559/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1156 - acc: 0.8593 - val_loss: 0.1024 - val_acc: 0.9000\n",
            "Epoch 560/800\n",
            "270/270 [==============================] - 0s 322us/step - loss: 0.1156 - acc: 0.8556 - val_loss: 0.1041 - val_acc: 0.9000\n",
            "Epoch 561/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1161 - acc: 0.8444 - val_loss: 0.1012 - val_acc: 0.9000\n",
            "Epoch 562/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1152 - acc: 0.8593 - val_loss: 0.1017 - val_acc: 0.8667\n",
            "Epoch 563/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1157 - acc: 0.8481 - val_loss: 0.1064 - val_acc: 0.8667\n",
            "Epoch 564/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1157 - acc: 0.8481 - val_loss: 0.1016 - val_acc: 0.9000\n",
            "Epoch 565/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1154 - acc: 0.8593 - val_loss: 0.1045 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00565: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 566/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1150 - acc: 0.8704 - val_loss: 0.1009 - val_acc: 0.9000\n",
            "Epoch 567/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1143 - acc: 0.8444 - val_loss: 0.1013 - val_acc: 0.9000\n",
            "Epoch 568/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1143 - acc: 0.8519 - val_loss: 0.1011 - val_acc: 0.9000\n",
            "Epoch 569/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1143 - acc: 0.8444 - val_loss: 0.1010 - val_acc: 0.9000\n",
            "Epoch 570/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1142 - acc: 0.8630 - val_loss: 0.1009 - val_acc: 0.9000\n",
            "Epoch 571/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1143 - acc: 0.8519 - val_loss: 0.1008 - val_acc: 0.9000\n",
            "Epoch 572/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1142 - acc: 0.8630 - val_loss: 0.1006 - val_acc: 0.9000\n",
            "Epoch 573/800\n",
            "270/270 [==============================] - 0s 368us/step - loss: 0.1142 - acc: 0.8556 - val_loss: 0.1007 - val_acc: 0.9000\n",
            "Epoch 574/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1142 - acc: 0.8630 - val_loss: 0.1010 - val_acc: 0.9000\n",
            "Epoch 575/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1142 - acc: 0.8519 - val_loss: 0.1013 - val_acc: 0.9000\n",
            "Epoch 576/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1142 - acc: 0.8444 - val_loss: 0.1012 - val_acc: 0.9000\n",
            "Epoch 577/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1141 - acc: 0.8519 - val_loss: 0.1008 - val_acc: 0.9000\n",
            "Epoch 578/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1142 - acc: 0.8593 - val_loss: 0.1009 - val_acc: 0.9000\n",
            "Epoch 579/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1142 - acc: 0.8556 - val_loss: 0.1011 - val_acc: 0.9000\n",
            "Epoch 580/800\n",
            "270/270 [==============================] - 0s 279us/step - loss: 0.1141 - acc: 0.8481 - val_loss: 0.1008 - val_acc: 0.9000\n",
            "Epoch 581/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1140 - acc: 0.8593 - val_loss: 0.1008 - val_acc: 0.9000\n",
            "Epoch 582/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1140 - acc: 0.8556 - val_loss: 0.1010 - val_acc: 0.9000\n",
            "Epoch 583/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1140 - acc: 0.8519 - val_loss: 0.1006 - val_acc: 0.9000\n",
            "Epoch 584/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1140 - acc: 0.8593 - val_loss: 0.1008 - val_acc: 0.9000\n",
            "Epoch 585/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1140 - acc: 0.8556 - val_loss: 0.1007 - val_acc: 0.9000\n",
            "Epoch 586/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1140 - acc: 0.8593 - val_loss: 0.1005 - val_acc: 0.9000\n",
            "Epoch 587/800\n",
            "270/270 [==============================] - 0s 376us/step - loss: 0.1139 - acc: 0.8519 - val_loss: 0.1007 - val_acc: 0.9000\n",
            "Epoch 588/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1140 - acc: 0.8593 - val_loss: 0.1008 - val_acc: 0.9000\n",
            "Epoch 589/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1139 - acc: 0.8519 - val_loss: 0.1007 - val_acc: 0.9000\n",
            "Epoch 590/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1140 - acc: 0.8667 - val_loss: 0.1007 - val_acc: 0.9000\n",
            "Epoch 591/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1139 - acc: 0.8519 - val_loss: 0.1003 - val_acc: 0.9000\n",
            "Epoch 592/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1139 - acc: 0.8519 - val_loss: 0.1005 - val_acc: 0.9000\n",
            "Epoch 593/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1139 - acc: 0.8556 - val_loss: 0.1005 - val_acc: 0.9000\n",
            "Epoch 594/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1138 - acc: 0.8667 - val_loss: 0.1006 - val_acc: 0.9000\n",
            "Epoch 595/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1138 - acc: 0.8593 - val_loss: 0.1007 - val_acc: 0.9000\n",
            "Epoch 596/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1138 - acc: 0.8630 - val_loss: 0.1004 - val_acc: 0.9000\n",
            "Epoch 597/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1138 - acc: 0.8519 - val_loss: 0.1004 - val_acc: 0.9000\n",
            "Epoch 598/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1137 - acc: 0.8593 - val_loss: 0.1005 - val_acc: 0.9000\n",
            "Epoch 599/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1138 - acc: 0.8444 - val_loss: 0.1004 - val_acc: 0.9000\n",
            "Epoch 600/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1138 - acc: 0.8556 - val_loss: 0.1004 - val_acc: 0.9000\n",
            "Epoch 601/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1137 - acc: 0.8630 - val_loss: 0.1003 - val_acc: 0.9000\n",
            "Epoch 602/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1137 - acc: 0.8481 - val_loss: 0.1002 - val_acc: 0.9000\n",
            "Epoch 603/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1138 - acc: 0.8667 - val_loss: 0.1003 - val_acc: 0.9000\n",
            "Epoch 604/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1136 - acc: 0.8519 - val_loss: 0.1004 - val_acc: 0.9000\n",
            "Epoch 605/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1136 - acc: 0.8630 - val_loss: 0.1003 - val_acc: 0.9000\n",
            "Epoch 606/800\n",
            "270/270 [==============================] - 0s 278us/step - loss: 0.1136 - acc: 0.8667 - val_loss: 0.1004 - val_acc: 0.9000\n",
            "Epoch 607/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1136 - acc: 0.8519 - val_loss: 0.1002 - val_acc: 0.9000\n",
            "Epoch 608/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1136 - acc: 0.8630 - val_loss: 0.1004 - val_acc: 0.9000\n",
            "Epoch 609/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1136 - acc: 0.8556 - val_loss: 0.1002 - val_acc: 0.9000\n",
            "Epoch 610/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1136 - acc: 0.8630 - val_loss: 0.1002 - val_acc: 0.9000\n",
            "Epoch 611/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1136 - acc: 0.8667 - val_loss: 0.1006 - val_acc: 0.9000\n",
            "Epoch 612/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1137 - acc: 0.8519 - val_loss: 0.1004 - val_acc: 0.9000\n",
            "Epoch 613/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.8556 - val_loss: 0.1001 - val_acc: 0.9000\n",
            "Epoch 614/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1135 - acc: 0.8667 - val_loss: 0.1002 - val_acc: 0.9000\n",
            "Epoch 615/800\n",
            "270/270 [==============================] - 0s 350us/step - loss: 0.1135 - acc: 0.8593 - val_loss: 0.1004 - val_acc: 0.9000\n",
            "Epoch 616/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1135 - acc: 0.8481 - val_loss: 0.1003 - val_acc: 0.9000\n",
            "Epoch 617/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1134 - acc: 0.8556 - val_loss: 0.1000 - val_acc: 0.9000\n",
            "Epoch 618/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1134 - acc: 0.8630 - val_loss: 0.1002 - val_acc: 0.9000\n",
            "Epoch 619/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1134 - acc: 0.8593 - val_loss: 0.1001 - val_acc: 0.9000\n",
            "Epoch 620/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.8556 - val_loss: 0.0999 - val_acc: 0.9000\n",
            "Epoch 621/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1134 - acc: 0.8593 - val_loss: 0.0998 - val_acc: 0.9000\n",
            "Epoch 622/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1133 - acc: 0.8630 - val_loss: 0.1002 - val_acc: 0.9000\n",
            "Epoch 623/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1133 - acc: 0.8630 - val_loss: 0.1000 - val_acc: 0.9000\n",
            "Epoch 624/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1134 - acc: 0.8667 - val_loss: 0.0999 - val_acc: 0.9000\n",
            "Epoch 625/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1133 - acc: 0.8519 - val_loss: 0.1002 - val_acc: 0.9000\n",
            "Epoch 626/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1133 - acc: 0.8519 - val_loss: 0.0999 - val_acc: 0.9000\n",
            "Epoch 627/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1133 - acc: 0.8667 - val_loss: 0.1000 - val_acc: 0.9000\n",
            "Epoch 628/800\n",
            "270/270 [==============================] - 0s 348us/step - loss: 0.1133 - acc: 0.8667 - val_loss: 0.0999 - val_acc: 0.9000\n",
            "Epoch 629/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1133 - acc: 0.8519 - val_loss: 0.0997 - val_acc: 0.9000\n",
            "Epoch 630/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1133 - acc: 0.8481 - val_loss: 0.0997 - val_acc: 0.9000\n",
            "Epoch 631/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1132 - acc: 0.8556 - val_loss: 0.0998 - val_acc: 0.9000\n",
            "Epoch 632/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1132 - acc: 0.8556 - val_loss: 0.0999 - val_acc: 0.9000\n",
            "Epoch 633/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1132 - acc: 0.8630 - val_loss: 0.0996 - val_acc: 0.9000\n",
            "Epoch 634/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1132 - acc: 0.8667 - val_loss: 0.0998 - val_acc: 0.9000\n",
            "Epoch 635/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1132 - acc: 0.8519 - val_loss: 0.0999 - val_acc: 0.9000\n",
            "Epoch 636/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1131 - acc: 0.8593 - val_loss: 0.0997 - val_acc: 0.9000\n",
            "Epoch 637/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1131 - acc: 0.8593 - val_loss: 0.0997 - val_acc: 0.9000\n",
            "Epoch 638/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1130 - acc: 0.8667 - val_loss: 0.0999 - val_acc: 0.9000\n",
            "Epoch 639/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1131 - acc: 0.8519 - val_loss: 0.0996 - val_acc: 0.9000\n",
            "Epoch 640/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1131 - acc: 0.8630 - val_loss: 0.0993 - val_acc: 0.9000\n",
            "Epoch 641/800\n",
            "270/270 [==============================] - 0s 377us/step - loss: 0.1131 - acc: 0.8556 - val_loss: 0.0997 - val_acc: 0.9000\n",
            "Epoch 642/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1130 - acc: 0.8630 - val_loss: 0.0997 - val_acc: 0.9000\n",
            "Epoch 643/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1130 - acc: 0.8593 - val_loss: 0.0998 - val_acc: 0.9000\n",
            "Epoch 644/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1131 - acc: 0.8481 - val_loss: 0.0997 - val_acc: 0.9000\n",
            "Epoch 645/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1130 - acc: 0.8519 - val_loss: 0.0996 - val_acc: 0.9000\n",
            "Epoch 646/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1130 - acc: 0.8630 - val_loss: 0.0995 - val_acc: 0.9000\n",
            "Epoch 647/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1130 - acc: 0.8519 - val_loss: 0.0994 - val_acc: 0.9000\n",
            "Epoch 648/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1129 - acc: 0.8556 - val_loss: 0.0995 - val_acc: 0.9000\n",
            "Epoch 649/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1129 - acc: 0.8556 - val_loss: 0.0994 - val_acc: 0.9000\n",
            "Epoch 650/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1130 - acc: 0.8593 - val_loss: 0.0994 - val_acc: 0.9000\n",
            "Epoch 651/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1128 - acc: 0.8556 - val_loss: 0.0996 - val_acc: 0.9000\n",
            "Epoch 652/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1128 - acc: 0.8593 - val_loss: 0.0995 - val_acc: 0.9000\n",
            "Epoch 653/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1128 - acc: 0.8556 - val_loss: 0.0991 - val_acc: 0.9000\n",
            "Epoch 654/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1128 - acc: 0.8481 - val_loss: 0.0994 - val_acc: 0.9000\n",
            "Epoch 655/800\n",
            "270/270 [==============================] - 0s 367us/step - loss: 0.1128 - acc: 0.8667 - val_loss: 0.0995 - val_acc: 0.9000\n",
            "Epoch 656/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1127 - acc: 0.8519 - val_loss: 0.0994 - val_acc: 0.9000\n",
            "Epoch 657/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1128 - acc: 0.8519 - val_loss: 0.0994 - val_acc: 0.9000\n",
            "Epoch 658/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1128 - acc: 0.8593 - val_loss: 0.0994 - val_acc: 0.9000\n",
            "Epoch 659/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1128 - acc: 0.8593 - val_loss: 0.0992 - val_acc: 0.9000\n",
            "Epoch 660/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1127 - acc: 0.8630 - val_loss: 0.0993 - val_acc: 0.9000\n",
            "Epoch 661/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1127 - acc: 0.8519 - val_loss: 0.0994 - val_acc: 0.9000\n",
            "Epoch 662/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1127 - acc: 0.8519 - val_loss: 0.0993 - val_acc: 0.9000\n",
            "Epoch 663/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1127 - acc: 0.8704 - val_loss: 0.0990 - val_acc: 0.9000\n",
            "Epoch 664/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1126 - acc: 0.8630 - val_loss: 0.0994 - val_acc: 0.9000\n",
            "Epoch 665/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1127 - acc: 0.8519 - val_loss: 0.0991 - val_acc: 0.9000\n",
            "Epoch 666/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1127 - acc: 0.8630 - val_loss: 0.0991 - val_acc: 0.9000\n",
            "Epoch 667/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1126 - acc: 0.8593 - val_loss: 0.0990 - val_acc: 0.9000\n",
            "Epoch 668/800\n",
            "270/270 [==============================] - 0s 326us/step - loss: 0.1126 - acc: 0.8556 - val_loss: 0.0990 - val_acc: 0.9000\n",
            "Epoch 669/800\n",
            "270/270 [==============================] - 0s 329us/step - loss: 0.1126 - acc: 0.8630 - val_loss: 0.0990 - val_acc: 0.9000\n",
            "Epoch 670/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1126 - acc: 0.8556 - val_loss: 0.0991 - val_acc: 0.9000\n",
            "Epoch 671/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1126 - acc: 0.8630 - val_loss: 0.0989 - val_acc: 0.9000\n",
            "Epoch 672/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1125 - acc: 0.8630 - val_loss: 0.0991 - val_acc: 0.9000\n",
            "Epoch 673/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1125 - acc: 0.8630 - val_loss: 0.0992 - val_acc: 0.9000\n",
            "Epoch 674/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1124 - acc: 0.8667 - val_loss: 0.0991 - val_acc: 0.9000\n",
            "Epoch 675/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1125 - acc: 0.8519 - val_loss: 0.0992 - val_acc: 0.9000\n",
            "Epoch 676/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1125 - acc: 0.8667 - val_loss: 0.0989 - val_acc: 0.9000\n",
            "Epoch 677/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1125 - acc: 0.8667 - val_loss: 0.0993 - val_acc: 0.9000\n",
            "Epoch 678/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1124 - acc: 0.8444 - val_loss: 0.0989 - val_acc: 0.9000\n",
            "Epoch 679/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1125 - acc: 0.8630 - val_loss: 0.0986 - val_acc: 0.9000\n",
            "Epoch 680/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1124 - acc: 0.8481 - val_loss: 0.0988 - val_acc: 0.9000\n",
            "Epoch 681/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1125 - acc: 0.8704 - val_loss: 0.0984 - val_acc: 0.9000\n",
            "Epoch 682/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1124 - acc: 0.8667 - val_loss: 0.0989 - val_acc: 0.9000\n",
            "Epoch 683/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1123 - acc: 0.8593 - val_loss: 0.0989 - val_acc: 0.9000\n",
            "Epoch 684/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1123 - acc: 0.8593 - val_loss: 0.0988 - val_acc: 0.9000\n",
            "Epoch 685/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1123 - acc: 0.8630 - val_loss: 0.0987 - val_acc: 0.9000\n",
            "Epoch 686/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1123 - acc: 0.8556 - val_loss: 0.0988 - val_acc: 0.9000\n",
            "Epoch 687/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1123 - acc: 0.8593 - val_loss: 0.0987 - val_acc: 0.9000\n",
            "Epoch 688/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1123 - acc: 0.8630 - val_loss: 0.0989 - val_acc: 0.9000\n",
            "Epoch 689/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1122 - acc: 0.8593 - val_loss: 0.0987 - val_acc: 0.9000\n",
            "Epoch 690/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1122 - acc: 0.8630 - val_loss: 0.0984 - val_acc: 0.9000\n",
            "Epoch 691/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1122 - acc: 0.8556 - val_loss: 0.0985 - val_acc: 0.9000\n",
            "Epoch 692/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1122 - acc: 0.8704 - val_loss: 0.0987 - val_acc: 0.9000\n",
            "Epoch 693/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1122 - acc: 0.8556 - val_loss: 0.0984 - val_acc: 0.9000\n",
            "Epoch 694/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1122 - acc: 0.8667 - val_loss: 0.0984 - val_acc: 0.9000\n",
            "Epoch 695/800\n",
            "270/270 [==============================] - 0s 355us/step - loss: 0.1121 - acc: 0.8556 - val_loss: 0.0985 - val_acc: 0.9000\n",
            "Epoch 696/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1122 - acc: 0.8704 - val_loss: 0.0987 - val_acc: 0.9000\n",
            "Epoch 697/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1121 - acc: 0.8630 - val_loss: 0.0988 - val_acc: 0.9000\n",
            "Epoch 698/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1120 - acc: 0.8630 - val_loss: 0.0985 - val_acc: 0.9000\n",
            "Epoch 699/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1121 - acc: 0.8667 - val_loss: 0.0987 - val_acc: 0.9000\n",
            "Epoch 700/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1121 - acc: 0.8556 - val_loss: 0.0985 - val_acc: 0.9000\n",
            "Epoch 701/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1121 - acc: 0.8667 - val_loss: 0.0986 - val_acc: 0.9000\n",
            "Epoch 702/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1120 - acc: 0.8593 - val_loss: 0.0988 - val_acc: 0.9000\n",
            "Epoch 703/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1120 - acc: 0.8593 - val_loss: 0.0985 - val_acc: 0.9000\n",
            "Epoch 704/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1120 - acc: 0.8593 - val_loss: 0.0985 - val_acc: 0.9000\n",
            "Epoch 705/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1119 - acc: 0.8593 - val_loss: 0.0984 - val_acc: 0.9000\n",
            "Epoch 706/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1120 - acc: 0.8630 - val_loss: 0.0986 - val_acc: 0.9000\n",
            "Epoch 707/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1119 - acc: 0.8556 - val_loss: 0.0985 - val_acc: 0.9000\n",
            "Epoch 708/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1119 - acc: 0.8593 - val_loss: 0.0984 - val_acc: 0.9000\n",
            "Epoch 709/800\n",
            "270/270 [==============================] - 0s 363us/step - loss: 0.1119 - acc: 0.8704 - val_loss: 0.0985 - val_acc: 0.9000\n",
            "Epoch 710/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1118 - acc: 0.8556 - val_loss: 0.0985 - val_acc: 0.9000\n",
            "Epoch 711/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1119 - acc: 0.8556 - val_loss: 0.0983 - val_acc: 0.9000\n",
            "Epoch 712/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1119 - acc: 0.8630 - val_loss: 0.0984 - val_acc: 0.9000\n",
            "Epoch 713/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1118 - acc: 0.8630 - val_loss: 0.0984 - val_acc: 0.9000\n",
            "Epoch 714/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1117 - acc: 0.8593 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 715/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1118 - acc: 0.8667 - val_loss: 0.0983 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00715: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 716/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1117 - acc: 0.8630 - val_loss: 0.0983 - val_acc: 0.9000\n",
            "Epoch 717/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1117 - acc: 0.8593 - val_loss: 0.0983 - val_acc: 0.9000\n",
            "Epoch 718/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0982 - val_acc: 0.9000\n",
            "Epoch 719/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 720/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1116 - acc: 0.8593 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 721/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1116 - acc: 0.8593 - val_loss: 0.0982 - val_acc: 0.9000\n",
            "Epoch 722/800\n",
            "270/270 [==============================] - 0s 350us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0982 - val_acc: 0.9000\n",
            "Epoch 723/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0982 - val_acc: 0.9000\n",
            "Epoch 724/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1116 - acc: 0.8667 - val_loss: 0.0982 - val_acc: 0.9000\n",
            "Epoch 725/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1116 - acc: 0.8593 - val_loss: 0.0982 - val_acc: 0.9000\n",
            "Epoch 726/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1116 - acc: 0.8593 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 727/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0982 - val_acc: 0.9000\n",
            "Epoch 728/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 729/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0982 - val_acc: 0.9000\n",
            "Epoch 730/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0982 - val_acc: 0.9000\n",
            "Epoch 731/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0982 - val_acc: 0.9000\n",
            "Epoch 732/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0982 - val_acc: 0.9000\n",
            "Epoch 733/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 734/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1115 - acc: 0.8593 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 735/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 736/800\n",
            "270/270 [==============================] - 0s 347us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 737/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 738/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 739/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 740/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 741/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1115 - acc: 0.8593 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 742/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1115 - acc: 0.8593 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 743/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1116 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 744/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 745/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1115 - acc: 0.8593 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 746/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1115 - acc: 0.8593 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 747/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 748/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 749/800\n",
            "270/270 [==============================] - 0s 328us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 750/800\n",
            "270/270 [==============================] - 0s 335us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 751/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1115 - acc: 0.8593 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 752/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 753/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 754/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 755/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 756/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 757/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 758/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 759/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 760/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 761/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 762/800\n",
            "270/270 [==============================] - 0s 341us/step - loss: 0.1115 - acc: 0.8593 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 763/800\n",
            "270/270 [==============================] - 0s 324us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 764/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 765/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 766/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 767/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 768/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 769/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 770/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 771/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 772/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0978 - val_acc: 0.9000\n",
            "Epoch 773/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 774/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1115 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 775/800\n",
            "270/270 [==============================] - 0s 368us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 776/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 777/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 778/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1114 - acc: 0.8593 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 779/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1114 - acc: 0.8593 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 780/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 781/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 782/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0978 - val_acc: 0.9000\n",
            "Epoch 783/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 784/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1113 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 785/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 786/800\n",
            "270/270 [==============================] - 0s 327us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0978 - val_acc: 0.9000\n",
            "Epoch 787/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 788/800\n",
            "270/270 [==============================] - 0s 337us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0978 - val_acc: 0.9000\n",
            "Epoch 789/800\n",
            "270/270 [==============================] - 0s 331us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0978 - val_acc: 0.9000\n",
            "Epoch 790/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 791/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1113 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 792/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 793/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1114 - acc: 0.8593 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 794/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 795/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1113 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 796/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1113 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 797/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1114 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 798/800\n",
            "270/270 [==============================] - 0s 276us/step - loss: 0.1113 - acc: 0.8630 - val_loss: 0.0979 - val_acc: 0.9000\n",
            "Epoch 799/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1113 - acc: 0.8593 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "Epoch 800/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1113 - acc: 0.8593 - val_loss: 0.0980 - val_acc: 0.9000\n",
            "300/300 [==============================] - 0s 94us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[2.7949571959177653, 0.2600000000993411]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "u1doUpdStDAB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27977
        },
        "outputId": "3bdd7005-f36c-4261-a9f9-5aa8c35a03b7"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Results with one sample of anomily every 40 samples\n",
        "full_anom = 0\n",
        "anom_samples = 1\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,min_lr=1e-6,min_delta=0.0001,\n",
        "                              patience=200,verbose = 1)\n",
        "# history = autoencoder.fit(x_train2, x_train2,\n",
        "#                     epochs=nb_epoch,\n",
        "#                     batch_size=batch_size,\n",
        "#                     #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "#                     validation_split=.1,\n",
        "#                     verbose=1,callbacks=[reduce_lr])\n",
        "\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
        "                               verbose=0,\n",
        "                               save_best_only=True)\n",
        "tensorboard = TensorBoard(log_dir='./logs',\n",
        "                          histogram_freq=0,\n",
        "                          write_graph=True,\n",
        "                          write_images=True)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2, x_test2),\n",
        "                    validation_split=.1,\n",
        "                    shuffle=True,\n",
        "                    verbose=1,callbacks=[reduce_lr, checkpointer, tensorboard]).history \n",
        "\n",
        "score = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 270 samples, validate on 30 samples\n",
            "Epoch 1/800\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1190 - acc: 0.8593 - val_loss: 0.2570 - val_acc: 0.7333\n",
            "Epoch 2/800\n",
            "270/270 [==============================] - 0s 368us/step - loss: 0.1193 - acc: 0.8741 - val_loss: 0.2485 - val_acc: 0.7333\n",
            "Epoch 3/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1179 - acc: 0.8778 - val_loss: 0.2439 - val_acc: 0.7000\n",
            "Epoch 4/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1168 - acc: 0.8778 - val_loss: 0.2383 - val_acc: 0.6333\n",
            "Epoch 5/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1174 - acc: 0.8778 - val_loss: 0.2422 - val_acc: 0.7000\n",
            "Epoch 6/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1174 - acc: 0.8704 - val_loss: 0.2596 - val_acc: 0.7333\n",
            "Epoch 7/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1184 - acc: 0.8778 - val_loss: 0.2508 - val_acc: 0.7000\n",
            "Epoch 8/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1213 - acc: 0.8593 - val_loss: 0.2487 - val_acc: 0.7667\n",
            "Epoch 9/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1166 - acc: 0.8889 - val_loss: 0.2441 - val_acc: 0.7333\n",
            "Epoch 10/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1167 - acc: 0.8778 - val_loss: 0.2424 - val_acc: 0.6667\n",
            "Epoch 11/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1192 - acc: 0.8704 - val_loss: 0.2453 - val_acc: 0.7667\n",
            "Epoch 12/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1162 - acc: 0.8926 - val_loss: 0.2439 - val_acc: 0.7667\n",
            "Epoch 13/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1159 - acc: 0.8889 - val_loss: 0.2470 - val_acc: 0.7667\n",
            "Epoch 14/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1161 - acc: 0.8889 - val_loss: 0.2449 - val_acc: 0.7000\n",
            "Epoch 15/800\n",
            "270/270 [==============================] - 0s 341us/step - loss: 0.1179 - acc: 0.8889 - val_loss: 0.2440 - val_acc: 0.7000\n",
            "Epoch 16/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1172 - acc: 0.8889 - val_loss: 0.2456 - val_acc: 0.7667\n",
            "Epoch 17/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1163 - acc: 0.8926 - val_loss: 0.2469 - val_acc: 0.7667\n",
            "Epoch 18/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1167 - acc: 0.8704 - val_loss: 0.2462 - val_acc: 0.7333\n",
            "Epoch 19/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1161 - acc: 0.8926 - val_loss: 0.2454 - val_acc: 0.8000\n",
            "Epoch 20/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1161 - acc: 0.8815 - val_loss: 0.2530 - val_acc: 0.7333\n",
            "Epoch 21/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1157 - acc: 0.8815 - val_loss: 0.2456 - val_acc: 0.7333\n",
            "Epoch 22/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1169 - acc: 0.8852 - val_loss: 0.2468 - val_acc: 0.7333\n",
            "Epoch 23/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1170 - acc: 0.8704 - val_loss: 0.2533 - val_acc: 0.7333\n",
            "Epoch 24/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1181 - acc: 0.8593 - val_loss: 0.2409 - val_acc: 0.7000\n",
            "Epoch 25/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1178 - acc: 0.8778 - val_loss: 0.2433 - val_acc: 0.7667\n",
            "Epoch 26/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1155 - acc: 0.8704 - val_loss: 0.2476 - val_acc: 0.7667\n",
            "Epoch 27/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1155 - acc: 0.8815 - val_loss: 0.2523 - val_acc: 0.7000\n",
            "Epoch 28/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1164 - acc: 0.8926 - val_loss: 0.2452 - val_acc: 0.7667\n",
            "Epoch 29/800\n",
            "270/270 [==============================] - 0s 362us/step - loss: 0.1157 - acc: 0.8889 - val_loss: 0.2474 - val_acc: 0.7333\n",
            "Epoch 30/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1163 - acc: 0.8889 - val_loss: 0.2457 - val_acc: 0.7000\n",
            "Epoch 31/800\n",
            "270/270 [==============================] - 0s 325us/step - loss: 0.1161 - acc: 0.8926 - val_loss: 0.2517 - val_acc: 0.7333\n",
            "Epoch 32/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1161 - acc: 0.8852 - val_loss: 0.2416 - val_acc: 0.7333\n",
            "Epoch 33/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1156 - acc: 0.8778 - val_loss: 0.2427 - val_acc: 0.7333\n",
            "Epoch 34/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1161 - acc: 0.8815 - val_loss: 0.2449 - val_acc: 0.7333\n",
            "Epoch 35/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1193 - acc: 0.8815 - val_loss: 0.2422 - val_acc: 0.7333\n",
            "Epoch 36/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1154 - acc: 0.8741 - val_loss: 0.2463 - val_acc: 0.7667\n",
            "Epoch 37/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1156 - acc: 0.8889 - val_loss: 0.2434 - val_acc: 0.7333\n",
            "Epoch 38/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1146 - acc: 0.8889 - val_loss: 0.2476 - val_acc: 0.7667\n",
            "Epoch 39/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1151 - acc: 0.8741 - val_loss: 0.2478 - val_acc: 0.7333\n",
            "Epoch 40/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1154 - acc: 0.8852 - val_loss: 0.2546 - val_acc: 0.7667\n",
            "Epoch 41/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1149 - acc: 0.8852 - val_loss: 0.2500 - val_acc: 0.7667\n",
            "Epoch 42/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1150 - acc: 0.8926 - val_loss: 0.2412 - val_acc: 0.7333\n",
            "Epoch 43/800\n",
            "270/270 [==============================] - 0s 361us/step - loss: 0.1152 - acc: 0.8926 - val_loss: 0.2475 - val_acc: 0.7667\n",
            "Epoch 44/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1141 - acc: 0.8815 - val_loss: 0.2474 - val_acc: 0.7667\n",
            "Epoch 45/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1151 - acc: 0.8926 - val_loss: 0.2559 - val_acc: 0.7333\n",
            "Epoch 46/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1191 - acc: 0.8778 - val_loss: 0.2498 - val_acc: 0.7000\n",
            "Epoch 47/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1156 - acc: 0.8778 - val_loss: 0.2530 - val_acc: 0.7667\n",
            "Epoch 48/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1148 - acc: 0.8926 - val_loss: 0.2467 - val_acc: 0.7667\n",
            "Epoch 49/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1141 - acc: 0.8926 - val_loss: 0.2491 - val_acc: 0.7667\n",
            "Epoch 50/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1157 - acc: 0.8852 - val_loss: 0.2576 - val_acc: 0.7667\n",
            "Epoch 51/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1166 - acc: 0.8889 - val_loss: 0.2476 - val_acc: 0.7333\n",
            "Epoch 52/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1149 - acc: 0.8741 - val_loss: 0.2487 - val_acc: 0.7667\n",
            "Epoch 53/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1155 - acc: 0.8667 - val_loss: 0.2413 - val_acc: 0.7667\n",
            "Epoch 54/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1141 - acc: 0.8926 - val_loss: 0.2429 - val_acc: 0.7667\n",
            "Epoch 55/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1140 - acc: 0.8815 - val_loss: 0.2424 - val_acc: 0.7333\n",
            "Epoch 56/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1151 - acc: 0.8741 - val_loss: 0.2483 - val_acc: 0.7667\n",
            "Epoch 57/800\n",
            "270/270 [==============================] - 0s 363us/step - loss: 0.1137 - acc: 0.8815 - val_loss: 0.2393 - val_acc: 0.7000\n",
            "Epoch 58/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1136 - acc: 0.8852 - val_loss: 0.2471 - val_acc: 0.7333\n",
            "Epoch 59/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1135 - acc: 0.8852 - val_loss: 0.2418 - val_acc: 0.7000\n",
            "Epoch 60/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1136 - acc: 0.8926 - val_loss: 0.2429 - val_acc: 0.6667\n",
            "Epoch 61/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1210 - acc: 0.8593 - val_loss: 0.2424 - val_acc: 0.7333\n",
            "Epoch 62/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1148 - acc: 0.8926 - val_loss: 0.2487 - val_acc: 0.7333\n",
            "Epoch 63/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1139 - acc: 0.8815 - val_loss: 0.2437 - val_acc: 0.7667\n",
            "Epoch 64/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1133 - acc: 0.8778 - val_loss: 0.2414 - val_acc: 0.7333\n",
            "Epoch 65/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1136 - acc: 0.8926 - val_loss: 0.2431 - val_acc: 0.7667\n",
            "Epoch 66/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1133 - acc: 0.9074 - val_loss: 0.2358 - val_acc: 0.7333\n",
            "Epoch 67/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1138 - acc: 0.8741 - val_loss: 0.2485 - val_acc: 0.7333\n",
            "Epoch 68/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1134 - acc: 0.8852 - val_loss: 0.2440 - val_acc: 0.8000\n",
            "Epoch 69/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1139 - acc: 0.8926 - val_loss: 0.2437 - val_acc: 0.7667\n",
            "Epoch 70/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1133 - acc: 0.8926 - val_loss: 0.2436 - val_acc: 0.7667\n",
            "Epoch 71/800\n",
            "270/270 [==============================] - 0s 362us/step - loss: 0.1160 - acc: 0.8667 - val_loss: 0.2447 - val_acc: 0.7667\n",
            "Epoch 72/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1134 - acc: 0.8963 - val_loss: 0.2370 - val_acc: 0.7333\n",
            "Epoch 73/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1137 - acc: 0.8815 - val_loss: 0.2483 - val_acc: 0.7333\n",
            "Epoch 74/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1141 - acc: 0.8852 - val_loss: 0.2471 - val_acc: 0.7333\n",
            "Epoch 75/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1148 - acc: 0.8963 - val_loss: 0.2447 - val_acc: 0.7667\n",
            "Epoch 76/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1136 - acc: 0.8889 - val_loss: 0.2442 - val_acc: 0.7333\n",
            "Epoch 77/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1131 - acc: 0.8852 - val_loss: 0.2437 - val_acc: 0.7667\n",
            "Epoch 78/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1130 - acc: 0.8852 - val_loss: 0.2600 - val_acc: 0.7667\n",
            "Epoch 79/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1150 - acc: 0.8852 - val_loss: 0.2426 - val_acc: 0.7333\n",
            "Epoch 80/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1136 - acc: 0.8926 - val_loss: 0.2490 - val_acc: 0.7667\n",
            "Epoch 81/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1128 - acc: 0.8815 - val_loss: 0.2453 - val_acc: 0.7667\n",
            "Epoch 82/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1126 - acc: 0.8889 - val_loss: 0.2420 - val_acc: 0.7667\n",
            "Epoch 83/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1125 - acc: 0.8963 - val_loss: 0.2398 - val_acc: 0.7333\n",
            "Epoch 84/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1134 - acc: 0.8852 - val_loss: 0.2408 - val_acc: 0.7333\n",
            "Epoch 85/800\n",
            "270/270 [==============================] - 0s 355us/step - loss: 0.1128 - acc: 0.8889 - val_loss: 0.2417 - val_acc: 0.7333\n",
            "Epoch 86/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1146 - acc: 0.8852 - val_loss: 0.2435 - val_acc: 0.7333\n",
            "Epoch 87/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1136 - acc: 0.8852 - val_loss: 0.2423 - val_acc: 0.7000\n",
            "Epoch 88/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1124 - acc: 0.8926 - val_loss: 0.2454 - val_acc: 0.7667\n",
            "Epoch 89/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1127 - acc: 0.9000 - val_loss: 0.2438 - val_acc: 0.7667\n",
            "Epoch 90/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1130 - acc: 0.8852 - val_loss: 0.2449 - val_acc: 0.7667\n",
            "Epoch 91/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1125 - acc: 0.8963 - val_loss: 0.2428 - val_acc: 0.8000\n",
            "Epoch 92/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1124 - acc: 0.8815 - val_loss: 0.2424 - val_acc: 0.7667\n",
            "Epoch 93/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1129 - acc: 0.8963 - val_loss: 0.2393 - val_acc: 0.7667\n",
            "Epoch 94/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1124 - acc: 0.8815 - val_loss: 0.2441 - val_acc: 0.7667\n",
            "Epoch 95/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1118 - acc: 0.8852 - val_loss: 0.2441 - val_acc: 0.7667\n",
            "Epoch 96/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1127 - acc: 0.8889 - val_loss: 0.2406 - val_acc: 0.7333\n",
            "Epoch 97/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1120 - acc: 0.8852 - val_loss: 0.2401 - val_acc: 0.7667\n",
            "Epoch 98/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1120 - acc: 0.8852 - val_loss: 0.2437 - val_acc: 0.7333\n",
            "Epoch 99/800\n",
            "270/270 [==============================] - 0s 340us/step - loss: 0.1128 - acc: 0.8926 - val_loss: 0.2406 - val_acc: 0.7000\n",
            "Epoch 100/800\n",
            "270/270 [==============================] - 0s 341us/step - loss: 0.1118 - acc: 0.8778 - val_loss: 0.2386 - val_acc: 0.7000\n",
            "Epoch 101/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1125 - acc: 0.8963 - val_loss: 0.2671 - val_acc: 0.7333\n",
            "Epoch 102/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1143 - acc: 0.8704 - val_loss: 0.2402 - val_acc: 0.7667\n",
            "Epoch 103/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1120 - acc: 0.8926 - val_loss: 0.2432 - val_acc: 0.7333\n",
            "Epoch 104/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1117 - acc: 0.9074 - val_loss: 0.2410 - val_acc: 0.7667\n",
            "Epoch 105/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1118 - acc: 0.8852 - val_loss: 0.2458 - val_acc: 0.7667\n",
            "Epoch 106/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1119 - acc: 0.8852 - val_loss: 0.2430 - val_acc: 0.7667\n",
            "Epoch 107/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1120 - acc: 0.8852 - val_loss: 0.2405 - val_acc: 0.7667\n",
            "Epoch 108/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1116 - acc: 0.9000 - val_loss: 0.2421 - val_acc: 0.7000\n",
            "Epoch 109/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1117 - acc: 0.8889 - val_loss: 0.2376 - val_acc: 0.7000\n",
            "Epoch 110/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1116 - acc: 0.8815 - val_loss: 0.2436 - val_acc: 0.6667\n",
            "Epoch 111/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1128 - acc: 0.8889 - val_loss: 0.2413 - val_acc: 0.7667\n",
            "Epoch 112/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1114 - acc: 0.8889 - val_loss: 0.2433 - val_acc: 0.7333\n",
            "Epoch 113/800\n",
            "270/270 [==============================] - 0s 333us/step - loss: 0.1151 - acc: 0.8815 - val_loss: 0.2476 - val_acc: 0.7333\n",
            "Epoch 114/800\n",
            "270/270 [==============================] - 0s 341us/step - loss: 0.1130 - acc: 0.8889 - val_loss: 0.2421 - val_acc: 0.7667\n",
            "Epoch 115/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1113 - acc: 0.8852 - val_loss: 0.2458 - val_acc: 0.7333\n",
            "Epoch 116/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1116 - acc: 0.9037 - val_loss: 0.2427 - val_acc: 0.7667\n",
            "Epoch 117/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1114 - acc: 0.8815 - val_loss: 0.2398 - val_acc: 0.7667\n",
            "Epoch 118/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1113 - acc: 0.8963 - val_loss: 0.2506 - val_acc: 0.7667\n",
            "Epoch 119/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1114 - acc: 0.8926 - val_loss: 0.2493 - val_acc: 0.7333\n",
            "Epoch 120/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1117 - acc: 0.8926 - val_loss: 0.2413 - val_acc: 0.7667\n",
            "Epoch 121/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1111 - acc: 0.8963 - val_loss: 0.2386 - val_acc: 0.7667\n",
            "Epoch 122/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1110 - acc: 0.8778 - val_loss: 0.2466 - val_acc: 0.7667\n",
            "Epoch 123/800\n",
            "270/270 [==============================] - 0s 322us/step - loss: 0.1115 - acc: 0.9074 - val_loss: 0.2447 - val_acc: 0.8000\n",
            "Epoch 124/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1119 - acc: 0.8852 - val_loss: 0.2395 - val_acc: 0.7333\n",
            "Epoch 125/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1110 - acc: 0.8852 - val_loss: 0.2426 - val_acc: 0.7667\n",
            "Epoch 126/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1109 - acc: 0.8778 - val_loss: 0.2435 - val_acc: 0.7667\n",
            "Epoch 127/800\n",
            "270/270 [==============================] - 0s 350us/step - loss: 0.1109 - acc: 0.8963 - val_loss: 0.2451 - val_acc: 0.7333\n",
            "Epoch 128/800\n",
            "270/270 [==============================] - 0s 328us/step - loss: 0.1119 - acc: 0.8963 - val_loss: 0.2451 - val_acc: 0.7667\n",
            "Epoch 129/800\n",
            "270/270 [==============================] - 0s 325us/step - loss: 0.1129 - acc: 0.8630 - val_loss: 0.2396 - val_acc: 0.7667\n",
            "Epoch 130/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1105 - acc: 0.8963 - val_loss: 0.2373 - val_acc: 0.7667\n",
            "Epoch 131/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1108 - acc: 0.9000 - val_loss: 0.2392 - val_acc: 0.7667\n",
            "Epoch 132/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1106 - acc: 0.8926 - val_loss: 0.2390 - val_acc: 0.7333\n",
            "Epoch 133/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1105 - acc: 0.9000 - val_loss: 0.2430 - val_acc: 0.7667\n",
            "Epoch 134/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1109 - acc: 0.8889 - val_loss: 0.2462 - val_acc: 0.7667\n",
            "Epoch 135/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1106 - acc: 0.8926 - val_loss: 0.2320 - val_acc: 0.7000\n",
            "Epoch 136/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1109 - acc: 0.8889 - val_loss: 0.2352 - val_acc: 0.7000\n",
            "Epoch 137/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1141 - acc: 0.8889 - val_loss: 0.2382 - val_acc: 0.7667\n",
            "Epoch 138/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1101 - acc: 0.8889 - val_loss: 0.2412 - val_acc: 0.7333\n",
            "Epoch 139/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1108 - acc: 0.8926 - val_loss: 0.2375 - val_acc: 0.7333\n",
            "Epoch 140/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1105 - acc: 0.8889 - val_loss: 0.2404 - val_acc: 0.7667\n",
            "Epoch 141/800\n",
            "270/270 [==============================] - 0s 362us/step - loss: 0.1100 - acc: 0.8963 - val_loss: 0.2415 - val_acc: 0.7333\n",
            "Epoch 142/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1116 - acc: 0.8778 - val_loss: 0.2408 - val_acc: 0.7667\n",
            "Epoch 143/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1107 - acc: 0.8815 - val_loss: 0.2433 - val_acc: 0.7667\n",
            "Epoch 144/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1098 - acc: 0.8926 - val_loss: 0.2402 - val_acc: 0.7667\n",
            "Epoch 145/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1104 - acc: 0.8815 - val_loss: 0.2367 - val_acc: 0.7000\n",
            "Epoch 146/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1113 - acc: 0.8963 - val_loss: 0.2412 - val_acc: 0.7333\n",
            "Epoch 147/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1098 - acc: 0.8889 - val_loss: 0.2397 - val_acc: 0.7667\n",
            "Epoch 148/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1096 - acc: 0.8889 - val_loss: 0.2362 - val_acc: 0.7667\n",
            "Epoch 149/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1106 - acc: 0.8889 - val_loss: 0.2433 - val_acc: 0.7667\n",
            "Epoch 150/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1096 - acc: 0.8926 - val_loss: 0.2406 - val_acc: 0.7333\n",
            "Epoch 151/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1099 - acc: 0.9000 - val_loss: 0.2375 - val_acc: 0.7333\n",
            "Epoch 152/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1112 - acc: 0.8889 - val_loss: 0.2374 - val_acc: 0.8000\n",
            "Epoch 153/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1093 - acc: 0.9037 - val_loss: 0.2365 - val_acc: 0.7333\n",
            "Epoch 154/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1098 - acc: 0.8815 - val_loss: 0.2417 - val_acc: 0.8000\n",
            "Epoch 155/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1100 - acc: 0.8852 - val_loss: 0.2423 - val_acc: 0.8000\n",
            "Epoch 156/800\n",
            "270/270 [==============================] - 0s 356us/step - loss: 0.1094 - acc: 0.8926 - val_loss: 0.2360 - val_acc: 0.7667\n",
            "Epoch 157/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1092 - acc: 0.9037 - val_loss: 0.2412 - val_acc: 0.7667\n",
            "Epoch 158/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1096 - acc: 0.8889 - val_loss: 0.2384 - val_acc: 0.7667\n",
            "Epoch 159/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1095 - acc: 0.8852 - val_loss: 0.2411 - val_acc: 0.7667\n",
            "Epoch 160/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1100 - acc: 0.8926 - val_loss: 0.2382 - val_acc: 0.7667\n",
            "Epoch 161/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1102 - acc: 0.8889 - val_loss: 0.2418 - val_acc: 0.7667\n",
            "Epoch 162/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1107 - acc: 0.9000 - val_loss: 0.2362 - val_acc: 0.7667\n",
            "Epoch 163/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1095 - acc: 0.8889 - val_loss: 0.2374 - val_acc: 0.7667\n",
            "Epoch 164/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1090 - acc: 0.8926 - val_loss: 0.2391 - val_acc: 0.7333\n",
            "Epoch 165/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1094 - acc: 0.9037 - val_loss: 0.2374 - val_acc: 0.6667\n",
            "Epoch 166/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1100 - acc: 0.8852 - val_loss: 0.2388 - val_acc: 0.7333\n",
            "Epoch 167/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1093 - acc: 0.8963 - val_loss: 0.2370 - val_acc: 0.7333\n",
            "Epoch 168/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1104 - acc: 0.8778 - val_loss: 0.2372 - val_acc: 0.7333\n",
            "Epoch 169/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1091 - acc: 0.8963 - val_loss: 0.2374 - val_acc: 0.7667\n",
            "Epoch 170/800\n",
            "270/270 [==============================] - 0s 339us/step - loss: 0.1090 - acc: 0.8963 - val_loss: 0.2356 - val_acc: 0.7333\n",
            "Epoch 171/800\n",
            "270/270 [==============================] - 0s 323us/step - loss: 0.1095 - acc: 0.9000 - val_loss: 0.2375 - val_acc: 0.7333\n",
            "Epoch 172/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1089 - acc: 0.8963 - val_loss: 0.2398 - val_acc: 0.7667\n",
            "Epoch 173/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1095 - acc: 0.8889 - val_loss: 0.2402 - val_acc: 0.7333\n",
            "Epoch 174/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1087 - acc: 0.8963 - val_loss: 0.2416 - val_acc: 0.8000\n",
            "Epoch 175/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1089 - acc: 0.8889 - val_loss: 0.2365 - val_acc: 0.7667\n",
            "Epoch 176/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1088 - acc: 0.8926 - val_loss: 0.2348 - val_acc: 0.7333\n",
            "Epoch 177/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1084 - acc: 0.9000 - val_loss: 0.2395 - val_acc: 0.7333\n",
            "Epoch 178/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1088 - acc: 0.8963 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 179/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1098 - acc: 0.8852 - val_loss: 0.2404 - val_acc: 0.7333\n",
            "Epoch 180/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1091 - acc: 0.8926 - val_loss: 0.2338 - val_acc: 0.7667\n",
            "Epoch 181/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1083 - acc: 0.8963 - val_loss: 0.2396 - val_acc: 0.7667\n",
            "Epoch 182/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1089 - acc: 0.8963 - val_loss: 0.2383 - val_acc: 0.7667\n",
            "Epoch 183/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1082 - acc: 0.9000 - val_loss: 0.2331 - val_acc: 0.7667\n",
            "Epoch 184/800\n",
            "270/270 [==============================] - 0s 327us/step - loss: 0.1104 - acc: 0.8852 - val_loss: 0.2363 - val_acc: 0.7667\n",
            "Epoch 185/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1079 - acc: 0.9074 - val_loss: 0.2387 - val_acc: 0.7667\n",
            "Epoch 186/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1085 - acc: 0.8963 - val_loss: 0.2377 - val_acc: 0.7667\n",
            "Epoch 187/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1086 - acc: 0.8963 - val_loss: 0.2374 - val_acc: 0.7667\n",
            "Epoch 188/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1088 - acc: 0.8815 - val_loss: 0.2411 - val_acc: 0.7667\n",
            "Epoch 189/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1079 - acc: 0.9037 - val_loss: 0.2457 - val_acc: 0.7333\n",
            "Epoch 190/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1086 - acc: 0.8926 - val_loss: 0.2445 - val_acc: 0.7333\n",
            "Epoch 191/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1080 - acc: 0.8963 - val_loss: 0.2368 - val_acc: 0.7667\n",
            "Epoch 192/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1083 - acc: 0.8889 - val_loss: 0.2439 - val_acc: 0.7667\n",
            "Epoch 193/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1082 - acc: 0.9000 - val_loss: 0.2364 - val_acc: 0.7667\n",
            "Epoch 194/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1081 - acc: 0.9074 - val_loss: 0.2393 - val_acc: 0.7667\n",
            "Epoch 195/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1079 - acc: 0.9037 - val_loss: 0.2343 - val_acc: 0.7667\n",
            "Epoch 196/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1077 - acc: 0.9037 - val_loss: 0.2384 - val_acc: 0.7667\n",
            "Epoch 197/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1082 - acc: 0.9037 - val_loss: 0.2410 - val_acc: 0.8000\n",
            "Epoch 198/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1083 - acc: 0.8852 - val_loss: 0.2406 - val_acc: 0.7667\n",
            "Epoch 199/800\n",
            "270/270 [==============================] - 0s 360us/step - loss: 0.1080 - acc: 0.8852 - val_loss: 0.2325 - val_acc: 0.7333\n",
            "Epoch 200/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1079 - acc: 0.8926 - val_loss: 0.2390 - val_acc: 0.7667\n",
            "Epoch 201/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1087 - acc: 0.8963 - val_loss: 0.2421 - val_acc: 0.7333\n",
            "Epoch 202/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1085 - acc: 0.8815 - val_loss: 0.2399 - val_acc: 0.7667\n",
            "Epoch 203/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1077 - acc: 0.9037 - val_loss: 0.2393 - val_acc: 0.7333\n",
            "Epoch 204/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1080 - acc: 0.8963 - val_loss: 0.2427 - val_acc: 0.7667\n",
            "Epoch 205/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1077 - acc: 0.8852 - val_loss: 0.2332 - val_acc: 0.7000\n",
            "Epoch 206/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1080 - acc: 0.9074 - val_loss: 0.2327 - val_acc: 0.7333\n",
            "Epoch 207/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1074 - acc: 0.9074 - val_loss: 0.2353 - val_acc: 0.7333\n",
            "Epoch 208/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1079 - acc: 0.8963 - val_loss: 0.2364 - val_acc: 0.7667\n",
            "Epoch 209/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1077 - acc: 0.9000 - val_loss: 0.2348 - val_acc: 0.7000\n",
            "Epoch 210/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1075 - acc: 0.8963 - val_loss: 0.2387 - val_acc: 0.7667\n",
            "Epoch 211/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1080 - acc: 0.8963 - val_loss: 0.2305 - val_acc: 0.7667\n",
            "Epoch 212/800\n",
            "270/270 [==============================] - 0s 322us/step - loss: 0.1086 - acc: 0.9037 - val_loss: 0.2403 - val_acc: 0.7667\n",
            "Epoch 213/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1075 - acc: 0.8889 - val_loss: 0.2288 - val_acc: 0.7000\n",
            "Epoch 214/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1076 - acc: 0.9000 - val_loss: 0.2377 - val_acc: 0.7667\n",
            "Epoch 215/800\n",
            "270/270 [==============================] - 0s 327us/step - loss: 0.1071 - acc: 0.9074 - val_loss: 0.2317 - val_acc: 0.7333\n",
            "Epoch 216/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1072 - acc: 0.8963 - val_loss: 0.2394 - val_acc: 0.7667\n",
            "Epoch 217/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1076 - acc: 0.8963 - val_loss: 0.2419 - val_acc: 0.7667\n",
            "Epoch 218/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1076 - acc: 0.9037 - val_loss: 0.2359 - val_acc: 0.7333\n",
            "Epoch 219/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1075 - acc: 0.9074 - val_loss: 0.2359 - val_acc: 0.7667\n",
            "\n",
            "Epoch 00219: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 220/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1065 - acc: 0.9111 - val_loss: 0.2342 - val_acc: 0.7667\n",
            "Epoch 221/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1063 - acc: 0.8963 - val_loss: 0.2346 - val_acc: 0.7667\n",
            "Epoch 222/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1063 - acc: 0.9037 - val_loss: 0.2344 - val_acc: 0.7667\n",
            "Epoch 223/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1063 - acc: 0.8963 - val_loss: 0.2349 - val_acc: 0.7667\n",
            "Epoch 224/800\n",
            "270/270 [==============================] - 0s 370us/step - loss: 0.1063 - acc: 0.9037 - val_loss: 0.2342 - val_acc: 0.7667\n",
            "Epoch 225/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1063 - acc: 0.9037 - val_loss: 0.2336 - val_acc: 0.7667\n",
            "Epoch 226/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1063 - acc: 0.9037 - val_loss: 0.2346 - val_acc: 0.7667\n",
            "Epoch 227/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1063 - acc: 0.9037 - val_loss: 0.2346 - val_acc: 0.7667\n",
            "Epoch 228/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1063 - acc: 0.9000 - val_loss: 0.2340 - val_acc: 0.7667\n",
            "Epoch 229/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1063 - acc: 0.9037 - val_loss: 0.2341 - val_acc: 0.7667\n",
            "Epoch 230/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1063 - acc: 0.9037 - val_loss: 0.2343 - val_acc: 0.7667\n",
            "Epoch 231/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1062 - acc: 0.9037 - val_loss: 0.2338 - val_acc: 0.7667\n",
            "Epoch 232/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1062 - acc: 0.9037 - val_loss: 0.2347 - val_acc: 0.7667\n",
            "Epoch 233/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1063 - acc: 0.9037 - val_loss: 0.2339 - val_acc: 0.7667\n",
            "Epoch 234/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1062 - acc: 0.9037 - val_loss: 0.2340 - val_acc: 0.7667\n",
            "Epoch 235/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1062 - acc: 0.9037 - val_loss: 0.2326 - val_acc: 0.7667\n",
            "Epoch 236/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1062 - acc: 0.9000 - val_loss: 0.2338 - val_acc: 0.7667\n",
            "Epoch 237/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1062 - acc: 0.9037 - val_loss: 0.2345 - val_acc: 0.7667\n",
            "Epoch 238/800\n",
            "270/270 [==============================] - 0s 352us/step - loss: 0.1062 - acc: 0.9074 - val_loss: 0.2335 - val_acc: 0.7667\n",
            "Epoch 239/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1062 - acc: 0.9037 - val_loss: 0.2349 - val_acc: 0.7667\n",
            "Epoch 240/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1062 - acc: 0.9074 - val_loss: 0.2349 - val_acc: 0.7667\n",
            "Epoch 241/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1062 - acc: 0.9037 - val_loss: 0.2346 - val_acc: 0.7667\n",
            "Epoch 242/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1062 - acc: 0.9074 - val_loss: 0.2332 - val_acc: 0.7667\n",
            "Epoch 243/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1062 - acc: 0.9074 - val_loss: 0.2330 - val_acc: 0.7667\n",
            "Epoch 244/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1062 - acc: 0.9037 - val_loss: 0.2336 - val_acc: 0.7667\n",
            "Epoch 245/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1062 - acc: 0.9037 - val_loss: 0.2335 - val_acc: 0.7667\n",
            "Epoch 246/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1061 - acc: 0.9074 - val_loss: 0.2343 - val_acc: 0.7667\n",
            "Epoch 247/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1061 - acc: 0.9037 - val_loss: 0.2347 - val_acc: 0.7667\n",
            "Epoch 248/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1061 - acc: 0.9037 - val_loss: 0.2329 - val_acc: 0.7667\n",
            "Epoch 249/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1061 - acc: 0.9037 - val_loss: 0.2329 - val_acc: 0.7667\n",
            "Epoch 250/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1061 - acc: 0.9074 - val_loss: 0.2326 - val_acc: 0.7667\n",
            "Epoch 251/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1061 - acc: 0.9037 - val_loss: 0.2332 - val_acc: 0.7667\n",
            "Epoch 252/800\n",
            "270/270 [==============================] - 0s 338us/step - loss: 0.1061 - acc: 0.9037 - val_loss: 0.2328 - val_acc: 0.7667\n",
            "Epoch 253/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1061 - acc: 0.9037 - val_loss: 0.2336 - val_acc: 0.7667\n",
            "Epoch 254/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1061 - acc: 0.9037 - val_loss: 0.2328 - val_acc: 0.7667\n",
            "Epoch 255/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1060 - acc: 0.9037 - val_loss: 0.2331 - val_acc: 0.7667\n",
            "Epoch 256/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1061 - acc: 0.9037 - val_loss: 0.2336 - val_acc: 0.7667\n",
            "Epoch 257/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1060 - acc: 0.9037 - val_loss: 0.2321 - val_acc: 0.7667\n",
            "Epoch 258/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1060 - acc: 0.9037 - val_loss: 0.2323 - val_acc: 0.7667\n",
            "Epoch 259/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1060 - acc: 0.9074 - val_loss: 0.2341 - val_acc: 0.7667\n",
            "Epoch 260/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1060 - acc: 0.9037 - val_loss: 0.2347 - val_acc: 0.7667\n",
            "Epoch 261/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1060 - acc: 0.9037 - val_loss: 0.2333 - val_acc: 0.7667\n",
            "Epoch 262/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1060 - acc: 0.9074 - val_loss: 0.2346 - val_acc: 0.7667\n",
            "Epoch 263/800\n",
            "270/270 [==============================] - 0s 327us/step - loss: 0.1061 - acc: 0.9000 - val_loss: 0.2342 - val_acc: 0.7667\n",
            "Epoch 264/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1061 - acc: 0.9074 - val_loss: 0.2340 - val_acc: 0.7667\n",
            "Epoch 265/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1060 - acc: 0.9074 - val_loss: 0.2341 - val_acc: 0.7667\n",
            "Epoch 266/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1060 - acc: 0.9074 - val_loss: 0.2345 - val_acc: 0.7667\n",
            "Epoch 267/800\n",
            "270/270 [==============================] - 0s 335us/step - loss: 0.1060 - acc: 0.9074 - val_loss: 0.2339 - val_acc: 0.7667\n",
            "Epoch 268/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1060 - acc: 0.9074 - val_loss: 0.2336 - val_acc: 0.7667\n",
            "Epoch 269/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1060 - acc: 0.9037 - val_loss: 0.2348 - val_acc: 0.7667\n",
            "Epoch 270/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1060 - acc: 0.9074 - val_loss: 0.2331 - val_acc: 0.7667\n",
            "Epoch 271/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1059 - acc: 0.9074 - val_loss: 0.2331 - val_acc: 0.7667\n",
            "Epoch 272/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1059 - acc: 0.9037 - val_loss: 0.2334 - val_acc: 0.7667\n",
            "Epoch 273/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1060 - acc: 0.9074 - val_loss: 0.2336 - val_acc: 0.7667\n",
            "Epoch 274/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1059 - acc: 0.9000 - val_loss: 0.2340 - val_acc: 0.7667\n",
            "Epoch 275/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1059 - acc: 0.9000 - val_loss: 0.2342 - val_acc: 0.8000\n",
            "Epoch 276/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1059 - acc: 0.9000 - val_loss: 0.2328 - val_acc: 0.7667\n",
            "Epoch 277/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1060 - acc: 0.9037 - val_loss: 0.2330 - val_acc: 0.7667\n",
            "Epoch 278/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1059 - acc: 0.9037 - val_loss: 0.2341 - val_acc: 0.7667\n",
            "Epoch 279/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1059 - acc: 0.9037 - val_loss: 0.2336 - val_acc: 0.7667\n",
            "Epoch 280/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1059 - acc: 0.9037 - val_loss: 0.2341 - val_acc: 0.7667\n",
            "Epoch 281/800\n",
            "270/270 [==============================] - 0s 337us/step - loss: 0.1059 - acc: 0.9074 - val_loss: 0.2335 - val_acc: 0.7667\n",
            "Epoch 282/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1059 - acc: 0.9037 - val_loss: 0.2330 - val_acc: 0.7667\n",
            "Epoch 283/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1059 - acc: 0.9111 - val_loss: 0.2340 - val_acc: 0.7667\n",
            "Epoch 284/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1058 - acc: 0.9037 - val_loss: 0.2341 - val_acc: 0.7667\n",
            "Epoch 285/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1059 - acc: 0.9074 - val_loss: 0.2328 - val_acc: 0.7667\n",
            "Epoch 286/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1058 - acc: 0.9074 - val_loss: 0.2336 - val_acc: 0.7667\n",
            "Epoch 287/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1058 - acc: 0.9074 - val_loss: 0.2345 - val_acc: 0.7667\n",
            "Epoch 288/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1059 - acc: 0.9037 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 289/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1059 - acc: 0.9074 - val_loss: 0.2319 - val_acc: 0.7667\n",
            "Epoch 290/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1058 - acc: 0.9074 - val_loss: 0.2328 - val_acc: 0.7667\n",
            "Epoch 291/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1058 - acc: 0.9074 - val_loss: 0.2306 - val_acc: 0.7667\n",
            "Epoch 292/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1059 - acc: 0.9074 - val_loss: 0.2326 - val_acc: 0.7667\n",
            "Epoch 293/800\n",
            "270/270 [==============================] - 0s 332us/step - loss: 0.1058 - acc: 0.9074 - val_loss: 0.2335 - val_acc: 0.7667\n",
            "Epoch 294/800\n",
            "270/270 [==============================] - 0s 355us/step - loss: 0.1058 - acc: 0.9000 - val_loss: 0.2327 - val_acc: 0.7667\n",
            "Epoch 295/800\n",
            "270/270 [==============================] - 0s 326us/step - loss: 0.1059 - acc: 0.9000 - val_loss: 0.2333 - val_acc: 0.7667\n",
            "Epoch 296/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1058 - acc: 0.9074 - val_loss: 0.2338 - val_acc: 0.7667\n",
            "Epoch 297/800\n",
            "270/270 [==============================] - 0s 322us/step - loss: 0.1058 - acc: 0.9037 - val_loss: 0.2321 - val_acc: 0.7667\n",
            "Epoch 298/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1057 - acc: 0.9074 - val_loss: 0.2322 - val_acc: 0.7667\n",
            "Epoch 299/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1057 - acc: 0.9074 - val_loss: 0.2342 - val_acc: 0.7667\n",
            "Epoch 300/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1057 - acc: 0.9037 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 301/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1058 - acc: 0.8963 - val_loss: 0.2320 - val_acc: 0.7667\n",
            "Epoch 302/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1058 - acc: 0.9074 - val_loss: 0.2335 - val_acc: 0.7667\n",
            "Epoch 303/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1057 - acc: 0.9037 - val_loss: 0.2347 - val_acc: 0.7667\n",
            "Epoch 304/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1057 - acc: 0.9037 - val_loss: 0.2325 - val_acc: 0.7667\n",
            "Epoch 305/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1057 - acc: 0.9074 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 306/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1057 - acc: 0.9111 - val_loss: 0.2332 - val_acc: 0.7667\n",
            "Epoch 307/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1057 - acc: 0.9074 - val_loss: 0.2324 - val_acc: 0.7667\n",
            "Epoch 308/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1057 - acc: 0.9074 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 309/800\n",
            "270/270 [==============================] - 0s 351us/step - loss: 0.1057 - acc: 0.9074 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 310/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1056 - acc: 0.9000 - val_loss: 0.2334 - val_acc: 0.7667\n",
            "Epoch 311/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1057 - acc: 0.9037 - val_loss: 0.2342 - val_acc: 0.7667\n",
            "Epoch 312/800\n",
            "270/270 [==============================] - 0s 330us/step - loss: 0.1056 - acc: 0.9074 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 313/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1057 - acc: 0.9074 - val_loss: 0.2318 - val_acc: 0.7667\n",
            "Epoch 314/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1056 - acc: 0.9037 - val_loss: 0.2330 - val_acc: 0.7667\n",
            "Epoch 315/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1056 - acc: 0.9074 - val_loss: 0.2340 - val_acc: 0.7667\n",
            "Epoch 316/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1056 - acc: 0.9000 - val_loss: 0.2333 - val_acc: 0.7667\n",
            "Epoch 317/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1057 - acc: 0.9074 - val_loss: 0.2321 - val_acc: 0.7667\n",
            "Epoch 318/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1056 - acc: 0.9037 - val_loss: 0.2322 - val_acc: 0.7667\n",
            "Epoch 319/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1056 - acc: 0.9037 - val_loss: 0.2330 - val_acc: 0.7667\n",
            "Epoch 320/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1056 - acc: 0.9074 - val_loss: 0.2339 - val_acc: 0.7667\n",
            "Epoch 321/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1055 - acc: 0.9000 - val_loss: 0.2338 - val_acc: 0.7667\n",
            "Epoch 322/800\n",
            "270/270 [==============================] - 0s 343us/step - loss: 0.1056 - acc: 0.9037 - val_loss: 0.2302 - val_acc: 0.7333\n",
            "Epoch 323/800\n",
            "270/270 [==============================] - 0s 343us/step - loss: 0.1057 - acc: 0.9037 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 324/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1055 - acc: 0.9037 - val_loss: 0.2302 - val_acc: 0.7667\n",
            "Epoch 325/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1056 - acc: 0.9074 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 326/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1056 - acc: 0.9037 - val_loss: 0.2329 - val_acc: 0.7667\n",
            "Epoch 327/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1055 - acc: 0.9037 - val_loss: 0.2319 - val_acc: 0.7667\n",
            "Epoch 328/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1055 - acc: 0.9074 - val_loss: 0.2329 - val_acc: 0.7667\n",
            "Epoch 329/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1055 - acc: 0.9037 - val_loss: 0.2340 - val_acc: 0.7667\n",
            "Epoch 330/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1055 - acc: 0.9037 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 331/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1055 - acc: 0.9111 - val_loss: 0.2332 - val_acc: 0.7667\n",
            "Epoch 332/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1055 - acc: 0.9037 - val_loss: 0.2333 - val_acc: 0.7667\n",
            "Epoch 333/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1055 - acc: 0.9074 - val_loss: 0.2325 - val_acc: 0.7667\n",
            "Epoch 334/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1055 - acc: 0.9074 - val_loss: 0.2326 - val_acc: 0.7667\n",
            "Epoch 335/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1055 - acc: 0.9037 - val_loss: 0.2330 - val_acc: 0.7667\n",
            "Epoch 336/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1055 - acc: 0.9037 - val_loss: 0.2338 - val_acc: 0.7667\n",
            "Epoch 337/800\n",
            "270/270 [==============================] - 0s 332us/step - loss: 0.1055 - acc: 0.9074 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 338/800\n",
            "270/270 [==============================] - 0s 322us/step - loss: 0.1055 - acc: 0.9074 - val_loss: 0.2318 - val_acc: 0.7667\n",
            "Epoch 339/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1055 - acc: 0.9074 - val_loss: 0.2320 - val_acc: 0.7667\n",
            "Epoch 340/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1055 - acc: 0.9111 - val_loss: 0.2329 - val_acc: 0.7667\n",
            "Epoch 341/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1055 - acc: 0.9037 - val_loss: 0.2331 - val_acc: 0.7667\n",
            "Epoch 342/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1054 - acc: 0.9074 - val_loss: 0.2329 - val_acc: 0.7667\n",
            "Epoch 343/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1055 - acc: 0.9074 - val_loss: 0.2326 - val_acc: 0.7667\n",
            "Epoch 344/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1054 - acc: 0.9074 - val_loss: 0.2337 - val_acc: 0.7667\n",
            "Epoch 345/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1054 - acc: 0.9037 - val_loss: 0.2327 - val_acc: 0.7667\n",
            "Epoch 346/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1054 - acc: 0.9111 - val_loss: 0.2334 - val_acc: 0.7667\n",
            "Epoch 347/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1054 - acc: 0.9074 - val_loss: 0.2324 - val_acc: 0.7667\n",
            "Epoch 348/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1054 - acc: 0.9074 - val_loss: 0.2338 - val_acc: 0.7667\n",
            "Epoch 349/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1054 - acc: 0.9037 - val_loss: 0.2336 - val_acc: 0.7667\n",
            "Epoch 350/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1054 - acc: 0.9111 - val_loss: 0.2325 - val_acc: 0.7667\n",
            "Epoch 351/800\n",
            "270/270 [==============================] - 0s 343us/step - loss: 0.1054 - acc: 0.9037 - val_loss: 0.2333 - val_acc: 0.7667\n",
            "Epoch 352/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1054 - acc: 0.9074 - val_loss: 0.2329 - val_acc: 0.7667\n",
            "Epoch 353/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1053 - acc: 0.9037 - val_loss: 0.2335 - val_acc: 0.7667\n",
            "Epoch 354/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1054 - acc: 0.9074 - val_loss: 0.2329 - val_acc: 0.7667\n",
            "Epoch 355/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1053 - acc: 0.9074 - val_loss: 0.2333 - val_acc: 0.7667\n",
            "Epoch 356/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1053 - acc: 0.9074 - val_loss: 0.2327 - val_acc: 0.7667\n",
            "Epoch 357/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1053 - acc: 0.9074 - val_loss: 0.2336 - val_acc: 0.7667\n",
            "Epoch 358/800\n",
            "270/270 [==============================] - 0s 278us/step - loss: 0.1053 - acc: 0.9111 - val_loss: 0.2324 - val_acc: 0.7667\n",
            "Epoch 359/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1053 - acc: 0.9037 - val_loss: 0.2324 - val_acc: 0.7667\n",
            "Epoch 360/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1053 - acc: 0.9074 - val_loss: 0.2321 - val_acc: 0.7667\n",
            "Epoch 361/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1053 - acc: 0.9074 - val_loss: 0.2334 - val_acc: 0.7667\n",
            "Epoch 362/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1053 - acc: 0.9074 - val_loss: 0.2328 - val_acc: 0.7667\n",
            "Epoch 363/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1053 - acc: 0.9074 - val_loss: 0.2326 - val_acc: 0.7667\n",
            "Epoch 364/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1053 - acc: 0.9111 - val_loss: 0.2330 - val_acc: 0.7667\n",
            "Epoch 365/800\n",
            "270/270 [==============================] - 0s 364us/step - loss: 0.1053 - acc: 0.9111 - val_loss: 0.2319 - val_acc: 0.7667\n",
            "Epoch 366/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1052 - acc: 0.9074 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 367/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1052 - acc: 0.9037 - val_loss: 0.2326 - val_acc: 0.7667\n",
            "Epoch 368/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1052 - acc: 0.9074 - val_loss: 0.2329 - val_acc: 0.7667\n",
            "Epoch 369/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1052 - acc: 0.9074 - val_loss: 0.2325 - val_acc: 0.7667\n",
            "Epoch 370/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1052 - acc: 0.9074 - val_loss: 0.2340 - val_acc: 0.7667\n",
            "Epoch 371/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1052 - acc: 0.9037 - val_loss: 0.2328 - val_acc: 0.7667\n",
            "Epoch 372/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1052 - acc: 0.9111 - val_loss: 0.2300 - val_acc: 0.7667\n",
            "Epoch 373/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1052 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 374/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1052 - acc: 0.9074 - val_loss: 0.2323 - val_acc: 0.7667\n",
            "Epoch 375/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1052 - acc: 0.9037 - val_loss: 0.2327 - val_acc: 0.7667\n",
            "Epoch 376/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1052 - acc: 0.9037 - val_loss: 0.2320 - val_acc: 0.7667\n",
            "Epoch 377/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1051 - acc: 0.9074 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 378/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1052 - acc: 0.9074 - val_loss: 0.2331 - val_acc: 0.7667\n",
            "Epoch 379/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1052 - acc: 0.9148 - val_loss: 0.2321 - val_acc: 0.7667\n",
            "Epoch 380/800\n",
            "270/270 [==============================] - 0s 324us/step - loss: 0.1051 - acc: 0.9074 - val_loss: 0.2319 - val_acc: 0.7667\n",
            "Epoch 381/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1051 - acc: 0.9111 - val_loss: 0.2334 - val_acc: 0.7667\n",
            "Epoch 382/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1051 - acc: 0.9074 - val_loss: 0.2324 - val_acc: 0.7667\n",
            "Epoch 383/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1051 - acc: 0.9111 - val_loss: 0.2333 - val_acc: 0.7667\n",
            "Epoch 384/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1051 - acc: 0.9074 - val_loss: 0.2330 - val_acc: 0.7667\n",
            "Epoch 385/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1051 - acc: 0.9111 - val_loss: 0.2326 - val_acc: 0.7667\n",
            "Epoch 386/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1050 - acc: 0.9074 - val_loss: 0.2322 - val_acc: 0.7667\n",
            "Epoch 387/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1051 - acc: 0.9074 - val_loss: 0.2326 - val_acc: 0.7667\n",
            "Epoch 388/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1051 - acc: 0.9111 - val_loss: 0.2304 - val_acc: 0.7667\n",
            "Epoch 389/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1051 - acc: 0.9074 - val_loss: 0.2330 - val_acc: 0.7667\n",
            "Epoch 390/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1051 - acc: 0.9074 - val_loss: 0.2327 - val_acc: 0.7667\n",
            "Epoch 391/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1050 - acc: 0.9074 - val_loss: 0.2328 - val_acc: 0.7667\n",
            "Epoch 392/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1051 - acc: 0.9037 - val_loss: 0.2334 - val_acc: 0.7667\n",
            "Epoch 393/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1050 - acc: 0.9037 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 394/800\n",
            "270/270 [==============================] - 0s 341us/step - loss: 0.1050 - acc: 0.9037 - val_loss: 0.2321 - val_acc: 0.7667\n",
            "Epoch 395/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1050 - acc: 0.9037 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 396/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1050 - acc: 0.9074 - val_loss: 0.2324 - val_acc: 0.7667\n",
            "Epoch 397/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1051 - acc: 0.9148 - val_loss: 0.2322 - val_acc: 0.7667\n",
            "Epoch 398/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1050 - acc: 0.9074 - val_loss: 0.2325 - val_acc: 0.7667\n",
            "Epoch 399/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1050 - acc: 0.9037 - val_loss: 0.2325 - val_acc: 0.7667\n",
            "Epoch 400/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1050 - acc: 0.9074 - val_loss: 0.2327 - val_acc: 0.7667\n",
            "Epoch 401/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1050 - acc: 0.9148 - val_loss: 0.2322 - val_acc: 0.7667\n",
            "Epoch 402/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1050 - acc: 0.9074 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 403/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1049 - acc: 0.9148 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 404/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1050 - acc: 0.9148 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 405/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1050 - acc: 0.9037 - val_loss: 0.2321 - val_acc: 0.7667\n",
            "Epoch 406/800\n",
            "270/270 [==============================] - 0s 278us/step - loss: 0.1050 - acc: 0.9074 - val_loss: 0.2319 - val_acc: 0.7667\n",
            "Epoch 407/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1050 - acc: 0.9074 - val_loss: 0.2293 - val_acc: 0.7333\n",
            "Epoch 408/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1051 - acc: 0.9074 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 409/800\n",
            "270/270 [==============================] - 0s 330us/step - loss: 0.1049 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 410/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1049 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 411/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1050 - acc: 0.9111 - val_loss: 0.2307 - val_acc: 0.7667\n",
            "Epoch 412/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1050 - acc: 0.9074 - val_loss: 0.2326 - val_acc: 0.7667\n",
            "Epoch 413/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1049 - acc: 0.9037 - val_loss: 0.2300 - val_acc: 0.7667\n",
            "Epoch 414/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1049 - acc: 0.9037 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 415/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1049 - acc: 0.9037 - val_loss: 0.2314 - val_acc: 0.8000\n",
            "Epoch 416/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1049 - acc: 0.9074 - val_loss: 0.2320 - val_acc: 0.7667\n",
            "Epoch 417/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1049 - acc: 0.9074 - val_loss: 0.2331 - val_acc: 0.7667\n",
            "Epoch 418/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1049 - acc: 0.9111 - val_loss: 0.2320 - val_acc: 0.7667\n",
            "Epoch 419/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1048 - acc: 0.9074 - val_loss: 0.2315 - val_acc: 0.8000\n",
            "\n",
            "Epoch 00419: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 420/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1048 - acc: 0.9074 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 421/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1047 - acc: 0.9074 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 422/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 423/800\n",
            "270/270 [==============================] - 0s 350us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 424/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 425/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 426/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 427/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 428/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 429/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 430/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2318 - val_acc: 0.7667\n",
            "Epoch 431/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2318 - val_acc: 0.7667\n",
            "Epoch 432/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 433/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 434/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 435/800\n",
            "270/270 [==============================] - 0s 331us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 436/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 437/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2319 - val_acc: 0.7667\n",
            "Epoch 438/800\n",
            "270/270 [==============================] - 0s 340us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2318 - val_acc: 0.7667\n",
            "Epoch 439/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1047 - acc: 0.9074 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 440/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 441/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 442/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 443/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 444/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 445/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 446/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 447/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2319 - val_acc: 0.7667\n",
            "Epoch 448/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2318 - val_acc: 0.7667\n",
            "Epoch 449/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 450/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 451/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 452/800\n",
            "270/270 [==============================] - 0s 381us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 453/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 454/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 455/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 456/800\n",
            "270/270 [==============================] - 0s 324us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 457/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 458/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 459/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 460/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 461/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 462/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 463/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 464/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 465/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 466/800\n",
            "270/270 [==============================] - 0s 388us/step - loss: 0.1047 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 467/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 468/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 469/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 470/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 471/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 472/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 473/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 474/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 475/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 476/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 477/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 478/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 479/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 480/800\n",
            "270/270 [==============================] - 0s 366us/step - loss: 0.1046 - acc: 0.9074 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 481/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1046 - acc: 0.9037 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 482/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 483/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 484/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 485/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 486/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 487/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 488/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 489/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 490/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 491/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1046 - acc: 0.9074 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 492/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 493/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 494/800\n",
            "270/270 [==============================] - 0s 395us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 495/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 496/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 497/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 498/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 499/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1046 - acc: 0.9074 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 500/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 501/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 502/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 503/800\n",
            "270/270 [==============================] - 0s 322us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 504/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 505/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 506/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 507/800\n",
            "270/270 [==============================] - 0s 327us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 508/800\n",
            "270/270 [==============================] - 0s 357us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 509/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 510/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 511/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1046 - acc: 0.9074 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 512/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 513/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 514/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 515/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 516/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 517/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 518/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 519/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 520/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 521/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 522/800\n",
            "270/270 [==============================] - 0s 359us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 523/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1046 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 524/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2319 - val_acc: 0.7667\n",
            "Epoch 525/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 526/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 527/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 528/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 529/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 530/800\n",
            "270/270 [==============================] - 0s 313us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 531/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 532/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 533/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 534/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 535/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 536/800\n",
            "270/270 [==============================] - 0s 357us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2307 - val_acc: 0.7667\n",
            "Epoch 537/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 538/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 539/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 540/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 541/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 542/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 543/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 544/800\n",
            "270/270 [==============================] - 0s 323us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 545/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 546/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 547/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 548/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 549/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 550/800\n",
            "270/270 [==============================] - 0s 369us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 551/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 552/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 553/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 554/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 555/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 556/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 557/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1045 - acc: 0.9074 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 558/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 559/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1045 - acc: 0.9074 - val_loss: 0.2305 - val_acc: 0.7667\n",
            "Epoch 560/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 561/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 562/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 563/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2307 - val_acc: 0.7667\n",
            "Epoch 564/800\n",
            "270/270 [==============================] - 0s 349us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2306 - val_acc: 0.7667\n",
            "Epoch 565/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 566/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 567/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 568/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 569/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 570/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 571/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1045 - acc: 0.9074 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 572/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 573/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 574/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 575/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1045 - acc: 0.9074 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 576/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 577/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 578/800\n",
            "270/270 [==============================] - 0s 380us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 579/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 580/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 581/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 582/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 583/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 584/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 585/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1044 - acc: 0.9074 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 586/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 587/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 588/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1045 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 589/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 590/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 591/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 592/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 593/800\n",
            "270/270 [==============================] - 0s 348us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2316 - val_acc: 0.7667\n",
            "Epoch 594/800\n",
            "270/270 [==============================] - 0s 278us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2317 - val_acc: 0.7667\n",
            "Epoch 595/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2318 - val_acc: 0.7667\n",
            "Epoch 596/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 597/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 598/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 599/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 600/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 601/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 602/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 603/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 604/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 605/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 606/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 607/800\n",
            "270/270 [==============================] - 0s 326us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 608/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1044 - acc: 0.9074 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 609/800\n",
            "270/270 [==============================] - 0s 277us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2315 - val_acc: 0.7667\n",
            "Epoch 610/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2314 - val_acc: 0.7667\n",
            "Epoch 611/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 612/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 613/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2307 - val_acc: 0.7667\n",
            "Epoch 614/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2307 - val_acc: 0.7667\n",
            "Epoch 615/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2306 - val_acc: 0.7667\n",
            "Epoch 616/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 617/800\n",
            "270/270 [==============================] - 0s 278us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 618/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 619/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "\n",
            "Epoch 00619: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
            "Epoch 620/800\n",
            "270/270 [==============================] - 0s 281us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 621/800\n",
            "270/270 [==============================] - 0s 279us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2313 - val_acc: 0.7667\n",
            "Epoch 622/800\n",
            "270/270 [==============================] - 0s 350us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 623/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 624/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 625/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 626/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 627/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 628/800\n",
            "270/270 [==============================] - 0s 287us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 629/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 630/800\n",
            "270/270 [==============================] - 0s 284us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 631/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 632/800\n",
            "270/270 [==============================] - 0s 282us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 633/800\n",
            "270/270 [==============================] - 0s 279us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 634/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 635/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 636/800\n",
            "270/270 [==============================] - 0s 285us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 637/800\n",
            "270/270 [==============================] - 0s 347us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 638/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 639/800\n",
            "270/270 [==============================] - 0s 283us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 640/800\n",
            "270/270 [==============================] - 0s 286us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 641/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 642/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 643/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 644/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 645/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 646/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 647/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 648/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 649/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1044 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 650/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 651/800\n",
            "270/270 [==============================] - 0s 343us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 652/800\n",
            "270/270 [==============================] - 0s 331us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 653/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 654/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 655/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 656/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 657/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 658/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 659/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 660/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 661/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 662/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 663/800\n",
            "270/270 [==============================] - 0s 300us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 664/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 665/800\n",
            "270/270 [==============================] - 0s 344us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 666/800\n",
            "270/270 [==============================] - 0s 339us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 667/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 668/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 669/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 670/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 671/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 672/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 673/800\n",
            "270/270 [==============================] - 0s 322us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 674/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 675/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 676/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 677/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 678/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 679/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 680/800\n",
            "270/270 [==============================] - 0s 331us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 681/800\n",
            "270/270 [==============================] - 0s 323us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 682/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 683/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 684/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 685/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 686/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 687/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 688/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 689/800\n",
            "270/270 [==============================] - 0s 291us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 690/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 691/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 692/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 693/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 694/800\n",
            "270/270 [==============================] - 0s 367us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 695/800\n",
            "270/270 [==============================] - 0s 324us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 696/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 697/800\n",
            "270/270 [==============================] - 0s 296us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2312 - val_acc: 0.7667\n",
            "Epoch 698/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 699/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 700/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 701/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 702/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 703/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 704/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 705/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 706/800\n",
            "270/270 [==============================] - 0s 289us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 707/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 708/800\n",
            "270/270 [==============================] - 0s 373us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 709/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 710/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 711/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 712/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 713/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 714/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 715/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 716/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 717/800\n",
            "270/270 [==============================] - 0s 294us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 718/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 719/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 720/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 721/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2307 - val_acc: 0.7667\n",
            "Epoch 722/800\n",
            "270/270 [==============================] - 0s 370us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2307 - val_acc: 0.7667\n",
            "Epoch 723/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2307 - val_acc: 0.7667\n",
            "Epoch 724/800\n",
            "270/270 [==============================] - 0s 322us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 725/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 726/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 727/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 728/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 729/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 730/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 731/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 732/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 733/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 734/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 735/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 736/800\n",
            "270/270 [==============================] - 0s 367us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 737/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 738/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 739/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 740/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 741/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 742/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2311 - val_acc: 0.7667\n",
            "Epoch 743/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 744/800\n",
            "270/270 [==============================] - 0s 311us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 745/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 746/800\n",
            "270/270 [==============================] - 0s 312us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 747/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 748/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 749/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 750/800\n",
            "270/270 [==============================] - 0s 364us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 751/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 752/800\n",
            "270/270 [==============================] - 0s 327us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 753/800\n",
            "270/270 [==============================] - 0s 307us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 754/800\n",
            "270/270 [==============================] - 0s 301us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 755/800\n",
            "270/270 [==============================] - 0s 321us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2307 - val_acc: 0.7667\n",
            "Epoch 756/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2307 - val_acc: 0.7667\n",
            "Epoch 757/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2307 - val_acc: 0.7667\n",
            "Epoch 758/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 759/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2307 - val_acc: 0.7667\n",
            "Epoch 760/800\n",
            "270/270 [==============================] - 0s 310us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 761/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 762/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 763/800\n",
            "270/270 [==============================] - 0s 288us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 764/800\n",
            "270/270 [==============================] - 0s 377us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 765/800\n",
            "270/270 [==============================] - 0s 320us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 766/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 767/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2307 - val_acc: 0.7667\n",
            "Epoch 768/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2306 - val_acc: 0.7667\n",
            "Epoch 769/800\n",
            "270/270 [==============================] - 0s 306us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2306 - val_acc: 0.7667\n",
            "Epoch 770/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2307 - val_acc: 0.7667\n",
            "Epoch 771/800\n",
            "270/270 [==============================] - 0s 315us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 772/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 773/800\n",
            "270/270 [==============================] - 0s 280us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 774/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 775/800\n",
            "270/270 [==============================] - 0s 292us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 776/800\n",
            "270/270 [==============================] - 0s 295us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 777/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 778/800\n",
            "270/270 [==============================] - 0s 366us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 779/800\n",
            "270/270 [==============================] - 0s 318us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 780/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 781/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 782/800\n",
            "270/270 [==============================] - 0s 316us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2308 - val_acc: 0.7667\n",
            "Epoch 783/800\n",
            "270/270 [==============================] - 0s 293us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 784/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 785/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 786/800\n",
            "270/270 [==============================] - 0s 302us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 787/800\n",
            "270/270 [==============================] - 0s 308us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 788/800\n",
            "270/270 [==============================] - 0s 319us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 789/800\n",
            "270/270 [==============================] - 0s 314us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 790/800\n",
            "270/270 [==============================] - 0s 299us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 791/800\n",
            "270/270 [==============================] - 0s 297us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 792/800\n",
            "270/270 [==============================] - 0s 375us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 793/800\n",
            "270/270 [==============================] - 0s 317us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 794/800\n",
            "270/270 [==============================] - 0s 326us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.7667\n",
            "Epoch 795/800\n",
            "270/270 [==============================] - 0s 298us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 796/800\n",
            "270/270 [==============================] - 0s 290us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 797/800\n",
            "270/270 [==============================] - 0s 304us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 798/800\n",
            "270/270 [==============================] - 0s 305us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 799/800\n",
            "270/270 [==============================] - 0s 309us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "Epoch 800/800\n",
            "270/270 [==============================] - 0s 303us/step - loss: 0.1043 - acc: 0.9111 - val_loss: 0.2309 - val_acc: 0.7667\n",
            "307/307 [==============================] - 0s 96us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1.0978583660013124, 0.5016286656600256]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "EmOIaHLa8IP_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27977
        },
        "outputId": "7cb2d2a7-9021-4b7e-d3b2-67b34cbdd1ce"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Results with one sample of anomily every 40 samples\n",
        "full_anom = 0\n",
        "anom_samples = 1\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,min_lr=1e-6,min_delta=0.0001,\n",
        "                              patience=200,verbose = 1)\n",
        "# history = autoencoder.fit(x_train2, x_train2,\n",
        "#                     epochs=nb_epoch,\n",
        "#                     batch_size=batch_size,\n",
        "#                     #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "#                     validation_split=.1,\n",
        "#                     verbose=1,callbacks=[reduce_lr])\n",
        "\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
        "                               verbose=0,\n",
        "                               save_best_only=True)\n",
        "tensorboard = TensorBoard(log_dir='./logs',\n",
        "                          histogram_freq=0,\n",
        "                          write_graph=True,\n",
        "                          write_images=True)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_test2, x_test2),\n",
        "                    validation_split=.1,\n",
        "                    shuffle=True,\n",
        "                    verbose=1,callbacks=[reduce_lr, checkpointer, tensorboard]).history \n",
        "\n",
        "score = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 300 samples, validate on 307 samples\n",
            "Epoch 1/800\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1248 - acc: 0.8767 - val_loss: 1.1054 - val_acc: 0.4756\n",
            "Epoch 2/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1179 - acc: 0.8833 - val_loss: 1.1125 - val_acc: 0.4723\n",
            "Epoch 3/800\n",
            "300/300 [==============================] - 0s 405us/step - loss: 0.1174 - acc: 0.8867 - val_loss: 1.1062 - val_acc: 0.5212\n",
            "Epoch 4/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1177 - acc: 0.8933 - val_loss: 1.1168 - val_acc: 0.4332\n",
            "Epoch 5/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1189 - acc: 0.8967 - val_loss: 1.0979 - val_acc: 0.5505\n",
            "Epoch 6/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1185 - acc: 0.8967 - val_loss: 1.1044 - val_acc: 0.4821\n",
            "Epoch 7/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1180 - acc: 0.8833 - val_loss: 1.1252 - val_acc: 0.5081\n",
            "Epoch 8/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1189 - acc: 0.8867 - val_loss: 1.0987 - val_acc: 0.4463\n",
            "Epoch 9/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1179 - acc: 0.8867 - val_loss: 1.1181 - val_acc: 0.4528\n",
            "Epoch 10/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1181 - acc: 0.8900 - val_loss: 1.1017 - val_acc: 0.5244\n",
            "Epoch 11/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1174 - acc: 0.8967 - val_loss: 1.0897 - val_acc: 0.5081\n",
            "Epoch 12/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1178 - acc: 0.8733 - val_loss: 1.1107 - val_acc: 0.5016\n",
            "Epoch 13/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1176 - acc: 0.8767 - val_loss: 1.0991 - val_acc: 0.5993\n",
            "Epoch 14/800\n",
            "300/300 [==============================] - 0s 394us/step - loss: 0.1188 - acc: 0.8967 - val_loss: 1.0911 - val_acc: 0.5016\n",
            "Epoch 15/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1188 - acc: 0.8967 - val_loss: 1.1240 - val_acc: 0.5147\n",
            "Epoch 16/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1200 - acc: 0.8767 - val_loss: 1.1104 - val_acc: 0.4723\n",
            "Epoch 17/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1182 - acc: 0.8733 - val_loss: 1.1188 - val_acc: 0.5081\n",
            "Epoch 18/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1189 - acc: 0.8900 - val_loss: 1.0982 - val_acc: 0.4104\n",
            "Epoch 19/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1191 - acc: 0.8767 - val_loss: 1.1132 - val_acc: 0.4821\n",
            "Epoch 20/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1171 - acc: 0.8933 - val_loss: 1.1199 - val_acc: 0.4593\n",
            "Epoch 21/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1185 - acc: 0.8767 - val_loss: 1.1270 - val_acc: 0.4951\n",
            "Epoch 22/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1185 - acc: 0.8800 - val_loss: 1.1423 - val_acc: 0.4821\n",
            "Epoch 23/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1173 - acc: 0.8867 - val_loss: 1.1021 - val_acc: 0.4756\n",
            "Epoch 24/800\n",
            "300/300 [==============================] - 0s 405us/step - loss: 0.1168 - acc: 0.8767 - val_loss: 1.1111 - val_acc: 0.5147\n",
            "Epoch 25/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1168 - acc: 0.8833 - val_loss: 1.0986 - val_acc: 0.4593\n",
            "Epoch 26/800\n",
            "300/300 [==============================] - 0s 382us/step - loss: 0.1178 - acc: 0.8867 - val_loss: 1.0980 - val_acc: 0.5049\n",
            "Epoch 27/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1188 - acc: 0.8800 - val_loss: 1.1177 - val_acc: 0.4723\n",
            "Epoch 28/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1172 - acc: 0.8867 - val_loss: 1.0917 - val_acc: 0.5016\n",
            "Epoch 29/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1179 - acc: 0.8900 - val_loss: 1.1195 - val_acc: 0.5668\n",
            "Epoch 30/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1179 - acc: 0.8833 - val_loss: 1.1487 - val_acc: 0.5863\n",
            "Epoch 31/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1194 - acc: 0.8767 - val_loss: 1.1282 - val_acc: 0.5081\n",
            "Epoch 32/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1183 - acc: 0.8867 - val_loss: 1.1173 - val_acc: 0.4821\n",
            "Epoch 33/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1168 - acc: 0.8900 - val_loss: 1.0833 - val_acc: 0.4169\n",
            "Epoch 34/800\n",
            "300/300 [==============================] - 0s 384us/step - loss: 0.1174 - acc: 0.9000 - val_loss: 1.1166 - val_acc: 0.5309\n",
            "Epoch 35/800\n",
            "300/300 [==============================] - 0s 426us/step - loss: 0.1176 - acc: 0.9000 - val_loss: 1.0903 - val_acc: 0.5244\n",
            "Epoch 36/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1170 - acc: 0.8967 - val_loss: 1.0893 - val_acc: 0.4658\n",
            "Epoch 37/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1166 - acc: 0.8833 - val_loss: 1.1305 - val_acc: 0.4756\n",
            "Epoch 38/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1169 - acc: 0.8867 - val_loss: 1.1346 - val_acc: 0.5244\n",
            "Epoch 39/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1168 - acc: 0.8867 - val_loss: 1.0913 - val_acc: 0.4821\n",
            "Epoch 40/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1184 - acc: 0.8800 - val_loss: 1.0994 - val_acc: 0.5016\n",
            "Epoch 41/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1174 - acc: 0.8900 - val_loss: 1.1345 - val_acc: 0.4593\n",
            "Epoch 42/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1184 - acc: 0.8800 - val_loss: 1.0975 - val_acc: 0.4723\n",
            "Epoch 43/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1163 - acc: 0.8900 - val_loss: 1.0997 - val_acc: 0.5016\n",
            "Epoch 44/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1175 - acc: 0.8967 - val_loss: 1.1120 - val_acc: 0.4788\n",
            "Epoch 45/800\n",
            "300/300 [==============================] - 0s 428us/step - loss: 0.1161 - acc: 0.8867 - val_loss: 1.1126 - val_acc: 0.5016\n",
            "Epoch 46/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1170 - acc: 0.8900 - val_loss: 1.1182 - val_acc: 0.5309\n",
            "Epoch 47/800\n",
            "300/300 [==============================] - 0s 382us/step - loss: 0.1173 - acc: 0.8867 - val_loss: 1.1187 - val_acc: 0.6026\n",
            "Epoch 48/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1169 - acc: 0.8800 - val_loss: 1.0895 - val_acc: 0.4169\n",
            "Epoch 49/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1174 - acc: 0.8900 - val_loss: 1.1077 - val_acc: 0.4463\n",
            "Epoch 50/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1160 - acc: 0.8967 - val_loss: 1.1099 - val_acc: 0.5309\n",
            "Epoch 51/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1170 - acc: 0.8833 - val_loss: 1.1074 - val_acc: 0.4365\n",
            "Epoch 52/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1171 - acc: 0.8867 - val_loss: 1.1040 - val_acc: 0.4593\n",
            "Epoch 53/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1161 - acc: 0.8900 - val_loss: 1.1253 - val_acc: 0.5668\n",
            "Epoch 54/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1161 - acc: 0.8933 - val_loss: 1.0982 - val_acc: 0.4853\n",
            "Epoch 55/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1164 - acc: 0.8900 - val_loss: 1.1081 - val_acc: 0.5309\n",
            "Epoch 56/800\n",
            "300/300 [==============================] - 0s 427us/step - loss: 0.1159 - acc: 0.8867 - val_loss: 1.1231 - val_acc: 0.5244\n",
            "Epoch 57/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1181 - acc: 0.8767 - val_loss: 1.1527 - val_acc: 0.4886\n",
            "Epoch 58/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1186 - acc: 0.8767 - val_loss: 1.1192 - val_acc: 0.4397\n",
            "Epoch 59/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1166 - acc: 0.8867 - val_loss: 1.1032 - val_acc: 0.4821\n",
            "Epoch 60/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1167 - acc: 0.8967 - val_loss: 1.0917 - val_acc: 0.4267\n",
            "Epoch 61/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1176 - acc: 0.8867 - val_loss: 1.1239 - val_acc: 0.5016\n",
            "Epoch 62/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1193 - acc: 0.8867 - val_loss: 1.1094 - val_acc: 0.5993\n",
            "Epoch 63/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1175 - acc: 0.8800 - val_loss: 1.0879 - val_acc: 0.5016\n",
            "Epoch 64/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1160 - acc: 0.8867 - val_loss: 1.0882 - val_acc: 0.5081\n",
            "Epoch 65/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1164 - acc: 0.8800 - val_loss: 1.1043 - val_acc: 0.4560\n",
            "Epoch 66/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1154 - acc: 0.9067 - val_loss: 1.1042 - val_acc: 0.4723\n",
            "Epoch 67/800\n",
            "300/300 [==============================] - 0s 420us/step - loss: 0.1159 - acc: 0.8867 - val_loss: 1.0927 - val_acc: 0.4267\n",
            "Epoch 68/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1168 - acc: 0.9000 - val_loss: 1.0865 - val_acc: 0.4495\n",
            "Epoch 69/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1168 - acc: 0.8933 - val_loss: 1.1012 - val_acc: 0.4593\n",
            "Epoch 70/800\n",
            "300/300 [==============================] - 0s 384us/step - loss: 0.1157 - acc: 0.8900 - val_loss: 1.1072 - val_acc: 0.5049\n",
            "Epoch 71/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1157 - acc: 0.8900 - val_loss: 1.1079 - val_acc: 0.4593\n",
            "Epoch 72/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1163 - acc: 0.9000 - val_loss: 1.0833 - val_acc: 0.4397\n",
            "Epoch 73/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1182 - acc: 0.8800 - val_loss: 1.1272 - val_acc: 0.4756\n",
            "Epoch 74/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1177 - acc: 0.8733 - val_loss: 1.1144 - val_acc: 0.4919\n",
            "Epoch 75/800\n",
            "300/300 [==============================] - 0s 385us/step - loss: 0.1163 - acc: 0.8867 - val_loss: 1.1067 - val_acc: 0.5016\n",
            "Epoch 76/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1162 - acc: 0.8833 - val_loss: 1.0989 - val_acc: 0.5081\n",
            "Epoch 77/800\n",
            "300/300 [==============================] - 0s 422us/step - loss: 0.1154 - acc: 0.8900 - val_loss: 1.1018 - val_acc: 0.5309\n",
            "Epoch 78/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1159 - acc: 0.8900 - val_loss: 1.0936 - val_acc: 0.5537\n",
            "Epoch 79/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1158 - acc: 0.9000 - val_loss: 1.0938 - val_acc: 0.5016\n",
            "Epoch 80/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1165 - acc: 0.9000 - val_loss: 1.0867 - val_acc: 0.5081\n",
            "Epoch 81/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1157 - acc: 0.8867 - val_loss: 1.1049 - val_acc: 0.5212\n",
            "Epoch 82/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1154 - acc: 0.8933 - val_loss: 1.0979 - val_acc: 0.5537\n",
            "Epoch 83/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1159 - acc: 0.8900 - val_loss: 1.1088 - val_acc: 0.4723\n",
            "Epoch 84/800\n",
            "300/300 [==============================] - 0s 380us/step - loss: 0.1171 - acc: 0.8800 - val_loss: 1.0776 - val_acc: 0.4169\n",
            "Epoch 85/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1202 - acc: 0.8967 - val_loss: 1.0873 - val_acc: 0.4300\n",
            "Epoch 86/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1152 - acc: 0.8967 - val_loss: 1.0932 - val_acc: 0.4104\n",
            "Epoch 87/800\n",
            "300/300 [==============================] - 0s 442us/step - loss: 0.1167 - acc: 0.8933 - val_loss: 1.0840 - val_acc: 0.4104\n",
            "Epoch 88/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1151 - acc: 0.8933 - val_loss: 1.1022 - val_acc: 0.4593\n",
            "Epoch 89/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1162 - acc: 0.8833 - val_loss: 1.0914 - val_acc: 0.4853\n",
            "Epoch 90/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1152 - acc: 0.9067 - val_loss: 1.0861 - val_acc: 0.5081\n",
            "Epoch 91/800\n",
            "300/300 [==============================] - 0s 380us/step - loss: 0.1164 - acc: 0.8900 - val_loss: 1.0916 - val_acc: 0.4267\n",
            "Epoch 92/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1151 - acc: 0.9000 - val_loss: 1.0922 - val_acc: 0.4267\n",
            "Epoch 93/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1163 - acc: 0.9067 - val_loss: 1.0873 - val_acc: 0.4104\n",
            "Epoch 94/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1163 - acc: 0.9000 - val_loss: 1.1033 - val_acc: 0.5212\n",
            "Epoch 95/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1146 - acc: 0.9000 - val_loss: 1.0894 - val_acc: 0.4039\n",
            "Epoch 96/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1155 - acc: 0.8933 - val_loss: 1.0908 - val_acc: 0.4300\n",
            "Epoch 97/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1155 - acc: 0.8867 - val_loss: 1.0729 - val_acc: 0.4365\n",
            "Epoch 98/800\n",
            "300/300 [==============================] - 0s 416us/step - loss: 0.1156 - acc: 0.8900 - val_loss: 1.0824 - val_acc: 0.4495\n",
            "Epoch 99/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1165 - acc: 0.8933 - val_loss: 1.0955 - val_acc: 0.4169\n",
            "Epoch 100/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1153 - acc: 0.8900 - val_loss: 1.1120 - val_acc: 0.4756\n",
            "Epoch 101/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1180 - acc: 0.8867 - val_loss: 1.0886 - val_acc: 0.4593\n",
            "Epoch 102/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1151 - acc: 0.8933 - val_loss: 1.0925 - val_acc: 0.4463\n",
            "Epoch 103/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1149 - acc: 0.9000 - val_loss: 1.0757 - val_acc: 0.4104\n",
            "Epoch 104/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1171 - acc: 0.9033 - val_loss: 1.0777 - val_acc: 0.4365\n",
            "Epoch 105/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1153 - acc: 0.8933 - val_loss: 1.0985 - val_acc: 0.4169\n",
            "Epoch 106/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1149 - acc: 0.8933 - val_loss: 1.0982 - val_acc: 0.4593\n",
            "Epoch 107/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1151 - acc: 0.8900 - val_loss: 1.0935 - val_acc: 0.5765\n",
            "Epoch 108/800\n",
            "300/300 [==============================] - 0s 434us/step - loss: 0.1144 - acc: 0.9033 - val_loss: 1.0984 - val_acc: 0.4267\n",
            "Epoch 109/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1150 - acc: 0.8833 - val_loss: 1.1101 - val_acc: 0.4951\n",
            "Epoch 110/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1153 - acc: 0.9033 - val_loss: 1.0826 - val_acc: 0.4104\n",
            "Epoch 111/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1145 - acc: 0.8933 - val_loss: 1.0940 - val_acc: 0.4691\n",
            "Epoch 112/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1147 - acc: 0.8967 - val_loss: 1.0797 - val_acc: 0.4039\n",
            "Epoch 113/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1154 - acc: 0.8933 - val_loss: 1.0917 - val_acc: 0.5016\n",
            "Epoch 114/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1169 - acc: 0.8900 - val_loss: 1.0971 - val_acc: 0.5147\n",
            "Epoch 115/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1148 - acc: 0.9033 - val_loss: 1.0817 - val_acc: 0.3844\n",
            "Epoch 116/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1145 - acc: 0.9000 - val_loss: 1.1002 - val_acc: 0.4691\n",
            "Epoch 117/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1147 - acc: 0.9000 - val_loss: 1.0787 - val_acc: 0.4691\n",
            "Epoch 118/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1144 - acc: 0.9000 - val_loss: 1.0861 - val_acc: 0.4853\n",
            "Epoch 119/800\n",
            "300/300 [==============================] - 0s 422us/step - loss: 0.1145 - acc: 0.9033 - val_loss: 1.0979 - val_acc: 0.4723\n",
            "Epoch 120/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1146 - acc: 0.9000 - val_loss: 1.0980 - val_acc: 0.5016\n",
            "Epoch 121/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1144 - acc: 0.9000 - val_loss: 1.0936 - val_acc: 0.5081\n",
            "Epoch 122/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1141 - acc: 0.8833 - val_loss: 1.0815 - val_acc: 0.4267\n",
            "Epoch 123/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1144 - acc: 0.8967 - val_loss: 1.0652 - val_acc: 0.4104\n",
            "Epoch 124/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1177 - acc: 0.9033 - val_loss: 1.0977 - val_acc: 0.5570\n",
            "Epoch 125/800\n",
            "300/300 [==============================] - 0s 387us/step - loss: 0.1141 - acc: 0.8867 - val_loss: 1.0918 - val_acc: 0.5179\n",
            "Epoch 126/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1143 - acc: 0.8900 - val_loss: 1.1042 - val_acc: 0.4463\n",
            "Epoch 127/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1143 - acc: 0.8967 - val_loss: 1.0877 - val_acc: 0.5049\n",
            "Epoch 128/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1141 - acc: 0.8933 - val_loss: 1.0891 - val_acc: 0.5016\n",
            "Epoch 129/800\n",
            "300/300 [==============================] - 0s 425us/step - loss: 0.1146 - acc: 0.9000 - val_loss: 1.0961 - val_acc: 0.4463\n",
            "Epoch 130/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1144 - acc: 0.9033 - val_loss: 1.1041 - val_acc: 0.4625\n",
            "Epoch 131/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1150 - acc: 0.8900 - val_loss: 1.0877 - val_acc: 0.4821\n",
            "Epoch 132/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1141 - acc: 0.8867 - val_loss: 1.0684 - val_acc: 0.4658\n",
            "Epoch 133/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1142 - acc: 0.8933 - val_loss: 1.0615 - val_acc: 0.4593\n",
            "Epoch 134/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1155 - acc: 0.9000 - val_loss: 1.0944 - val_acc: 0.5016\n",
            "Epoch 135/800\n",
            "300/300 [==============================] - 0s 386us/step - loss: 0.1146 - acc: 0.8867 - val_loss: 1.1008 - val_acc: 0.4756\n",
            "Epoch 136/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1145 - acc: 0.9000 - val_loss: 1.0974 - val_acc: 0.4169\n",
            "Epoch 137/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1141 - acc: 0.9000 - val_loss: 1.1073 - val_acc: 0.4365\n",
            "Epoch 138/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1147 - acc: 0.8867 - val_loss: 1.0963 - val_acc: 0.4169\n",
            "Epoch 139/800\n",
            "300/300 [==============================] - 0s 438us/step - loss: 0.1140 - acc: 0.8933 - val_loss: 1.0929 - val_acc: 0.4821\n",
            "Epoch 140/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1141 - acc: 0.8933 - val_loss: 1.0764 - val_acc: 0.4723\n",
            "Epoch 141/800\n",
            "300/300 [==============================] - 0s 387us/step - loss: 0.1149 - acc: 0.8967 - val_loss: 1.0828 - val_acc: 0.4104\n",
            "Epoch 142/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1142 - acc: 0.9067 - val_loss: 1.0876 - val_acc: 0.4691\n",
            "Epoch 143/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1139 - acc: 0.9000 - val_loss: 1.0894 - val_acc: 0.4593\n",
            "Epoch 144/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1137 - acc: 0.8967 - val_loss: 1.0906 - val_acc: 0.4463\n",
            "Epoch 145/800\n",
            "300/300 [==============================] - 0s 382us/step - loss: 0.1136 - acc: 0.9000 - val_loss: 1.0803 - val_acc: 0.4397\n",
            "Epoch 146/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1143 - acc: 0.8933 - val_loss: 1.0815 - val_acc: 0.5277\n",
            "Epoch 147/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1175 - acc: 0.8867 - val_loss: 1.0901 - val_acc: 0.5081\n",
            "Epoch 148/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1144 - acc: 0.8967 - val_loss: 1.0919 - val_acc: 0.4723\n",
            "Epoch 149/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1134 - acc: 0.9000 - val_loss: 1.0659 - val_acc: 0.4756\n",
            "Epoch 150/800\n",
            "300/300 [==============================] - 0s 412us/step - loss: 0.1151 - acc: 0.8967 - val_loss: 1.0780 - val_acc: 0.4300\n",
            "Epoch 151/800\n",
            "300/300 [==============================] - 0s 382us/step - loss: 0.1143 - acc: 0.8933 - val_loss: 1.0932 - val_acc: 0.4332\n",
            "Epoch 152/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1165 - acc: 0.8833 - val_loss: 1.0977 - val_acc: 0.4593\n",
            "Epoch 153/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1136 - acc: 0.8933 - val_loss: 1.0716 - val_acc: 0.4821\n",
            "Epoch 154/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1145 - acc: 0.8967 - val_loss: 1.0983 - val_acc: 0.4104\n",
            "Epoch 155/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1143 - acc: 0.8967 - val_loss: 1.1057 - val_acc: 0.4169\n",
            "Epoch 156/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1144 - acc: 0.8967 - val_loss: 1.0836 - val_acc: 0.4528\n",
            "Epoch 157/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1135 - acc: 0.9000 - val_loss: 1.0773 - val_acc: 0.5179\n",
            "Epoch 158/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1143 - acc: 0.8867 - val_loss: 1.1041 - val_acc: 0.4691\n",
            "Epoch 159/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1136 - acc: 0.9000 - val_loss: 1.1002 - val_acc: 0.5179\n",
            "Epoch 160/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1141 - acc: 0.8933 - val_loss: 1.0854 - val_acc: 0.4723\n",
            "Epoch 161/800\n",
            "300/300 [==============================] - 0s 405us/step - loss: 0.1139 - acc: 0.8967 - val_loss: 1.0528 - val_acc: 0.4007\n",
            "Epoch 162/800\n",
            "300/300 [==============================] - 0s 341us/step - loss: 0.1140 - acc: 0.9033 - val_loss: 1.0836 - val_acc: 0.4007\n",
            "Epoch 163/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1138 - acc: 0.8967 - val_loss: 1.1143 - val_acc: 0.5961\n",
            "Epoch 164/800\n",
            "300/300 [==============================] - 0s 346us/step - loss: 0.1181 - acc: 0.8867 - val_loss: 1.0865 - val_acc: 0.4235\n",
            "Epoch 165/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1144 - acc: 0.8967 - val_loss: 1.0744 - val_acc: 0.4821\n",
            "Epoch 166/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1136 - acc: 0.8967 - val_loss: 1.0698 - val_acc: 0.4463\n",
            "Epoch 167/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1138 - acc: 0.8900 - val_loss: 1.0781 - val_acc: 0.5440\n",
            "Epoch 168/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1134 - acc: 0.9000 - val_loss: 1.0666 - val_acc: 0.4169\n",
            "Epoch 169/800\n",
            "300/300 [==============================] - 0s 341us/step - loss: 0.1143 - acc: 0.9000 - val_loss: 1.1017 - val_acc: 0.4821\n",
            "Epoch 170/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1137 - acc: 0.8900 - val_loss: 1.0691 - val_acc: 0.4169\n",
            "Epoch 171/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1139 - acc: 0.8967 - val_loss: 1.0847 - val_acc: 0.4788\n",
            "Epoch 172/800\n",
            "300/300 [==============================] - 0s 411us/step - loss: 0.1144 - acc: 0.8933 - val_loss: 1.0850 - val_acc: 0.4397\n",
            "Epoch 173/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1133 - acc: 0.8967 - val_loss: 1.0828 - val_acc: 0.4853\n",
            "Epoch 174/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1132 - acc: 0.9000 - val_loss: 1.0869 - val_acc: 0.4267\n",
            "Epoch 175/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1130 - acc: 0.8967 - val_loss: 1.0923 - val_acc: 0.4560\n",
            "Epoch 176/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1139 - acc: 0.9067 - val_loss: 1.0846 - val_acc: 0.4756\n",
            "Epoch 177/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1134 - acc: 0.8967 - val_loss: 1.0762 - val_acc: 0.4463\n",
            "Epoch 178/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1145 - acc: 0.9100 - val_loss: 1.0840 - val_acc: 0.4691\n",
            "Epoch 179/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1139 - acc: 0.9000 - val_loss: 1.1108 - val_acc: 0.5081\n",
            "Epoch 180/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1164 - acc: 0.9000 - val_loss: 1.0927 - val_acc: 0.5114\n",
            "Epoch 181/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1134 - acc: 0.9000 - val_loss: 1.1004 - val_acc: 0.4495\n",
            "Epoch 182/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1137 - acc: 0.8900 - val_loss: 1.0707 - val_acc: 0.4821\n",
            "Epoch 183/800\n",
            "300/300 [==============================] - 0s 405us/step - loss: 0.1137 - acc: 0.9033 - val_loss: 1.1046 - val_acc: 0.5700\n",
            "Epoch 184/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1141 - acc: 0.9000 - val_loss: 1.1042 - val_acc: 0.4463\n",
            "Epoch 185/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1133 - acc: 0.9067 - val_loss: 1.0779 - val_acc: 0.4397\n",
            "Epoch 186/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1135 - acc: 0.8800 - val_loss: 1.0775 - val_acc: 0.4332\n",
            "Epoch 187/800\n",
            "300/300 [==============================] - 0s 344us/step - loss: 0.1129 - acc: 0.9033 - val_loss: 1.0713 - val_acc: 0.4593\n",
            "Epoch 188/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1137 - acc: 0.8900 - val_loss: 1.0713 - val_acc: 0.4658\n",
            "Epoch 189/800\n",
            "300/300 [==============================] - 0s 345us/step - loss: 0.1140 - acc: 0.9033 - val_loss: 1.0772 - val_acc: 0.4072\n",
            "Epoch 190/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1153 - acc: 0.8933 - val_loss: 1.0803 - val_acc: 0.4723\n",
            "Epoch 191/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1130 - acc: 0.9000 - val_loss: 1.0749 - val_acc: 0.3616\n",
            "Epoch 192/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1132 - acc: 0.9067 - val_loss: 1.0902 - val_acc: 0.4886\n",
            "Epoch 193/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1135 - acc: 0.9033 - val_loss: 1.0816 - val_acc: 0.5049\n",
            "Epoch 194/800\n",
            "300/300 [==============================] - 0s 462us/step - loss: 0.1139 - acc: 0.9000 - val_loss: 1.0670 - val_acc: 0.3779\n",
            "Epoch 195/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1132 - acc: 0.8867 - val_loss: 1.0847 - val_acc: 0.4332\n",
            "Epoch 196/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1140 - acc: 0.9000 - val_loss: 1.0836 - val_acc: 0.4691\n",
            "Epoch 197/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1138 - acc: 0.9000 - val_loss: 1.0757 - val_acc: 0.4104\n",
            "Epoch 198/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1136 - acc: 0.8867 - val_loss: 1.0718 - val_acc: 0.4169\n",
            "Epoch 199/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1131 - acc: 0.8933 - val_loss: 1.0843 - val_acc: 0.4169\n",
            "Epoch 200/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1131 - acc: 0.9100 - val_loss: 1.0649 - val_acc: 0.4528\n",
            "Epoch 201/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1127 - acc: 0.9033 - val_loss: 1.0758 - val_acc: 0.4723\n",
            "Epoch 202/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1131 - acc: 0.9000 - val_loss: 1.0716 - val_acc: 0.4104\n",
            "Epoch 203/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1129 - acc: 0.9000 - val_loss: 1.0801 - val_acc: 0.4365\n",
            "Epoch 204/800\n",
            "300/300 [==============================] - 0s 422us/step - loss: 0.1136 - acc: 0.9000 - val_loss: 1.0534 - val_acc: 0.4072\n",
            "Epoch 205/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1138 - acc: 0.9067 - val_loss: 1.0746 - val_acc: 0.3779\n",
            "Epoch 206/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1140 - acc: 0.9000 - val_loss: 1.0704 - val_acc: 0.4072\n",
            "Epoch 207/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1126 - acc: 0.9067 - val_loss: 1.0733 - val_acc: 0.4072\n",
            "Epoch 208/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1128 - acc: 0.9033 - val_loss: 1.0707 - val_acc: 0.4528\n",
            "Epoch 209/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1131 - acc: 0.8933 - val_loss: 1.0682 - val_acc: 0.4169\n",
            "Epoch 210/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1127 - acc: 0.9100 - val_loss: 1.0712 - val_acc: 0.3811\n",
            "Epoch 211/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1129 - acc: 0.9033 - val_loss: 1.0826 - val_acc: 0.4593\n",
            "Epoch 212/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1141 - acc: 0.9067 - val_loss: 1.0625 - val_acc: 0.4332\n",
            "Epoch 213/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1128 - acc: 0.9067 - val_loss: 1.0708 - val_acc: 0.4723\n",
            "Epoch 214/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1131 - acc: 0.8933 - val_loss: 1.0659 - val_acc: 0.4463\n",
            "Epoch 215/800\n",
            "300/300 [==============================] - 0s 426us/step - loss: 0.1132 - acc: 0.8900 - val_loss: 1.0851 - val_acc: 0.4756\n",
            "Epoch 216/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1129 - acc: 0.9000 - val_loss: 1.0622 - val_acc: 0.4104\n",
            "Epoch 217/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1128 - acc: 0.9000 - val_loss: 1.0785 - val_acc: 0.4463\n",
            "Epoch 218/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1128 - acc: 0.9067 - val_loss: 1.0643 - val_acc: 0.4235\n",
            "Epoch 219/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1130 - acc: 0.9000 - val_loss: 1.0785 - val_acc: 0.4463\n",
            "Epoch 220/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1129 - acc: 0.9067 - val_loss: 1.0785 - val_acc: 0.4723\n",
            "Epoch 221/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1126 - acc: 0.9000 - val_loss: 1.0714 - val_acc: 0.4007\n",
            "Epoch 222/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1126 - acc: 0.9033 - val_loss: 1.0778 - val_acc: 0.4691\n",
            "Epoch 223/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1127 - acc: 0.9000 - val_loss: 1.0689 - val_acc: 0.3974\n",
            "Epoch 224/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1126 - acc: 0.9000 - val_loss: 1.0771 - val_acc: 0.4495\n",
            "Epoch 225/800\n",
            "300/300 [==============================] - 0s 416us/step - loss: 0.1127 - acc: 0.9100 - val_loss: 1.0713 - val_acc: 0.4593\n",
            "Epoch 226/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1123 - acc: 0.9033 - val_loss: 1.0641 - val_acc: 0.4104\n",
            "Epoch 227/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1146 - acc: 0.9100 - val_loss: 1.0732 - val_acc: 0.4235\n",
            "Epoch 228/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1126 - acc: 0.8900 - val_loss: 1.0584 - val_acc: 0.4463\n",
            "Epoch 229/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1124 - acc: 0.9067 - val_loss: 1.0675 - val_acc: 0.4723\n",
            "Epoch 230/800\n",
            "300/300 [==============================] - 0s 381us/step - loss: 0.1131 - acc: 0.9033 - val_loss: 1.0884 - val_acc: 0.4235\n",
            "Epoch 231/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1131 - acc: 0.9100 - val_loss: 1.0724 - val_acc: 0.4267\n",
            "Epoch 232/800\n",
            "300/300 [==============================] - 0s 382us/step - loss: 0.1137 - acc: 0.9000 - val_loss: 1.0942 - val_acc: 0.5049\n",
            "Epoch 233/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1127 - acc: 0.9100 - val_loss: 1.0801 - val_acc: 0.4300\n",
            "Epoch 234/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1129 - acc: 0.8967 - val_loss: 1.0942 - val_acc: 0.4691\n",
            "Epoch 235/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1130 - acc: 0.9000 - val_loss: 1.0696 - val_acc: 0.5049\n",
            "Epoch 236/800\n",
            "300/300 [==============================] - 0s 422us/step - loss: 0.1128 - acc: 0.9033 - val_loss: 1.0721 - val_acc: 0.4495\n",
            "Epoch 237/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1126 - acc: 0.8967 - val_loss: 1.0655 - val_acc: 0.4137\n",
            "Epoch 238/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1123 - acc: 0.8900 - val_loss: 1.0716 - val_acc: 0.4788\n",
            "Epoch 239/800\n",
            "300/300 [==============================] - 0s 380us/step - loss: 0.1123 - acc: 0.9067 - val_loss: 1.0740 - val_acc: 0.4267\n",
            "Epoch 240/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1122 - acc: 0.9033 - val_loss: 1.0776 - val_acc: 0.4463\n",
            "Epoch 241/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1138 - acc: 0.8933 - val_loss: 1.0681 - val_acc: 0.4528\n",
            "Epoch 242/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1130 - acc: 0.8900 - val_loss: 1.0573 - val_acc: 0.4104\n",
            "Epoch 243/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1132 - acc: 0.9033 - val_loss: 1.0533 - val_acc: 0.4235\n",
            "Epoch 244/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1123 - acc: 0.9100 - val_loss: 1.0654 - val_acc: 0.4007\n",
            "Epoch 245/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1126 - acc: 0.9100 - val_loss: 1.0755 - val_acc: 0.4332\n",
            "Epoch 246/800\n",
            "300/300 [==============================] - 0s 397us/step - loss: 0.1123 - acc: 0.9133 - val_loss: 1.0696 - val_acc: 0.4593\n",
            "Epoch 247/800\n",
            "300/300 [==============================] - 0s 388us/step - loss: 0.1122 - acc: 0.9067 - val_loss: 1.0575 - val_acc: 0.4691\n",
            "\n",
            "Epoch 00247: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 248/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1121 - acc: 0.9100 - val_loss: 1.0705 - val_acc: 0.4528\n",
            "Epoch 249/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1116 - acc: 0.9067 - val_loss: 1.0695 - val_acc: 0.4463\n",
            "Epoch 250/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1115 - acc: 0.9067 - val_loss: 1.0711 - val_acc: 0.4528\n",
            "Epoch 251/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1116 - acc: 0.9033 - val_loss: 1.0758 - val_acc: 0.4495\n",
            "Epoch 252/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1116 - acc: 0.9067 - val_loss: 1.0709 - val_acc: 0.4463\n",
            "Epoch 253/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1116 - acc: 0.9000 - val_loss: 1.0691 - val_acc: 0.4300\n",
            "Epoch 254/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1115 - acc: 0.9000 - val_loss: 1.0695 - val_acc: 0.4332\n",
            "Epoch 255/800\n",
            "300/300 [==============================] - 0s 417us/step - loss: 0.1115 - acc: 0.8967 - val_loss: 1.0668 - val_acc: 0.4463\n",
            "Epoch 256/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1116 - acc: 0.9067 - val_loss: 1.0695 - val_acc: 0.4463\n",
            "Epoch 257/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1115 - acc: 0.9067 - val_loss: 1.0704 - val_acc: 0.4463\n",
            "Epoch 258/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1115 - acc: 0.9033 - val_loss: 1.0700 - val_acc: 0.4397\n",
            "Epoch 259/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1115 - acc: 0.9067 - val_loss: 1.0708 - val_acc: 0.4300\n",
            "Epoch 260/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1115 - acc: 0.9000 - val_loss: 1.0694 - val_acc: 0.4495\n",
            "Epoch 261/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1115 - acc: 0.9000 - val_loss: 1.0704 - val_acc: 0.4495\n",
            "Epoch 262/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1115 - acc: 0.9033 - val_loss: 1.0671 - val_acc: 0.4495\n",
            "Epoch 263/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1115 - acc: 0.9033 - val_loss: 1.0704 - val_acc: 0.4463\n",
            "Epoch 264/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1115 - acc: 0.9033 - val_loss: 1.0691 - val_acc: 0.4300\n",
            "Epoch 265/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1115 - acc: 0.9000 - val_loss: 1.0690 - val_acc: 0.4267\n",
            "Epoch 266/800\n",
            "300/300 [==============================] - 0s 423us/step - loss: 0.1115 - acc: 0.9067 - val_loss: 1.0682 - val_acc: 0.4332\n",
            "Epoch 267/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1115 - acc: 0.9033 - val_loss: 1.0686 - val_acc: 0.4463\n",
            "Epoch 268/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1115 - acc: 0.9067 - val_loss: 1.0683 - val_acc: 0.4463\n",
            "Epoch 269/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1115 - acc: 0.9033 - val_loss: 1.0687 - val_acc: 0.4495\n",
            "Epoch 270/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1115 - acc: 0.9100 - val_loss: 1.0690 - val_acc: 0.4300\n",
            "Epoch 271/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1116 - acc: 0.8900 - val_loss: 1.0667 - val_acc: 0.4300\n",
            "Epoch 272/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1115 - acc: 0.9067 - val_loss: 1.0727 - val_acc: 0.4463\n",
            "Epoch 273/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1115 - acc: 0.9000 - val_loss: 1.0673 - val_acc: 0.4495\n",
            "Epoch 274/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1115 - acc: 0.9033 - val_loss: 1.0695 - val_acc: 0.4528\n",
            "Epoch 275/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1115 - acc: 0.9033 - val_loss: 1.0661 - val_acc: 0.4397\n",
            "Epoch 276/800\n",
            "300/300 [==============================] - 0s 426us/step - loss: 0.1115 - acc: 0.9067 - val_loss: 1.0701 - val_acc: 0.4397\n",
            "Epoch 277/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1115 - acc: 0.9067 - val_loss: 1.0689 - val_acc: 0.4365\n",
            "Epoch 278/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1114 - acc: 0.9000 - val_loss: 1.0680 - val_acc: 0.4397\n",
            "Epoch 279/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1115 - acc: 0.9000 - val_loss: 1.0682 - val_acc: 0.4463\n",
            "Epoch 280/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1115 - acc: 0.8967 - val_loss: 1.0690 - val_acc: 0.4528\n",
            "Epoch 281/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1115 - acc: 0.9067 - val_loss: 1.0679 - val_acc: 0.4528\n",
            "Epoch 282/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1115 - acc: 0.9033 - val_loss: 1.0635 - val_acc: 0.4365\n",
            "Epoch 283/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1115 - acc: 0.9033 - val_loss: 1.0673 - val_acc: 0.4300\n",
            "Epoch 284/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1115 - acc: 0.9000 - val_loss: 1.0669 - val_acc: 0.4463\n",
            "Epoch 285/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1115 - acc: 0.9067 - val_loss: 1.0659 - val_acc: 0.4430\n",
            "Epoch 286/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1114 - acc: 0.9133 - val_loss: 1.0685 - val_acc: 0.4593\n",
            "Epoch 287/800\n",
            "300/300 [==============================] - 0s 435us/step - loss: 0.1115 - acc: 0.8967 - val_loss: 1.0660 - val_acc: 0.4528\n",
            "Epoch 288/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1114 - acc: 0.9000 - val_loss: 1.0676 - val_acc: 0.4463\n",
            "Epoch 289/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1115 - acc: 0.9067 - val_loss: 1.0663 - val_acc: 0.4365\n",
            "Epoch 290/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1115 - acc: 0.9000 - val_loss: 1.0697 - val_acc: 0.4528\n",
            "Epoch 291/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0703 - val_acc: 0.4332\n",
            "Epoch 292/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0684 - val_acc: 0.4463\n",
            "Epoch 293/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1114 - acc: 0.9000 - val_loss: 1.0670 - val_acc: 0.4463\n",
            "Epoch 294/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1115 - acc: 0.9000 - val_loss: 1.0679 - val_acc: 0.4300\n",
            "Epoch 295/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0698 - val_acc: 0.4463\n",
            "Epoch 296/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1114 - acc: 0.9067 - val_loss: 1.0661 - val_acc: 0.4463\n",
            "Epoch 297/800\n",
            "300/300 [==============================] - 0s 431us/step - loss: 0.1114 - acc: 0.9000 - val_loss: 1.0676 - val_acc: 0.4397\n",
            "Epoch 298/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1114 - acc: 0.9000 - val_loss: 1.0653 - val_acc: 0.4463\n",
            "Epoch 299/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1114 - acc: 0.9000 - val_loss: 1.0696 - val_acc: 0.4658\n",
            "Epoch 300/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1115 - acc: 0.9067 - val_loss: 1.0690 - val_acc: 0.4365\n",
            "Epoch 301/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1115 - acc: 0.9067 - val_loss: 1.0671 - val_acc: 0.4365\n",
            "Epoch 302/800\n",
            "300/300 [==============================] - 0s 388us/step - loss: 0.1115 - acc: 0.9067 - val_loss: 1.0666 - val_acc: 0.4397\n",
            "Epoch 303/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1115 - acc: 0.8967 - val_loss: 1.0692 - val_acc: 0.4332\n",
            "Epoch 304/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0684 - val_acc: 0.4593\n",
            "Epoch 305/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0652 - val_acc: 0.4593\n",
            "Epoch 306/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1114 - acc: 0.9067 - val_loss: 1.0646 - val_acc: 0.4332\n",
            "Epoch 307/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1115 - acc: 0.9033 - val_loss: 1.0663 - val_acc: 0.4300\n",
            "Epoch 308/800\n",
            "300/300 [==============================] - 0s 420us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0661 - val_acc: 0.4300\n",
            "Epoch 309/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1114 - acc: 0.9067 - val_loss: 1.0675 - val_acc: 0.4397\n",
            "Epoch 310/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1114 - acc: 0.9000 - val_loss: 1.0630 - val_acc: 0.4463\n",
            "Epoch 311/800\n",
            "300/300 [==============================] - 0s 383us/step - loss: 0.1114 - acc: 0.8967 - val_loss: 1.0680 - val_acc: 0.4463\n",
            "Epoch 312/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1114 - acc: 0.9067 - val_loss: 1.0655 - val_acc: 0.4300\n",
            "Epoch 313/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0684 - val_acc: 0.4463\n",
            "Epoch 314/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0679 - val_acc: 0.4397\n",
            "Epoch 315/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0663 - val_acc: 0.4528\n",
            "Epoch 316/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0672 - val_acc: 0.4463\n",
            "Epoch 317/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0665 - val_acc: 0.4300\n",
            "Epoch 318/800\n",
            "300/300 [==============================] - 0s 346us/step - loss: 0.1114 - acc: 0.9067 - val_loss: 1.0663 - val_acc: 0.4300\n",
            "Epoch 319/800\n",
            "300/300 [==============================] - 0s 413us/step - loss: 0.1115 - acc: 0.9000 - val_loss: 1.0666 - val_acc: 0.4300\n",
            "Epoch 320/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0662 - val_acc: 0.4300\n",
            "Epoch 321/800\n",
            "300/300 [==============================] - 0s 349us/step - loss: 0.1114 - acc: 0.9100 - val_loss: 1.0688 - val_acc: 0.4463\n",
            "Epoch 322/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0684 - val_acc: 0.4397\n",
            "Epoch 323/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1114 - acc: 0.9067 - val_loss: 1.0673 - val_acc: 0.4397\n",
            "Epoch 324/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1113 - acc: 0.9067 - val_loss: 1.0636 - val_acc: 0.4332\n",
            "Epoch 325/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0682 - val_acc: 0.4463\n",
            "Epoch 326/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1114 - acc: 0.9000 - val_loss: 1.0636 - val_acc: 0.4463\n",
            "Epoch 327/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0662 - val_acc: 0.4463\n",
            "Epoch 328/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0660 - val_acc: 0.4332\n",
            "Epoch 329/800\n",
            "300/300 [==============================] - 0s 339us/step - loss: 0.1113 - acc: 0.9067 - val_loss: 1.0636 - val_acc: 0.4365\n",
            "Epoch 330/800\n",
            "300/300 [==============================] - 0s 403us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0654 - val_acc: 0.4463\n",
            "Epoch 331/800\n",
            "300/300 [==============================] - 0s 349us/step - loss: 0.1114 - acc: 0.9067 - val_loss: 1.0706 - val_acc: 0.4658\n",
            "Epoch 332/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0657 - val_acc: 0.4463\n",
            "Epoch 333/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1113 - acc: 0.9067 - val_loss: 1.0632 - val_acc: 0.4267\n",
            "Epoch 334/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1114 - acc: 0.9000 - val_loss: 1.0680 - val_acc: 0.4300\n",
            "Epoch 335/800\n",
            "300/300 [==============================] - 0s 344us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0652 - val_acc: 0.4365\n",
            "Epoch 336/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1113 - acc: 0.9000 - val_loss: 1.0670 - val_acc: 0.4463\n",
            "Epoch 337/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0625 - val_acc: 0.4463\n",
            "Epoch 338/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0660 - val_acc: 0.4528\n",
            "Epoch 339/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1113 - acc: 0.9100 - val_loss: 1.0642 - val_acc: 0.4267\n",
            "Epoch 340/800\n",
            "300/300 [==============================] - 0s 343us/step - loss: 0.1113 - acc: 0.9067 - val_loss: 1.0637 - val_acc: 0.4463\n",
            "Epoch 341/800\n",
            "300/300 [==============================] - 0s 404us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0633 - val_acc: 0.4463\n",
            "Epoch 342/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0673 - val_acc: 0.4528\n",
            "Epoch 343/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0651 - val_acc: 0.4300\n",
            "Epoch 344/800\n",
            "300/300 [==============================] - 0s 339us/step - loss: 0.1114 - acc: 0.9000 - val_loss: 1.0639 - val_acc: 0.4463\n",
            "Epoch 345/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0636 - val_acc: 0.4365\n",
            "Epoch 346/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0687 - val_acc: 0.4397\n",
            "Epoch 347/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1113 - acc: 0.9067 - val_loss: 1.0660 - val_acc: 0.4463\n",
            "Epoch 348/800\n",
            "300/300 [==============================] - 0s 337us/step - loss: 0.1113 - acc: 0.9067 - val_loss: 1.0666 - val_acc: 0.4495\n",
            "Epoch 349/800\n",
            "300/300 [==============================] - 0s 338us/step - loss: 0.1113 - acc: 0.9067 - val_loss: 1.0671 - val_acc: 0.4463\n",
            "Epoch 350/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1113 - acc: 0.9067 - val_loss: 1.0682 - val_acc: 0.4495\n",
            "Epoch 351/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0674 - val_acc: 0.4528\n",
            "Epoch 352/800\n",
            "300/300 [==============================] - 0s 400us/step - loss: 0.1113 - acc: 0.9000 - val_loss: 1.0647 - val_acc: 0.4463\n",
            "Epoch 353/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0632 - val_acc: 0.4495\n",
            "Epoch 354/800\n",
            "300/300 [==============================] - 0s 342us/step - loss: 0.1113 - acc: 0.9000 - val_loss: 1.0637 - val_acc: 0.4495\n",
            "Epoch 355/800\n",
            "300/300 [==============================] - 0s 384us/step - loss: 0.1114 - acc: 0.9033 - val_loss: 1.0665 - val_acc: 0.4528\n",
            "Epoch 356/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1113 - acc: 0.9067 - val_loss: 1.0625 - val_acc: 0.4300\n",
            "Epoch 357/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1113 - acc: 0.9067 - val_loss: 1.0656 - val_acc: 0.4495\n",
            "Epoch 358/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1112 - acc: 0.9000 - val_loss: 1.0673 - val_acc: 0.4463\n",
            "Epoch 359/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1113 - acc: 0.9067 - val_loss: 1.0641 - val_acc: 0.4365\n",
            "Epoch 360/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1113 - acc: 0.9000 - val_loss: 1.0690 - val_acc: 0.4463\n",
            "Epoch 361/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1112 - acc: 0.9100 - val_loss: 1.0655 - val_acc: 0.4463\n",
            "Epoch 362/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1113 - acc: 0.9100 - val_loss: 1.0685 - val_acc: 0.4463\n",
            "Epoch 363/800\n",
            "300/300 [==============================] - 0s 411us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0678 - val_acc: 0.4365\n",
            "Epoch 364/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1112 - acc: 0.9033 - val_loss: 1.0676 - val_acc: 0.4397\n",
            "Epoch 365/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1112 - acc: 0.9067 - val_loss: 1.0652 - val_acc: 0.4463\n",
            "Epoch 366/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0629 - val_acc: 0.4300\n",
            "Epoch 367/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0699 - val_acc: 0.4300\n",
            "Epoch 368/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0651 - val_acc: 0.4300\n",
            "Epoch 369/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1113 - acc: 0.9067 - val_loss: 1.0654 - val_acc: 0.4300\n",
            "Epoch 370/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1112 - acc: 0.9100 - val_loss: 1.0685 - val_acc: 0.4300\n",
            "Epoch 371/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1112 - acc: 0.9067 - val_loss: 1.0687 - val_acc: 0.4397\n",
            "Epoch 372/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1113 - acc: 0.9033 - val_loss: 1.0653 - val_acc: 0.4430\n",
            "Epoch 373/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1112 - acc: 0.9067 - val_loss: 1.0613 - val_acc: 0.4365\n",
            "Epoch 374/800\n",
            "300/300 [==============================] - 0s 437us/step - loss: 0.1112 - acc: 0.9100 - val_loss: 1.0644 - val_acc: 0.4463\n",
            "Epoch 375/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1112 - acc: 0.9067 - val_loss: 1.0662 - val_acc: 0.4463\n",
            "Epoch 376/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1113 - acc: 0.9067 - val_loss: 1.0671 - val_acc: 0.4463\n",
            "Epoch 377/800\n",
            "300/300 [==============================] - 0s 382us/step - loss: 0.1112 - acc: 0.9133 - val_loss: 1.0652 - val_acc: 0.4463\n",
            "Epoch 378/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1112 - acc: 0.9000 - val_loss: 1.0670 - val_acc: 0.4463\n",
            "Epoch 379/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1112 - acc: 0.9100 - val_loss: 1.0659 - val_acc: 0.4365\n",
            "Epoch 380/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1112 - acc: 0.9067 - val_loss: 1.0675 - val_acc: 0.4528\n",
            "Epoch 381/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1112 - acc: 0.9100 - val_loss: 1.0639 - val_acc: 0.4463\n",
            "Epoch 382/800\n",
            "300/300 [==============================] - 0s 380us/step - loss: 0.1112 - acc: 0.9033 - val_loss: 1.0661 - val_acc: 0.4365\n",
            "Epoch 383/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1112 - acc: 0.9033 - val_loss: 1.0651 - val_acc: 0.4267\n",
            "Epoch 384/800\n",
            "300/300 [==============================] - 0s 423us/step - loss: 0.1112 - acc: 0.9033 - val_loss: 1.0645 - val_acc: 0.4430\n",
            "Epoch 385/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1111 - acc: 0.9067 - val_loss: 1.0677 - val_acc: 0.4397\n",
            "Epoch 386/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1112 - acc: 0.9067 - val_loss: 1.0677 - val_acc: 0.4300\n",
            "Epoch 387/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1112 - acc: 0.9033 - val_loss: 1.0702 - val_acc: 0.4463\n",
            "Epoch 388/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1112 - acc: 0.9033 - val_loss: 1.0623 - val_acc: 0.4267\n",
            "Epoch 389/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1112 - acc: 0.9000 - val_loss: 1.0714 - val_acc: 0.4463\n",
            "Epoch 390/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1112 - acc: 0.9000 - val_loss: 1.0677 - val_acc: 0.4397\n",
            "Epoch 391/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1112 - acc: 0.9033 - val_loss: 1.0648 - val_acc: 0.4365\n",
            "Epoch 392/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1111 - acc: 0.9000 - val_loss: 1.0640 - val_acc: 0.4300\n",
            "Epoch 393/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1112 - acc: 0.9100 - val_loss: 1.0612 - val_acc: 0.4365\n",
            "Epoch 394/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1112 - acc: 0.9067 - val_loss: 1.0632 - val_acc: 0.4397\n",
            "Epoch 395/800\n",
            "300/300 [==============================] - 0s 430us/step - loss: 0.1112 - acc: 0.9033 - val_loss: 1.0619 - val_acc: 0.4332\n",
            "Epoch 396/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1112 - acc: 0.9067 - val_loss: 1.0643 - val_acc: 0.4365\n",
            "Epoch 397/800\n",
            "300/300 [==============================] - 0s 382us/step - loss: 0.1111 - acc: 0.9067 - val_loss: 1.0616 - val_acc: 0.4300\n",
            "Epoch 398/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1111 - acc: 0.9100 - val_loss: 1.0661 - val_acc: 0.4332\n",
            "Epoch 399/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1111 - acc: 0.9067 - val_loss: 1.0630 - val_acc: 0.4365\n",
            "Epoch 400/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1111 - acc: 0.8967 - val_loss: 1.0656 - val_acc: 0.4463\n",
            "Epoch 401/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1111 - acc: 0.9000 - val_loss: 1.0629 - val_acc: 0.4332\n",
            "Epoch 402/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1112 - acc: 0.9067 - val_loss: 1.0645 - val_acc: 0.4463\n",
            "Epoch 403/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1111 - acc: 0.9100 - val_loss: 1.0616 - val_acc: 0.4463\n",
            "Epoch 404/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1112 - acc: 0.9200 - val_loss: 1.0633 - val_acc: 0.4300\n",
            "Epoch 405/800\n",
            "300/300 [==============================] - 0s 419us/step - loss: 0.1111 - acc: 0.9067 - val_loss: 1.0602 - val_acc: 0.4267\n",
            "Epoch 406/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1111 - acc: 0.9067 - val_loss: 1.0648 - val_acc: 0.4495\n",
            "Epoch 407/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1111 - acc: 0.9100 - val_loss: 1.0627 - val_acc: 0.4300\n",
            "Epoch 408/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1112 - acc: 0.9100 - val_loss: 1.0639 - val_acc: 0.4300\n",
            "Epoch 409/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1111 - acc: 0.9100 - val_loss: 1.0666 - val_acc: 0.4365\n",
            "Epoch 410/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1111 - acc: 0.9033 - val_loss: 1.0657 - val_acc: 0.4528\n",
            "Epoch 411/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1111 - acc: 0.9067 - val_loss: 1.0645 - val_acc: 0.4397\n",
            "Epoch 412/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1111 - acc: 0.9067 - val_loss: 1.0655 - val_acc: 0.4463\n",
            "Epoch 413/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1111 - acc: 0.9033 - val_loss: 1.0646 - val_acc: 0.4267\n",
            "Epoch 414/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1112 - acc: 0.9067 - val_loss: 1.0690 - val_acc: 0.4300\n",
            "Epoch 415/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1111 - acc: 0.9100 - val_loss: 1.0657 - val_acc: 0.4397\n",
            "Epoch 416/800\n",
            "300/300 [==============================] - 0s 421us/step - loss: 0.1111 - acc: 0.9100 - val_loss: 1.0628 - val_acc: 0.4202\n",
            "Epoch 417/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1113 - acc: 0.9000 - val_loss: 1.0665 - val_acc: 0.4267\n",
            "Epoch 418/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1112 - acc: 0.9000 - val_loss: 1.0646 - val_acc: 0.4365\n",
            "Epoch 419/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1111 - acc: 0.9067 - val_loss: 1.0611 - val_acc: 0.4300\n",
            "Epoch 420/800\n",
            "300/300 [==============================] - 0s 383us/step - loss: 0.1111 - acc: 0.9067 - val_loss: 1.0613 - val_acc: 0.4202\n",
            "Epoch 421/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1111 - acc: 0.9033 - val_loss: 1.0655 - val_acc: 0.4235\n",
            "Epoch 422/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1111 - acc: 0.9033 - val_loss: 1.0631 - val_acc: 0.4169\n",
            "Epoch 423/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1111 - acc: 0.9033 - val_loss: 1.0622 - val_acc: 0.4300\n",
            "Epoch 424/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1112 - acc: 0.9133 - val_loss: 1.0614 - val_acc: 0.4267\n",
            "Epoch 425/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1111 - acc: 0.9067 - val_loss: 1.0665 - val_acc: 0.4463\n",
            "Epoch 426/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1110 - acc: 0.9033 - val_loss: 1.0619 - val_acc: 0.4235\n",
            "Epoch 427/800\n",
            "300/300 [==============================] - 0s 421us/step - loss: 0.1111 - acc: 0.9033 - val_loss: 1.0623 - val_acc: 0.4463\n",
            "Epoch 428/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1110 - acc: 0.9067 - val_loss: 1.0605 - val_acc: 0.4463\n",
            "Epoch 429/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1111 - acc: 0.9100 - val_loss: 1.0594 - val_acc: 0.4463\n",
            "Epoch 430/800\n",
            "300/300 [==============================] - 0s 392us/step - loss: 0.1111 - acc: 0.9000 - val_loss: 1.0644 - val_acc: 0.4300\n",
            "Epoch 431/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1111 - acc: 0.9067 - val_loss: 1.0644 - val_acc: 0.4397\n",
            "Epoch 432/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1110 - acc: 0.9067 - val_loss: 1.0639 - val_acc: 0.4528\n",
            "Epoch 433/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1111 - acc: 0.9000 - val_loss: 1.0631 - val_acc: 0.4463\n",
            "Epoch 434/800\n",
            "300/300 [==============================] - 0s 381us/step - loss: 0.1110 - acc: 0.9100 - val_loss: 1.0667 - val_acc: 0.4560\n",
            "Epoch 435/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1111 - acc: 0.9067 - val_loss: 1.0607 - val_acc: 0.4300\n",
            "Epoch 436/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1110 - acc: 0.9033 - val_loss: 1.0638 - val_acc: 0.4300\n",
            "Epoch 437/800\n",
            "300/300 [==============================] - 0s 437us/step - loss: 0.1110 - acc: 0.9033 - val_loss: 1.0599 - val_acc: 0.4332\n",
            "Epoch 438/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1110 - acc: 0.9033 - val_loss: 1.0602 - val_acc: 0.4202\n",
            "Epoch 439/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1111 - acc: 0.9033 - val_loss: 1.0623 - val_acc: 0.4169\n",
            "Epoch 440/800\n",
            "300/300 [==============================] - 0s 388us/step - loss: 0.1111 - acc: 0.9100 - val_loss: 1.0668 - val_acc: 0.4332\n",
            "Epoch 441/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1110 - acc: 0.9100 - val_loss: 1.0652 - val_acc: 0.4365\n",
            "Epoch 442/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1110 - acc: 0.9033 - val_loss: 1.0611 - val_acc: 0.4300\n",
            "Epoch 443/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1110 - acc: 0.9100 - val_loss: 1.0629 - val_acc: 0.4495\n",
            "Epoch 444/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1110 - acc: 0.9067 - val_loss: 1.0569 - val_acc: 0.4267\n",
            "Epoch 445/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1111 - acc: 0.9033 - val_loss: 1.0628 - val_acc: 0.4463\n",
            "Epoch 446/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1110 - acc: 0.9100 - val_loss: 1.0623 - val_acc: 0.4397\n",
            "Epoch 447/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1110 - acc: 0.9100 - val_loss: 1.0623 - val_acc: 0.4365\n",
            "\n",
            "Epoch 00447: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 448/800\n",
            "300/300 [==============================] - 0s 423us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0615 - val_acc: 0.4300\n",
            "Epoch 449/800\n",
            "300/300 [==============================] - 0s 384us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0619 - val_acc: 0.4365\n",
            "Epoch 450/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1109 - acc: 0.9033 - val_loss: 1.0623 - val_acc: 0.4365\n",
            "Epoch 451/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0625 - val_acc: 0.4365\n",
            "Epoch 452/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0626 - val_acc: 0.4332\n",
            "Epoch 453/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1109 - acc: 0.9033 - val_loss: 1.0626 - val_acc: 0.4300\n",
            "Epoch 454/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0632 - val_acc: 0.4365\n",
            "Epoch 455/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0631 - val_acc: 0.4300\n",
            "Epoch 456/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0629 - val_acc: 0.4300\n",
            "Epoch 457/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0631 - val_acc: 0.4300\n",
            "Epoch 458/800\n",
            "300/300 [==============================] - 0s 423us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0633 - val_acc: 0.4365\n",
            "Epoch 459/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1109 - acc: 0.9033 - val_loss: 1.0622 - val_acc: 0.4300\n",
            "Epoch 460/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1109 - acc: 0.9133 - val_loss: 1.0623 - val_acc: 0.4365\n",
            "Epoch 461/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0628 - val_acc: 0.4365\n",
            "Epoch 462/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1108 - acc: 0.9133 - val_loss: 1.0622 - val_acc: 0.4397\n",
            "Epoch 463/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0615 - val_acc: 0.4397\n",
            "Epoch 464/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0617 - val_acc: 0.4397\n",
            "Epoch 465/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0616 - val_acc: 0.4365\n",
            "Epoch 466/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0619 - val_acc: 0.4300\n",
            "Epoch 467/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0616 - val_acc: 0.4300\n",
            "Epoch 468/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0622 - val_acc: 0.4300\n",
            "Epoch 469/800\n",
            "300/300 [==============================] - 0s 432us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0622 - val_acc: 0.4300\n",
            "Epoch 470/800\n",
            "300/300 [==============================] - 0s 382us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0621 - val_acc: 0.4300\n",
            "Epoch 471/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0622 - val_acc: 0.4300\n",
            "Epoch 472/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0627 - val_acc: 0.4300\n",
            "Epoch 473/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0624 - val_acc: 0.4300\n",
            "Epoch 474/800\n",
            "300/300 [==============================] - 0s 380us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0626 - val_acc: 0.4300\n",
            "Epoch 475/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0633 - val_acc: 0.4365\n",
            "Epoch 476/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0628 - val_acc: 0.4397\n",
            "Epoch 477/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0616 - val_acc: 0.4430\n",
            "Epoch 478/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0624 - val_acc: 0.4397\n",
            "Epoch 479/800\n",
            "300/300 [==============================] - 0s 407us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0630 - val_acc: 0.4300\n",
            "Epoch 480/800\n",
            "300/300 [==============================] - 0s 384us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0627 - val_acc: 0.4300\n",
            "Epoch 481/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0629 - val_acc: 0.4300\n",
            "Epoch 482/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0628 - val_acc: 0.4365\n",
            "Epoch 483/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0621 - val_acc: 0.4365\n",
            "Epoch 484/800\n",
            "300/300 [==============================] - 0s 383us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0613 - val_acc: 0.4300\n",
            "Epoch 485/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0619 - val_acc: 0.4300\n",
            "Epoch 486/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0625 - val_acc: 0.4365\n",
            "Epoch 487/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0628 - val_acc: 0.4300\n",
            "Epoch 488/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0627 - val_acc: 0.4365\n",
            "Epoch 489/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0617 - val_acc: 0.4332\n",
            "Epoch 490/800\n",
            "300/300 [==============================] - 0s 394us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0625 - val_acc: 0.4332\n",
            "Epoch 491/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1109 - acc: 0.9067 - val_loss: 1.0624 - val_acc: 0.4332\n",
            "Epoch 492/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0624 - val_acc: 0.4397\n",
            "Epoch 493/800\n",
            "300/300 [==============================] - 0s 343us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0627 - val_acc: 0.4463\n",
            "Epoch 494/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0624 - val_acc: 0.4300\n",
            "Epoch 495/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0618 - val_acc: 0.4300\n",
            "Epoch 496/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0621 - val_acc: 0.4300\n",
            "Epoch 497/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0627 - val_acc: 0.4300\n",
            "Epoch 498/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0628 - val_acc: 0.4332\n",
            "Epoch 499/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0634 - val_acc: 0.4365\n",
            "Epoch 500/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0614 - val_acc: 0.4365\n",
            "Epoch 501/800\n",
            "300/300 [==============================] - 0s 397us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0618 - val_acc: 0.4365\n",
            "Epoch 502/800\n",
            "300/300 [==============================] - 0s 344us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0629 - val_acc: 0.4365\n",
            "Epoch 503/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0624 - val_acc: 0.4332\n",
            "Epoch 504/800\n",
            "300/300 [==============================] - 0s 349us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0617 - val_acc: 0.4300\n",
            "Epoch 505/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0612 - val_acc: 0.4332\n",
            "Epoch 506/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0612 - val_acc: 0.4365\n",
            "Epoch 507/800\n",
            "300/300 [==============================] - 0s 349us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0616 - val_acc: 0.4365\n",
            "Epoch 508/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0617 - val_acc: 0.4300\n",
            "Epoch 509/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0626 - val_acc: 0.4300\n",
            "Epoch 510/800\n",
            "300/300 [==============================] - 0s 343us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0622 - val_acc: 0.4365\n",
            "Epoch 511/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0616 - val_acc: 0.4365\n",
            "Epoch 512/800\n",
            "300/300 [==============================] - 0s 405us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0624 - val_acc: 0.4397\n",
            "Epoch 513/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0626 - val_acc: 0.4365\n",
            "Epoch 514/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0621 - val_acc: 0.4365\n",
            "Epoch 515/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0609 - val_acc: 0.4365\n",
            "Epoch 516/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0617 - val_acc: 0.4397\n",
            "Epoch 517/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0622 - val_acc: 0.4397\n",
            "Epoch 518/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0611 - val_acc: 0.4300\n",
            "Epoch 519/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1109 - acc: 0.9100 - val_loss: 1.0619 - val_acc: 0.4300\n",
            "Epoch 520/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0629 - val_acc: 0.4300\n",
            "Epoch 521/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0621 - val_acc: 0.4300\n",
            "Epoch 522/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0621 - val_acc: 0.4365\n",
            "Epoch 523/800\n",
            "300/300 [==============================] - 0s 423us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0623 - val_acc: 0.4365\n",
            "Epoch 524/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0618 - val_acc: 0.4397\n",
            "Epoch 525/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0615 - val_acc: 0.4397\n",
            "Epoch 526/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0617 - val_acc: 0.4365\n",
            "Epoch 527/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0617 - val_acc: 0.4300\n",
            "Epoch 528/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0614 - val_acc: 0.4300\n",
            "Epoch 529/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0611 - val_acc: 0.4332\n",
            "Epoch 530/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0612 - val_acc: 0.4300\n",
            "Epoch 531/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0619 - val_acc: 0.4300\n",
            "Epoch 532/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0618 - val_acc: 0.4300\n",
            "Epoch 533/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0613 - val_acc: 0.4300\n",
            "Epoch 534/800\n",
            "300/300 [==============================] - 0s 430us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0615 - val_acc: 0.4300\n",
            "Epoch 535/800\n",
            "300/300 [==============================] - 0s 381us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0619 - val_acc: 0.4300\n",
            "Epoch 536/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0614 - val_acc: 0.4300\n",
            "Epoch 537/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0619 - val_acc: 0.4300\n",
            "Epoch 538/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0616 - val_acc: 0.4300\n",
            "Epoch 539/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0614 - val_acc: 0.4300\n",
            "Epoch 540/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0613 - val_acc: 0.4300\n",
            "Epoch 541/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0615 - val_acc: 0.4300\n",
            "Epoch 542/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0614 - val_acc: 0.4300\n",
            "Epoch 543/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0625 - val_acc: 0.4300\n",
            "Epoch 544/800\n",
            "300/300 [==============================] - 0s 430us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0628 - val_acc: 0.4300\n",
            "Epoch 545/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0626 - val_acc: 0.4332\n",
            "Epoch 546/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0621 - val_acc: 0.4365\n",
            "Epoch 547/800\n",
            "300/300 [==============================] - 0s 380us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0617 - val_acc: 0.4332\n",
            "Epoch 548/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0616 - val_acc: 0.4300\n",
            "Epoch 549/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0618 - val_acc: 0.4300\n",
            "Epoch 550/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0623 - val_acc: 0.4300\n",
            "Epoch 551/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0616 - val_acc: 0.4300\n",
            "Epoch 552/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0612 - val_acc: 0.4300\n",
            "Epoch 553/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0615 - val_acc: 0.4300\n",
            "Epoch 554/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0612 - val_acc: 0.4300\n",
            "Epoch 555/800\n",
            "300/300 [==============================] - 0s 422us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0604 - val_acc: 0.4300\n",
            "Epoch 556/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0612 - val_acc: 0.4365\n",
            "Epoch 557/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0611 - val_acc: 0.4300\n",
            "Epoch 558/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0612 - val_acc: 0.4300\n",
            "Epoch 559/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0620 - val_acc: 0.4300\n",
            "Epoch 560/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0610 - val_acc: 0.4300\n",
            "Epoch 561/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0609 - val_acc: 0.4300\n",
            "Epoch 562/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0616 - val_acc: 0.4365\n",
            "Epoch 563/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0606 - val_acc: 0.4365\n",
            "Epoch 564/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0606 - val_acc: 0.4365\n",
            "Epoch 565/800\n",
            "300/300 [==============================] - 0s 404us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0616 - val_acc: 0.4365\n",
            "Epoch 566/800\n",
            "300/300 [==============================] - 0s 406us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0620 - val_acc: 0.4365\n",
            "Epoch 567/800\n",
            "300/300 [==============================] - 0s 380us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0619 - val_acc: 0.4300\n",
            "Epoch 568/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0615 - val_acc: 0.4365\n",
            "Epoch 569/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0604 - val_acc: 0.4300\n",
            "Epoch 570/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0603 - val_acc: 0.4300\n",
            "Epoch 571/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0600 - val_acc: 0.4300\n",
            "Epoch 572/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0603 - val_acc: 0.4365\n",
            "Epoch 573/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0612 - val_acc: 0.4365\n",
            "Epoch 574/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0607 - val_acc: 0.4300\n",
            "Epoch 575/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0606 - val_acc: 0.4300\n",
            "Epoch 576/800\n",
            "300/300 [==============================] - 0s 419us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0608 - val_acc: 0.4300\n",
            "Epoch 577/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0611 - val_acc: 0.4300\n",
            "Epoch 578/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0610 - val_acc: 0.4300\n",
            "Epoch 579/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0610 - val_acc: 0.4300\n",
            "Epoch 580/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1108 - acc: 0.9033 - val_loss: 1.0613 - val_acc: 0.4300\n",
            "Epoch 581/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0622 - val_acc: 0.4300\n",
            "Epoch 582/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0617 - val_acc: 0.4267\n",
            "Epoch 583/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0628 - val_acc: 0.4300\n",
            "Epoch 584/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1108 - acc: 0.9000 - val_loss: 1.0623 - val_acc: 0.4300\n",
            "Epoch 585/800\n",
            "300/300 [==============================] - 0s 381us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0607 - val_acc: 0.4300\n",
            "Epoch 586/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0607 - val_acc: 0.4365\n",
            "Epoch 587/800\n",
            "300/300 [==============================] - 0s 407us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0610 - val_acc: 0.4365\n",
            "Epoch 588/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0613 - val_acc: 0.4397\n",
            "Epoch 589/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1108 - acc: 0.9033 - val_loss: 1.0602 - val_acc: 0.4300\n",
            "Epoch 590/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 591/800\n",
            "300/300 [==============================] - 0s 383us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0601 - val_acc: 0.4332\n",
            "Epoch 592/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0603 - val_acc: 0.4300\n",
            "Epoch 593/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1108 - acc: 0.9133 - val_loss: 1.0601 - val_acc: 0.4332\n",
            "Epoch 594/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1108 - acc: 0.9133 - val_loss: 1.0610 - val_acc: 0.4365\n",
            "Epoch 595/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0610 - val_acc: 0.4300\n",
            "Epoch 596/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0608 - val_acc: 0.4300\n",
            "Epoch 597/800\n",
            "300/300 [==============================] - 0s 422us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0607 - val_acc: 0.4300\n",
            "Epoch 598/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0605 - val_acc: 0.4300\n",
            "Epoch 599/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0620 - val_acc: 0.4365\n",
            "Epoch 600/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0607 - val_acc: 0.4300\n",
            "Epoch 601/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1108 - acc: 0.9033 - val_loss: 1.0609 - val_acc: 0.4300\n",
            "Epoch 602/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1108 - acc: 0.9033 - val_loss: 1.0618 - val_acc: 0.4267\n",
            "Epoch 603/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0618 - val_acc: 0.4235\n",
            "Epoch 604/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0614 - val_acc: 0.4267\n",
            "Epoch 605/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0609 - val_acc: 0.4300\n",
            "Epoch 606/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0602 - val_acc: 0.4365\n",
            "Epoch 607/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0601 - val_acc: 0.4365\n",
            "Epoch 608/800\n",
            "300/300 [==============================] - 0s 402us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0603 - val_acc: 0.4332\n",
            "Epoch 609/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0603 - val_acc: 0.4300\n",
            "Epoch 610/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0606 - val_acc: 0.4300\n",
            "Epoch 611/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0607 - val_acc: 0.4300\n",
            "Epoch 612/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0611 - val_acc: 0.4300\n",
            "Epoch 613/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 614/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 615/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0611 - val_acc: 0.4300\n",
            "Epoch 616/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0616 - val_acc: 0.4300\n",
            "Epoch 617/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0605 - val_acc: 0.4300\n",
            "Epoch 618/800\n",
            "300/300 [==============================] - 0s 418us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0605 - val_acc: 0.4300\n",
            "Epoch 619/800\n",
            "300/300 [==============================] - 0s 387us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0613 - val_acc: 0.4365\n",
            "Epoch 620/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0606 - val_acc: 0.4332\n",
            "Epoch 621/800\n",
            "300/300 [==============================] - 0s 383us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0611 - val_acc: 0.4365\n",
            "Epoch 622/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0613 - val_acc: 0.4365\n",
            "Epoch 623/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0608 - val_acc: 0.4300\n",
            "Epoch 624/800\n",
            "300/300 [==============================] - 0s 382us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 625/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0610 - val_acc: 0.4300\n",
            "Epoch 626/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0604 - val_acc: 0.4365\n",
            "Epoch 627/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 628/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0607 - val_acc: 0.4300\n",
            "Epoch 629/800\n",
            "300/300 [==============================] - 0s 421us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0604 - val_acc: 0.4300\n",
            "Epoch 630/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0610 - val_acc: 0.4300\n",
            "Epoch 631/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 632/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0600 - val_acc: 0.4365\n",
            "Epoch 633/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0608 - val_acc: 0.4300\n",
            "Epoch 634/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0608 - val_acc: 0.4300\n",
            "Epoch 635/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 636/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1107 - acc: 0.9067 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 637/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 638/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0593 - val_acc: 0.4300\n",
            "Epoch 639/800\n",
            "300/300 [==============================] - 0s 398us/step - loss: 0.1108 - acc: 0.9100 - val_loss: 1.0608 - val_acc: 0.4332\n",
            "Epoch 640/800\n",
            "300/300 [==============================] - 0s 408us/step - loss: 0.1108 - acc: 0.9067 - val_loss: 1.0605 - val_acc: 0.4365\n",
            "Epoch 641/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1107 - acc: 0.9067 - val_loss: 1.0600 - val_acc: 0.4365\n",
            "Epoch 642/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0605 - val_acc: 0.4365\n",
            "Epoch 643/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1107 - acc: 0.9067 - val_loss: 1.0602 - val_acc: 0.4300\n",
            "Epoch 644/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 645/800\n",
            "300/300 [==============================] - 0s 388us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0603 - val_acc: 0.4300\n",
            "Epoch 646/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1108 - acc: 0.9033 - val_loss: 1.0603 - val_acc: 0.4300\n",
            "Epoch 647/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "\n",
            "Epoch 00647: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
            "Epoch 648/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 649/800\n",
            "300/300 [==============================] - 0s 381us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 650/800\n",
            "300/300 [==============================] - 0s 419us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0600 - val_acc: 0.4300\n",
            "Epoch 651/800\n",
            "300/300 [==============================] - 0s 392us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0600 - val_acc: 0.4300\n",
            "Epoch 652/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 653/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 654/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 655/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 656/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 657/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 658/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 659/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 660/800\n",
            "300/300 [==============================] - 0s 391us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 661/800\n",
            "300/300 [==============================] - 0s 380us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 662/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 663/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 664/800\n",
            "300/300 [==============================] - 0s 343us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 665/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1107 - acc: 0.9067 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 666/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1107 - acc: 0.9067 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 667/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1107 - acc: 0.9067 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 668/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1107 - acc: 0.9067 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 669/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 670/800\n",
            "300/300 [==============================] - 0s 340us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 671/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 672/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1107 - acc: 0.9067 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 673/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 674/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 675/800\n",
            "300/300 [==============================] - 0s 344us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 676/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 677/800\n",
            "300/300 [==============================] - 0s 341us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 678/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 679/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 680/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 681/800\n",
            "300/300 [==============================] - 0s 349us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 682/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 683/800\n",
            "300/300 [==============================] - 0s 411us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 684/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 685/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0594 - val_acc: 0.4300\n",
            "Epoch 686/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 687/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 688/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 689/800\n",
            "300/300 [==============================] - 0s 346us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 690/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 691/800\n",
            "300/300 [==============================] - 0s 341us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 692/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 693/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 694/800\n",
            "300/300 [==============================] - 0s 410us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 695/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0600 - val_acc: 0.4300\n",
            "Epoch 696/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 697/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1107 - acc: 0.9067 - val_loss: 1.0601 - val_acc: 0.4300\n",
            "Epoch 698/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0601 - val_acc: 0.4300\n",
            "Epoch 699/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0602 - val_acc: 0.4300\n",
            "Epoch 700/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0600 - val_acc: 0.4300\n",
            "Epoch 701/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0601 - val_acc: 0.4300\n",
            "Epoch 702/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0601 - val_acc: 0.4300\n",
            "Epoch 703/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0600 - val_acc: 0.4300\n",
            "Epoch 704/800\n",
            "300/300 [==============================] - 0s 406us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 705/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 706/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 707/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0600 - val_acc: 0.4300\n",
            "Epoch 708/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 709/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 710/800\n",
            "300/300 [==============================] - 0s 380us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 711/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0600 - val_acc: 0.4300\n",
            "Epoch 712/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 713/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 714/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 715/800\n",
            "300/300 [==============================] - 0s 405us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0600 - val_acc: 0.4300\n",
            "Epoch 716/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0601 - val_acc: 0.4300\n",
            "Epoch 717/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0602 - val_acc: 0.4300\n",
            "Epoch 718/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0601 - val_acc: 0.4300\n",
            "Epoch 719/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0601 - val_acc: 0.4300\n",
            "Epoch 720/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 721/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0602 - val_acc: 0.4300\n",
            "Epoch 722/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0602 - val_acc: 0.4300\n",
            "Epoch 723/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0604 - val_acc: 0.4300\n",
            "Epoch 724/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0603 - val_acc: 0.4300\n",
            "Epoch 725/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0601 - val_acc: 0.4300\n",
            "Epoch 726/800\n",
            "300/300 [==============================] - 0s 430us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0604 - val_acc: 0.4300\n",
            "Epoch 727/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0605 - val_acc: 0.4300\n",
            "Epoch 728/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0603 - val_acc: 0.4300\n",
            "Epoch 729/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0603 - val_acc: 0.4300\n",
            "Epoch 730/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0603 - val_acc: 0.4300\n",
            "Epoch 731/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0604 - val_acc: 0.4300\n",
            "Epoch 732/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0603 - val_acc: 0.4300\n",
            "Epoch 733/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1107 - acc: 0.9067 - val_loss: 1.0600 - val_acc: 0.4300\n",
            "Epoch 734/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 735/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 736/800\n",
            "300/300 [==============================] - 0s 433us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 737/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 738/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 739/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0600 - val_acc: 0.4300\n",
            "Epoch 740/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1107 - acc: 0.9067 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 741/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 742/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1107 - acc: 0.9067 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 743/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 744/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 745/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 746/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 747/800\n",
            "300/300 [==============================] - 0s 429us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 748/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 749/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 750/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 751/800\n",
            "300/300 [==============================] - 0s 385us/step - loss: 0.1107 - acc: 0.9067 - val_loss: 1.0600 - val_acc: 0.4300\n",
            "Epoch 752/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0600 - val_acc: 0.4300\n",
            "Epoch 753/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 754/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 755/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0593 - val_acc: 0.4300\n",
            "Epoch 756/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0594 - val_acc: 0.4300\n",
            "Epoch 757/800\n",
            "300/300 [==============================] - 0s 401us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0593 - val_acc: 0.4300\n",
            "Epoch 758/800\n",
            "300/300 [==============================] - 0s 391us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0593 - val_acc: 0.4300\n",
            "Epoch 759/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 760/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 761/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 762/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 763/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 764/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 765/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 766/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 767/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 768/800\n",
            "300/300 [==============================] - 0s 414us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 769/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 770/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 771/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 772/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 773/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0594 - val_acc: 0.4300\n",
            "Epoch 774/800\n",
            "300/300 [==============================] - 0s 378us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 775/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 776/800\n",
            "300/300 [==============================] - 0s 382us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 777/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 778/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0594 - val_acc: 0.4300\n",
            "Epoch 779/800\n",
            "300/300 [==============================] - 0s 422us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 780/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 781/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 782/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 783/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 784/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0599 - val_acc: 0.4300\n",
            "Epoch 785/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0600 - val_acc: 0.4300\n",
            "Epoch 786/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 787/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 788/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 789/800\n",
            "300/300 [==============================] - 0s 423us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0598 - val_acc: 0.4300\n",
            "Epoch 790/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1107 - acc: 0.9067 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 791/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0594 - val_acc: 0.4300\n",
            "Epoch 792/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 793/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 794/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 795/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 796/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0597 - val_acc: 0.4300\n",
            "Epoch 797/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0596 - val_acc: 0.4300\n",
            "Epoch 798/800\n",
            "300/300 [==============================] - 0s 386us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 799/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0595 - val_acc: 0.4300\n",
            "Epoch 800/800\n",
            "300/300 [==============================] - 0s 417us/step - loss: 0.1107 - acc: 0.9100 - val_loss: 1.0593 - val_acc: 0.4300\n",
            "307/307 [==============================] - 0s 94us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1.0593274774982409, 0.4299674273896295]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xyb_A0GQ8zfe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "3a62f368-87db-47a0-9457-efea7c7b226f"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['test'], loc='upper right');\n",
        "\n"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1b3bdac5c0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Zgz6pfU7oYwk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13212
        },
        "outputId": "bef0b49e-61b1-440c-c668-c514acce457c"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Results with full anomily \n",
        "full_anom = 0\n",
        "anom_samples = 1\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='acc', factor=0.2,min_lr=1e-7,min_delta=0.001,\n",
        "                              patience=200,verbose = 1)\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
        "                               verbose=0,\n",
        "                               save_best_only=True)\n",
        "tensorboard = TensorBoard(log_dir='./logs',\n",
        "                          histogram_freq=0,\n",
        "                          write_graph=True,\n",
        "                          write_images=True)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_test2, x_test2),\n",
        "                    #validation_split=.1,\n",
        "                    shuffle=True,\n",
        "                    verbose=1,callbacks=[reduce_lr, checkpointer, tensorboard]).history \n",
        "                         \n",
        "\n",
        "score = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 300 samples, validate on 307 samples\n",
            "Epoch 1/800\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.1205 - acc: 0.8967 - val_loss: 3.0520 - val_acc: 0.0000e+00\n",
            "Epoch 2/800\n",
            "300/300 [==============================] - 0s 417us/step - loss: 0.1184 - acc: 0.9233 - val_loss: 3.0335 - val_acc: 0.0000e+00\n",
            "Epoch 3/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1196 - acc: 0.9200 - val_loss: 2.9312 - val_acc: 0.0000e+00\n",
            "Epoch 4/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1199 - acc: 0.8967 - val_loss: 3.0575 - val_acc: 0.0000e+00\n",
            "Epoch 5/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1188 - acc: 0.9267 - val_loss: 3.0571 - val_acc: 0.0000e+00\n",
            "Epoch 6/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1200 - acc: 0.9133 - val_loss: 3.0526 - val_acc: 0.0000e+00\n",
            "Epoch 7/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1184 - acc: 0.9267 - val_loss: 3.0729 - val_acc: 0.0000e+00\n",
            "Epoch 8/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1193 - acc: 0.9033 - val_loss: 3.0949 - val_acc: 0.0000e+00\n",
            "Epoch 9/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1196 - acc: 0.9033 - val_loss: 3.1423 - val_acc: 0.0000e+00\n",
            "Epoch 10/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1188 - acc: 0.9233 - val_loss: 3.1466 - val_acc: 0.0000e+00\n",
            "Epoch 11/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1204 - acc: 0.8967 - val_loss: 3.0999 - val_acc: 0.0000e+00\n",
            "Epoch 12/800\n",
            "300/300 [==============================] - 0s 420us/step - loss: 0.1182 - acc: 0.9133 - val_loss: 3.1334 - val_acc: 0.0000e+00\n",
            "Epoch 13/800\n",
            "300/300 [==============================] - 0s 349us/step - loss: 0.1185 - acc: 0.9133 - val_loss: 3.1444 - val_acc: 0.0000e+00\n",
            "Epoch 14/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1193 - acc: 0.9100 - val_loss: 3.1233 - val_acc: 0.0000e+00\n",
            "Epoch 15/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1187 - acc: 0.9167 - val_loss: 3.1529 - val_acc: 0.0000e+00\n",
            "Epoch 16/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1186 - acc: 0.9167 - val_loss: 3.1221 - val_acc: 0.0000e+00\n",
            "Epoch 17/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1189 - acc: 0.9133 - val_loss: 3.1059 - val_acc: 0.0000e+00\n",
            "Epoch 18/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1190 - acc: 0.9267 - val_loss: 3.0921 - val_acc: 0.0000e+00\n",
            "Epoch 19/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1186 - acc: 0.9233 - val_loss: 3.2076 - val_acc: 0.0000e+00\n",
            "Epoch 20/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1185 - acc: 0.9200 - val_loss: 3.0874 - val_acc: 0.0000e+00\n",
            "Epoch 21/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1196 - acc: 0.9133 - val_loss: 3.1115 - val_acc: 0.0000e+00\n",
            "Epoch 22/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1185 - acc: 0.9100 - val_loss: 3.2145 - val_acc: 0.0000e+00\n",
            "Epoch 23/800\n",
            "300/300 [==============================] - 0s 423us/step - loss: 0.1193 - acc: 0.9167 - val_loss: 3.0650 - val_acc: 0.0000e+00\n",
            "Epoch 24/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1194 - acc: 0.9133 - val_loss: 3.0864 - val_acc: 0.0000e+00\n",
            "Epoch 25/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1181 - acc: 0.9233 - val_loss: 3.0754 - val_acc: 0.0000e+00\n",
            "Epoch 26/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1219 - acc: 0.9300 - val_loss: 3.1585 - val_acc: 0.0000e+00\n",
            "Epoch 27/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1200 - acc: 0.9133 - val_loss: 3.0885 - val_acc: 0.0000e+00\n",
            "Epoch 28/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1186 - acc: 0.9267 - val_loss: 3.2460 - val_acc: 0.0000e+00\n",
            "Epoch 29/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1194 - acc: 0.9200 - val_loss: 3.1169 - val_acc: 0.0000e+00\n",
            "Epoch 30/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1188 - acc: 0.9100 - val_loss: 3.1227 - val_acc: 0.0000e+00\n",
            "Epoch 31/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1190 - acc: 0.9233 - val_loss: 3.1664 - val_acc: 0.0000e+00\n",
            "Epoch 32/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1202 - acc: 0.9133 - val_loss: 3.2087 - val_acc: 0.0000e+00\n",
            "Epoch 33/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1187 - acc: 0.9267 - val_loss: 3.1755 - val_acc: 0.0000e+00\n",
            "Epoch 34/800\n",
            "300/300 [==============================] - 0s 406us/step - loss: 0.1185 - acc: 0.9267 - val_loss: 3.2110 - val_acc: 0.0000e+00\n",
            "Epoch 35/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1196 - acc: 0.9133 - val_loss: 3.1833 - val_acc: 0.0000e+00\n",
            "Epoch 36/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1187 - acc: 0.9167 - val_loss: 3.2532 - val_acc: 0.0000e+00\n",
            "Epoch 37/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1228 - acc: 0.8933 - val_loss: 3.2226 - val_acc: 0.0000e+00\n",
            "Epoch 38/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1177 - acc: 0.9333 - val_loss: 3.2772 - val_acc: 0.0000e+00\n",
            "Epoch 39/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1183 - acc: 0.9267 - val_loss: 3.2645 - val_acc: 0.0000e+00\n",
            "Epoch 40/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1178 - acc: 0.9200 - val_loss: 3.2427 - val_acc: 0.0000e+00\n",
            "Epoch 41/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1178 - acc: 0.9233 - val_loss: 3.2796 - val_acc: 0.0000e+00\n",
            "Epoch 42/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1182 - acc: 0.9367 - val_loss: 3.3168 - val_acc: 0.0000e+00\n",
            "Epoch 43/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1190 - acc: 0.9167 - val_loss: 3.3014 - val_acc: 0.0000e+00\n",
            "Epoch 44/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1199 - acc: 0.9133 - val_loss: 3.2753 - val_acc: 0.0000e+00\n",
            "Epoch 45/800\n",
            "300/300 [==============================] - 0s 423us/step - loss: 0.1180 - acc: 0.9233 - val_loss: 3.3281 - val_acc: 0.0000e+00\n",
            "Epoch 46/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1181 - acc: 0.9333 - val_loss: 3.2431 - val_acc: 0.0000e+00\n",
            "Epoch 47/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1184 - acc: 0.9100 - val_loss: 3.2826 - val_acc: 0.0000e+00\n",
            "Epoch 48/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1184 - acc: 0.9400 - val_loss: 3.2322 - val_acc: 0.0000e+00\n",
            "Epoch 49/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1184 - acc: 0.9200 - val_loss: 3.2231 - val_acc: 0.0000e+00\n",
            "Epoch 50/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1182 - acc: 0.9133 - val_loss: 3.2604 - val_acc: 0.0000e+00\n",
            "Epoch 51/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1179 - acc: 0.9233 - val_loss: 3.2439 - val_acc: 0.0000e+00\n",
            "Epoch 52/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1191 - acc: 0.9267 - val_loss: 3.2723 - val_acc: 0.0000e+00\n",
            "Epoch 53/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1181 - acc: 0.9267 - val_loss: 3.2758 - val_acc: 0.0000e+00\n",
            "Epoch 54/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1196 - acc: 0.9167 - val_loss: 3.2218 - val_acc: 0.0000e+00\n",
            "Epoch 55/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1184 - acc: 0.9200 - val_loss: 3.2460 - val_acc: 0.0000e+00\n",
            "Epoch 56/800\n",
            "300/300 [==============================] - 0s 403us/step - loss: 0.1185 - acc: 0.9200 - val_loss: 3.2149 - val_acc: 0.0000e+00\n",
            "Epoch 57/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1178 - acc: 0.9267 - val_loss: 3.2812 - val_acc: 0.0000e+00\n",
            "Epoch 58/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1179 - acc: 0.9267 - val_loss: 3.3172 - val_acc: 0.0000e+00\n",
            "Epoch 59/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1178 - acc: 0.9300 - val_loss: 3.3237 - val_acc: 0.0000e+00\n",
            "Epoch 60/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1180 - acc: 0.9233 - val_loss: 3.3295 - val_acc: 0.0000e+00\n",
            "Epoch 61/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1184 - acc: 0.9200 - val_loss: 3.3449 - val_acc: 0.0000e+00\n",
            "Epoch 62/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1178 - acc: 0.9200 - val_loss: 3.3828 - val_acc: 0.0000e+00\n",
            "Epoch 63/800\n",
            "300/300 [==============================] - 0s 386us/step - loss: 0.1184 - acc: 0.9300 - val_loss: 3.3324 - val_acc: 0.0000e+00\n",
            "Epoch 64/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1177 - acc: 0.9233 - val_loss: 3.3258 - val_acc: 0.0000e+00\n",
            "Epoch 65/800\n",
            "300/300 [==============================] - 0s 343us/step - loss: 0.1195 - acc: 0.9100 - val_loss: 3.3231 - val_acc: 0.0000e+00\n",
            "Epoch 66/800\n",
            "300/300 [==============================] - 0s 416us/step - loss: 0.1176 - acc: 0.9133 - val_loss: 3.3959 - val_acc: 0.0000e+00\n",
            "Epoch 67/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1179 - acc: 0.9267 - val_loss: 3.3573 - val_acc: 0.0000e+00\n",
            "Epoch 68/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1177 - acc: 0.9233 - val_loss: 3.3774 - val_acc: 0.0000e+00\n",
            "Epoch 69/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1194 - acc: 0.9200 - val_loss: 3.3184 - val_acc: 0.0000e+00\n",
            "Epoch 70/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1191 - acc: 0.9300 - val_loss: 3.2874 - val_acc: 0.0000e+00\n",
            "Epoch 71/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1203 - acc: 0.9067 - val_loss: 3.3005 - val_acc: 0.0000e+00\n",
            "Epoch 72/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1181 - acc: 0.9067 - val_loss: 3.3687 - val_acc: 0.0000e+00\n",
            "Epoch 73/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1178 - acc: 0.9233 - val_loss: 3.4164 - val_acc: 0.0000e+00\n",
            "Epoch 74/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1180 - acc: 0.9200 - val_loss: 3.3590 - val_acc: 0.0000e+00\n",
            "Epoch 75/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1180 - acc: 0.9200 - val_loss: 3.3669 - val_acc: 0.0000e+00\n",
            "Epoch 76/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1180 - acc: 0.9200 - val_loss: 3.3251 - val_acc: 0.0000e+00\n",
            "Epoch 77/800\n",
            "300/300 [==============================] - 0s 423us/step - loss: 0.1174 - acc: 0.9200 - val_loss: 3.4460 - val_acc: 0.0000e+00\n",
            "Epoch 78/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1177 - acc: 0.9200 - val_loss: 3.3973 - val_acc: 0.0000e+00\n",
            "Epoch 79/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1190 - acc: 0.9167 - val_loss: 3.3710 - val_acc: 0.0000e+00\n",
            "Epoch 80/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1187 - acc: 0.9300 - val_loss: 3.3568 - val_acc: 0.0000e+00\n",
            "Epoch 81/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1186 - acc: 0.9233 - val_loss: 3.3873 - val_acc: 0.0000e+00\n",
            "Epoch 82/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1189 - acc: 0.9167 - val_loss: 3.3899 - val_acc: 0.0000e+00\n",
            "Epoch 83/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1181 - acc: 0.9067 - val_loss: 3.4024 - val_acc: 0.0000e+00\n",
            "Epoch 84/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1181 - acc: 0.9267 - val_loss: 3.3980 - val_acc: 0.0000e+00\n",
            "Epoch 85/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1180 - acc: 0.9167 - val_loss: 3.4612 - val_acc: 0.0000e+00\n",
            "Epoch 86/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1177 - acc: 0.9200 - val_loss: 3.4463 - val_acc: 0.0000e+00\n",
            "Epoch 87/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1187 - acc: 0.9167 - val_loss: 3.4885 - val_acc: 0.0000e+00\n",
            "Epoch 88/800\n",
            "300/300 [==============================] - 0s 419us/step - loss: 0.1180 - acc: 0.9300 - val_loss: 3.3538 - val_acc: 0.0000e+00\n",
            "Epoch 89/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1189 - acc: 0.9167 - val_loss: 3.4315 - val_acc: 0.0000e+00\n",
            "Epoch 90/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1182 - acc: 0.9200 - val_loss: 3.4036 - val_acc: 0.0000e+00\n",
            "Epoch 91/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1177 - acc: 0.9167 - val_loss: 3.3580 - val_acc: 0.0000e+00\n",
            "Epoch 92/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1192 - acc: 0.9200 - val_loss: 3.4159 - val_acc: 0.0000e+00\n",
            "Epoch 93/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1180 - acc: 0.9267 - val_loss: 3.4045 - val_acc: 0.0000e+00\n",
            "Epoch 94/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1201 - acc: 0.9033 - val_loss: 3.4158 - val_acc: 0.0000e+00\n",
            "Epoch 95/800\n",
            "300/300 [==============================] - 0s 376us/step - loss: 0.1181 - acc: 0.9133 - val_loss: 3.4685 - val_acc: 0.0000e+00\n",
            "Epoch 96/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1185 - acc: 0.9167 - val_loss: 3.5256 - val_acc: 0.0000e+00\n",
            "Epoch 97/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1187 - acc: 0.9033 - val_loss: 3.5129 - val_acc: 0.0000e+00\n",
            "Epoch 98/800\n",
            "300/300 [==============================] - 0s 428us/step - loss: 0.1205 - acc: 0.9167 - val_loss: 3.4115 - val_acc: 0.0000e+00\n",
            "Epoch 99/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1177 - acc: 0.9300 - val_loss: 3.5248 - val_acc: 0.0000e+00\n",
            "Epoch 100/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1171 - acc: 0.9233 - val_loss: 3.5193 - val_acc: 0.0000e+00\n",
            "Epoch 101/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1179 - acc: 0.9233 - val_loss: 3.4850 - val_acc: 0.0000e+00\n",
            "Epoch 102/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1183 - acc: 0.9133 - val_loss: 3.5074 - val_acc: 0.0000e+00\n",
            "Epoch 103/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1180 - acc: 0.9200 - val_loss: 3.5148 - val_acc: 0.0000e+00\n",
            "Epoch 104/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1174 - acc: 0.9133 - val_loss: 3.5668 - val_acc: 0.0000e+00\n",
            "Epoch 105/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1174 - acc: 0.9267 - val_loss: 3.5296 - val_acc: 0.0000e+00\n",
            "Epoch 106/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1178 - acc: 0.9233 - val_loss: 3.4919 - val_acc: 0.0000e+00\n",
            "Epoch 107/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1185 - acc: 0.8933 - val_loss: 3.5047 - val_acc: 0.0000e+00\n",
            "Epoch 108/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1173 - acc: 0.9267 - val_loss: 3.5373 - val_acc: 0.0000e+00\n",
            "Epoch 109/800\n",
            "300/300 [==============================] - 0s 416us/step - loss: 0.1181 - acc: 0.9200 - val_loss: 3.5215 - val_acc: 0.0000e+00\n",
            "Epoch 110/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1177 - acc: 0.9133 - val_loss: 3.4915 - val_acc: 0.0000e+00\n",
            "Epoch 111/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1179 - acc: 0.9200 - val_loss: 3.5862 - val_acc: 0.0000e+00\n",
            "Epoch 112/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1184 - acc: 0.9133 - val_loss: 3.6208 - val_acc: 0.0000e+00\n",
            "Epoch 113/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1181 - acc: 0.9067 - val_loss: 3.5703 - val_acc: 0.0000e+00\n",
            "Epoch 114/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1183 - acc: 0.9100 - val_loss: 3.5740 - val_acc: 0.0000e+00\n",
            "Epoch 115/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1184 - acc: 0.9167 - val_loss: 3.6127 - val_acc: 0.0000e+00\n",
            "Epoch 116/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1205 - acc: 0.9133 - val_loss: 3.5325 - val_acc: 0.0000e+00\n",
            "Epoch 117/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1170 - acc: 0.9267 - val_loss: 3.4540 - val_acc: 0.0000e+00\n",
            "Epoch 118/800\n",
            "300/300 [==============================] - 0s 344us/step - loss: 0.1186 - acc: 0.9300 - val_loss: 3.6139 - val_acc: 0.0000e+00\n",
            "Epoch 119/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1185 - acc: 0.9133 - val_loss: 3.5972 - val_acc: 0.0000e+00\n",
            "Epoch 120/800\n",
            "300/300 [==============================] - 0s 408us/step - loss: 0.1176 - acc: 0.9200 - val_loss: 3.6569 - val_acc: 0.0000e+00\n",
            "Epoch 121/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1177 - acc: 0.9067 - val_loss: 3.6153 - val_acc: 0.0000e+00\n",
            "Epoch 122/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1174 - acc: 0.9233 - val_loss: 3.6128 - val_acc: 0.0000e+00\n",
            "Epoch 123/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1179 - acc: 0.9200 - val_loss: 3.6273 - val_acc: 0.0000e+00\n",
            "Epoch 124/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1175 - acc: 0.9200 - val_loss: 3.6500 - val_acc: 0.0000e+00\n",
            "Epoch 125/800\n",
            "300/300 [==============================] - 0s 344us/step - loss: 0.1180 - acc: 0.9200 - val_loss: 3.5590 - val_acc: 0.0000e+00\n",
            "Epoch 126/800\n",
            "300/300 [==============================] - 0s 343us/step - loss: 0.1178 - acc: 0.9200 - val_loss: 3.6306 - val_acc: 0.0000e+00\n",
            "Epoch 127/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1184 - acc: 0.9000 - val_loss: 3.6215 - val_acc: 0.0000e+00\n",
            "Epoch 128/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1181 - acc: 0.9233 - val_loss: 3.6769 - val_acc: 0.0000e+00\n",
            "Epoch 129/800\n",
            "300/300 [==============================] - 0s 349us/step - loss: 0.1177 - acc: 0.9233 - val_loss: 3.5861 - val_acc: 0.0000e+00\n",
            "Epoch 130/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1179 - acc: 0.9200 - val_loss: 3.6434 - val_acc: 0.0000e+00\n",
            "Epoch 131/800\n",
            "300/300 [==============================] - 0s 397us/step - loss: 0.1177 - acc: 0.9233 - val_loss: 3.6205 - val_acc: 0.0000e+00\n",
            "Epoch 132/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1174 - acc: 0.9233 - val_loss: 3.6584 - val_acc: 0.0000e+00\n",
            "Epoch 133/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1171 - acc: 0.9267 - val_loss: 3.6499 - val_acc: 0.0000e+00\n",
            "Epoch 134/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1174 - acc: 0.9200 - val_loss: 3.6515 - val_acc: 0.0000e+00\n",
            "Epoch 135/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1179 - acc: 0.9033 - val_loss: 3.5997 - val_acc: 0.0000e+00\n",
            "Epoch 136/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1172 - acc: 0.9167 - val_loss: 3.6362 - val_acc: 0.0000e+00\n",
            "Epoch 137/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1170 - acc: 0.9133 - val_loss: 3.6161 - val_acc: 0.0000e+00\n",
            "Epoch 138/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1173 - acc: 0.9200 - val_loss: 3.6315 - val_acc: 0.0000e+00\n",
            "Epoch 139/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1174 - acc: 0.9233 - val_loss: 3.7318 - val_acc: 0.0000e+00\n",
            "Epoch 140/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1175 - acc: 0.9167 - val_loss: 3.6173 - val_acc: 0.0000e+00\n",
            "Epoch 141/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1185 - acc: 0.9133 - val_loss: 3.6665 - val_acc: 0.0000e+00\n",
            "Epoch 142/800\n",
            "300/300 [==============================] - 0s 417us/step - loss: 0.1171 - acc: 0.9233 - val_loss: 3.7271 - val_acc: 0.0000e+00\n",
            "Epoch 143/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1172 - acc: 0.9200 - val_loss: 3.7649 - val_acc: 0.0000e+00\n",
            "Epoch 144/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1172 - acc: 0.9200 - val_loss: 3.7762 - val_acc: 0.0000e+00\n",
            "Epoch 145/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1173 - acc: 0.9200 - val_loss: 3.7593 - val_acc: 0.0000e+00\n",
            "Epoch 146/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1180 - acc: 0.9067 - val_loss: 3.7615 - val_acc: 0.0000e+00\n",
            "Epoch 147/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1171 - acc: 0.9300 - val_loss: 3.7802 - val_acc: 0.0000e+00\n",
            "Epoch 148/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1169 - acc: 0.9133 - val_loss: 3.8192 - val_acc: 0.0000e+00\n",
            "Epoch 149/800\n",
            "300/300 [==============================] - 0s 373us/step - loss: 0.1173 - acc: 0.9167 - val_loss: 3.8980 - val_acc: 0.0000e+00\n",
            "Epoch 150/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1173 - acc: 0.9333 - val_loss: 3.7944 - val_acc: 0.0000e+00\n",
            "Epoch 151/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1178 - acc: 0.9000 - val_loss: 3.7646 - val_acc: 0.0000e+00\n",
            "Epoch 152/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1199 - acc: 0.8833 - val_loss: 3.8668 - val_acc: 0.0000e+00\n",
            "Epoch 153/800\n",
            "300/300 [==============================] - 0s 417us/step - loss: 0.1168 - acc: 0.9267 - val_loss: 3.8491 - val_acc: 0.0000e+00\n",
            "Epoch 154/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1176 - acc: 0.9167 - val_loss: 3.8604 - val_acc: 0.0000e+00\n",
            "Epoch 155/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1171 - acc: 0.9233 - val_loss: 3.8535 - val_acc: 0.0000e+00\n",
            "Epoch 156/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1201 - acc: 0.9000 - val_loss: 3.8019 - val_acc: 0.0000e+00\n",
            "Epoch 157/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1170 - acc: 0.9233 - val_loss: 3.7790 - val_acc: 0.0000e+00\n",
            "Epoch 158/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1178 - acc: 0.9067 - val_loss: 3.7361 - val_acc: 0.0000e+00\n",
            "Epoch 159/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1173 - acc: 0.9133 - val_loss: 3.7822 - val_acc: 0.0000e+00\n",
            "Epoch 160/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1171 - acc: 0.9233 - val_loss: 3.8118 - val_acc: 0.0000e+00\n",
            "Epoch 161/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1190 - acc: 0.9133 - val_loss: 3.8502 - val_acc: 0.0000e+00\n",
            "Epoch 162/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1173 - acc: 0.9133 - val_loss: 3.8209 - val_acc: 0.0000e+00\n",
            "Epoch 163/800\n",
            "300/300 [==============================] - 0s 401us/step - loss: 0.1171 - acc: 0.9133 - val_loss: 3.8680 - val_acc: 0.0000e+00\n",
            "Epoch 164/800\n",
            "300/300 [==============================] - 0s 377us/step - loss: 0.1166 - acc: 0.9100 - val_loss: 3.8236 - val_acc: 0.0000e+00\n",
            "Epoch 165/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1173 - acc: 0.9067 - val_loss: 3.7821 - val_acc: 0.0000e+00\n",
            "Epoch 166/800\n",
            "300/300 [==============================] - 0s 374us/step - loss: 0.1170 - acc: 0.9033 - val_loss: 3.8420 - val_acc: 0.0000e+00\n",
            "Epoch 167/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1178 - acc: 0.9100 - val_loss: 3.9092 - val_acc: 0.0000e+00\n",
            "Epoch 168/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1167 - acc: 0.9167 - val_loss: 3.8276 - val_acc: 0.0000e+00\n",
            "Epoch 169/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1170 - acc: 0.9033 - val_loss: 3.8336 - val_acc: 0.0000e+00\n",
            "Epoch 170/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1169 - acc: 0.9100 - val_loss: 3.9111 - val_acc: 0.0000e+00\n",
            "Epoch 171/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1189 - acc: 0.9067 - val_loss: 3.8949 - val_acc: 0.0000e+00\n",
            "Epoch 172/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1194 - acc: 0.9067 - val_loss: 3.8288 - val_acc: 0.0000e+00\n",
            "Epoch 173/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1175 - acc: 0.9000 - val_loss: 3.7810 - val_acc: 0.0000e+00\n",
            "Epoch 174/800\n",
            "300/300 [==============================] - 0s 422us/step - loss: 0.1165 - acc: 0.9133 - val_loss: 3.8805 - val_acc: 0.0000e+00\n",
            "Epoch 175/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1171 - acc: 0.9133 - val_loss: 3.8518 - val_acc: 0.0000e+00\n",
            "Epoch 176/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1172 - acc: 0.9133 - val_loss: 3.9347 - val_acc: 0.0000e+00\n",
            "Epoch 177/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1167 - acc: 0.9100 - val_loss: 3.8712 - val_acc: 0.0000e+00\n",
            "Epoch 178/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1173 - acc: 0.9167 - val_loss: 3.9802 - val_acc: 0.0000e+00\n",
            "Epoch 179/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1177 - acc: 0.9033 - val_loss: 3.8885 - val_acc: 0.0000e+00\n",
            "Epoch 180/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1172 - acc: 0.9067 - val_loss: 4.0205 - val_acc: 0.0000e+00\n",
            "Epoch 181/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1178 - acc: 0.9100 - val_loss: 3.9173 - val_acc: 0.0000e+00\n",
            "Epoch 182/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1168 - acc: 0.9167 - val_loss: 3.8664 - val_acc: 0.0000e+00\n",
            "Epoch 183/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1167 - acc: 0.9200 - val_loss: 3.9083 - val_acc: 0.0000e+00\n",
            "Epoch 184/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1166 - acc: 0.9167 - val_loss: 3.9048 - val_acc: 0.0000e+00\n",
            "Epoch 185/800\n",
            "300/300 [==============================] - 0s 416us/step - loss: 0.1169 - acc: 0.9100 - val_loss: 3.9203 - val_acc: 0.0000e+00\n",
            "Epoch 186/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1174 - acc: 0.9167 - val_loss: 3.9047 - val_acc: 0.0000e+00\n",
            "Epoch 187/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1166 - acc: 0.9067 - val_loss: 3.8294 - val_acc: 0.0000e+00\n",
            "Epoch 188/800\n",
            "300/300 [==============================] - 0s 375us/step - loss: 0.1171 - acc: 0.9000 - val_loss: 3.9480 - val_acc: 0.0000e+00\n",
            "Epoch 189/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1173 - acc: 0.9133 - val_loss: 3.9208 - val_acc: 0.0000e+00\n",
            "Epoch 190/800\n",
            "300/300 [==============================] - 0s 349us/step - loss: 0.1194 - acc: 0.9000 - val_loss: 3.9445 - val_acc: 0.0000e+00\n",
            "Epoch 191/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1174 - acc: 0.9133 - val_loss: 3.9945 - val_acc: 0.0000e+00\n",
            "Epoch 192/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1174 - acc: 0.9100 - val_loss: 4.0409 - val_acc: 0.0000e+00\n",
            "Epoch 193/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1166 - acc: 0.9133 - val_loss: 3.9988 - val_acc: 0.0000e+00\n",
            "Epoch 194/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1169 - acc: 0.9000 - val_loss: 4.0277 - val_acc: 0.0000e+00\n",
            "Epoch 195/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1171 - acc: 0.9133 - val_loss: 4.0855 - val_acc: 0.0000e+00\n",
            "Epoch 196/800\n",
            "300/300 [==============================] - 0s 410us/step - loss: 0.1170 - acc: 0.9200 - val_loss: 4.1040 - val_acc: 0.0000e+00\n",
            "Epoch 197/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1169 - acc: 0.9067 - val_loss: 4.0456 - val_acc: 0.0000e+00\n",
            "Epoch 198/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1164 - acc: 0.9133 - val_loss: 4.0889 - val_acc: 0.0000e+00\n",
            "Epoch 199/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1168 - acc: 0.9100 - val_loss: 4.0711 - val_acc: 0.0000e+00\n",
            "Epoch 200/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1171 - acc: 0.9133 - val_loss: 4.1217 - val_acc: 0.0000e+00\n",
            "Epoch 201/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1166 - acc: 0.8933 - val_loss: 4.1338 - val_acc: 0.0000e+00\n",
            "Epoch 202/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1167 - acc: 0.9200 - val_loss: 4.1913 - val_acc: 0.0000e+00\n",
            "Epoch 203/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1201 - acc: 0.8933 - val_loss: 4.2018 - val_acc: 0.0000e+00\n",
            "Epoch 204/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1175 - acc: 0.9200 - val_loss: 4.2361 - val_acc: 0.0000e+00\n",
            "Epoch 205/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1166 - acc: 0.9133 - val_loss: 4.2660 - val_acc: 0.0000e+00\n",
            "Epoch 206/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1183 - acc: 0.9067 - val_loss: 4.0853 - val_acc: 0.0000e+00\n",
            "Epoch 207/800\n",
            "300/300 [==============================] - 0s 409us/step - loss: 0.1169 - acc: 0.9067 - val_loss: 4.0703 - val_acc: 0.0000e+00\n",
            "Epoch 208/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1173 - acc: 0.9133 - val_loss: 4.0138 - val_acc: 0.0000e+00\n",
            "Epoch 209/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1179 - acc: 0.9000 - val_loss: 4.0452 - val_acc: 0.0000e+00\n",
            "Epoch 210/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1169 - acc: 0.9100 - val_loss: 4.0217 - val_acc: 0.0000e+00\n",
            "Epoch 211/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1168 - acc: 0.9167 - val_loss: 4.0169 - val_acc: 0.0000e+00\n",
            "Epoch 212/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1177 - acc: 0.9133 - val_loss: 3.9895 - val_acc: 0.0000e+00\n",
            "Epoch 213/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1170 - acc: 0.9200 - val_loss: 4.0555 - val_acc: 0.0000e+00\n",
            "Epoch 214/800\n",
            "300/300 [==============================] - 0s 385us/step - loss: 0.1178 - acc: 0.9100 - val_loss: 4.0196 - val_acc: 0.0000e+00\n",
            "Epoch 215/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1178 - acc: 0.9000 - val_loss: 3.9855 - val_acc: 0.0000e+00\n",
            "Epoch 216/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1167 - acc: 0.9100 - val_loss: 4.0276 - val_acc: 0.0000e+00\n",
            "Epoch 217/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1167 - acc: 0.9167 - val_loss: 3.9621 - val_acc: 0.0000e+00\n",
            "Epoch 218/800\n",
            "300/300 [==============================] - 0s 426us/step - loss: 0.1177 - acc: 0.9000 - val_loss: 4.0821 - val_acc: 0.0000e+00\n",
            "Epoch 219/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1167 - acc: 0.9100 - val_loss: 4.0694 - val_acc: 0.0000e+00\n",
            "Epoch 220/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1163 - acc: 0.9200 - val_loss: 4.0927 - val_acc: 0.0000e+00\n",
            "Epoch 221/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1167 - acc: 0.9133 - val_loss: 4.1059 - val_acc: 0.0000e+00\n",
            "Epoch 222/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1170 - acc: 0.9133 - val_loss: 4.1805 - val_acc: 0.0000e+00\n",
            "Epoch 223/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1169 - acc: 0.9067 - val_loss: 4.1734 - val_acc: 0.0000e+00\n",
            "Epoch 224/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1163 - acc: 0.9167 - val_loss: 4.1808 - val_acc: 0.0000e+00\n",
            "Epoch 225/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1167 - acc: 0.9200 - val_loss: 4.1912 - val_acc: 0.0000e+00\n",
            "Epoch 226/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1246 - acc: 0.9000 - val_loss: 4.2747 - val_acc: 0.0000e+00\n",
            "Epoch 227/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1172 - acc: 0.9033 - val_loss: 4.3332 - val_acc: 0.0000e+00\n",
            "Epoch 228/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1174 - acc: 0.9100 - val_loss: 4.2678 - val_acc: 0.0000e+00\n",
            "Epoch 229/800\n",
            "300/300 [==============================] - 0s 412us/step - loss: 0.1167 - acc: 0.9100 - val_loss: 4.2453 - val_acc: 0.0000e+00\n",
            "Epoch 230/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1167 - acc: 0.9033 - val_loss: 4.2330 - val_acc: 0.0000e+00\n",
            "Epoch 231/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1174 - acc: 0.9000 - val_loss: 4.2308 - val_acc: 0.0000e+00\n",
            "Epoch 232/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1180 - acc: 0.9167 - val_loss: 4.2287 - val_acc: 0.0000e+00\n",
            "Epoch 233/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1168 - acc: 0.9100 - val_loss: 4.2038 - val_acc: 0.0000e+00\n",
            "Epoch 234/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1168 - acc: 0.9133 - val_loss: 4.2005 - val_acc: 0.0000e+00\n",
            "Epoch 235/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1169 - acc: 0.9067 - val_loss: 4.2139 - val_acc: 0.0000e+00\n",
            "Epoch 236/800\n",
            "300/300 [==============================] - 0s 371us/step - loss: 0.1166 - acc: 0.9133 - val_loss: 4.2488 - val_acc: 0.0000e+00\n",
            "Epoch 237/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1173 - acc: 0.9167 - val_loss: 4.2292 - val_acc: 0.0000e+00\n",
            "Epoch 238/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1172 - acc: 0.9033 - val_loss: 4.2297 - val_acc: 0.0000e+00\n",
            "Epoch 239/800\n",
            "300/300 [==============================] - 0s 396us/step - loss: 0.1163 - acc: 0.9067 - val_loss: 4.2614 - val_acc: 0.0000e+00\n",
            "Epoch 240/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1161 - acc: 0.9067 - val_loss: 4.3019 - val_acc: 0.0000e+00\n",
            "Epoch 241/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1159 - acc: 0.9200 - val_loss: 4.3488 - val_acc: 0.0000e+00\n",
            "Epoch 242/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1165 - acc: 0.9033 - val_loss: 4.3076 - val_acc: 0.0000e+00\n",
            "Epoch 243/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1163 - acc: 0.9067 - val_loss: 4.3893 - val_acc: 0.0000e+00\n",
            "Epoch 244/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1164 - acc: 0.9033 - val_loss: 4.3587 - val_acc: 0.0000e+00\n",
            "Epoch 245/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1167 - acc: 0.9167 - val_loss: 4.4266 - val_acc: 0.0000e+00\n",
            "Epoch 246/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1162 - acc: 0.9000 - val_loss: 4.4537 - val_acc: 0.0000e+00\n",
            "Epoch 247/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1169 - acc: 0.9100 - val_loss: 4.4154 - val_acc: 0.0000e+00\n",
            "Epoch 248/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1167 - acc: 0.9067 - val_loss: 4.4217 - val_acc: 0.0000e+00\n",
            "\n",
            "Epoch 00248: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 249/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1154 - acc: 0.9100 - val_loss: 4.4338 - val_acc: 0.0000e+00\n",
            "Epoch 250/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1153 - acc: 0.9100 - val_loss: 4.4468 - val_acc: 0.0000e+00\n",
            "Epoch 251/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1153 - acc: 0.9200 - val_loss: 4.4515 - val_acc: 0.0000e+00\n",
            "Epoch 252/800\n",
            "300/300 [==============================] - 0s 429us/step - loss: 0.1153 - acc: 0.9133 - val_loss: 4.4514 - val_acc: 0.0000e+00\n",
            "Epoch 253/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1154 - acc: 0.9100 - val_loss: 4.4630 - val_acc: 0.0000e+00\n",
            "Epoch 254/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1153 - acc: 0.9133 - val_loss: 4.4781 - val_acc: 0.0000e+00\n",
            "Epoch 255/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.4664 - val_acc: 0.0000e+00\n",
            "Epoch 256/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1153 - acc: 0.9067 - val_loss: 4.4838 - val_acc: 0.0000e+00\n",
            "Epoch 257/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.4863 - val_acc: 0.0000e+00\n",
            "Epoch 258/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.5005 - val_acc: 0.0000e+00\n",
            "Epoch 259/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1153 - acc: 0.9133 - val_loss: 4.5147 - val_acc: 0.0000e+00\n",
            "Epoch 260/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1154 - acc: 0.9167 - val_loss: 4.5014 - val_acc: 0.0000e+00\n",
            "Epoch 261/800\n",
            "300/300 [==============================] - 0s 364us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.5218 - val_acc: 0.0000e+00\n",
            "Epoch 262/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.5339 - val_acc: 0.0000e+00\n",
            "Epoch 263/800\n",
            "300/300 [==============================] - 0s 410us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.5327 - val_acc: 0.0000e+00\n",
            "Epoch 264/800\n",
            "300/300 [==============================] - 0s 367us/step - loss: 0.1153 - acc: 0.9200 - val_loss: 4.5425 - val_acc: 0.0000e+00\n",
            "Epoch 265/800\n",
            "300/300 [==============================] - 0s 359us/step - loss: 0.1153 - acc: 0.9100 - val_loss: 4.5615 - val_acc: 0.0000e+00\n",
            "Epoch 266/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.5640 - val_acc: 0.0000e+00\n",
            "Epoch 267/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.5721 - val_acc: 0.0000e+00\n",
            "Epoch 268/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.5720 - val_acc: 0.0000e+00\n",
            "Epoch 269/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.5741 - val_acc: 0.0000e+00\n",
            "Epoch 270/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.6053 - val_acc: 0.0000e+00\n",
            "Epoch 271/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1153 - acc: 0.9200 - val_loss: 4.5949 - val_acc: 0.0000e+00\n",
            "Epoch 272/800\n",
            "300/300 [==============================] - 0s 360us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.5957 - val_acc: 0.0000e+00\n",
            "Epoch 273/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1153 - acc: 0.9067 - val_loss: 4.6135 - val_acc: 0.0000e+00\n",
            "Epoch 274/800\n",
            "300/300 [==============================] - 0s 420us/step - loss: 0.1153 - acc: 0.9133 - val_loss: 4.6213 - val_acc: 0.0000e+00\n",
            "Epoch 275/800\n",
            "300/300 [==============================] - 0s 369us/step - loss: 0.1152 - acc: 0.9100 - val_loss: 4.6303 - val_acc: 0.0000e+00\n",
            "Epoch 276/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1153 - acc: 0.9200 - val_loss: 4.6063 - val_acc: 0.0000e+00\n",
            "Epoch 277/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1152 - acc: 0.9100 - val_loss: 4.6244 - val_acc: 0.0000e+00\n",
            "Epoch 278/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1153 - acc: 0.9100 - val_loss: 4.6443 - val_acc: 0.0000e+00\n",
            "Epoch 279/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.6492 - val_acc: 0.0000e+00\n",
            "Epoch 280/800\n",
            "300/300 [==============================] - 0s 340us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.6572 - val_acc: 0.0000e+00\n",
            "Epoch 281/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.6614 - val_acc: 0.0000e+00\n",
            "Epoch 282/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.6718 - val_acc: 0.0000e+00\n",
            "Epoch 283/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.6687 - val_acc: 0.0000e+00\n",
            "Epoch 284/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.6938 - val_acc: 0.0000e+00\n",
            "Epoch 285/800\n",
            "300/300 [==============================] - 0s 391us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.6945 - val_acc: 0.0000e+00\n",
            "Epoch 286/800\n",
            "300/300 [==============================] - 0s 339us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.7023 - val_acc: 0.0000e+00\n",
            "Epoch 287/800\n",
            "300/300 [==============================] - 0s 337us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.7162 - val_acc: 0.0000e+00\n",
            "Epoch 288/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1152 - acc: 0.9100 - val_loss: 4.7307 - val_acc: 0.0000e+00\n",
            "Epoch 289/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.7408 - val_acc: 0.0000e+00\n",
            "Epoch 290/800\n",
            "300/300 [==============================] - 0s 363us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.7419 - val_acc: 0.0000e+00\n",
            "Epoch 291/800\n",
            "300/300 [==============================] - 0s 338us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.7550 - val_acc: 0.0000e+00\n",
            "Epoch 292/800\n",
            "300/300 [==============================] - 0s 347us/step - loss: 0.1152 - acc: 0.9233 - val_loss: 4.7435 - val_acc: 0.0000e+00\n",
            "Epoch 293/800\n",
            "300/300 [==============================] - 0s 345us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.7823 - val_acc: 0.0000e+00\n",
            "Epoch 294/800\n",
            "300/300 [==============================] - 0s 339us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.7693 - val_acc: 0.0000e+00\n",
            "Epoch 295/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 4.7847 - val_acc: 0.0000e+00\n",
            "Epoch 296/800\n",
            "300/300 [==============================] - 0s 385us/step - loss: 0.1153 - acc: 0.9100 - val_loss: 4.7911 - val_acc: 0.0000e+00\n",
            "Epoch 297/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.7898 - val_acc: 0.0000e+00\n",
            "Epoch 298/800\n",
            "300/300 [==============================] - 0s 337us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.8081 - val_acc: 0.0000e+00\n",
            "Epoch 299/800\n",
            "300/300 [==============================] - 0s 341us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 4.8231 - val_acc: 0.0000e+00\n",
            "Epoch 300/800\n",
            "300/300 [==============================] - 0s 340us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.8166 - val_acc: 0.0000e+00\n",
            "Epoch 301/800\n",
            "300/300 [==============================] - 0s 330us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.8435 - val_acc: 0.0000e+00\n",
            "Epoch 302/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.8233 - val_acc: 0.0000e+00\n",
            "Epoch 303/800\n",
            "300/300 [==============================] - 0s 338us/step - loss: 0.1152 - acc: 0.9200 - val_loss: 4.8443 - val_acc: 0.0000e+00\n",
            "Epoch 304/800\n",
            "300/300 [==============================] - 0s 350us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.8636 - val_acc: 0.0000e+00\n",
            "Epoch 305/800\n",
            "300/300 [==============================] - 0s 345us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.8596 - val_acc: 0.0000e+00\n",
            "Epoch 306/800\n",
            "300/300 [==============================] - 0s 339us/step - loss: 0.1152 - acc: 0.9133 - val_loss: 4.8540 - val_acc: 0.0000e+00\n",
            "Epoch 307/800\n",
            "300/300 [==============================] - 0s 345us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.8783 - val_acc: 0.0000e+00\n",
            "Epoch 308/800\n",
            "300/300 [==============================] - 0s 387us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.8918 - val_acc: 0.0000e+00\n",
            "Epoch 309/800\n",
            "300/300 [==============================] - 0s 342us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.8795 - val_acc: 0.0000e+00\n",
            "Epoch 310/800\n",
            "300/300 [==============================] - 0s 342us/step - loss: 0.1152 - acc: 0.9067 - val_loss: 4.8853 - val_acc: 0.0000e+00\n",
            "Epoch 311/800\n",
            "300/300 [==============================] - 0s 345us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.8899 - val_acc: 0.0000e+00\n",
            "Epoch 312/800\n",
            "300/300 [==============================] - 0s 339us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 4.9131 - val_acc: 0.0000e+00\n",
            "Epoch 313/800\n",
            "300/300 [==============================] - 0s 351us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 4.9190 - val_acc: 0.0000e+00\n",
            "Epoch 314/800\n",
            "300/300 [==============================] - 0s 343us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.9232 - val_acc: 0.0000e+00\n",
            "Epoch 315/800\n",
            "300/300 [==============================] - 0s 344us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.9404 - val_acc: 0.0000e+00\n",
            "Epoch 316/800\n",
            "300/300 [==============================] - 0s 344us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 4.9577 - val_acc: 0.0000e+00\n",
            "Epoch 317/800\n",
            "300/300 [==============================] - 0s 340us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 4.9223 - val_acc: 0.0000e+00\n",
            "Epoch 318/800\n",
            "300/300 [==============================] - 0s 343us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 4.9538 - val_acc: 0.0000e+00\n",
            "Epoch 319/800\n",
            "300/300 [==============================] - 0s 391us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 4.9721 - val_acc: 0.0000e+00\n",
            "Epoch 320/800\n",
            "300/300 [==============================] - 0s 339us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 4.9789 - val_acc: 0.0000e+00\n",
            "Epoch 321/800\n",
            "300/300 [==============================] - 0s 354us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.9780 - val_acc: 0.0000e+00\n",
            "Epoch 322/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1151 - acc: 0.9100 - val_loss: 4.9995 - val_acc: 0.0000e+00\n",
            "Epoch 323/800\n",
            "300/300 [==============================] - 0s 379us/step - loss: 0.1150 - acc: 0.9133 - val_loss: 4.9822 - val_acc: 0.0000e+00\n",
            "Epoch 324/800\n",
            "300/300 [==============================] - 0s 353us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 4.9655 - val_acc: 0.0000e+00\n",
            "Epoch 325/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1152 - acc: 0.9100 - val_loss: 4.9905 - val_acc: 0.0000e+00\n",
            "Epoch 326/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1151 - acc: 0.9100 - val_loss: 5.0043 - val_acc: 0.0000e+00\n",
            "Epoch 327/800\n",
            "300/300 [==============================] - 0s 352us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 5.0076 - val_acc: 0.0000e+00\n",
            "Epoch 328/800\n",
            "300/300 [==============================] - 0s 356us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 5.0154 - val_acc: 0.0000e+00\n",
            "Epoch 329/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 5.0365 - val_acc: 0.0000e+00\n",
            "Epoch 330/800\n",
            "300/300 [==============================] - 0s 401us/step - loss: 0.1151 - acc: 0.9233 - val_loss: 5.0320 - val_acc: 0.0000e+00\n",
            "Epoch 331/800\n",
            "300/300 [==============================] - 0s 355us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 5.0654 - val_acc: 0.0000e+00\n",
            "Epoch 332/800\n",
            "300/300 [==============================] - 0s 372us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 5.0605 - val_acc: 0.0000e+00\n",
            "Epoch 333/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1150 - acc: 0.9133 - val_loss: 5.0576 - val_acc: 0.0000e+00\n",
            "Epoch 334/800\n",
            "300/300 [==============================] - 0s 368us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 5.0886 - val_acc: 0.0000e+00\n",
            "Epoch 335/800\n",
            "300/300 [==============================] - 0s 357us/step - loss: 0.1150 - acc: 0.9133 - val_loss: 5.0924 - val_acc: 0.0000e+00\n",
            "Epoch 336/800\n",
            "300/300 [==============================] - 0s 362us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 5.0826 - val_acc: 0.0000e+00\n",
            "Epoch 337/800\n",
            "300/300 [==============================] - 0s 365us/step - loss: 0.1150 - acc: 0.9067 - val_loss: 5.0825 - val_acc: 0.0000e+00\n",
            "Epoch 338/800\n",
            "300/300 [==============================] - 0s 370us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 5.1033 - val_acc: 0.0000e+00\n",
            "Epoch 339/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 5.1141 - val_acc: 0.0000e+00\n",
            "Epoch 340/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1150 - acc: 0.9133 - val_loss: 5.1110 - val_acc: 0.0000e+00\n",
            "Epoch 341/800\n",
            "300/300 [==============================] - 0s 420us/step - loss: 0.1150 - acc: 0.9167 - val_loss: 5.0980 - val_acc: 0.0000e+00\n",
            "Epoch 342/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 5.1328 - val_acc: 0.0000e+00\n",
            "Epoch 343/800\n",
            "300/300 [==============================] - 0s 348us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 5.1290 - val_acc: 0.0000e+00\n",
            "Epoch 344/800\n",
            "300/300 [==============================] - 0s 366us/step - loss: 0.1151 - acc: 0.9100 - val_loss: 5.1293 - val_acc: 0.0000e+00\n",
            "Epoch 345/800\n",
            "300/300 [==============================] - 0s 358us/step - loss: 0.1151 - acc: 0.9133 - val_loss: 5.1332 - val_acc: 0.0000e+00\n",
            "Epoch 346/800\n",
            "300/300 [==============================] - 0s 361us/step - loss: 0.1150 - acc: 0.9100 - val_loss: 5.1417 - val_acc: 0.0000e+00\n",
            "Epoch 347/800\n",
            " 32/300 [==>...........................] - ETA: 0s - loss: 0.0882 - acc: 0.9375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-207-0577789a8ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0;31m#validation_split=.1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     verbose=1,callbacks=[reduce_lr, checkpointer, tensorboard]).history \n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1240\u001b[0m                         \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m    117\u001b[0m            (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   4117\u001b[0m     \"\"\"\n\u001b[1;32m   4118\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 4119\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   4120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   4031\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4033\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4034\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   4150\u001b[0m             \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4152\u001b[0;31m         \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'introselect'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m     \"\"\"\n\u001b[1;32m    580\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpartitioned\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DoKUgpm5vgNb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "123b7494-8b7d-45b7-d890-e0505901066b"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['test'], loc='upper right');\n",
        "\n"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFnCAYAAAChL+DqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUNdoiySyLJMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1b598a3c88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RTZH1L09vtq7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1493
        },
        "outputId": "7959a2a7-ead1-4be1-961a-7756b5a94126"
      },
      "cell_type": "code",
      "source": [
        "x_test[0:85,:].astype('int')"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,    0,   67, 3785, 8740, 7435],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,    0,   67, 3785, 8740, 7435],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,    0,   67, 3785, 8740, 7435],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,    0,   67, 3785, 8740, 7435],\n",
              "       [  61,   67,   41, 3785, 7435, 9962],\n",
              "       [  61,   67,   41, 3785, 7435, 9962]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "metadata": {
        "id": "AVeSq6nUqU-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "d601ab21-6a9c-4220-91a1-8397713eecf4"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right');\n",
        "\n"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1b5d333ef0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4V37QvLdM5ZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27908
        },
        "outputId": "c56931a9-50bc-40b6-9eb0-ea318e3ede10"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Results with full anomily \n",
        "full_anom = 1 \n",
        "anom_samples = 0\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
        "                              patience=300,verbose = 1)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "                    validation_split=.1,\n",
        "                    verbose=1,callbacks=[reduce_lr])\n",
        "\n",
        "score = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 180 samples, validate on 20 samples\n",
            "Epoch 1/800\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1152 - acc: 0.8667 - val_loss: 0.1742 - val_acc: 0.7000\n",
            "Epoch 2/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1145 - acc: 0.8611 - val_loss: 0.1704 - val_acc: 0.7500\n",
            "Epoch 3/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1134 - acc: 0.8667 - val_loss: 0.1692 - val_acc: 0.8000\n",
            "Epoch 4/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1138 - acc: 0.8611 - val_loss: 0.1701 - val_acc: 0.7000\n",
            "Epoch 5/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1147 - acc: 0.8556 - val_loss: 0.1743 - val_acc: 0.7500\n",
            "Epoch 6/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1144 - acc: 0.8556 - val_loss: 0.1706 - val_acc: 0.7500\n",
            "Epoch 7/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1145 - acc: 0.8556 - val_loss: 0.1695 - val_acc: 0.8000\n",
            "Epoch 8/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1144 - acc: 0.8611 - val_loss: 0.1714 - val_acc: 0.7500\n",
            "Epoch 9/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1145 - acc: 0.8833 - val_loss: 0.1703 - val_acc: 0.8000\n",
            "Epoch 10/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1146 - acc: 0.8611 - val_loss: 0.1720 - val_acc: 0.7000\n",
            "Epoch 11/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1137 - acc: 0.8722 - val_loss: 0.1713 - val_acc: 0.7500\n",
            "Epoch 12/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1138 - acc: 0.8778 - val_loss: 0.1691 - val_acc: 0.8000\n",
            "Epoch 13/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1145 - acc: 0.8611 - val_loss: 0.1739 - val_acc: 0.7000\n",
            "Epoch 14/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1142 - acc: 0.8556 - val_loss: 0.1693 - val_acc: 0.7500\n",
            "Epoch 15/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1147 - acc: 0.8722 - val_loss: 0.1693 - val_acc: 0.7500\n",
            "Epoch 16/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.8500 - val_loss: 0.1694 - val_acc: 0.7000\n",
            "Epoch 17/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1145 - acc: 0.8667 - val_loss: 0.1716 - val_acc: 0.8000\n",
            "Epoch 18/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1144 - acc: 0.8778 - val_loss: 0.1682 - val_acc: 0.8000\n",
            "Epoch 19/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1138 - acc: 0.8722 - val_loss: 0.1703 - val_acc: 0.8000\n",
            "Epoch 20/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1134 - acc: 0.8444 - val_loss: 0.1687 - val_acc: 0.7500\n",
            "Epoch 21/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1136 - acc: 0.8944 - val_loss: 0.1700 - val_acc: 0.7500\n",
            "Epoch 22/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1156 - acc: 0.8444 - val_loss: 0.1683 - val_acc: 0.7500\n",
            "Epoch 23/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1135 - acc: 0.8944 - val_loss: 0.1698 - val_acc: 0.8000\n",
            "Epoch 24/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1138 - acc: 0.8667 - val_loss: 0.1686 - val_acc: 0.7500\n",
            "Epoch 25/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1137 - acc: 0.8611 - val_loss: 0.1715 - val_acc: 0.7000\n",
            "Epoch 26/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1137 - acc: 0.8500 - val_loss: 0.1689 - val_acc: 0.7500\n",
            "Epoch 27/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1134 - acc: 0.8611 - val_loss: 0.1673 - val_acc: 0.8000\n",
            "Epoch 28/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1146 - acc: 0.8611 - val_loss: 0.1710 - val_acc: 0.7500\n",
            "Epoch 29/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1142 - acc: 0.8556 - val_loss: 0.1678 - val_acc: 0.8000\n",
            "Epoch 30/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1131 - acc: 0.8667 - val_loss: 0.1673 - val_acc: 0.8000\n",
            "Epoch 31/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1142 - acc: 0.8722 - val_loss: 0.1724 - val_acc: 0.8000\n",
            "Epoch 32/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.8722 - val_loss: 0.1688 - val_acc: 0.8000\n",
            "Epoch 33/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1143 - acc: 0.8556 - val_loss: 0.1679 - val_acc: 0.8000\n",
            "Epoch 34/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1145 - acc: 0.8500 - val_loss: 0.1673 - val_acc: 0.7500\n",
            "Epoch 35/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1130 - acc: 0.8944 - val_loss: 0.1704 - val_acc: 0.7500\n",
            "Epoch 36/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1137 - acc: 0.8667 - val_loss: 0.1720 - val_acc: 0.7000\n",
            "Epoch 37/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1143 - acc: 0.8444 - val_loss: 0.1684 - val_acc: 0.7500\n",
            "Epoch 38/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1133 - acc: 0.8611 - val_loss: 0.1677 - val_acc: 0.7500\n",
            "Epoch 39/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.8556 - val_loss: 0.1694 - val_acc: 0.7500\n",
            "Epoch 40/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1139 - acc: 0.8556 - val_loss: 0.1699 - val_acc: 0.8000\n",
            "Epoch 41/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1138 - acc: 0.8611 - val_loss: 0.1673 - val_acc: 0.8000\n",
            "Epoch 42/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1136 - acc: 0.8722 - val_loss: 0.1675 - val_acc: 0.8000\n",
            "Epoch 43/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1137 - acc: 0.8333 - val_loss: 0.1690 - val_acc: 0.7500\n",
            "Epoch 44/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1138 - acc: 0.8556 - val_loss: 0.1697 - val_acc: 0.7500\n",
            "Epoch 45/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1137 - acc: 0.8500 - val_loss: 0.1700 - val_acc: 0.7500\n",
            "Epoch 46/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.1142 - acc: 0.8444 - val_loss: 0.1698 - val_acc: 0.7000\n",
            "Epoch 47/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1135 - acc: 0.8556 - val_loss: 0.1703 - val_acc: 0.8000\n",
            "Epoch 48/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1138 - acc: 0.8333 - val_loss: 0.1679 - val_acc: 0.7500\n",
            "Epoch 49/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1130 - acc: 0.8611 - val_loss: 0.1691 - val_acc: 0.7500\n",
            "Epoch 50/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1136 - acc: 0.8722 - val_loss: 0.1687 - val_acc: 0.8000\n",
            "Epoch 51/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1151 - acc: 0.8333 - val_loss: 0.1671 - val_acc: 0.8000\n",
            "Epoch 52/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1133 - acc: 0.8444 - val_loss: 0.1677 - val_acc: 0.8000\n",
            "Epoch 53/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1129 - acc: 0.8833 - val_loss: 0.1702 - val_acc: 0.7500\n",
            "Epoch 54/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1141 - acc: 0.8333 - val_loss: 0.1694 - val_acc: 0.8000\n",
            "Epoch 55/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.8333 - val_loss: 0.1716 - val_acc: 0.8000\n",
            "Epoch 56/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1152 - acc: 0.8389 - val_loss: 0.1688 - val_acc: 0.7500\n",
            "Epoch 57/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1132 - acc: 0.8500 - val_loss: 0.1671 - val_acc: 0.8000\n",
            "Epoch 58/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1125 - acc: 0.8667 - val_loss: 0.1671 - val_acc: 0.8000\n",
            "Epoch 59/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1132 - acc: 0.8667 - val_loss: 0.1666 - val_acc: 0.7500\n",
            "Epoch 60/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1136 - acc: 0.8500 - val_loss: 0.1678 - val_acc: 0.8000\n",
            "Epoch 61/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1136 - acc: 0.8667 - val_loss: 0.1686 - val_acc: 0.7000\n",
            "Epoch 62/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1129 - acc: 0.8556 - val_loss: 0.1682 - val_acc: 0.8000\n",
            "Epoch 63/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1129 - acc: 0.8778 - val_loss: 0.1695 - val_acc: 0.8000\n",
            "Epoch 64/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1131 - acc: 0.8778 - val_loss: 0.1674 - val_acc: 0.7500\n",
            "Epoch 65/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1135 - acc: 0.8444 - val_loss: 0.1668 - val_acc: 0.8000\n",
            "Epoch 66/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1127 - acc: 0.8778 - val_loss: 0.1707 - val_acc: 0.7000\n",
            "Epoch 67/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1136 - acc: 0.8500 - val_loss: 0.1696 - val_acc: 0.8000\n",
            "Epoch 68/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1183 - acc: 0.8444 - val_loss: 0.1692 - val_acc: 0.7500\n",
            "Epoch 69/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1133 - acc: 0.8500 - val_loss: 0.1677 - val_acc: 0.7500\n",
            "Epoch 70/800\n",
            "180/180 [==============================] - 0s 332us/step - loss: 0.1127 - acc: 0.8667 - val_loss: 0.1682 - val_acc: 0.8000\n",
            "Epoch 71/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1129 - acc: 0.8556 - val_loss: 0.1669 - val_acc: 0.8000\n",
            "Epoch 72/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1125 - acc: 0.8611 - val_loss: 0.1668 - val_acc: 0.8000\n",
            "Epoch 73/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1129 - acc: 0.8556 - val_loss: 0.1680 - val_acc: 0.7500\n",
            "Epoch 74/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1129 - acc: 0.8556 - val_loss: 0.1695 - val_acc: 0.7000\n",
            "Epoch 75/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1138 - acc: 0.8500 - val_loss: 0.1683 - val_acc: 0.8500\n",
            "Epoch 76/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1123 - acc: 0.8611 - val_loss: 0.1692 - val_acc: 0.7500\n",
            "Epoch 77/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1146 - acc: 0.8722 - val_loss: 0.1663 - val_acc: 0.8000\n",
            "Epoch 78/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1129 - acc: 0.8611 - val_loss: 0.1683 - val_acc: 0.7500\n",
            "Epoch 79/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.8500 - val_loss: 0.1654 - val_acc: 0.7500\n",
            "Epoch 80/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1125 - acc: 0.8833 - val_loss: 0.1667 - val_acc: 0.8000\n",
            "Epoch 81/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1128 - acc: 0.8722 - val_loss: 0.1652 - val_acc: 0.8500\n",
            "Epoch 82/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1128 - acc: 0.8833 - val_loss: 0.1680 - val_acc: 0.7500\n",
            "Epoch 83/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1122 - acc: 0.8667 - val_loss: 0.1674 - val_acc: 0.8000\n",
            "Epoch 84/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1133 - acc: 0.8500 - val_loss: 0.1721 - val_acc: 0.7500\n",
            "Epoch 85/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1130 - acc: 0.8222 - val_loss: 0.1663 - val_acc: 0.8000\n",
            "Epoch 86/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1125 - acc: 0.8722 - val_loss: 0.1669 - val_acc: 0.8000\n",
            "Epoch 87/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1125 - acc: 0.8667 - val_loss: 0.1691 - val_acc: 0.7000\n",
            "Epoch 88/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1125 - acc: 0.8556 - val_loss: 0.1669 - val_acc: 0.8000\n",
            "Epoch 89/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1127 - acc: 0.8722 - val_loss: 0.1666 - val_acc: 0.8000\n",
            "Epoch 90/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1130 - acc: 0.8556 - val_loss: 0.1668 - val_acc: 0.8500\n",
            "Epoch 91/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1131 - acc: 0.8278 - val_loss: 0.1663 - val_acc: 0.8000\n",
            "Epoch 92/800\n",
            "180/180 [==============================] - 0s 331us/step - loss: 0.1128 - acc: 0.8444 - val_loss: 0.1657 - val_acc: 0.8000\n",
            "Epoch 93/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.1127 - acc: 0.8500 - val_loss: 0.1666 - val_acc: 0.8000\n",
            "Epoch 94/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1141 - acc: 0.8389 - val_loss: 0.1647 - val_acc: 0.8000\n",
            "Epoch 95/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1125 - acc: 0.8667 - val_loss: 0.1654 - val_acc: 0.8000\n",
            "Epoch 96/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1127 - acc: 0.8611 - val_loss: 0.1678 - val_acc: 0.7500\n",
            "Epoch 97/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1127 - acc: 0.8556 - val_loss: 0.1678 - val_acc: 0.7500\n",
            "Epoch 98/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1128 - acc: 0.8278 - val_loss: 0.1667 - val_acc: 0.7500\n",
            "Epoch 99/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1130 - acc: 0.8611 - val_loss: 0.1724 - val_acc: 0.7500\n",
            "Epoch 100/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1190 - acc: 0.8333 - val_loss: 0.1678 - val_acc: 0.8000\n",
            "Epoch 101/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1122 - acc: 0.8556 - val_loss: 0.1671 - val_acc: 0.8000\n",
            "Epoch 102/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1125 - acc: 0.8667 - val_loss: 0.1653 - val_acc: 0.8500\n",
            "Epoch 103/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1125 - acc: 0.8667 - val_loss: 0.1664 - val_acc: 0.8000\n",
            "Epoch 104/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1122 - acc: 0.8556 - val_loss: 0.1650 - val_acc: 0.7500\n",
            "Epoch 105/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1121 - acc: 0.8778 - val_loss: 0.1673 - val_acc: 0.7000\n",
            "Epoch 106/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1125 - acc: 0.8500 - val_loss: 0.1661 - val_acc: 0.8500\n",
            "Epoch 107/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1126 - acc: 0.8444 - val_loss: 0.1652 - val_acc: 0.7500\n",
            "Epoch 108/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1122 - acc: 0.8611 - val_loss: 0.1680 - val_acc: 0.7500\n",
            "Epoch 109/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1120 - acc: 0.8333 - val_loss: 0.1653 - val_acc: 0.7500\n",
            "Epoch 110/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1139 - acc: 0.8722 - val_loss: 0.1663 - val_acc: 0.7000\n",
            "Epoch 111/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1128 - acc: 0.8333 - val_loss: 0.1657 - val_acc: 0.7500\n",
            "Epoch 112/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1124 - acc: 0.8444 - val_loss: 0.1683 - val_acc: 0.7000\n",
            "Epoch 113/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1134 - acc: 0.8556 - val_loss: 0.1666 - val_acc: 0.8000\n",
            "Epoch 114/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1123 - acc: 0.8500 - val_loss: 0.1662 - val_acc: 0.8500\n",
            "Epoch 115/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1124 - acc: 0.8500 - val_loss: 0.1642 - val_acc: 0.8000\n",
            "Epoch 116/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1121 - acc: 0.8778 - val_loss: 0.1671 - val_acc: 0.7500\n",
            "Epoch 117/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1125 - acc: 0.8556 - val_loss: 0.1673 - val_acc: 0.8000\n",
            "Epoch 118/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1133 - acc: 0.8444 - val_loss: 0.1650 - val_acc: 0.8000\n",
            "Epoch 119/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1133 - acc: 0.8667 - val_loss: 0.1646 - val_acc: 0.8000\n",
            "Epoch 120/800\n",
            "180/180 [==============================] - 0s 259us/step - loss: 0.1120 - acc: 0.8667 - val_loss: 0.1685 - val_acc: 0.7500\n",
            "Epoch 121/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1139 - acc: 0.8667 - val_loss: 0.1653 - val_acc: 0.8000\n",
            "Epoch 122/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1122 - acc: 0.8722 - val_loss: 0.1656 - val_acc: 0.8000\n",
            "Epoch 123/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1119 - acc: 0.8444 - val_loss: 0.1659 - val_acc: 0.8000\n",
            "Epoch 124/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1120 - acc: 0.8667 - val_loss: 0.1660 - val_acc: 0.7000\n",
            "Epoch 125/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1129 - acc: 0.8611 - val_loss: 0.1653 - val_acc: 0.8000\n",
            "Epoch 126/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1122 - acc: 0.8722 - val_loss: 0.1689 - val_acc: 0.7500\n",
            "Epoch 127/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1123 - acc: 0.8611 - val_loss: 0.1676 - val_acc: 0.8000\n",
            "Epoch 128/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1130 - acc: 0.8500 - val_loss: 0.1641 - val_acc: 0.8000\n",
            "Epoch 129/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1122 - acc: 0.8556 - val_loss: 0.1667 - val_acc: 0.7500\n",
            "Epoch 130/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1119 - acc: 0.8667 - val_loss: 0.1651 - val_acc: 0.8000\n",
            "Epoch 131/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1119 - acc: 0.8611 - val_loss: 0.1654 - val_acc: 0.8500\n",
            "Epoch 132/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1117 - acc: 0.8722 - val_loss: 0.1663 - val_acc: 0.8000\n",
            "Epoch 133/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1122 - acc: 0.8611 - val_loss: 0.1651 - val_acc: 0.7500\n",
            "Epoch 134/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1122 - acc: 0.8611 - val_loss: 0.1654 - val_acc: 0.7500\n",
            "Epoch 135/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1121 - acc: 0.8444 - val_loss: 0.1653 - val_acc: 0.7500\n",
            "Epoch 136/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1133 - acc: 0.8556 - val_loss: 0.1670 - val_acc: 0.7000\n",
            "Epoch 137/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1124 - acc: 0.8778 - val_loss: 0.1656 - val_acc: 0.8000\n",
            "Epoch 138/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1119 - acc: 0.8556 - val_loss: 0.1649 - val_acc: 0.8000\n",
            "Epoch 139/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1126 - acc: 0.8500 - val_loss: 0.1649 - val_acc: 0.8000\n",
            "Epoch 140/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1117 - acc: 0.8611 - val_loss: 0.1642 - val_acc: 0.8000\n",
            "Epoch 141/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1124 - acc: 0.8667 - val_loss: 0.1639 - val_acc: 0.8000\n",
            "Epoch 142/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1124 - acc: 0.8556 - val_loss: 0.1647 - val_acc: 0.8500\n",
            "Epoch 143/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1118 - acc: 0.8722 - val_loss: 0.1657 - val_acc: 0.8000\n",
            "Epoch 144/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1124 - acc: 0.8667 - val_loss: 0.1685 - val_acc: 0.7500\n",
            "Epoch 145/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1126 - acc: 0.8556 - val_loss: 0.1656 - val_acc: 0.8500\n",
            "Epoch 146/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1131 - acc: 0.8389 - val_loss: 0.1640 - val_acc: 0.8000\n",
            "Epoch 147/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1122 - acc: 0.8556 - val_loss: 0.1660 - val_acc: 0.7500\n",
            "Epoch 148/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1124 - acc: 0.8556 - val_loss: 0.1645 - val_acc: 0.7500\n",
            "Epoch 149/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1117 - acc: 0.8833 - val_loss: 0.1638 - val_acc: 0.8000\n",
            "Epoch 150/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1121 - acc: 0.8556 - val_loss: 0.1641 - val_acc: 0.8000\n",
            "Epoch 151/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1126 - acc: 0.8722 - val_loss: 0.1635 - val_acc: 0.8000\n",
            "Epoch 152/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1122 - acc: 0.8833 - val_loss: 0.1666 - val_acc: 0.8000\n",
            "Epoch 153/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1119 - acc: 0.8500 - val_loss: 0.1663 - val_acc: 0.8000\n",
            "Epoch 154/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1124 - acc: 0.8444 - val_loss: 0.1641 - val_acc: 0.8000\n",
            "Epoch 155/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1118 - acc: 0.8500 - val_loss: 0.1655 - val_acc: 0.8500\n",
            "Epoch 156/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1126 - acc: 0.8389 - val_loss: 0.1649 - val_acc: 0.8000\n",
            "Epoch 157/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1114 - acc: 0.8778 - val_loss: 0.1638 - val_acc: 0.7500\n",
            "Epoch 158/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1123 - acc: 0.8722 - val_loss: 0.1663 - val_acc: 0.8000\n",
            "Epoch 159/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1126 - acc: 0.8611 - val_loss: 0.1647 - val_acc: 0.8000\n",
            "Epoch 160/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1121 - acc: 0.8444 - val_loss: 0.1650 - val_acc: 0.7500\n",
            "Epoch 161/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1121 - acc: 0.8444 - val_loss: 0.1648 - val_acc: 0.8500\n",
            "Epoch 162/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1126 - acc: 0.8611 - val_loss: 0.1644 - val_acc: 0.8000\n",
            "Epoch 163/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1119 - acc: 0.8667 - val_loss: 0.1646 - val_acc: 0.8000\n",
            "Epoch 164/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1120 - acc: 0.8556 - val_loss: 0.1634 - val_acc: 0.7500\n",
            "Epoch 165/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1140 - acc: 0.8667 - val_loss: 0.1694 - val_acc: 0.8000\n",
            "Epoch 166/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1128 - acc: 0.8556 - val_loss: 0.1650 - val_acc: 0.7500\n",
            "Epoch 167/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1117 - acc: 0.8389 - val_loss: 0.1641 - val_acc: 0.8500\n",
            "Epoch 168/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1118 - acc: 0.8778 - val_loss: 0.1685 - val_acc: 0.7500\n",
            "Epoch 169/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1130 - acc: 0.8444 - val_loss: 0.1641 - val_acc: 0.7500\n",
            "Epoch 170/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1122 - acc: 0.8444 - val_loss: 0.1651 - val_acc: 0.8000\n",
            "Epoch 171/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1121 - acc: 0.8667 - val_loss: 0.1629 - val_acc: 0.8000\n",
            "Epoch 172/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1119 - acc: 0.8556 - val_loss: 0.1637 - val_acc: 0.8000\n",
            "Epoch 173/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1123 - acc: 0.8611 - val_loss: 0.1637 - val_acc: 0.8500\n",
            "Epoch 174/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1125 - acc: 0.8667 - val_loss: 0.1685 - val_acc: 0.8000\n",
            "Epoch 175/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1129 - acc: 0.8556 - val_loss: 0.1639 - val_acc: 0.7500\n",
            "Epoch 176/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1115 - acc: 0.8611 - val_loss: 0.1675 - val_acc: 0.7500\n",
            "Epoch 177/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1119 - acc: 0.8500 - val_loss: 0.1654 - val_acc: 0.7500\n",
            "Epoch 178/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1121 - acc: 0.8611 - val_loss: 0.1654 - val_acc: 0.8000\n",
            "Epoch 179/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1117 - acc: 0.8333 - val_loss: 0.1638 - val_acc: 0.8000\n",
            "Epoch 180/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1123 - acc: 0.8667 - val_loss: 0.1627 - val_acc: 0.8500\n",
            "Epoch 181/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1120 - acc: 0.8833 - val_loss: 0.1646 - val_acc: 0.8000\n",
            "Epoch 182/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1116 - acc: 0.8722 - val_loss: 0.1702 - val_acc: 0.7500\n",
            "Epoch 183/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1135 - acc: 0.8500 - val_loss: 0.1679 - val_acc: 0.7500\n",
            "Epoch 184/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1117 - acc: 0.8500 - val_loss: 0.1633 - val_acc: 0.8000\n",
            "Epoch 185/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1117 - acc: 0.8667 - val_loss: 0.1654 - val_acc: 0.7000\n",
            "Epoch 186/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1115 - acc: 0.8556 - val_loss: 0.1637 - val_acc: 0.8500\n",
            "Epoch 187/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1112 - acc: 0.8611 - val_loss: 0.1650 - val_acc: 0.8000\n",
            "Epoch 188/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1116 - acc: 0.8389 - val_loss: 0.1625 - val_acc: 0.8000\n",
            "Epoch 189/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1127 - acc: 0.8444 - val_loss: 0.1638 - val_acc: 0.8000\n",
            "Epoch 190/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1119 - acc: 0.8444 - val_loss: 0.1636 - val_acc: 0.7500\n",
            "Epoch 191/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1115 - acc: 0.8778 - val_loss: 0.1638 - val_acc: 0.8000\n",
            "Epoch 192/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1113 - acc: 0.8667 - val_loss: 0.1636 - val_acc: 0.8000\n",
            "Epoch 193/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1119 - acc: 0.8611 - val_loss: 0.1648 - val_acc: 0.7500\n",
            "Epoch 194/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1118 - acc: 0.8611 - val_loss: 0.1635 - val_acc: 0.8000\n",
            "Epoch 195/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1122 - acc: 0.8556 - val_loss: 0.1627 - val_acc: 0.8000\n",
            "Epoch 196/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1127 - acc: 0.8611 - val_loss: 0.1647 - val_acc: 0.7500\n",
            "Epoch 197/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1113 - acc: 0.8722 - val_loss: 0.1656 - val_acc: 0.8500\n",
            "Epoch 198/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1120 - acc: 0.8556 - val_loss: 0.1688 - val_acc: 0.7500\n",
            "Epoch 199/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1145 - acc: 0.8500 - val_loss: 0.1642 - val_acc: 0.8500\n",
            "Epoch 200/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1120 - acc: 0.8722 - val_loss: 0.1654 - val_acc: 0.7500\n",
            "Epoch 201/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1119 - acc: 0.8556 - val_loss: 0.1633 - val_acc: 0.8000\n",
            "Epoch 202/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1114 - acc: 0.8556 - val_loss: 0.1637 - val_acc: 0.8000\n",
            "Epoch 203/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1115 - acc: 0.8500 - val_loss: 0.1635 - val_acc: 0.7500\n",
            "Epoch 204/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1113 - acc: 0.8444 - val_loss: 0.1654 - val_acc: 0.8000\n",
            "Epoch 205/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1116 - acc: 0.8833 - val_loss: 0.1634 - val_acc: 0.8000\n",
            "Epoch 206/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1122 - acc: 0.8667 - val_loss: 0.1793 - val_acc: 0.7000\n",
            "Epoch 207/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.8556 - val_loss: 0.1661 - val_acc: 0.7500\n",
            "Epoch 208/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.1112 - acc: 0.8333 - val_loss: 0.1644 - val_acc: 0.8500\n",
            "Epoch 209/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1117 - acc: 0.8611 - val_loss: 0.1630 - val_acc: 0.8000\n",
            "Epoch 210/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1111 - acc: 0.8611 - val_loss: 0.1646 - val_acc: 0.8000\n",
            "Epoch 211/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1108 - acc: 0.8556 - val_loss: 0.1628 - val_acc: 0.8500\n",
            "Epoch 212/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1112 - acc: 0.8722 - val_loss: 0.1624 - val_acc: 0.7500\n",
            "Epoch 213/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1114 - acc: 0.8778 - val_loss: 0.1646 - val_acc: 0.8500\n",
            "Epoch 214/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1116 - acc: 0.8444 - val_loss: 0.1643 - val_acc: 0.8500\n",
            "Epoch 215/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1116 - acc: 0.8556 - val_loss: 0.1648 - val_acc: 0.8000\n",
            "Epoch 216/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1115 - acc: 0.8333 - val_loss: 0.1615 - val_acc: 0.8000\n",
            "Epoch 217/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1112 - acc: 0.8667 - val_loss: 0.1643 - val_acc: 0.8000\n",
            "Epoch 218/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1114 - acc: 0.8389 - val_loss: 0.1620 - val_acc: 0.8000\n",
            "Epoch 219/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1111 - acc: 0.8722 - val_loss: 0.1640 - val_acc: 0.8000\n",
            "Epoch 220/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1111 - acc: 0.8500 - val_loss: 0.1659 - val_acc: 0.8500\n",
            "Epoch 221/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1119 - acc: 0.8389 - val_loss: 0.1626 - val_acc: 0.8000\n",
            "Epoch 222/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1118 - acc: 0.8667 - val_loss: 0.1623 - val_acc: 0.8000\n",
            "Epoch 223/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1114 - acc: 0.8833 - val_loss: 0.1628 - val_acc: 0.8000\n",
            "Epoch 224/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1110 - acc: 0.8444 - val_loss: 0.1626 - val_acc: 0.7500\n",
            "Epoch 225/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1120 - acc: 0.8722 - val_loss: 0.1677 - val_acc: 0.7000\n",
            "Epoch 226/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1131 - acc: 0.8556 - val_loss: 0.1661 - val_acc: 0.8000\n",
            "Epoch 227/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1127 - acc: 0.8444 - val_loss: 0.1641 - val_acc: 0.8500\n",
            "Epoch 228/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1114 - acc: 0.8500 - val_loss: 0.1652 - val_acc: 0.7500\n",
            "Epoch 229/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1132 - acc: 0.8389 - val_loss: 0.1633 - val_acc: 0.8000\n",
            "Epoch 230/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1113 - acc: 0.8444 - val_loss: 0.1647 - val_acc: 0.7500\n",
            "Epoch 231/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1111 - acc: 0.8556 - val_loss: 0.1680 - val_acc: 0.7500\n",
            "Epoch 232/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1134 - acc: 0.8389 - val_loss: 0.1684 - val_acc: 0.7500\n",
            "Epoch 233/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1126 - acc: 0.8500 - val_loss: 0.1680 - val_acc: 0.7000\n",
            "Epoch 234/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1121 - acc: 0.8500 - val_loss: 0.1632 - val_acc: 0.7500\n",
            "Epoch 235/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1115 - acc: 0.8556 - val_loss: 0.1626 - val_acc: 0.7500\n",
            "Epoch 236/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1117 - acc: 0.8667 - val_loss: 0.1639 - val_acc: 0.7000\n",
            "Epoch 237/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1117 - acc: 0.8500 - val_loss: 0.1621 - val_acc: 0.8000\n",
            "Epoch 238/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1113 - acc: 0.8611 - val_loss: 0.1631 - val_acc: 0.8000\n",
            "Epoch 239/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1115 - acc: 0.8611 - val_loss: 0.1643 - val_acc: 0.8000\n",
            "Epoch 240/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1117 - acc: 0.8722 - val_loss: 0.1620 - val_acc: 0.7500\n",
            "Epoch 241/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1112 - acc: 0.8778 - val_loss: 0.1642 - val_acc: 0.8000\n",
            "Epoch 242/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1121 - acc: 0.8667 - val_loss: 0.1642 - val_acc: 0.7500\n",
            "Epoch 243/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1120 - acc: 0.8500 - val_loss: 0.1625 - val_acc: 0.8500\n",
            "Epoch 244/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1108 - acc: 0.8667 - val_loss: 0.1625 - val_acc: 0.8000\n",
            "Epoch 245/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1112 - acc: 0.8556 - val_loss: 0.1629 - val_acc: 0.8500\n",
            "Epoch 246/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.1628 - val_acc: 0.8000\n",
            "Epoch 247/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1114 - acc: 0.8500 - val_loss: 0.1623 - val_acc: 0.8500\n",
            "Epoch 248/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1112 - acc: 0.8667 - val_loss: 0.1633 - val_acc: 0.7500\n",
            "Epoch 249/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1111 - acc: 0.8556 - val_loss: 0.1643 - val_acc: 0.8500\n",
            "Epoch 250/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1111 - acc: 0.8611 - val_loss: 0.1629 - val_acc: 0.8000\n",
            "Epoch 251/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.1628 - val_acc: 0.8500\n",
            "Epoch 252/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1108 - acc: 0.8556 - val_loss: 0.1645 - val_acc: 0.7500\n",
            "Epoch 253/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1117 - acc: 0.8444 - val_loss: 0.1652 - val_acc: 0.7500\n",
            "Epoch 254/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.1109 - acc: 0.8556 - val_loss: 0.1631 - val_acc: 0.8500\n",
            "Epoch 255/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1106 - acc: 0.8611 - val_loss: 0.1639 - val_acc: 0.7500\n",
            "Epoch 256/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1113 - acc: 0.8444 - val_loss: 0.1621 - val_acc: 0.8000\n",
            "Epoch 257/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1106 - acc: 0.8778 - val_loss: 0.1644 - val_acc: 0.8000\n",
            "Epoch 258/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1112 - acc: 0.8389 - val_loss: 0.1626 - val_acc: 0.8500\n",
            "Epoch 259/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1112 - acc: 0.8611 - val_loss: 0.1661 - val_acc: 0.8000\n",
            "Epoch 260/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1126 - acc: 0.8444 - val_loss: 0.1619 - val_acc: 0.8000\n",
            "Epoch 261/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1115 - acc: 0.8667 - val_loss: 0.1625 - val_acc: 0.7500\n",
            "Epoch 262/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1113 - acc: 0.8778 - val_loss: 0.1620 - val_acc: 0.8000\n",
            "Epoch 263/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1112 - acc: 0.8667 - val_loss: 0.1635 - val_acc: 0.8000\n",
            "Epoch 264/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1109 - acc: 0.8556 - val_loss: 0.1630 - val_acc: 0.8500\n",
            "Epoch 265/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1110 - acc: 0.8611 - val_loss: 0.1618 - val_acc: 0.8000\n",
            "Epoch 266/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1106 - acc: 0.8833 - val_loss: 0.1677 - val_acc: 0.7000\n",
            "Epoch 267/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1117 - acc: 0.8444 - val_loss: 0.1647 - val_acc: 0.7500\n",
            "Epoch 268/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1110 - acc: 0.8333 - val_loss: 0.1626 - val_acc: 0.8000\n",
            "Epoch 269/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1115 - acc: 0.8500 - val_loss: 0.1633 - val_acc: 0.7500\n",
            "Epoch 270/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1113 - acc: 0.8389 - val_loss: 0.1617 - val_acc: 0.8500\n",
            "Epoch 271/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1110 - acc: 0.8667 - val_loss: 0.1645 - val_acc: 0.7500\n",
            "Epoch 272/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1123 - acc: 0.8556 - val_loss: 0.1636 - val_acc: 0.7000\n",
            "Epoch 273/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1110 - acc: 0.8722 - val_loss: 0.1643 - val_acc: 0.8000\n",
            "Epoch 274/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1119 - acc: 0.8833 - val_loss: 0.1631 - val_acc: 0.7500\n",
            "Epoch 275/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1111 - acc: 0.8611 - val_loss: 0.1650 - val_acc: 0.8000\n",
            "Epoch 276/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1113 - acc: 0.8500 - val_loss: 0.1633 - val_acc: 0.7500\n",
            "Epoch 277/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1114 - acc: 0.8444 - val_loss: 0.1628 - val_acc: 0.7500\n",
            "Epoch 278/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1112 - acc: 0.8556 - val_loss: 0.1656 - val_acc: 0.7500\n",
            "Epoch 279/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1110 - acc: 0.8722 - val_loss: 0.1616 - val_acc: 0.8500\n",
            "Epoch 280/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1105 - acc: 0.8611 - val_loss: 0.1615 - val_acc: 0.7500\n",
            "Epoch 281/800\n",
            "180/180 [==============================] - 0s 259us/step - loss: 0.1108 - acc: 0.8611 - val_loss: 0.1621 - val_acc: 0.8000\n",
            "Epoch 282/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1106 - acc: 0.8667 - val_loss: 0.1641 - val_acc: 0.7500\n",
            "Epoch 283/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1126 - acc: 0.8667 - val_loss: 0.1636 - val_acc: 0.8000\n",
            "Epoch 284/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1116 - acc: 0.8611 - val_loss: 0.1650 - val_acc: 0.7500\n",
            "Epoch 285/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1143 - acc: 0.8167 - val_loss: 0.1617 - val_acc: 0.8000\n",
            "Epoch 286/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1109 - acc: 0.8722 - val_loss: 0.1616 - val_acc: 0.8000\n",
            "Epoch 287/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1107 - acc: 0.8778 - val_loss: 0.1622 - val_acc: 0.8500\n",
            "Epoch 288/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1105 - acc: 0.8722 - val_loss: 0.1661 - val_acc: 0.8000\n",
            "Epoch 289/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1115 - acc: 0.8611 - val_loss: 0.1648 - val_acc: 0.8500\n",
            "Epoch 290/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1118 - acc: 0.8556 - val_loss: 0.1626 - val_acc: 0.8000\n",
            "Epoch 291/800\n",
            "180/180 [==============================] - 0s 257us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.1626 - val_acc: 0.8000\n",
            "Epoch 292/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1105 - acc: 0.8556 - val_loss: 0.1628 - val_acc: 0.8000\n",
            "Epoch 293/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1110 - acc: 0.8500 - val_loss: 0.1641 - val_acc: 0.8000\n",
            "Epoch 294/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1109 - acc: 0.8444 - val_loss: 0.1635 - val_acc: 0.8500\n",
            "Epoch 295/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1114 - acc: 0.8556 - val_loss: 0.1644 - val_acc: 0.7500\n",
            "Epoch 296/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1109 - acc: 0.8500 - val_loss: 0.1617 - val_acc: 0.8500\n",
            "Epoch 297/800\n",
            "180/180 [==============================] - 0s 252us/step - loss: 0.1112 - acc: 0.8722 - val_loss: 0.1630 - val_acc: 0.8500\n",
            "Epoch 298/800\n",
            "180/180 [==============================] - 0s 255us/step - loss: 0.1114 - acc: 0.8722 - val_loss: 0.1625 - val_acc: 0.8000\n",
            "Epoch 299/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1104 - acc: 0.8667 - val_loss: 0.1637 - val_acc: 0.8000\n",
            "Epoch 300/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1123 - acc: 0.8500 - val_loss: 0.1621 - val_acc: 0.7500\n",
            "Epoch 301/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1108 - acc: 0.8611 - val_loss: 0.1614 - val_acc: 0.8500\n",
            "Epoch 302/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1108 - acc: 0.8556 - val_loss: 0.1623 - val_acc: 0.8000\n",
            "Epoch 303/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1112 - acc: 0.8722 - val_loss: 0.1626 - val_acc: 0.9000\n",
            "Epoch 304/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1103 - acc: 0.8778 - val_loss: 0.1612 - val_acc: 0.8000\n",
            "Epoch 305/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1104 - acc: 0.8611 - val_loss: 0.1610 - val_acc: 0.7500\n",
            "Epoch 306/800\n",
            "180/180 [==============================] - 0s 249us/step - loss: 0.1105 - acc: 0.8722 - val_loss: 0.1645 - val_acc: 0.7500\n",
            "Epoch 307/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1106 - acc: 0.8611 - val_loss: 0.1619 - val_acc: 0.8000\n",
            "Epoch 308/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1103 - acc: 0.8556 - val_loss: 0.1616 - val_acc: 0.8000\n",
            "Epoch 309/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1119 - acc: 0.8444 - val_loss: 0.1628 - val_acc: 0.7500\n",
            "Epoch 310/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1106 - acc: 0.8667 - val_loss: 0.1636 - val_acc: 0.8000\n",
            "Epoch 311/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1131 - acc: 0.8389 - val_loss: 0.1614 - val_acc: 0.8000\n",
            "Epoch 312/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1107 - acc: 0.8444 - val_loss: 0.1613 - val_acc: 0.8500\n",
            "Epoch 313/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1114 - acc: 0.8333 - val_loss: 0.1625 - val_acc: 0.8000\n",
            "Epoch 314/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1107 - acc: 0.8667 - val_loss: 0.1628 - val_acc: 0.8500\n",
            "Epoch 315/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1107 - acc: 0.8556 - val_loss: 0.1631 - val_acc: 0.7500\n",
            "Epoch 316/800\n",
            "180/180 [==============================] - 0s 251us/step - loss: 0.1114 - acc: 0.8500 - val_loss: 0.1616 - val_acc: 0.8000\n",
            "Epoch 317/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1107 - acc: 0.8500 - val_loss: 0.1636 - val_acc: 0.8000\n",
            "Epoch 318/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1107 - acc: 0.8667 - val_loss: 0.1624 - val_acc: 0.8000\n",
            "Epoch 319/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.1626 - val_acc: 0.8500\n",
            "Epoch 320/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1105 - acc: 0.8611 - val_loss: 0.1628 - val_acc: 0.8000\n",
            "Epoch 321/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1109 - acc: 0.8500 - val_loss: 0.1615 - val_acc: 0.8000\n",
            "Epoch 322/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1105 - acc: 0.8722 - val_loss: 0.1619 - val_acc: 0.8000\n",
            "Epoch 323/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1105 - acc: 0.8611 - val_loss: 0.1608 - val_acc: 0.8500\n",
            "Epoch 324/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1108 - acc: 0.8778 - val_loss: 0.1634 - val_acc: 0.7500\n",
            "Epoch 325/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1108 - acc: 0.8722 - val_loss: 0.1636 - val_acc: 0.7500\n",
            "Epoch 326/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1110 - acc: 0.8500 - val_loss: 0.1611 - val_acc: 0.8000\n",
            "Epoch 327/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1104 - acc: 0.8722 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 328/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1107 - acc: 0.8667 - val_loss: 0.1631 - val_acc: 0.7500\n",
            "Epoch 329/800\n",
            "180/180 [==============================] - 0s 257us/step - loss: 0.1112 - acc: 0.8444 - val_loss: 0.1623 - val_acc: 0.8500\n",
            "Epoch 330/800\n",
            "180/180 [==============================] - 0s 254us/step - loss: 0.1108 - acc: 0.8556 - val_loss: 0.1623 - val_acc: 0.7500\n",
            "Epoch 331/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1103 - acc: 0.8444 - val_loss: 0.1617 - val_acc: 0.8500\n",
            "Epoch 332/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1106 - acc: 0.8444 - val_loss: 0.1623 - val_acc: 0.7500\n",
            "Epoch 333/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1103 - acc: 0.8500 - val_loss: 0.1643 - val_acc: 0.8000\n",
            "Epoch 334/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1115 - acc: 0.8500 - val_loss: 0.1629 - val_acc: 0.7500\n",
            "Epoch 335/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1106 - acc: 0.8667 - val_loss: 0.1609 - val_acc: 0.8000\n",
            "Epoch 336/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1105 - acc: 0.8444 - val_loss: 0.1624 - val_acc: 0.7500\n",
            "Epoch 337/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1108 - acc: 0.8611 - val_loss: 0.1620 - val_acc: 0.8000\n",
            "Epoch 338/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1104 - acc: 0.8778 - val_loss: 0.1612 - val_acc: 0.8000\n",
            "Epoch 339/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1113 - acc: 0.8944 - val_loss: 0.1654 - val_acc: 0.7500\n",
            "Epoch 340/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1112 - acc: 0.8611 - val_loss: 0.1643 - val_acc: 0.7000\n",
            "Epoch 341/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1106 - acc: 0.8500 - val_loss: 0.1622 - val_acc: 0.8000\n",
            "Epoch 342/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1104 - acc: 0.8778 - val_loss: 0.1618 - val_acc: 0.8000\n",
            "Epoch 343/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1103 - acc: 0.8556 - val_loss: 0.1617 - val_acc: 0.8500\n",
            "Epoch 344/800\n",
            "180/180 [==============================] - 0s 251us/step - loss: 0.1109 - acc: 0.8556 - val_loss: 0.1651 - val_acc: 0.7000\n",
            "Epoch 345/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1111 - acc: 0.8611 - val_loss: 0.1661 - val_acc: 0.7000\n",
            "Epoch 346/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1108 - acc: 0.8389 - val_loss: 0.1622 - val_acc: 0.8500\n",
            "Epoch 347/800\n",
            "180/180 [==============================] - 0s 319us/step - loss: 0.1103 - acc: 0.8667 - val_loss: 0.1614 - val_acc: 0.8000\n",
            "Epoch 348/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1103 - acc: 0.8500 - val_loss: 0.1605 - val_acc: 0.8000\n",
            "Epoch 349/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1104 - acc: 0.8778 - val_loss: 0.1653 - val_acc: 0.7500\n",
            "Epoch 350/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1120 - acc: 0.8556 - val_loss: 0.1614 - val_acc: 0.8500\n",
            "Epoch 351/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1105 - acc: 0.8556 - val_loss: 0.1653 - val_acc: 0.7000\n",
            "Epoch 352/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1104 - acc: 0.8500 - val_loss: 0.1679 - val_acc: 0.7500\n",
            "Epoch 353/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1114 - acc: 0.8500 - val_loss: 0.1618 - val_acc: 0.8000\n",
            "Epoch 354/800\n",
            "180/180 [==============================] - 0s 250us/step - loss: 0.1106 - acc: 0.8611 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 355/800\n",
            "180/180 [==============================] - 0s 259us/step - loss: 0.1102 - acc: 0.8611 - val_loss: 0.1615 - val_acc: 0.8000\n",
            "Epoch 356/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1105 - acc: 0.8556 - val_loss: 0.1609 - val_acc: 0.8500\n",
            "Epoch 357/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.1610 - val_acc: 0.8000\n",
            "Epoch 358/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1110 - acc: 0.8944 - val_loss: 0.1639 - val_acc: 0.8500\n",
            "Epoch 359/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1112 - acc: 0.8556 - val_loss: 0.1612 - val_acc: 0.8500\n",
            "Epoch 360/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1107 - acc: 0.8722 - val_loss: 0.1614 - val_acc: 0.8000\n",
            "Epoch 361/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1115 - acc: 0.8556 - val_loss: 0.1616 - val_acc: 0.8000\n",
            "Epoch 362/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1101 - acc: 0.8444 - val_loss: 0.1612 - val_acc: 0.8500\n",
            "Epoch 363/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1103 - acc: 0.8556 - val_loss: 0.1604 - val_acc: 0.7500\n",
            "Epoch 364/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1110 - acc: 0.8611 - val_loss: 0.1676 - val_acc: 0.7500\n",
            "Epoch 365/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1116 - acc: 0.8333 - val_loss: 0.1604 - val_acc: 0.7500\n",
            "Epoch 366/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.1642 - val_acc: 0.7500\n",
            "Epoch 367/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1127 - acc: 0.8333 - val_loss: 0.1622 - val_acc: 0.8000\n",
            "Epoch 368/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1102 - acc: 0.8500 - val_loss: 0.1610 - val_acc: 0.7500\n",
            "Epoch 369/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1101 - acc: 0.8389 - val_loss: 0.1637 - val_acc: 0.8000\n",
            "Epoch 370/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.1625 - val_acc: 0.8500\n",
            "Epoch 371/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1104 - acc: 0.8500 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 372/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1104 - acc: 0.8556 - val_loss: 0.1647 - val_acc: 0.8500\n",
            "Epoch 373/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1103 - acc: 0.8500 - val_loss: 0.1640 - val_acc: 0.7500\n",
            "Epoch 374/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1107 - acc: 0.8667 - val_loss: 0.1612 - val_acc: 0.8500\n",
            "Epoch 375/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1108 - acc: 0.8722 - val_loss: 0.1629 - val_acc: 0.7500\n",
            "Epoch 376/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1101 - acc: 0.8556 - val_loss: 0.1616 - val_acc: 0.8000\n",
            "Epoch 377/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1108 - acc: 0.8667 - val_loss: 0.1640 - val_acc: 0.7500\n",
            "Epoch 378/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1102 - acc: 0.8611 - val_loss: 0.1627 - val_acc: 0.8500\n",
            "Epoch 379/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1105 - acc: 0.8444 - val_loss: 0.1604 - val_acc: 0.8500\n",
            "Epoch 380/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1108 - acc: 0.8667 - val_loss: 0.1606 - val_acc: 0.8000\n",
            "Epoch 381/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1101 - acc: 0.8500 - val_loss: 0.1621 - val_acc: 0.8500\n",
            "Epoch 382/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.1618 - val_acc: 0.8000\n",
            "Epoch 383/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1107 - acc: 0.8611 - val_loss: 0.1624 - val_acc: 0.8500\n",
            "Epoch 384/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1116 - acc: 0.8500 - val_loss: 0.1606 - val_acc: 0.8000\n",
            "Epoch 385/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1105 - acc: 0.8667 - val_loss: 0.1604 - val_acc: 0.8500\n",
            "Epoch 386/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1098 - acc: 0.8833 - val_loss: 0.1610 - val_acc: 0.8500\n",
            "Epoch 387/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1100 - acc: 0.8778 - val_loss: 0.1615 - val_acc: 0.8500\n",
            "Epoch 388/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1101 - acc: 0.8611 - val_loss: 0.1613 - val_acc: 0.7500\n",
            "Epoch 389/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1102 - acc: 0.8611 - val_loss: 0.1599 - val_acc: 0.8000\n",
            "Epoch 390/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1103 - acc: 0.8722 - val_loss: 0.1616 - val_acc: 0.8500\n",
            "Epoch 391/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1101 - acc: 0.8667 - val_loss: 0.1620 - val_acc: 0.8000\n",
            "Epoch 392/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1104 - acc: 0.8556 - val_loss: 0.1638 - val_acc: 0.7500\n",
            "Epoch 393/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1105 - acc: 0.8611 - val_loss: 0.1626 - val_acc: 0.8500\n",
            "Epoch 394/800\n",
            "180/180 [==============================] - 0s 308us/step - loss: 0.1102 - acc: 0.8611 - val_loss: 0.1610 - val_acc: 0.8500\n",
            "Epoch 395/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1101 - acc: 0.8500 - val_loss: 0.1655 - val_acc: 0.8000\n",
            "Epoch 396/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1115 - acc: 0.8389 - val_loss: 0.1661 - val_acc: 0.7000\n",
            "Epoch 397/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.1598 - val_acc: 0.7500\n",
            "Epoch 398/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1101 - acc: 0.8556 - val_loss: 0.1620 - val_acc: 0.7500\n",
            "Epoch 399/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1102 - acc: 0.8667 - val_loss: 0.1623 - val_acc: 0.7500\n",
            "Epoch 400/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1100 - acc: 0.8778 - val_loss: 0.1632 - val_acc: 0.7500\n",
            "Epoch 401/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1105 - acc: 0.8500 - val_loss: 0.1632 - val_acc: 0.7500\n",
            "Epoch 402/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.1616 - val_acc: 0.8500\n",
            "Epoch 403/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1105 - acc: 0.8556 - val_loss: 0.1610 - val_acc: 0.7500\n",
            "Epoch 404/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1102 - acc: 0.8500 - val_loss: 0.1616 - val_acc: 0.8000\n",
            "Epoch 405/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1100 - acc: 0.8500 - val_loss: 0.1612 - val_acc: 0.8000\n",
            "Epoch 406/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1097 - acc: 0.8389 - val_loss: 0.1619 - val_acc: 0.7500\n",
            "Epoch 407/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1101 - acc: 0.8611 - val_loss: 0.1609 - val_acc: 0.7500\n",
            "Epoch 408/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1105 - acc: 0.8500 - val_loss: 0.1604 - val_acc: 0.8500\n",
            "Epoch 409/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1102 - acc: 0.8667 - val_loss: 0.1623 - val_acc: 0.8000\n",
            "Epoch 410/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1106 - acc: 0.8556 - val_loss: 0.1626 - val_acc: 0.7500\n",
            "Epoch 411/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1104 - acc: 0.8444 - val_loss: 0.1609 - val_acc: 0.8500\n",
            "Epoch 412/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1111 - acc: 0.8667 - val_loss: 0.1611 - val_acc: 0.7500\n",
            "Epoch 413/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1103 - acc: 0.8444 - val_loss: 0.1611 - val_acc: 0.7500\n",
            "Epoch 414/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1101 - acc: 0.8611 - val_loss: 0.1615 - val_acc: 0.7500\n",
            "Epoch 415/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1103 - acc: 0.8611 - val_loss: 0.1607 - val_acc: 0.7500\n",
            "Epoch 416/800\n",
            "180/180 [==============================] - 0s 257us/step - loss: 0.1106 - acc: 0.8444 - val_loss: 0.1610 - val_acc: 0.8500\n",
            "Epoch 417/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1109 - acc: 0.8556 - val_loss: 0.1592 - val_acc: 0.8000\n",
            "Epoch 418/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1107 - acc: 0.8556 - val_loss: 0.1612 - val_acc: 0.7500\n",
            "Epoch 419/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1105 - acc: 0.8333 - val_loss: 0.1607 - val_acc: 0.8000\n",
            "Epoch 420/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1103 - acc: 0.8611 - val_loss: 0.1594 - val_acc: 0.8000\n",
            "Epoch 421/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1103 - acc: 0.8722 - val_loss: 0.1610 - val_acc: 0.8000\n",
            "Epoch 422/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1099 - acc: 0.8556 - val_loss: 0.1600 - val_acc: 0.7500\n",
            "Epoch 423/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1100 - acc: 0.8556 - val_loss: 0.1605 - val_acc: 0.8000\n",
            "Epoch 424/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1097 - acc: 0.8667 - val_loss: 0.1607 - val_acc: 0.8000\n",
            "Epoch 425/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1105 - acc: 0.8444 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 426/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1104 - acc: 0.8722 - val_loss: 0.1605 - val_acc: 0.8500\n",
            "Epoch 427/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.1610 - val_acc: 0.8000\n",
            "Epoch 428/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1095 - acc: 0.8444 - val_loss: 0.1611 - val_acc: 0.7500\n",
            "Epoch 429/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1103 - acc: 0.8333 - val_loss: 0.1606 - val_acc: 0.7500\n",
            "Epoch 430/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1098 - acc: 0.8500 - val_loss: 0.1611 - val_acc: 0.7500\n",
            "Epoch 431/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1100 - acc: 0.8611 - val_loss: 0.1640 - val_acc: 0.7500\n",
            "Epoch 432/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1103 - acc: 0.8500 - val_loss: 0.1592 - val_acc: 0.8500\n",
            "Epoch 433/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1097 - acc: 0.8722 - val_loss: 0.1630 - val_acc: 0.8500\n",
            "Epoch 434/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1108 - acc: 0.8444 - val_loss: 0.1617 - val_acc: 0.7500\n",
            "Epoch 435/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1096 - acc: 0.8500 - val_loss: 0.1610 - val_acc: 0.8000\n",
            "Epoch 436/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1099 - acc: 0.8500 - val_loss: 0.1646 - val_acc: 0.7000\n",
            "Epoch 437/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1108 - acc: 0.8444 - val_loss: 0.1629 - val_acc: 0.7500\n",
            "Epoch 438/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1104 - acc: 0.8611 - val_loss: 0.1603 - val_acc: 0.8500\n",
            "Epoch 439/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1098 - acc: 0.8556 - val_loss: 0.1607 - val_acc: 0.8500\n",
            "Epoch 440/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1101 - acc: 0.8778 - val_loss: 0.1593 - val_acc: 0.8500\n",
            "Epoch 441/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1101 - acc: 0.8556 - val_loss: 0.1610 - val_acc: 0.8500\n",
            "Epoch 442/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1117 - acc: 0.8556 - val_loss: 0.1602 - val_acc: 0.8000\n",
            "Epoch 443/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1112 - acc: 0.8611 - val_loss: 0.1618 - val_acc: 0.7500\n",
            "Epoch 444/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1099 - acc: 0.8556 - val_loss: 0.1605 - val_acc: 0.8000\n",
            "Epoch 445/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1100 - acc: 0.8444 - val_loss: 0.1633 - val_acc: 0.7500\n",
            "Epoch 446/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.1610 - val_acc: 0.7500\n",
            "Epoch 447/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1096 - acc: 0.8500 - val_loss: 0.1597 - val_acc: 0.8500\n",
            "Epoch 448/800\n",
            "180/180 [==============================] - 0s 254us/step - loss: 0.1100 - acc: 0.8444 - val_loss: 0.1595 - val_acc: 0.8000\n",
            "Epoch 449/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1098 - acc: 0.8611 - val_loss: 0.1602 - val_acc: 0.7500\n",
            "Epoch 450/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1101 - acc: 0.8611 - val_loss: 0.1593 - val_acc: 0.7500\n",
            "Epoch 451/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1098 - acc: 0.8889 - val_loss: 0.1620 - val_acc: 0.7000\n",
            "Epoch 452/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1103 - acc: 0.8611 - val_loss: 0.1612 - val_acc: 0.8000\n",
            "Epoch 453/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1097 - acc: 0.8500 - val_loss: 0.1628 - val_acc: 0.8000\n",
            "Epoch 454/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1099 - acc: 0.8444 - val_loss: 0.1601 - val_acc: 0.8500\n",
            "Epoch 455/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1099 - acc: 0.8667 - val_loss: 0.1603 - val_acc: 0.7500\n",
            "Epoch 456/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1100 - acc: 0.8667 - val_loss: 0.1595 - val_acc: 0.8000\n",
            "Epoch 457/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1106 - acc: 0.8556 - val_loss: 0.1607 - val_acc: 0.7000\n",
            "Epoch 458/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1107 - acc: 0.8389 - val_loss: 0.1612 - val_acc: 0.8000\n",
            "Epoch 459/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1096 - acc: 0.8833 - val_loss: 0.1598 - val_acc: 0.8500\n",
            "Epoch 460/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1095 - acc: 0.8611 - val_loss: 0.1591 - val_acc: 0.8000\n",
            "Epoch 461/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1094 - acc: 0.8722 - val_loss: 0.1595 - val_acc: 0.8500\n",
            "Epoch 462/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1097 - acc: 0.8556 - val_loss: 0.1605 - val_acc: 0.8000\n",
            "Epoch 463/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1097 - acc: 0.8500 - val_loss: 0.1619 - val_acc: 0.8000\n",
            "Epoch 464/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1096 - acc: 0.8556 - val_loss: 0.1601 - val_acc: 0.8000\n",
            "Epoch 465/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1099 - acc: 0.8389 - val_loss: 0.1595 - val_acc: 0.8500\n",
            "Epoch 466/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1097 - acc: 0.8611 - val_loss: 0.1609 - val_acc: 0.8000\n",
            "Epoch 467/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1095 - acc: 0.8611 - val_loss: 0.1607 - val_acc: 0.8000\n",
            "Epoch 468/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1097 - acc: 0.8667 - val_loss: 0.1614 - val_acc: 0.7500\n",
            "Epoch 469/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1097 - acc: 0.8667 - val_loss: 0.1612 - val_acc: 0.7500\n",
            "Epoch 470/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1100 - acc: 0.8611 - val_loss: 0.1618 - val_acc: 0.8000\n",
            "Epoch 471/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1097 - acc: 0.8722 - val_loss: 0.1615 - val_acc: 0.7500\n",
            "Epoch 472/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1107 - acc: 0.8500 - val_loss: 0.1614 - val_acc: 0.8000\n",
            "Epoch 473/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1101 - acc: 0.8667 - val_loss: 0.1609 - val_acc: 0.7500\n",
            "Epoch 474/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1096 - acc: 0.8500 - val_loss: 0.1603 - val_acc: 0.8500\n",
            "Epoch 475/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1100 - acc: 0.8778 - val_loss: 0.1606 - val_acc: 0.8500\n",
            "Epoch 476/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1102 - acc: 0.8611 - val_loss: 0.1631 - val_acc: 0.8000\n",
            "Epoch 477/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.1614 - val_acc: 0.7500\n",
            "Epoch 478/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1097 - acc: 0.8611 - val_loss: 0.1603 - val_acc: 0.8500\n",
            "Epoch 479/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1099 - acc: 0.8611 - val_loss: 0.1599 - val_acc: 0.8500\n",
            "Epoch 480/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1094 - acc: 0.8722 - val_loss: 0.1593 - val_acc: 0.8000\n",
            "Epoch 481/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1100 - acc: 0.8389 - val_loss: 0.1591 - val_acc: 0.8500\n",
            "Epoch 482/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1097 - acc: 0.8556 - val_loss: 0.1603 - val_acc: 0.8500\n",
            "Epoch 483/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1099 - acc: 0.8778 - val_loss: 0.1614 - val_acc: 0.7500\n",
            "Epoch 484/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1099 - acc: 0.8667 - val_loss: 0.1606 - val_acc: 0.8500\n",
            "Epoch 485/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1100 - acc: 0.8889 - val_loss: 0.1597 - val_acc: 0.8000\n",
            "Epoch 486/800\n",
            "180/180 [==============================] - 0s 331us/step - loss: 0.1101 - acc: 0.8444 - val_loss: 0.1590 - val_acc: 0.7500\n",
            "Epoch 487/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1094 - acc: 0.8556 - val_loss: 0.1614 - val_acc: 0.8000\n",
            "Epoch 488/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1102 - acc: 0.8667 - val_loss: 0.1617 - val_acc: 0.7500\n",
            "Epoch 489/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1104 - acc: 0.8444 - val_loss: 0.1614 - val_acc: 0.8500\n",
            "Epoch 490/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1096 - acc: 0.8500 - val_loss: 0.1603 - val_acc: 0.7500\n",
            "Epoch 491/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1095 - acc: 0.8444 - val_loss: 0.1614 - val_acc: 0.7500\n",
            "Epoch 492/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1105 - acc: 0.8556 - val_loss: 0.1609 - val_acc: 0.7500\n",
            "Epoch 493/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1095 - acc: 0.8500 - val_loss: 0.1602 - val_acc: 0.8500\n",
            "Epoch 494/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1099 - acc: 0.8556 - val_loss: 0.1594 - val_acc: 0.8500\n",
            "Epoch 495/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.1111 - acc: 0.8500 - val_loss: 0.1601 - val_acc: 0.8500\n",
            "Epoch 496/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1094 - acc: 0.8333 - val_loss: 0.1602 - val_acc: 0.8500\n",
            "Epoch 497/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1097 - acc: 0.8611 - val_loss: 0.1597 - val_acc: 0.8000\n",
            "Epoch 498/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1098 - acc: 0.8556 - val_loss: 0.1619 - val_acc: 0.7500\n",
            "Epoch 499/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1096 - acc: 0.8500 - val_loss: 0.1608 - val_acc: 0.7500\n",
            "Epoch 500/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1093 - acc: 0.8778 - val_loss: 0.1607 - val_acc: 0.8000\n",
            "Epoch 501/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1108 - acc: 0.8389 - val_loss: 0.1595 - val_acc: 0.8000\n",
            "Epoch 502/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1097 - acc: 0.8667 - val_loss: 0.1599 - val_acc: 0.7500\n",
            "Epoch 503/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1101 - acc: 0.8722 - val_loss: 0.1597 - val_acc: 0.8000\n",
            "Epoch 504/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1101 - acc: 0.8444 - val_loss: 0.1594 - val_acc: 0.8500\n",
            "Epoch 505/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1104 - acc: 0.8667 - val_loss: 0.1594 - val_acc: 0.8500\n",
            "Epoch 506/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1105 - acc: 0.8222 - val_loss: 0.1635 - val_acc: 0.8000\n",
            "Epoch 507/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1109 - acc: 0.8778 - val_loss: 0.1610 - val_acc: 0.7000\n",
            "Epoch 508/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1095 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 509/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1102 - acc: 0.8611 - val_loss: 0.1600 - val_acc: 0.8000\n",
            "Epoch 510/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1093 - acc: 0.8611 - val_loss: 0.1630 - val_acc: 0.7500\n",
            "Epoch 511/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1100 - acc: 0.8611 - val_loss: 0.1601 - val_acc: 0.7500\n",
            "Epoch 512/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1101 - acc: 0.8556 - val_loss: 0.1609 - val_acc: 0.7500\n",
            "Epoch 513/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1099 - acc: 0.8611 - val_loss: 0.1601 - val_acc: 0.7500\n",
            "Epoch 514/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1094 - acc: 0.8611 - val_loss: 0.1646 - val_acc: 0.7500\n",
            "Epoch 515/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1116 - acc: 0.8556 - val_loss: 0.1597 - val_acc: 0.8500\n",
            "Epoch 516/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1098 - acc: 0.8611 - val_loss: 0.1613 - val_acc: 0.8000\n",
            "Epoch 517/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1103 - acc: 0.8611 - val_loss: 0.1624 - val_acc: 0.8500\n",
            "Epoch 518/800\n",
            "180/180 [==============================] - 0s 259us/step - loss: 0.1097 - acc: 0.8611 - val_loss: 0.1587 - val_acc: 0.8500\n",
            "Epoch 519/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1100 - acc: 0.8556 - val_loss: 0.1587 - val_acc: 0.8000\n",
            "Epoch 520/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1096 - acc: 0.8667 - val_loss: 0.1600 - val_acc: 0.8000\n",
            "Epoch 521/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1097 - acc: 0.8500 - val_loss: 0.1585 - val_acc: 0.8500\n",
            "Epoch 522/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1102 - acc: 0.8722 - val_loss: 0.1610 - val_acc: 0.7500\n",
            "Epoch 523/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1093 - acc: 0.8556 - val_loss: 0.1598 - val_acc: 0.8500\n",
            "Epoch 524/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1094 - acc: 0.8611 - val_loss: 0.1606 - val_acc: 0.8000\n",
            "Epoch 525/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1095 - acc: 0.8611 - val_loss: 0.1657 - val_acc: 0.7500\n",
            "Epoch 526/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1103 - acc: 0.8444 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 527/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1095 - acc: 0.8444 - val_loss: 0.1637 - val_acc: 0.8500\n",
            "Epoch 528/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1098 - acc: 0.8500 - val_loss: 0.1607 - val_acc: 0.8000\n",
            "Epoch 529/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1100 - acc: 0.8611 - val_loss: 0.1598 - val_acc: 0.7500\n",
            "Epoch 530/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1089 - acc: 0.8667 - val_loss: 0.1612 - val_acc: 0.8000\n",
            "Epoch 531/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1106 - acc: 0.8556 - val_loss: 0.1610 - val_acc: 0.8500\n",
            "Epoch 532/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.1097 - acc: 0.8611 - val_loss: 0.1609 - val_acc: 0.7500\n",
            "Epoch 533/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1092 - acc: 0.8722 - val_loss: 0.1620 - val_acc: 0.8500\n",
            "Epoch 534/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1099 - acc: 0.8611 - val_loss: 0.1589 - val_acc: 0.8000\n",
            "Epoch 535/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1092 - acc: 0.8778 - val_loss: 0.1596 - val_acc: 0.7500\n",
            "Epoch 536/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1101 - acc: 0.8611 - val_loss: 0.1603 - val_acc: 0.7500\n",
            "Epoch 537/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1103 - acc: 0.8556 - val_loss: 0.1580 - val_acc: 0.7500\n",
            "Epoch 538/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1093 - acc: 0.8500 - val_loss: 0.1598 - val_acc: 0.7500\n",
            "Epoch 539/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1090 - acc: 0.8722 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 540/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1102 - acc: 0.8667 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 541/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1090 - acc: 0.8500 - val_loss: 0.1582 - val_acc: 0.7500\n",
            "Epoch 542/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1093 - acc: 0.8667 - val_loss: 0.1638 - val_acc: 0.7500\n",
            "Epoch 543/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1099 - acc: 0.8444 - val_loss: 0.1631 - val_acc: 0.7000\n",
            "Epoch 544/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1093 - acc: 0.8500 - val_loss: 0.1620 - val_acc: 0.8000\n",
            "Epoch 545/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1096 - acc: 0.8444 - val_loss: 0.1596 - val_acc: 0.8500\n",
            "Epoch 546/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1100 - acc: 0.8722 - val_loss: 0.1599 - val_acc: 0.7500\n",
            "Epoch 547/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1093 - acc: 0.8556 - val_loss: 0.1591 - val_acc: 0.8000\n",
            "Epoch 548/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1100 - acc: 0.8833 - val_loss: 0.1606 - val_acc: 0.7500\n",
            "Epoch 549/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1095 - acc: 0.8778 - val_loss: 0.1591 - val_acc: 0.7500\n",
            "Epoch 550/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1092 - acc: 0.8444 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 551/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1102 - acc: 0.8500 - val_loss: 0.1597 - val_acc: 0.7500\n",
            "Epoch 552/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1089 - acc: 0.8667 - val_loss: 0.1611 - val_acc: 0.8500\n",
            "Epoch 553/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1096 - acc: 0.8611 - val_loss: 0.1598 - val_acc: 0.8000\n",
            "Epoch 554/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1104 - acc: 0.8500 - val_loss: 0.1604 - val_acc: 0.8500\n",
            "Epoch 555/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1096 - acc: 0.8556 - val_loss: 0.1588 - val_acc: 0.8500\n",
            "Epoch 556/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1094 - acc: 0.8667 - val_loss: 0.1626 - val_acc: 0.8500\n",
            "Epoch 557/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1108 - acc: 0.8556 - val_loss: 0.1605 - val_acc: 0.8500\n",
            "Epoch 558/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1095 - acc: 0.8500 - val_loss: 0.1605 - val_acc: 0.7500\n",
            "Epoch 559/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1096 - acc: 0.8556 - val_loss: 0.1605 - val_acc: 0.8500\n",
            "Epoch 560/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1100 - acc: 0.8556 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 561/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1095 - acc: 0.8833 - val_loss: 0.1596 - val_acc: 0.8000\n",
            "Epoch 562/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1102 - acc: 0.8444 - val_loss: 0.1598 - val_acc: 0.7500\n",
            "Epoch 563/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1097 - acc: 0.8611 - val_loss: 0.1590 - val_acc: 0.8500\n",
            "Epoch 564/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1090 - acc: 0.8667 - val_loss: 0.1612 - val_acc: 0.7500\n",
            "Epoch 565/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1093 - acc: 0.8556 - val_loss: 0.1605 - val_acc: 0.8500\n",
            "Epoch 566/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1098 - acc: 0.8500 - val_loss: 0.1592 - val_acc: 0.9000\n",
            "Epoch 567/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1101 - acc: 0.8722 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 568/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1096 - acc: 0.8722 - val_loss: 0.1600 - val_acc: 0.7500\n",
            "Epoch 569/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1091 - acc: 0.8611 - val_loss: 0.1588 - val_acc: 0.8500\n",
            "Epoch 570/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1096 - acc: 0.8778 - val_loss: 0.1603 - val_acc: 0.7500\n",
            "Epoch 571/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1096 - acc: 0.8500 - val_loss: 0.1593 - val_acc: 0.8500\n",
            "Epoch 572/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1102 - acc: 0.8389 - val_loss: 0.1592 - val_acc: 0.8000\n",
            "Epoch 573/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1091 - acc: 0.8722 - val_loss: 0.1595 - val_acc: 0.8500\n",
            "Epoch 574/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1097 - acc: 0.8333 - val_loss: 0.1608 - val_acc: 0.8000\n",
            "Epoch 575/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1094 - acc: 0.8667 - val_loss: 0.1601 - val_acc: 0.8500\n",
            "Epoch 576/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1093 - acc: 0.8611 - val_loss: 0.1592 - val_acc: 0.8500\n",
            "Epoch 577/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1096 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.7500\n",
            "Epoch 578/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.1093 - acc: 0.8611 - val_loss: 0.1592 - val_acc: 0.8500\n",
            "Epoch 579/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1089 - acc: 0.8556 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 580/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1093 - acc: 0.8611 - val_loss: 0.1605 - val_acc: 0.7500\n",
            "Epoch 581/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1097 - acc: 0.8556 - val_loss: 0.1585 - val_acc: 0.8500\n",
            "Epoch 582/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1091 - acc: 0.8944 - val_loss: 0.1611 - val_acc: 0.8500\n",
            "Epoch 583/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1100 - acc: 0.8556 - val_loss: 0.1634 - val_acc: 0.7500\n",
            "Epoch 584/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1106 - acc: 0.8500 - val_loss: 0.1597 - val_acc: 0.7500\n",
            "Epoch 585/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1093 - acc: 0.8556 - val_loss: 0.1592 - val_acc: 0.7500\n",
            "Epoch 586/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1092 - acc: 0.8611 - val_loss: 0.1606 - val_acc: 0.8500\n",
            "Epoch 587/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1090 - acc: 0.8667 - val_loss: 0.1615 - val_acc: 0.7500\n",
            "Epoch 588/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1095 - acc: 0.8556 - val_loss: 0.1591 - val_acc: 0.8500\n",
            "Epoch 589/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1093 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 590/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1094 - acc: 0.8500 - val_loss: 0.1605 - val_acc: 0.7500\n",
            "Epoch 591/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1092 - acc: 0.8611 - val_loss: 0.1587 - val_acc: 0.7500\n",
            "Epoch 592/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1089 - acc: 0.8667 - val_loss: 0.1607 - val_acc: 0.8000\n",
            "Epoch 593/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1096 - acc: 0.8611 - val_loss: 0.1588 - val_acc: 0.8000\n",
            "Epoch 594/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1090 - acc: 0.8556 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 595/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1093 - acc: 0.8778 - val_loss: 0.1585 - val_acc: 0.8500\n",
            "Epoch 596/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1091 - acc: 0.8611 - val_loss: 0.1577 - val_acc: 0.8500\n",
            "Epoch 597/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1093 - acc: 0.8667 - val_loss: 0.1598 - val_acc: 0.8000\n",
            "Epoch 598/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1095 - acc: 0.8667 - val_loss: 0.1597 - val_acc: 0.7500\n",
            "Epoch 599/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1092 - acc: 0.8556 - val_loss: 0.1580 - val_acc: 0.8500\n",
            "Epoch 600/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1090 - acc: 0.8667 - val_loss: 0.1589 - val_acc: 0.8500\n",
            "Epoch 601/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.1088 - acc: 0.8778 - val_loss: 0.1591 - val_acc: 0.9000\n",
            "Epoch 602/800\n",
            "180/180 [==============================] - 0s 306us/step - loss: 0.1091 - acc: 0.8722 - val_loss: 0.1632 - val_acc: 0.7500\n",
            "Epoch 603/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1095 - acc: 0.8500 - val_loss: 0.1577 - val_acc: 0.7500\n",
            "\n",
            "Epoch 00603: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 604/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1089 - acc: 0.8722 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 605/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1085 - acc: 0.8500 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 606/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 607/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1084 - acc: 0.8556 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 608/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1587 - val_acc: 0.8500\n",
            "Epoch 609/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1590 - val_acc: 0.8000\n",
            "Epoch 610/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1084 - acc: 0.8500 - val_loss: 0.1588 - val_acc: 0.8000\n",
            "Epoch 611/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1084 - acc: 0.8556 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 612/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 613/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1085 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 614/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 615/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 616/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 617/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8500\n",
            "Epoch 618/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 619/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1083 - acc: 0.8556 - val_loss: 0.1586 - val_acc: 0.8500\n",
            "Epoch 620/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 621/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.1084 - acc: 0.8556 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 622/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 623/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 624/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 625/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 626/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 627/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 628/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8500\n",
            "Epoch 629/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8500\n",
            "Epoch 630/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 631/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 632/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 633/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1588 - val_acc: 0.8000\n",
            "Epoch 634/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1084 - acc: 0.8556 - val_loss: 0.1588 - val_acc: 0.8000\n",
            "Epoch 635/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 636/800\n",
            "180/180 [==============================] - 0s 336us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 637/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1587 - val_acc: 0.8000\n",
            "Epoch 638/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 639/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 640/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 641/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1084 - acc: 0.8722 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 642/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8500\n",
            "Epoch 643/800\n",
            "180/180 [==============================] - 0s 328us/step - loss: 0.1084 - acc: 0.8556 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 644/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 645/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8500\n",
            "Epoch 646/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8500\n",
            "Epoch 647/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 648/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 649/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 650/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 651/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 652/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 653/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 654/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8500\n",
            "Epoch 655/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 656/800\n",
            "180/180 [==============================] - 0s 254us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 657/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 658/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 659/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1084 - acc: 0.8556 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 660/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 661/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 662/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 663/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 664/800\n",
            "180/180 [==============================] - 0s 255us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 665/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 666/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 667/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 668/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 669/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1084 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 670/800\n",
            "180/180 [==============================] - 0s 253us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8500\n",
            "Epoch 671/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1083 - acc: 0.8778 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 672/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1084 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8500\n",
            "Epoch 673/800\n",
            "180/180 [==============================] - 0s 256us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 674/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1083 - acc: 0.8556 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 675/800\n",
            "180/180 [==============================] - 0s 256us/step - loss: 0.1083 - acc: 0.8556 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 676/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 677/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 678/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 679/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 680/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 681/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 682/800\n",
            "180/180 [==============================] - 0s 255us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 683/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 684/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 685/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 686/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1083 - acc: 0.8556 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 687/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1083 - acc: 0.8778 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 688/800\n",
            "180/180 [==============================] - 0s 257us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 689/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 690/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 691/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 692/800\n",
            "180/180 [==============================] - 0s 256us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 693/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 694/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 695/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 696/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 697/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 698/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1083 - acc: 0.8778 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 699/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 700/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 701/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 702/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 703/800\n",
            "180/180 [==============================] - 0s 256us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 704/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 705/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 706/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 707/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 708/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 709/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 710/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 711/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 712/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 713/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 714/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 715/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 716/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1083 - acc: 0.8778 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 717/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 718/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 719/800\n",
            "180/180 [==============================] - 0s 255us/step - loss: 0.1084 - acc: 0.8500 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 720/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 721/800\n",
            "180/180 [==============================] - 0s 253us/step - loss: 0.1083 - acc: 0.8556 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 722/800\n",
            "180/180 [==============================] - 0s 252us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 723/800\n",
            "180/180 [==============================] - 0s 252us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 724/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1083 - acc: 0.8778 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 725/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 726/800\n",
            "180/180 [==============================] - 0s 256us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 727/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 728/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 729/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 730/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 731/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 732/800\n",
            "180/180 [==============================] - 0s 258us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 733/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1580 - val_acc: 0.8000\n",
            "Epoch 734/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 735/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 736/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 737/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 738/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 739/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1580 - val_acc: 0.8000\n",
            "Epoch 740/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1579 - val_acc: 0.8500\n",
            "Epoch 741/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 742/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 743/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 744/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 745/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 746/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 747/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 748/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1083 - acc: 0.8556 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 749/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 750/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 751/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1580 - val_acc: 0.8000\n",
            "Epoch 752/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 753/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 754/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8500\n",
            "Epoch 755/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 756/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 757/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 758/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1584 - val_acc: 0.8000\n",
            "Epoch 759/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 760/800\n",
            "180/180 [==============================] - 0s 313us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1579 - val_acc: 0.8000\n",
            "Epoch 761/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1083 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 762/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 763/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 764/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 765/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 766/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 767/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1580 - val_acc: 0.8000\n",
            "Epoch 768/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.7500\n",
            "Epoch 769/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1580 - val_acc: 0.8500\n",
            "Epoch 770/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1580 - val_acc: 0.8500\n",
            "Epoch 771/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 772/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 773/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 774/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1082 - acc: 0.8722 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 775/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1586 - val_acc: 0.8000\n",
            "Epoch 776/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 777/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1082 - acc: 0.8556 - val_loss: 0.1578 - val_acc: 0.8000\n",
            "Epoch 778/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1579 - val_acc: 0.8000\n",
            "Epoch 779/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 780/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 781/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 782/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 783/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1081 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 784/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 785/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1081 - acc: 0.8667 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 786/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1579 - val_acc: 0.8500\n",
            "Epoch 787/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1583 - val_acc: 0.8500\n",
            "Epoch 788/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1082 - acc: 0.8556 - val_loss: 0.1582 - val_acc: 0.8000\n",
            "Epoch 789/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 790/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1083 - acc: 0.8611 - val_loss: 0.1581 - val_acc: 0.7500\n",
            "Epoch 791/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1579 - val_acc: 0.8000\n",
            "Epoch 792/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1579 - val_acc: 0.8000\n",
            "Epoch 793/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1082 - acc: 0.8778 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 794/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1081 - acc: 0.8611 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 795/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1585 - val_acc: 0.8000\n",
            "Epoch 796/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1082 - acc: 0.8611 - val_loss: 0.1581 - val_acc: 0.8500\n",
            "Epoch 797/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1578 - val_acc: 0.8000\n",
            "Epoch 798/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "Epoch 799/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1082 - acc: 0.8778 - val_loss: 0.1583 - val_acc: 0.8000\n",
            "Epoch 800/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1083 - acc: 0.8556 - val_loss: 0.1581 - val_acc: 0.8000\n",
            "200/200 [==============================] - 0s 108us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[28.785220642089843, 0.215]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UluQVqf8OBBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 28186
        },
        "outputId": "63bdb3ef-0965-42f9-99b0-8de73890331a"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Results with full anomily \n",
        "full_anom = 1 \n",
        "anom_samples = 0\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
        "                              patience=200,verbose = 1)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "                    validation_split=.1,\n",
        "                    verbose=1,callbacks=[reduce_lr])\n",
        "\n",
        "score = autoencoder.predict( x_test2, batch_size=32, verbose=1, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 180 samples, validate on 20 samples\n",
            "Epoch 1/800\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 0.1203 - acc: 0.8389 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 2/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1150 - acc: 0.8722 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 3/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1154 - acc: 0.8944 - val_loss: 0.0508 - val_acc: 0.8500\n",
            "Epoch 4/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1158 - acc: 0.8778 - val_loss: 0.0509 - val_acc: 0.8500\n",
            "Epoch 5/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1155 - acc: 0.8778 - val_loss: 0.0510 - val_acc: 0.8000\n",
            "Epoch 6/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1156 - acc: 0.8889 - val_loss: 0.0494 - val_acc: 0.9000\n",
            "Epoch 7/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1157 - acc: 0.8833 - val_loss: 0.0509 - val_acc: 0.9000\n",
            "Epoch 8/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1162 - acc: 0.8778 - val_loss: 0.0498 - val_acc: 0.8500\n",
            "Epoch 9/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1161 - acc: 0.8889 - val_loss: 0.0493 - val_acc: 0.9000\n",
            "Epoch 10/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1158 - acc: 0.8889 - val_loss: 0.0514 - val_acc: 0.8500\n",
            "Epoch 11/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1183 - acc: 0.8667 - val_loss: 0.0508 - val_acc: 0.8500\n",
            "Epoch 12/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1151 - acc: 0.8944 - val_loss: 0.0495 - val_acc: 0.8500\n",
            "Epoch 13/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1164 - acc: 0.8722 - val_loss: 0.0492 - val_acc: 0.8000\n",
            "Epoch 14/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1152 - acc: 0.9000 - val_loss: 0.0515 - val_acc: 0.8500\n",
            "Epoch 15/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1165 - acc: 0.9056 - val_loss: 0.0504 - val_acc: 0.8000\n",
            "Epoch 16/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1154 - acc: 0.8944 - val_loss: 0.0506 - val_acc: 0.8500\n",
            "Epoch 17/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1152 - acc: 0.9056 - val_loss: 0.0536 - val_acc: 0.7500\n",
            "Epoch 18/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1155 - acc: 0.8944 - val_loss: 0.0492 - val_acc: 0.8000\n",
            "Epoch 19/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1153 - acc: 0.9111 - val_loss: 0.0512 - val_acc: 0.8500\n",
            "Epoch 20/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1169 - acc: 0.8944 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 21/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1159 - acc: 0.9111 - val_loss: 0.0503 - val_acc: 0.7500\n",
            "Epoch 22/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1157 - acc: 0.9056 - val_loss: 0.0507 - val_acc: 0.8000\n",
            "Epoch 23/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1161 - acc: 0.9111 - val_loss: 0.0508 - val_acc: 0.8000\n",
            "Epoch 24/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.1161 - acc: 0.9167 - val_loss: 0.0519 - val_acc: 0.8000\n",
            "Epoch 25/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1153 - acc: 0.9056 - val_loss: 0.0497 - val_acc: 0.8500\n",
            "Epoch 26/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1151 - acc: 0.9000 - val_loss: 0.0491 - val_acc: 0.8000\n",
            "Epoch 27/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1157 - acc: 0.9111 - val_loss: 0.0526 - val_acc: 0.8500\n",
            "Epoch 28/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1165 - acc: 0.9222 - val_loss: 0.0520 - val_acc: 0.8000\n",
            "Epoch 29/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1179 - acc: 0.9111 - val_loss: 0.0516 - val_acc: 0.7000\n",
            "Epoch 30/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1158 - acc: 0.8889 - val_loss: 0.0504 - val_acc: 0.7000\n",
            "Epoch 31/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1155 - acc: 0.9056 - val_loss: 0.0509 - val_acc: 0.8000\n",
            "Epoch 32/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1165 - acc: 0.9000 - val_loss: 0.0518 - val_acc: 0.8000\n",
            "Epoch 33/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1170 - acc: 0.8722 - val_loss: 0.0501 - val_acc: 0.8000\n",
            "Epoch 34/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1155 - acc: 0.9056 - val_loss: 0.0522 - val_acc: 0.8000\n",
            "Epoch 35/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1154 - acc: 0.9056 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 36/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1153 - acc: 0.9000 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 37/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1156 - acc: 0.9000 - val_loss: 0.0494 - val_acc: 0.8000\n",
            "Epoch 38/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1154 - acc: 0.9167 - val_loss: 0.0509 - val_acc: 0.8000\n",
            "Epoch 39/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1161 - acc: 0.8944 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 40/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1155 - acc: 0.9167 - val_loss: 0.0494 - val_acc: 0.8000\n",
            "Epoch 41/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1149 - acc: 0.9056 - val_loss: 0.0514 - val_acc: 0.8000\n",
            "Epoch 42/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1153 - acc: 0.9111 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 43/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 0.0529 - val_acc: 0.8500\n",
            "Epoch 44/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1164 - acc: 0.9278 - val_loss: 0.0498 - val_acc: 0.8000\n",
            "Epoch 45/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1154 - acc: 0.8722 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 46/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1150 - acc: 0.9111 - val_loss: 0.0495 - val_acc: 0.7500\n",
            "Epoch 47/800\n",
            "180/180 [==============================] - 0s 327us/step - loss: 0.1152 - acc: 0.9222 - val_loss: 0.0500 - val_acc: 0.8500\n",
            "Epoch 48/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1161 - acc: 0.9111 - val_loss: 0.0530 - val_acc: 0.8500\n",
            "Epoch 49/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1157 - acc: 0.9278 - val_loss: 0.0507 - val_acc: 0.8000\n",
            "Epoch 50/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1154 - acc: 0.9278 - val_loss: 0.0510 - val_acc: 0.8000\n",
            "Epoch 51/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1165 - acc: 0.9111 - val_loss: 0.0529 - val_acc: 0.7500\n",
            "Epoch 52/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1163 - acc: 0.9222 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 53/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1161 - acc: 0.9167 - val_loss: 0.0501 - val_acc: 0.8500\n",
            "Epoch 54/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1153 - acc: 0.9111 - val_loss: 0.0501 - val_acc: 0.7500\n",
            "Epoch 55/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1154 - acc: 0.9333 - val_loss: 0.0500 - val_acc: 0.8000\n",
            "Epoch 56/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1159 - acc: 0.9222 - val_loss: 0.0494 - val_acc: 0.8000\n",
            "Epoch 57/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1150 - acc: 0.9278 - val_loss: 0.0506 - val_acc: 0.8500\n",
            "Epoch 58/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1164 - acc: 0.9056 - val_loss: 0.0512 - val_acc: 0.8000\n",
            "Epoch 59/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0503 - val_acc: 0.7500\n",
            "Epoch 60/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1154 - acc: 0.9222 - val_loss: 0.0510 - val_acc: 0.7500\n",
            "Epoch 61/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1175 - acc: 0.8944 - val_loss: 0.0515 - val_acc: 0.7500\n",
            "Epoch 62/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1158 - acc: 0.9222 - val_loss: 0.0521 - val_acc: 0.7500\n",
            "Epoch 63/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1164 - acc: 0.9278 - val_loss: 0.0495 - val_acc: 0.8500\n",
            "Epoch 64/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1146 - acc: 0.9333 - val_loss: 0.0496 - val_acc: 0.8000\n",
            "Epoch 65/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1157 - acc: 0.9278 - val_loss: 0.0497 - val_acc: 0.8000\n",
            "Epoch 66/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1156 - acc: 0.9333 - val_loss: 0.0522 - val_acc: 0.8000\n",
            "Epoch 67/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1164 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.8500\n",
            "Epoch 68/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1149 - acc: 0.9278 - val_loss: 0.0493 - val_acc: 0.8500\n",
            "Epoch 69/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1148 - acc: 0.9333 - val_loss: 0.0525 - val_acc: 0.8500\n",
            "Epoch 70/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1159 - acc: 0.9167 - val_loss: 0.0511 - val_acc: 0.7500\n",
            "Epoch 71/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1170 - acc: 0.9056 - val_loss: 0.0494 - val_acc: 0.8500\n",
            "Epoch 72/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1148 - acc: 0.9222 - val_loss: 0.0552 - val_acc: 0.8500\n",
            "Epoch 73/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1177 - acc: 0.9111 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 74/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1148 - acc: 0.9389 - val_loss: 0.0541 - val_acc: 0.8500\n",
            "Epoch 75/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1160 - acc: 0.9278 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 76/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1148 - acc: 0.9278 - val_loss: 0.0517 - val_acc: 0.9000\n",
            "Epoch 77/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1168 - acc: 0.9333 - val_loss: 0.0492 - val_acc: 0.9000\n",
            "Epoch 78/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1166 - acc: 0.9333 - val_loss: 0.0517 - val_acc: 0.9000\n",
            "Epoch 79/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1168 - acc: 0.9167 - val_loss: 0.0509 - val_acc: 0.9500\n",
            "Epoch 80/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1151 - acc: 0.9444 - val_loss: 0.0515 - val_acc: 0.9000\n",
            "Epoch 81/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1162 - acc: 0.9500 - val_loss: 0.0502 - val_acc: 0.8000\n",
            "Epoch 82/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 83/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1157 - acc: 0.9222 - val_loss: 0.0512 - val_acc: 0.9000\n",
            "Epoch 84/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1154 - acc: 0.9389 - val_loss: 0.0492 - val_acc: 0.8000\n",
            "Epoch 85/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 86/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1149 - acc: 0.9278 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 87/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1156 - acc: 0.9278 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 88/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 0.0511 - val_acc: 0.8500\n",
            "Epoch 89/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1160 - acc: 0.9389 - val_loss: 0.0533 - val_acc: 0.8000\n",
            "Epoch 90/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1158 - acc: 0.9333 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 91/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1163 - acc: 0.9389 - val_loss: 0.0519 - val_acc: 0.8500\n",
            "Epoch 92/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1156 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 93/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1153 - acc: 0.9111 - val_loss: 0.0497 - val_acc: 0.8500\n",
            "Epoch 94/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1153 - acc: 0.9500 - val_loss: 0.0506 - val_acc: 0.8000\n",
            "Epoch 95/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1153 - acc: 0.9389 - val_loss: 0.0510 - val_acc: 0.8500\n",
            "Epoch 96/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1155 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 97/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1156 - acc: 0.9389 - val_loss: 0.0514 - val_acc: 0.8500\n",
            "Epoch 98/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1149 - acc: 0.9278 - val_loss: 0.0510 - val_acc: 0.8500\n",
            "Epoch 99/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0503 - val_acc: 0.9000\n",
            "Epoch 100/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1156 - acc: 0.9389 - val_loss: 0.0517 - val_acc: 0.8500\n",
            "Epoch 101/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1171 - acc: 0.9333 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 102/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1156 - acc: 0.9389 - val_loss: 0.0555 - val_acc: 0.7500\n",
            "Epoch 103/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1181 - acc: 0.9000 - val_loss: 0.0522 - val_acc: 0.9000\n",
            "Epoch 104/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1151 - acc: 0.9389 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 105/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1151 - acc: 0.9278 - val_loss: 0.0493 - val_acc: 0.8500\n",
            "Epoch 106/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1151 - acc: 0.9222 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 107/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1162 - acc: 0.9444 - val_loss: 0.0500 - val_acc: 0.8500\n",
            "Epoch 108/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1145 - acc: 0.9500 - val_loss: 0.0538 - val_acc: 0.8000\n",
            "Epoch 109/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1164 - acc: 0.9278 - val_loss: 0.0509 - val_acc: 0.8500\n",
            "Epoch 110/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1154 - acc: 0.9222 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 111/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0487 - val_acc: 0.8500\n",
            "Epoch 112/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1154 - acc: 0.9389 - val_loss: 0.0502 - val_acc: 0.9000\n",
            "Epoch 113/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1156 - acc: 0.9333 - val_loss: 0.0496 - val_acc: 0.8000\n",
            "Epoch 114/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1148 - acc: 0.9444 - val_loss: 0.0540 - val_acc: 0.8000\n",
            "Epoch 115/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1173 - acc: 0.9222 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 116/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1151 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 117/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1149 - acc: 0.9444 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 118/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0520 - val_acc: 0.8000\n",
            "Epoch 119/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0513 - val_acc: 0.9000\n",
            "Epoch 120/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1152 - acc: 0.9222 - val_loss: 0.0499 - val_acc: 0.9000\n",
            "Epoch 121/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0496 - val_acc: 0.8000\n",
            "Epoch 122/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1152 - acc: 0.9222 - val_loss: 0.0499 - val_acc: 0.7500\n",
            "Epoch 123/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0515 - val_acc: 0.8000\n",
            "Epoch 124/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1158 - acc: 0.9278 - val_loss: 0.0493 - val_acc: 0.8000\n",
            "Epoch 125/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1160 - acc: 0.9167 - val_loss: 0.0507 - val_acc: 0.8000\n",
            "Epoch 126/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1154 - acc: 0.9444 - val_loss: 0.0492 - val_acc: 0.9000\n",
            "Epoch 127/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1151 - acc: 0.9333 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 128/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1151 - acc: 0.9333 - val_loss: 0.0495 - val_acc: 0.8500\n",
            "Epoch 129/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1153 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 130/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1150 - acc: 0.9333 - val_loss: 0.0502 - val_acc: 0.9500\n",
            "Epoch 131/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1153 - acc: 0.9222 - val_loss: 0.0516 - val_acc: 0.9000\n",
            "Epoch 132/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1156 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.8000\n",
            "Epoch 133/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1158 - acc: 0.9278 - val_loss: 0.0503 - val_acc: 0.8500\n",
            "Epoch 134/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1151 - acc: 0.9389 - val_loss: 0.0504 - val_acc: 0.8000\n",
            "Epoch 135/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1149 - acc: 0.9444 - val_loss: 0.0505 - val_acc: 0.7500\n",
            "Epoch 136/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1152 - acc: 0.9389 - val_loss: 0.0487 - val_acc: 0.8000\n",
            "Epoch 137/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1151 - acc: 0.9389 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 138/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1158 - acc: 0.9167 - val_loss: 0.0533 - val_acc: 0.8500\n",
            "Epoch 139/800\n",
            "180/180 [==============================] - 0s 334us/step - loss: 0.1172 - acc: 0.9333 - val_loss: 0.0501 - val_acc: 0.9000\n",
            "Epoch 140/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1148 - acc: 0.9333 - val_loss: 0.0508 - val_acc: 0.8000\n",
            "Epoch 141/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1150 - acc: 0.9222 - val_loss: 0.0496 - val_acc: 0.9000\n",
            "Epoch 142/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1151 - acc: 0.9333 - val_loss: 0.0497 - val_acc: 0.8500\n",
            "Epoch 143/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1150 - acc: 0.9333 - val_loss: 0.0515 - val_acc: 0.8500\n",
            "Epoch 144/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1156 - acc: 0.9333 - val_loss: 0.0495 - val_acc: 0.9500\n",
            "Epoch 145/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0520 - val_acc: 0.8000\n",
            "Epoch 146/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1149 - acc: 0.9389 - val_loss: 0.0497 - val_acc: 0.8000\n",
            "Epoch 147/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1150 - acc: 0.9278 - val_loss: 0.0514 - val_acc: 0.9000\n",
            "Epoch 148/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1153 - acc: 0.9389 - val_loss: 0.0508 - val_acc: 0.8500\n",
            "Epoch 149/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1149 - acc: 0.9444 - val_loss: 0.0495 - val_acc: 0.9000\n",
            "Epoch 150/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1148 - acc: 0.9222 - val_loss: 0.0509 - val_acc: 0.9000\n",
            "Epoch 151/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1148 - acc: 0.9222 - val_loss: 0.0497 - val_acc: 0.8000\n",
            "Epoch 152/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1157 - acc: 0.9167 - val_loss: 0.0510 - val_acc: 0.9000\n",
            "Epoch 153/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1149 - acc: 0.9389 - val_loss: 0.0546 - val_acc: 0.8500\n",
            "Epoch 154/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1151 - acc: 0.9278 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 155/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1148 - acc: 0.9500 - val_loss: 0.0519 - val_acc: 0.9000\n",
            "Epoch 156/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1152 - acc: 0.9389 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 157/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1146 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.8500\n",
            "Epoch 158/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1150 - acc: 0.9278 - val_loss: 0.0495 - val_acc: 0.8000\n",
            "Epoch 159/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1153 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 160/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1149 - acc: 0.9278 - val_loss: 0.0507 - val_acc: 0.8500\n",
            "Epoch 161/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1156 - acc: 0.9222 - val_loss: 0.0495 - val_acc: 0.9000\n",
            "Epoch 162/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1156 - acc: 0.9222 - val_loss: 0.0506 - val_acc: 0.9000\n",
            "Epoch 163/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1158 - acc: 0.9389 - val_loss: 0.0504 - val_acc: 0.7500\n",
            "Epoch 164/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 165/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1145 - acc: 0.9278 - val_loss: 0.0513 - val_acc: 0.9000\n",
            "Epoch 166/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1162 - acc: 0.9222 - val_loss: 0.0493 - val_acc: 0.9500\n",
            "Epoch 167/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1147 - acc: 0.9333 - val_loss: 0.0505 - val_acc: 0.8500\n",
            "Epoch 168/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1154 - acc: 0.9278 - val_loss: 0.0513 - val_acc: 0.8500\n",
            "Epoch 169/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1147 - acc: 0.9222 - val_loss: 0.0497 - val_acc: 0.9500\n",
            "Epoch 170/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1146 - acc: 0.9389 - val_loss: 0.0492 - val_acc: 0.9000\n",
            "Epoch 171/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1145 - acc: 0.9444 - val_loss: 0.0504 - val_acc: 0.8500\n",
            "Epoch 172/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0509 - val_acc: 0.9000\n",
            "Epoch 173/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1158 - acc: 0.9389 - val_loss: 0.0501 - val_acc: 0.8500\n",
            "Epoch 174/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1148 - acc: 0.9389 - val_loss: 0.0511 - val_acc: 0.8500\n",
            "Epoch 175/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1149 - acc: 0.9333 - val_loss: 0.0492 - val_acc: 0.8000\n",
            "Epoch 176/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0506 - val_acc: 0.8500\n",
            "Epoch 177/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1146 - acc: 0.9444 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 178/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1144 - acc: 0.9389 - val_loss: 0.0497 - val_acc: 0.9000\n",
            "Epoch 179/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1154 - acc: 0.9278 - val_loss: 0.0513 - val_acc: 0.9000\n",
            "Epoch 180/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1161 - acc: 0.9389 - val_loss: 0.0524 - val_acc: 0.8000\n",
            "Epoch 181/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1158 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 182/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1150 - acc: 0.9222 - val_loss: 0.0495 - val_acc: 0.9000\n",
            "Epoch 183/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1158 - acc: 0.9389 - val_loss: 0.0502 - val_acc: 0.9000\n",
            "Epoch 184/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.1146 - acc: 0.9389 - val_loss: 0.0499 - val_acc: 0.8000\n",
            "Epoch 185/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1155 - acc: 0.9389 - val_loss: 0.0493 - val_acc: 0.8500\n",
            "Epoch 186/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1150 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 187/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1149 - acc: 0.9278 - val_loss: 0.0513 - val_acc: 0.8500\n",
            "Epoch 188/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1162 - acc: 0.9278 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 189/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1147 - acc: 0.9222 - val_loss: 0.0501 - val_acc: 0.9000\n",
            "Epoch 190/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1148 - acc: 0.9389 - val_loss: 0.0497 - val_acc: 0.8500\n",
            "Epoch 191/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1146 - acc: 0.9333 - val_loss: 0.0501 - val_acc: 0.9000\n",
            "Epoch 192/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1146 - acc: 0.9389 - val_loss: 0.0499 - val_acc: 0.9000\n",
            "Epoch 193/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1146 - acc: 0.9500 - val_loss: 0.0517 - val_acc: 0.9000\n",
            "Epoch 194/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1157 - acc: 0.9222 - val_loss: 0.0513 - val_acc: 0.9000\n",
            "Epoch 195/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1145 - acc: 0.9389 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 196/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1146 - acc: 0.9444 - val_loss: 0.0502 - val_acc: 0.8000\n",
            "Epoch 197/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1146 - acc: 0.9333 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 198/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1151 - acc: 0.9222 - val_loss: 0.0519 - val_acc: 0.9000\n",
            "Epoch 199/800\n",
            "180/180 [==============================] - 0s 257us/step - loss: 0.1149 - acc: 0.9333 - val_loss: 0.0500 - val_acc: 0.9000\n",
            "Epoch 200/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1147 - acc: 0.9333 - val_loss: 0.0501 - val_acc: 0.8500\n",
            "Epoch 201/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1156 - acc: 0.9278 - val_loss: 0.0514 - val_acc: 0.8000\n",
            "Epoch 202/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1161 - acc: 0.9222 - val_loss: 0.0512 - val_acc: 0.9000\n",
            "Epoch 203/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1166 - acc: 0.8944 - val_loss: 0.0510 - val_acc: 0.9000\n",
            "Epoch 204/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1150 - acc: 0.9278 - val_loss: 0.0517 - val_acc: 0.9000\n",
            "Epoch 205/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1151 - acc: 0.9278 - val_loss: 0.0499 - val_acc: 0.9000\n",
            "Epoch 206/800\n",
            "180/180 [==============================] - 0s 328us/step - loss: 0.1145 - acc: 0.9556 - val_loss: 0.0506 - val_acc: 0.9000\n",
            "Epoch 207/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1149 - acc: 0.9222 - val_loss: 0.0501 - val_acc: 0.9000\n",
            "Epoch 208/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1148 - acc: 0.9278 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 209/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1145 - acc: 0.9444 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 210/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 211/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1146 - acc: 0.9333 - val_loss: 0.0507 - val_acc: 0.8500\n",
            "Epoch 212/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1152 - acc: 0.9389 - val_loss: 0.0494 - val_acc: 0.8500\n",
            "Epoch 213/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1149 - acc: 0.9333 - val_loss: 0.0510 - val_acc: 0.9000\n",
            "Epoch 214/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1158 - acc: 0.9333 - val_loss: 0.0502 - val_acc: 0.9000\n",
            "Epoch 215/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1146 - acc: 0.9278 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 216/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1146 - acc: 0.9389 - val_loss: 0.0510 - val_acc: 0.9500\n",
            "Epoch 217/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1148 - acc: 0.9444 - val_loss: 0.0504 - val_acc: 0.9000\n",
            "Epoch 218/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1157 - acc: 0.9333 - val_loss: 0.0500 - val_acc: 0.9000\n",
            "Epoch 219/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0494 - val_acc: 0.9500\n",
            "Epoch 220/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1155 - acc: 0.9111 - val_loss: 0.0499 - val_acc: 0.9000\n",
            "Epoch 221/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1145 - acc: 0.9444 - val_loss: 0.0494 - val_acc: 0.8000\n",
            "Epoch 222/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1148 - acc: 0.9333 - val_loss: 0.0518 - val_acc: 0.8500\n",
            "Epoch 223/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1158 - acc: 0.9222 - val_loss: 0.0498 - val_acc: 0.8500\n",
            "Epoch 224/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1146 - acc: 0.9278 - val_loss: 0.0495 - val_acc: 0.9000\n",
            "Epoch 225/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1144 - acc: 0.9389 - val_loss: 0.0508 - val_acc: 0.9000\n",
            "Epoch 226/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0512 - val_acc: 0.8000\n",
            "Epoch 227/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1152 - acc: 0.9278 - val_loss: 0.0498 - val_acc: 0.8500\n",
            "Epoch 228/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1145 - acc: 0.9389 - val_loss: 0.0508 - val_acc: 0.8000\n",
            "Epoch 229/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.1146 - acc: 0.9167 - val_loss: 0.0498 - val_acc: 0.9000\n",
            "Epoch 230/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0539 - val_acc: 0.7500\n",
            "Epoch 231/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1156 - acc: 0.9167 - val_loss: 0.0503 - val_acc: 0.8500\n",
            "Epoch 232/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0499 - val_acc: 0.8500\n",
            "Epoch 233/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1146 - acc: 0.9278 - val_loss: 0.0543 - val_acc: 0.8500\n",
            "Epoch 234/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1158 - acc: 0.9111 - val_loss: 0.0496 - val_acc: 0.9000\n",
            "Epoch 235/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1148 - acc: 0.9333 - val_loss: 0.0493 - val_acc: 0.8500\n",
            "Epoch 236/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1151 - acc: 0.9278 - val_loss: 0.0506 - val_acc: 0.9500\n",
            "Epoch 237/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1151 - acc: 0.9333 - val_loss: 0.0495 - val_acc: 0.9000\n",
            "Epoch 238/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0504 - val_acc: 0.9000\n",
            "Epoch 239/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1152 - acc: 0.9167 - val_loss: 0.0499 - val_acc: 0.9500\n",
            "Epoch 240/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1147 - acc: 0.9278 - val_loss: 0.0502 - val_acc: 0.8500\n",
            "Epoch 241/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1149 - acc: 0.9278 - val_loss: 0.0519 - val_acc: 0.9500\n",
            "Epoch 242/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1155 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 243/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1145 - acc: 0.9222 - val_loss: 0.0495 - val_acc: 0.8500\n",
            "Epoch 244/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1153 - acc: 0.9167 - val_loss: 0.0499 - val_acc: 0.8000\n",
            "Epoch 245/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1142 - acc: 0.9444 - val_loss: 0.0500 - val_acc: 0.8500\n",
            "Epoch 246/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1154 - acc: 0.9333 - val_loss: 0.0497 - val_acc: 0.8500\n",
            "Epoch 247/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1145 - acc: 0.9389 - val_loss: 0.0508 - val_acc: 0.8000\n",
            "Epoch 248/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1148 - acc: 0.9222 - val_loss: 0.0494 - val_acc: 0.9000\n",
            "Epoch 249/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1139 - acc: 0.9389 - val_loss: 0.0508 - val_acc: 0.9000\n",
            "Epoch 250/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1149 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.8000\n",
            "Epoch 251/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1154 - acc: 0.9167 - val_loss: 0.0506 - val_acc: 0.8500\n",
            "Epoch 252/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1149 - acc: 0.9222 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 253/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1144 - acc: 0.9389 - val_loss: 0.0492 - val_acc: 0.7500\n",
            "Epoch 254/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1145 - acc: 0.9444 - val_loss: 0.0504 - val_acc: 0.9000\n",
            "Epoch 255/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1156 - acc: 0.9333 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 256/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1144 - acc: 0.9389 - val_loss: 0.0497 - val_acc: 0.9000\n",
            "Epoch 257/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1146 - acc: 0.9222 - val_loss: 0.0496 - val_acc: 0.8500\n",
            "Epoch 258/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1159 - acc: 0.9278 - val_loss: 0.0507 - val_acc: 0.8500\n",
            "Epoch 259/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1156 - acc: 0.9278 - val_loss: 0.0508 - val_acc: 0.9000\n",
            "Epoch 260/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1150 - acc: 0.9278 - val_loss: 0.0505 - val_acc: 0.9000\n",
            "Epoch 261/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1147 - acc: 0.9389 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 262/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1145 - acc: 0.9333 - val_loss: 0.0505 - val_acc: 0.9500\n",
            "Epoch 263/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1147 - acc: 0.9500 - val_loss: 0.0503 - val_acc: 0.9500\n",
            "Epoch 264/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1150 - acc: 0.9389 - val_loss: 0.0495 - val_acc: 0.9000\n",
            "Epoch 265/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1147 - acc: 0.9333 - val_loss: 0.0500 - val_acc: 0.8500\n",
            "Epoch 266/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1149 - acc: 0.9389 - val_loss: 0.0495 - val_acc: 0.8500\n",
            "Epoch 267/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1146 - acc: 0.9444 - val_loss: 0.0495 - val_acc: 0.9500\n",
            "Epoch 268/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1145 - acc: 0.9333 - val_loss: 0.0505 - val_acc: 0.8500\n",
            "Epoch 269/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1155 - acc: 0.9333 - val_loss: 0.0495 - val_acc: 0.8500\n",
            "Epoch 270/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1146 - acc: 0.9389 - val_loss: 0.0503 - val_acc: 0.8500\n",
            "Epoch 271/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1147 - acc: 0.9167 - val_loss: 0.0495 - val_acc: 0.9000\n",
            "Epoch 272/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1151 - acc: 0.9167 - val_loss: 0.0504 - val_acc: 0.9000\n",
            "Epoch 273/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1141 - acc: 0.9389 - val_loss: 0.0504 - val_acc: 0.8500\n",
            "Epoch 274/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.1156 - acc: 0.9278 - val_loss: 0.0511 - val_acc: 0.8500\n",
            "Epoch 275/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1152 - acc: 0.9333 - val_loss: 0.0487 - val_acc: 0.9000\n",
            "Epoch 276/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1142 - acc: 0.9389 - val_loss: 0.0495 - val_acc: 0.8000\n",
            "Epoch 277/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1147 - acc: 0.9500 - val_loss: 0.0492 - val_acc: 0.9000\n",
            "Epoch 278/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1145 - acc: 0.9500 - val_loss: 0.0496 - val_acc: 0.9000\n",
            "Epoch 279/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1143 - acc: 0.9222 - val_loss: 0.0494 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00279: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 280/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1140 - acc: 0.9222 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 281/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0492 - val_acc: 0.8500\n",
            "Epoch 282/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 283/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 284/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 285/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 286/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 287/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 288/800\n",
            "180/180 [==============================] - 0s 304us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 289/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 290/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 291/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 292/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 293/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1138 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 294/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 295/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 296/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 297/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 298/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 299/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1138 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 300/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 301/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 302/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 303/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 304/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 305/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 306/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 307/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 308/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 309/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 310/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 311/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 312/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 313/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.9278 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 314/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 315/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 316/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 317/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 318/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 319/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9500\n",
            "Epoch 320/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 321/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 322/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 323/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 324/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1138 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9500\n",
            "Epoch 325/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9500\n",
            "Epoch 326/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 327/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1138 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 328/800\n",
            "180/180 [==============================] - 0s 322us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 329/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 330/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 331/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 332/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 333/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 334/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 335/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 336/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 337/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 338/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 339/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 340/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 341/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 342/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 343/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 344/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 345/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 346/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 347/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1136 - acc: 0.9444 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 348/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 349/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 350/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 351/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 352/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 353/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 354/800\n",
            "180/180 [==============================] - 0s 324us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 355/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 356/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 357/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0492 - val_acc: 0.9500\n",
            "Epoch 358/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 359/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 360/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 361/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1137 - acc: 0.9500 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 362/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 363/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 364/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 365/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 366/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 367/800\n",
            "180/180 [==============================] - 0s 311us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 368/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 369/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 370/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 371/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 372/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0492 - val_acc: 0.9500\n",
            "Epoch 373/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 374/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 375/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 376/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 377/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 378/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 379/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9500\n",
            "Epoch 380/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 381/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 382/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 383/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 384/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 385/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 386/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 387/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 388/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 389/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 390/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1138 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 391/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 392/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 393/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 394/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 395/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 396/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 397/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 398/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 399/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1136 - acc: 0.9444 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 400/800\n",
            "180/180 [==============================] - 0s 316us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 401/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1138 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9500\n",
            "Epoch 402/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 403/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 404/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 405/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 406/800\n",
            "180/180 [==============================] - 0s 266us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 407/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 408/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 409/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1136 - acc: 0.9444 - val_loss: 0.0489 - val_acc: 0.9500\n",
            "Epoch 410/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9500\n",
            "Epoch 411/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 412/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 413/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9500\n",
            "Epoch 414/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 415/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.9500\n",
            "Epoch 416/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 417/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0487 - val_acc: 0.9000\n",
            "Epoch 418/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 419/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 420/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 421/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 422/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 423/800\n",
            "180/180 [==============================] - 0s 320us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 424/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 425/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 426/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 427/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 428/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 429/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 430/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 431/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8000\n",
            "Epoch 432/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 433/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 434/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 435/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 436/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 437/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 438/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 439/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0491 - val_acc: 0.9500\n",
            "Epoch 440/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 441/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 442/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9500\n",
            "Epoch 443/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 444/800\n",
            "180/180 [==============================] - 0s 254us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 445/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 446/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 447/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 448/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 449/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 450/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9500\n",
            "Epoch 451/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 452/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 453/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 454/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 455/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 456/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1136 - acc: 0.9444 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 457/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.9000\n",
            "Epoch 458/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1137 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 459/800\n",
            "180/180 [==============================] - 0s 301us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 460/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 461/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 462/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 463/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1137 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 464/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 465/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 466/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 467/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 468/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 469/800\n",
            "180/180 [==============================] - 0s 318us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 470/800\n",
            "180/180 [==============================] - 0s 329us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0491 - val_acc: 0.9000\n",
            "Epoch 471/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1136 - acc: 0.9333 - val_loss: 0.0491 - val_acc: 0.8500\n",
            "Epoch 472/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 473/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 474/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 475/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 476/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1136 - acc: 0.9278 - val_loss: 0.0490 - val_acc: 0.9000\n",
            "Epoch 477/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 478/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1137 - acc: 0.9444 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 479/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1136 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00479: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 480/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 481/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 482/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 483/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 484/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 485/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 486/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 487/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 488/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 489/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 490/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 491/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 492/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 493/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 494/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 495/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 496/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 497/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 498/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 499/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 500/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 501/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 502/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 503/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 504/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 505/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 506/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 507/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 508/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 509/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 510/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 511/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 512/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 513/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 514/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 515/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 516/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 517/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 518/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 519/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 520/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 521/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 522/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 523/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 524/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 525/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 526/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 527/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 528/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 529/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 530/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 531/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 532/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 533/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 534/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 535/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 536/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 537/800\n",
            "180/180 [==============================] - 0s 326us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 538/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 539/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 540/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 541/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 542/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 543/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 544/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 545/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 546/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 547/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 548/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 549/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 550/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 551/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 552/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 553/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 554/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 555/800\n",
            "180/180 [==============================] - 0s 303us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 556/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 557/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 558/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 559/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 560/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 561/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 562/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 563/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 564/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 565/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 566/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 567/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 568/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 569/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 570/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 571/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 572/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 573/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 574/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 575/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 576/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 577/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 578/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 579/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 580/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 581/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 582/800\n",
            "180/180 [==============================] - 0s 325us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 583/800\n",
            "180/180 [==============================] - 0s 300us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 584/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 585/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 586/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 587/800\n",
            "180/180 [==============================] - 0s 260us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 588/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 589/800\n",
            "180/180 [==============================] - 0s 297us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 590/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 591/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 592/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 593/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 594/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 595/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 596/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 597/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 598/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 599/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 600/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 601/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 602/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 603/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 604/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 605/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 606/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 607/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 608/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 609/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 610/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 611/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 612/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 613/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 614/800\n",
            "180/180 [==============================] - 0s 299us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 615/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 616/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 617/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0490 - val_acc: 0.8500\n",
            "Epoch 618/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 619/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 620/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 621/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 622/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 623/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 624/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 625/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 626/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 627/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 628/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 629/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 630/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 631/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 632/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 633/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 634/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 635/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 636/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 637/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 638/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 639/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 640/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 641/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 642/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 643/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 644/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 645/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 646/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 647/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 648/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 649/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 650/800\n",
            "180/180 [==============================] - 0s 323us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 651/800\n",
            "180/180 [==============================] - 0s 305us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 652/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 653/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 654/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 655/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 656/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 657/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 658/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 659/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 660/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 661/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 662/800\n",
            "180/180 [==============================] - 0s 302us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 663/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0488 - val_acc: 0.8500\n",
            "Epoch 664/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 665/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 666/800\n",
            "180/180 [==============================] - 0s 298us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 667/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 668/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 669/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 670/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 671/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 672/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 673/800\n",
            "180/180 [==============================] - 0s 406us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 674/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 675/800\n",
            "180/180 [==============================] - 0s 291us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 676/800\n",
            "180/180 [==============================] - 0s 315us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 677/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.9000\n",
            "Epoch 678/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1135 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 679/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00679: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
            "Epoch 680/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 681/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 682/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 683/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 684/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 685/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 686/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 687/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 688/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 689/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 690/800\n",
            "180/180 [==============================] - 0s 295us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 691/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 692/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 693/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 694/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 695/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 696/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 697/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 698/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 699/800\n",
            "180/180 [==============================] - 0s 285us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 700/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 701/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 702/800\n",
            "180/180 [==============================] - 0s 271us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 703/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 704/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 705/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 706/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 707/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 708/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 709/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 710/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 711/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 712/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 713/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 714/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 715/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 716/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 717/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 718/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 719/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 720/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 721/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 722/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 723/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 724/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 725/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 726/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 727/800\n",
            "180/180 [==============================] - 0s 290us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 728/800\n",
            "180/180 [==============================] - 0s 284us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 729/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 730/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 731/800\n",
            "180/180 [==============================] - 0s 294us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 732/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 733/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 734/800\n",
            "180/180 [==============================] - 0s 286us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 735/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 736/800\n",
            "180/180 [==============================] - 0s 265us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 737/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 738/800\n",
            "180/180 [==============================] - 0s 293us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 739/800\n",
            "180/180 [==============================] - 0s 262us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 740/800\n",
            "180/180 [==============================] - 0s 296us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 741/800\n",
            "180/180 [==============================] - 0s 331us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 742/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 743/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 744/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 745/800\n",
            "180/180 [==============================] - 0s 288us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 746/800\n",
            "180/180 [==============================] - 0s 307us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 747/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 748/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 749/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 750/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 751/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 752/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 753/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 754/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 755/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 756/800\n",
            "180/180 [==============================] - 0s 276us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 757/800\n",
            "180/180 [==============================] - 0s 287us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 758/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 759/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 760/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 761/800\n",
            "180/180 [==============================] - 0s 289us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 762/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 763/800\n",
            "180/180 [==============================] - 0s 334us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 764/800\n",
            "180/180 [==============================] - 0s 317us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 765/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 766/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 767/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 768/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 769/800\n",
            "180/180 [==============================] - 0s 282us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 770/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 771/800\n",
            "180/180 [==============================] - 0s 283us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 772/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 773/800\n",
            "180/180 [==============================] - 0s 277us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 774/800\n",
            "180/180 [==============================] - 0s 269us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 775/800\n",
            "180/180 [==============================] - 0s 261us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 776/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 777/800\n",
            "180/180 [==============================] - 0s 309us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 778/800\n",
            "180/180 [==============================] - 0s 273us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 779/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 780/800\n",
            "180/180 [==============================] - 0s 275us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 781/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 782/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 783/800\n",
            "180/180 [==============================] - 0s 281us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 784/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 785/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 786/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 787/800\n",
            "180/180 [==============================] - 0s 292us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 788/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 789/800\n",
            "180/180 [==============================] - 0s 272us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 790/800\n",
            "180/180 [==============================] - 0s 267us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 791/800\n",
            "180/180 [==============================] - 0s 270us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 792/800\n",
            "180/180 [==============================] - 0s 268us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 793/800\n",
            "180/180 [==============================] - 0s 263us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 794/800\n",
            "180/180 [==============================] - 0s 274us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 795/800\n",
            "180/180 [==============================] - 0s 279us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 796/800\n",
            "180/180 [==============================] - 0s 280us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 797/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 798/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 799/800\n",
            "180/180 [==============================] - 0s 278us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "Epoch 800/800\n",
            "180/180 [==============================] - 0s 264us/step - loss: 0.1134 - acc: 0.9389 - val_loss: 0.0489 - val_acc: 0.8500\n",
            "200/200 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[-0.23071837, -0.03977853, -0.30753464, -0.23373485, -0.2245971 ,\n",
              "         0.0804491 ],\n",
              "       [ 1.2501553 ,  0.1461766 ,  2.3173544 ,  1.25168   , -0.31123096,\n",
              "        -0.9387397 ],\n",
              "       [ 0.38003436, -0.8984928 ,  1.0986574 ,  0.3778442 ,  1.9418195 ,\n",
              "        -0.77557313],\n",
              "       ...,\n",
              "       [-0.34294498,  0.00456637,  1.2267983 , -0.34612447, -0.24486047,\n",
              "        -0.80579376],\n",
              "       [ 0.03626356, -0.01529723, -0.7169802 ,  0.03368816, -0.24747998,\n",
              "         1.0480211 ],\n",
              "       [-0.97515094,  1.1910412 , -0.922286  , -0.97556263, -0.78397596,\n",
              "         2.395676  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UeVPCQwagH0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6771863e-7a72-46cf-9746-bf74abea6807"
      },
      "cell_type": "code",
      "source": [
        "score2 = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score2)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 0s 139us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0.8472060966491699, 0.57]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lZnB5kVDh98q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b1a4a8a8-43ae-49b8-9290-352a5fcc31ff"
      },
      "cell_type": "code",
      "source": [
        "display(x_train[3,:])\n",
        "display(x_train[0,:])\n",
        "display(x_train[5,:])\n",
        "\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([8.53335151e+01, 7.88288937e+01, 7.13779116e+00, 9.84570089e+03,\n",
              "       6.51875228e+03, 5.53952782e+03])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([8.53335430e+01, 7.88288506e+01, 7.13932366e+00, 9.84570282e+03,\n",
              "       6.51875732e+03, 5.53950301e+03])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([8.53335452e+01, 7.88288630e+01, 7.13976024e+00, 9.84570297e+03,\n",
              "       6.51875588e+03, 5.53949594e+03])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "q43WIBzaOTsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "7d5bce6d-028d-4ae8-c6f0-f1226a2275f4"
      },
      "cell_type": "code",
      "source": [
        "display(score[0,:])\n",
        "display(x_test2[0,:])\n",
        "display(x_train2[2,:])\n",
        "display(x_train[3,:])\n",
        "display(x_test[0,:])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([-0.2799706 ,  0.7340043 , -0.57149446,  0.20620513,  0.7250215 ,\n",
              "        0.545471  ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([-0.13627917,  0.71676571, -0.56267982,  0.3875516 ,  0.71680732,\n",
              "        0.574813  ])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([-0.18443958,  1.23373152, -1.62555058,  0.42156024,  1.3637031 ,\n",
              "        1.601184  ])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([7.98813047e+01, 6.53505302e+01, 1.27098814e+00, 9.01627079e+03,\n",
              "       4.86375687e+03, 2.22070061e+03])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([7.98813043e+01, 3.41690118e-01, 1.26727822e+00, 9.01627280e+03,\n",
              "       3.80362979e+02, 2.22112900e+03])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "kFC4_jKKrKs5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27319
        },
        "outputId": "8c9d0434-5e68-4449-ec82-5d9f1b2d0d43"
      },
      "cell_type": "code",
      "source": [
        "#Results with one sample anomily \n",
        "# the duration of the anom can be tuned with anom_samples\n",
        "full_anom = 0\n",
        "anom_samples = 1\n",
        "nb_epoch = 800 # a bit overkill but wanted to see how it progressed w more epochs \n",
        "batch_size = 32\n",
        "import keras\n",
        "autoencoder.compile(optimizer='nadam', \n",
        "                    loss='mean_squared_error', \n",
        "                    #loss='kullback_leibler_divergence',\n",
        "                    metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
        "                              patience=300,verbose = 1)\n",
        "history = autoencoder.fit(x_train2, x_train2,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    #validation_data=(x_test2[0:200,:], x_test2[0:200,:]),\n",
        "                    validation_split=.1,\n",
        "                    verbose=1,callbacks=[reduce_lr])\n",
        "\n",
        "score = autoencoder.evaluate(x_test2, x_test2, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
        "\n",
        "display('[test_loss, test_acc]')\n",
        "display(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 180 samples, validate on 20 samples\n",
            "Epoch 1/800\n",
            "180/180 [==============================] - 9s 48ms/step - loss: 1.5007 - acc: 0.1944 - val_loss: 1.4750 - val_acc: 0.0500\n",
            "Epoch 2/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 1.4188 - acc: 0.1778 - val_loss: 1.3748 - val_acc: 0.1000\n",
            "Epoch 3/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 1.3436 - acc: 0.1778 - val_loss: 1.2763 - val_acc: 0.1000\n",
            "Epoch 4/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 1.2729 - acc: 0.1889 - val_loss: 1.1892 - val_acc: 0.1000\n",
            "Epoch 5/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 1.2061 - acc: 0.2000 - val_loss: 1.1073 - val_acc: 0.0500\n",
            "Epoch 6/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 1.1525 - acc: 0.2222 - val_loss: 1.0312 - val_acc: 0.0500\n",
            "Epoch 7/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 1.0978 - acc: 0.2389 - val_loss: 0.9676 - val_acc: 0.0500\n",
            "Epoch 8/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 1.0522 - acc: 0.2389 - val_loss: 0.9153 - val_acc: 0.0500\n",
            "Epoch 9/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 1.0107 - acc: 0.2333 - val_loss: 0.8732 - val_acc: 0.0500\n",
            "Epoch 10/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.9725 - acc: 0.2500 - val_loss: 0.8354 - val_acc: 0.1500\n",
            "Epoch 11/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.9422 - acc: 0.2500 - val_loss: 0.8030 - val_acc: 0.1500\n",
            "Epoch 12/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.9117 - acc: 0.2722 - val_loss: 0.7754 - val_acc: 0.1500\n",
            "Epoch 13/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.8858 - acc: 0.2833 - val_loss: 0.7522 - val_acc: 0.2000\n",
            "Epoch 14/800\n",
            "180/180 [==============================] - 0s 407us/step - loss: 0.8624 - acc: 0.2944 - val_loss: 0.7316 - val_acc: 0.2000\n",
            "Epoch 15/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.8392 - acc: 0.2944 - val_loss: 0.7142 - val_acc: 0.2000\n",
            "Epoch 16/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.8239 - acc: 0.3000 - val_loss: 0.6994 - val_acc: 0.2000\n",
            "Epoch 17/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.8069 - acc: 0.2889 - val_loss: 0.6862 - val_acc: 0.2000\n",
            "Epoch 18/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.7897 - acc: 0.2944 - val_loss: 0.6746 - val_acc: 0.2000\n",
            "Epoch 19/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.7771 - acc: 0.2944 - val_loss: 0.6637 - val_acc: 0.1500\n",
            "Epoch 20/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.7660 - acc: 0.2889 - val_loss: 0.6535 - val_acc: 0.1500\n",
            "Epoch 21/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.7481 - acc: 0.2889 - val_loss: 0.6434 - val_acc: 0.1500\n",
            "Epoch 22/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.7363 - acc: 0.2944 - val_loss: 0.6339 - val_acc: 0.1500\n",
            "Epoch 23/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.7256 - acc: 0.3000 - val_loss: 0.6249 - val_acc: 0.1500\n",
            "Epoch 24/800\n",
            "180/180 [==============================] - 0s 328us/step - loss: 0.7132 - acc: 0.3000 - val_loss: 0.6160 - val_acc: 0.1500\n",
            "Epoch 25/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.7003 - acc: 0.3111 - val_loss: 0.6074 - val_acc: 0.1500\n",
            "Epoch 26/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.6919 - acc: 0.3278 - val_loss: 0.5993 - val_acc: 0.1500\n",
            "Epoch 27/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.6804 - acc: 0.3222 - val_loss: 0.5914 - val_acc: 0.1500\n",
            "Epoch 28/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.6699 - acc: 0.3278 - val_loss: 0.5837 - val_acc: 0.1500\n",
            "Epoch 29/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.6585 - acc: 0.3278 - val_loss: 0.5755 - val_acc: 0.1500\n",
            "Epoch 30/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.6484 - acc: 0.3389 - val_loss: 0.5679 - val_acc: 0.1500\n",
            "Epoch 31/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.6386 - acc: 0.3611 - val_loss: 0.5605 - val_acc: 0.1500\n",
            "Epoch 32/800\n",
            "180/180 [==============================] - 0s 473us/step - loss: 0.6282 - acc: 0.3611 - val_loss: 0.5532 - val_acc: 0.1500\n",
            "Epoch 33/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.6191 - acc: 0.3667 - val_loss: 0.5460 - val_acc: 0.2000\n",
            "Epoch 34/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.6105 - acc: 0.3833 - val_loss: 0.5387 - val_acc: 0.2000\n",
            "Epoch 35/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.6019 - acc: 0.3722 - val_loss: 0.5318 - val_acc: 0.2000\n",
            "Epoch 36/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.5935 - acc: 0.3889 - val_loss: 0.5253 - val_acc: 0.2000\n",
            "Epoch 37/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.5843 - acc: 0.3889 - val_loss: 0.5186 - val_acc: 0.2000\n",
            "Epoch 38/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.5755 - acc: 0.4056 - val_loss: 0.5122 - val_acc: 0.2000\n",
            "Epoch 39/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.5672 - acc: 0.4056 - val_loss: 0.5058 - val_acc: 0.2500\n",
            "Epoch 40/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.5619 - acc: 0.4111 - val_loss: 0.4996 - val_acc: 0.3500\n",
            "Epoch 41/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.5539 - acc: 0.4111 - val_loss: 0.4934 - val_acc: 0.3500\n",
            "Epoch 42/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.5457 - acc: 0.4167 - val_loss: 0.4873 - val_acc: 0.3500\n",
            "Epoch 43/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.5392 - acc: 0.4389 - val_loss: 0.4813 - val_acc: 0.3500\n",
            "Epoch 44/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.5312 - acc: 0.4444 - val_loss: 0.4754 - val_acc: 0.4000\n",
            "Epoch 45/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.5251 - acc: 0.4611 - val_loss: 0.4695 - val_acc: 0.4000\n",
            "Epoch 46/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.5185 - acc: 0.4778 - val_loss: 0.4635 - val_acc: 0.4000\n",
            "Epoch 47/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.5124 - acc: 0.4833 - val_loss: 0.4575 - val_acc: 0.4000\n",
            "Epoch 48/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.5050 - acc: 0.4889 - val_loss: 0.4516 - val_acc: 0.4000\n",
            "Epoch 49/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.4986 - acc: 0.4944 - val_loss: 0.4456 - val_acc: 0.4000\n",
            "Epoch 50/800\n",
            "180/180 [==============================] - 0s 480us/step - loss: 0.4920 - acc: 0.4944 - val_loss: 0.4398 - val_acc: 0.4000\n",
            "Epoch 51/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.4860 - acc: 0.4944 - val_loss: 0.4339 - val_acc: 0.4000\n",
            "Epoch 52/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4799 - acc: 0.4944 - val_loss: 0.4282 - val_acc: 0.4000\n",
            "Epoch 53/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.4741 - acc: 0.5000 - val_loss: 0.4225 - val_acc: 0.4000\n",
            "Epoch 54/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4687 - acc: 0.5000 - val_loss: 0.4170 - val_acc: 0.4000\n",
            "Epoch 55/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.4627 - acc: 0.4889 - val_loss: 0.4113 - val_acc: 0.4000\n",
            "Epoch 56/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.4570 - acc: 0.4889 - val_loss: 0.4055 - val_acc: 0.4000\n",
            "Epoch 57/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.4512 - acc: 0.4944 - val_loss: 0.3998 - val_acc: 0.4000\n",
            "Epoch 58/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.4457 - acc: 0.4944 - val_loss: 0.3941 - val_acc: 0.4000\n",
            "Epoch 59/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4400 - acc: 0.5000 - val_loss: 0.3885 - val_acc: 0.4000\n",
            "Epoch 60/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.4348 - acc: 0.5056 - val_loss: 0.3827 - val_acc: 0.4000\n",
            "Epoch 61/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.4297 - acc: 0.5222 - val_loss: 0.3772 - val_acc: 0.4000\n",
            "Epoch 62/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.4241 - acc: 0.5167 - val_loss: 0.3718 - val_acc: 0.4000\n",
            "Epoch 63/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.4191 - acc: 0.5333 - val_loss: 0.3664 - val_acc: 0.4000\n",
            "Epoch 64/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.4132 - acc: 0.5444 - val_loss: 0.3613 - val_acc: 0.4500\n",
            "Epoch 65/800\n",
            "180/180 [==============================] - 0s 392us/step - loss: 0.4086 - acc: 0.5389 - val_loss: 0.3560 - val_acc: 0.4500\n",
            "Epoch 66/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.4038 - acc: 0.5389 - val_loss: 0.3506 - val_acc: 0.4500\n",
            "Epoch 67/800\n",
            "180/180 [==============================] - 0s 487us/step - loss: 0.3983 - acc: 0.5444 - val_loss: 0.3453 - val_acc: 0.5000\n",
            "Epoch 68/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.3933 - acc: 0.5556 - val_loss: 0.3400 - val_acc: 0.5500\n",
            "Epoch 69/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.3886 - acc: 0.5722 - val_loss: 0.3349 - val_acc: 0.5500\n",
            "Epoch 70/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.3830 - acc: 0.5556 - val_loss: 0.3297 - val_acc: 0.5500\n",
            "Epoch 71/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.3788 - acc: 0.5500 - val_loss: 0.3246 - val_acc: 0.5500\n",
            "Epoch 72/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.3741 - acc: 0.5611 - val_loss: 0.3196 - val_acc: 0.5500\n",
            "Epoch 73/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.3692 - acc: 0.5611 - val_loss: 0.3146 - val_acc: 0.5500\n",
            "Epoch 74/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.3644 - acc: 0.5556 - val_loss: 0.3098 - val_acc: 0.5500\n",
            "Epoch 75/800\n",
            "180/180 [==============================] - 0s 338us/step - loss: 0.3599 - acc: 0.5500 - val_loss: 0.3050 - val_acc: 0.5500\n",
            "Epoch 76/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.3557 - acc: 0.5556 - val_loss: 0.3005 - val_acc: 0.5500\n",
            "Epoch 77/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.3510 - acc: 0.5611 - val_loss: 0.2959 - val_acc: 0.5500\n",
            "Epoch 78/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.3460 - acc: 0.5722 - val_loss: 0.2914 - val_acc: 0.5500\n",
            "Epoch 79/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.3422 - acc: 0.5778 - val_loss: 0.2870 - val_acc: 0.5500\n",
            "Epoch 80/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.3376 - acc: 0.5611 - val_loss: 0.2824 - val_acc: 0.5500\n",
            "Epoch 81/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.3335 - acc: 0.5778 - val_loss: 0.2783 - val_acc: 0.5500\n",
            "Epoch 82/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.3289 - acc: 0.5722 - val_loss: 0.2743 - val_acc: 0.5500\n",
            "Epoch 83/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.3251 - acc: 0.5889 - val_loss: 0.2706 - val_acc: 0.5500\n",
            "Epoch 84/800\n",
            "180/180 [==============================] - 0s 496us/step - loss: 0.3208 - acc: 0.5944 - val_loss: 0.2666 - val_acc: 0.5500\n",
            "Epoch 85/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.3169 - acc: 0.5889 - val_loss: 0.2628 - val_acc: 0.5500\n",
            "Epoch 86/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.3127 - acc: 0.5889 - val_loss: 0.2585 - val_acc: 0.5500\n",
            "Epoch 87/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.3091 - acc: 0.6000 - val_loss: 0.2550 - val_acc: 0.5500\n",
            "Epoch 88/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.3045 - acc: 0.5889 - val_loss: 0.2515 - val_acc: 0.5500\n",
            "Epoch 89/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.3010 - acc: 0.5833 - val_loss: 0.2477 - val_acc: 0.5500\n",
            "Epoch 90/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.2974 - acc: 0.5944 - val_loss: 0.2438 - val_acc: 0.5500\n",
            "Epoch 91/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.2930 - acc: 0.5889 - val_loss: 0.2404 - val_acc: 0.6000\n",
            "Epoch 92/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.2897 - acc: 0.5889 - val_loss: 0.2366 - val_acc: 0.6000\n",
            "Epoch 93/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.2859 - acc: 0.6000 - val_loss: 0.2335 - val_acc: 0.6000\n",
            "Epoch 94/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.2824 - acc: 0.6000 - val_loss: 0.2304 - val_acc: 0.6000\n",
            "Epoch 95/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.2791 - acc: 0.6000 - val_loss: 0.2272 - val_acc: 0.6000\n",
            "Epoch 96/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.2753 - acc: 0.6111 - val_loss: 0.2243 - val_acc: 0.6000\n",
            "Epoch 97/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.2718 - acc: 0.6111 - val_loss: 0.2221 - val_acc: 0.6000\n",
            "Epoch 98/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.2686 - acc: 0.6056 - val_loss: 0.2183 - val_acc: 0.6000\n",
            "Epoch 99/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.2650 - acc: 0.6056 - val_loss: 0.2157 - val_acc: 0.6000\n",
            "Epoch 100/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.2619 - acc: 0.6111 - val_loss: 0.2122 - val_acc: 0.6000\n",
            "Epoch 101/800\n",
            "180/180 [==============================] - 0s 405us/step - loss: 0.2584 - acc: 0.6278 - val_loss: 0.2096 - val_acc: 0.6000\n",
            "Epoch 102/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.2556 - acc: 0.6056 - val_loss: 0.2066 - val_acc: 0.6000\n",
            "Epoch 103/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.2527 - acc: 0.6222 - val_loss: 0.2034 - val_acc: 0.6500\n",
            "Epoch 104/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.2495 - acc: 0.6278 - val_loss: 0.2005 - val_acc: 0.6500\n",
            "Epoch 105/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.2466 - acc: 0.6389 - val_loss: 0.1979 - val_acc: 0.6500\n",
            "Epoch 106/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.2436 - acc: 0.6389 - val_loss: 0.1955 - val_acc: 0.6000\n",
            "Epoch 107/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.2413 - acc: 0.6167 - val_loss: 0.1937 - val_acc: 0.6500\n",
            "Epoch 108/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.2385 - acc: 0.6333 - val_loss: 0.1916 - val_acc: 0.6500\n",
            "Epoch 109/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.2358 - acc: 0.6333 - val_loss: 0.1885 - val_acc: 0.6500\n",
            "Epoch 110/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.2329 - acc: 0.6389 - val_loss: 0.1873 - val_acc: 0.6500\n",
            "Epoch 111/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.2307 - acc: 0.6556 - val_loss: 0.1861 - val_acc: 0.6500\n",
            "Epoch 112/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.2284 - acc: 0.6389 - val_loss: 0.1823 - val_acc: 0.5500\n",
            "Epoch 113/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.2256 - acc: 0.6611 - val_loss: 0.1805 - val_acc: 0.5500\n",
            "Epoch 114/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.2239 - acc: 0.6611 - val_loss: 0.1781 - val_acc: 0.5500\n",
            "Epoch 115/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.2212 - acc: 0.6611 - val_loss: 0.1763 - val_acc: 0.6000\n",
            "Epoch 116/800\n",
            "180/180 [==============================] - 0s 336us/step - loss: 0.2190 - acc: 0.6667 - val_loss: 0.1745 - val_acc: 0.6000\n",
            "Epoch 117/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.2171 - acc: 0.6611 - val_loss: 0.1728 - val_acc: 0.5500\n",
            "Epoch 118/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.2149 - acc: 0.6778 - val_loss: 0.1728 - val_acc: 0.5500\n",
            "Epoch 119/800\n",
            "180/180 [==============================] - 0s 450us/step - loss: 0.2130 - acc: 0.6833 - val_loss: 0.1694 - val_acc: 0.6000\n",
            "Epoch 120/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.2109 - acc: 0.6778 - val_loss: 0.1673 - val_acc: 0.6000\n",
            "Epoch 121/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.2087 - acc: 0.6833 - val_loss: 0.1663 - val_acc: 0.6000\n",
            "Epoch 122/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.2072 - acc: 0.6722 - val_loss: 0.1646 - val_acc: 0.5500\n",
            "Epoch 123/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.2051 - acc: 0.6833 - val_loss: 0.1628 - val_acc: 0.6000\n",
            "Epoch 124/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.2036 - acc: 0.6722 - val_loss: 0.1614 - val_acc: 0.6000\n",
            "Epoch 125/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.2017 - acc: 0.6833 - val_loss: 0.1601 - val_acc: 0.6000\n",
            "Epoch 126/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1999 - acc: 0.7000 - val_loss: 0.1590 - val_acc: 0.6000\n",
            "Epoch 127/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1984 - acc: 0.6889 - val_loss: 0.1571 - val_acc: 0.5500\n",
            "Epoch 128/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1970 - acc: 0.6833 - val_loss: 0.1557 - val_acc: 0.5500\n",
            "Epoch 129/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1950 - acc: 0.6944 - val_loss: 0.1550 - val_acc: 0.5500\n",
            "Epoch 130/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1940 - acc: 0.7056 - val_loss: 0.1544 - val_acc: 0.5500\n",
            "Epoch 131/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1926 - acc: 0.6889 - val_loss: 0.1517 - val_acc: 0.5500\n",
            "Epoch 132/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1915 - acc: 0.7056 - val_loss: 0.1509 - val_acc: 0.5500\n",
            "Epoch 133/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1897 - acc: 0.7056 - val_loss: 0.1498 - val_acc: 0.5500\n",
            "Epoch 134/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.1881 - acc: 0.7000 - val_loss: 0.1483 - val_acc: 0.5500\n",
            "Epoch 135/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1870 - acc: 0.6944 - val_loss: 0.1480 - val_acc: 0.5500\n",
            "Epoch 136/800\n",
            "180/180 [==============================] - 0s 438us/step - loss: 0.1862 - acc: 0.6944 - val_loss: 0.1461 - val_acc: 0.5500\n",
            "Epoch 137/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.1842 - acc: 0.7056 - val_loss: 0.1452 - val_acc: 0.5500\n",
            "Epoch 138/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1832 - acc: 0.7056 - val_loss: 0.1448 - val_acc: 0.5500\n",
            "Epoch 139/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1822 - acc: 0.7111 - val_loss: 0.1426 - val_acc: 0.5500\n",
            "Epoch 140/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1808 - acc: 0.7167 - val_loss: 0.1429 - val_acc: 0.5500\n",
            "Epoch 141/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1797 - acc: 0.7222 - val_loss: 0.1430 - val_acc: 0.5500\n",
            "Epoch 142/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1788 - acc: 0.7222 - val_loss: 0.1413 - val_acc: 0.5500\n",
            "Epoch 143/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1775 - acc: 0.7222 - val_loss: 0.1397 - val_acc: 0.5500\n",
            "Epoch 144/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1766 - acc: 0.7222 - val_loss: 0.1390 - val_acc: 0.5000\n",
            "Epoch 145/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1757 - acc: 0.7056 - val_loss: 0.1387 - val_acc: 0.5500\n",
            "Epoch 146/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1744 - acc: 0.7222 - val_loss: 0.1381 - val_acc: 0.5000\n",
            "Epoch 147/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.1742 - acc: 0.7222 - val_loss: 0.1362 - val_acc: 0.5000\n",
            "Epoch 148/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1726 - acc: 0.7167 - val_loss: 0.1352 - val_acc: 0.5000\n",
            "Epoch 149/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1713 - acc: 0.7056 - val_loss: 0.1342 - val_acc: 0.5000\n",
            "Epoch 150/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1708 - acc: 0.7056 - val_loss: 0.1336 - val_acc: 0.5000\n",
            "Epoch 151/800\n",
            "180/180 [==============================] - 0s 330us/step - loss: 0.1698 - acc: 0.7111 - val_loss: 0.1330 - val_acc: 0.5000\n",
            "Epoch 152/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1691 - acc: 0.7056 - val_loss: 0.1327 - val_acc: 0.5000\n",
            "Epoch 153/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1687 - acc: 0.7167 - val_loss: 0.1322 - val_acc: 0.5000\n",
            "Epoch 154/800\n",
            "180/180 [==============================] - 0s 483us/step - loss: 0.1675 - acc: 0.7056 - val_loss: 0.1313 - val_acc: 0.5000\n",
            "Epoch 155/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1671 - acc: 0.7056 - val_loss: 0.1306 - val_acc: 0.5000\n",
            "Epoch 156/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1658 - acc: 0.7222 - val_loss: 0.1294 - val_acc: 0.5000\n",
            "Epoch 157/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1651 - acc: 0.7000 - val_loss: 0.1298 - val_acc: 0.5000\n",
            "Epoch 158/800\n",
            "180/180 [==============================] - 0s 337us/step - loss: 0.1644 - acc: 0.7167 - val_loss: 0.1289 - val_acc: 0.5500\n",
            "Epoch 159/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1638 - acc: 0.6889 - val_loss: 0.1304 - val_acc: 0.5500\n",
            "Epoch 160/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1632 - acc: 0.7111 - val_loss: 0.1275 - val_acc: 0.5500\n",
            "Epoch 161/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1628 - acc: 0.7056 - val_loss: 0.1267 - val_acc: 0.5500\n",
            "Epoch 162/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1615 - acc: 0.7111 - val_loss: 0.1262 - val_acc: 0.5500\n",
            "Epoch 163/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.1606 - acc: 0.7000 - val_loss: 0.1257 - val_acc: 0.5500\n",
            "Epoch 164/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1601 - acc: 0.7056 - val_loss: 0.1246 - val_acc: 0.5500\n",
            "Epoch 165/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1593 - acc: 0.7056 - val_loss: 0.1250 - val_acc: 0.5500\n",
            "Epoch 166/800\n",
            "180/180 [==============================] - 0s 334us/step - loss: 0.1590 - acc: 0.7000 - val_loss: 0.1232 - val_acc: 0.5500\n",
            "Epoch 167/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1584 - acc: 0.7222 - val_loss: 0.1244 - val_acc: 0.5500\n",
            "Epoch 168/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.1576 - acc: 0.7167 - val_loss: 0.1240 - val_acc: 0.5500\n",
            "Epoch 169/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1571 - acc: 0.7222 - val_loss: 0.1225 - val_acc: 0.5500\n",
            "Epoch 170/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1570 - acc: 0.7000 - val_loss: 0.1215 - val_acc: 0.6000\n",
            "Epoch 171/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.1559 - acc: 0.7111 - val_loss: 0.1222 - val_acc: 0.6000\n",
            "Epoch 172/800\n",
            "180/180 [==============================] - 0s 464us/step - loss: 0.1554 - acc: 0.6944 - val_loss: 0.1217 - val_acc: 0.6000\n",
            "Epoch 173/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1547 - acc: 0.7167 - val_loss: 0.1210 - val_acc: 0.6000\n",
            "Epoch 174/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1546 - acc: 0.7111 - val_loss: 0.1209 - val_acc: 0.6000\n",
            "Epoch 175/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1539 - acc: 0.7056 - val_loss: 0.1197 - val_acc: 0.6000\n",
            "Epoch 176/800\n",
            "180/180 [==============================] - 0s 334us/step - loss: 0.1535 - acc: 0.7278 - val_loss: 0.1192 - val_acc: 0.6000\n",
            "Epoch 177/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.1528 - acc: 0.7278 - val_loss: 0.1199 - val_acc: 0.6000\n",
            "Epoch 178/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1526 - acc: 0.7167 - val_loss: 0.1193 - val_acc: 0.6000\n",
            "Epoch 179/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1519 - acc: 0.7278 - val_loss: 0.1179 - val_acc: 0.6000\n",
            "Epoch 180/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1516 - acc: 0.7222 - val_loss: 0.1185 - val_acc: 0.6000\n",
            "Epoch 181/800\n",
            "180/180 [==============================] - 0s 335us/step - loss: 0.1517 - acc: 0.7167 - val_loss: 0.1184 - val_acc: 0.6000\n",
            "Epoch 182/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1507 - acc: 0.7389 - val_loss: 0.1173 - val_acc: 0.6000\n",
            "Epoch 183/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1501 - acc: 0.7278 - val_loss: 0.1166 - val_acc: 0.6000\n",
            "Epoch 184/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1497 - acc: 0.7389 - val_loss: 0.1169 - val_acc: 0.6000\n",
            "Epoch 185/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.1494 - acc: 0.7333 - val_loss: 0.1156 - val_acc: 0.6000\n",
            "Epoch 186/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1488 - acc: 0.7333 - val_loss: 0.1156 - val_acc: 0.6000\n",
            "Epoch 187/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1483 - acc: 0.7333 - val_loss: 0.1156 - val_acc: 0.6000\n",
            "Epoch 188/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.1480 - acc: 0.7278 - val_loss: 0.1159 - val_acc: 0.6000\n",
            "Epoch 189/800\n",
            "180/180 [==============================] - 0s 436us/step - loss: 0.1474 - acc: 0.7222 - val_loss: 0.1148 - val_acc: 0.6000\n",
            "Epoch 190/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1474 - acc: 0.7333 - val_loss: 0.1158 - val_acc: 0.6000\n",
            "Epoch 191/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1472 - acc: 0.7389 - val_loss: 0.1137 - val_acc: 0.6000\n",
            "Epoch 192/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1464 - acc: 0.7278 - val_loss: 0.1135 - val_acc: 0.6000\n",
            "Epoch 193/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1461 - acc: 0.7278 - val_loss: 0.1127 - val_acc: 0.6000\n",
            "Epoch 194/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1457 - acc: 0.7167 - val_loss: 0.1127 - val_acc: 0.6000\n",
            "Epoch 195/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1456 - acc: 0.7333 - val_loss: 0.1123 - val_acc: 0.6000\n",
            "Epoch 196/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1450 - acc: 0.7278 - val_loss: 0.1118 - val_acc: 0.6000\n",
            "Epoch 197/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1448 - acc: 0.7222 - val_loss: 0.1122 - val_acc: 0.6000\n",
            "Epoch 198/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1442 - acc: 0.7278 - val_loss: 0.1128 - val_acc: 0.6000\n",
            "Epoch 199/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.1439 - acc: 0.7278 - val_loss: 0.1119 - val_acc: 0.6000\n",
            "Epoch 200/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1434 - acc: 0.7278 - val_loss: 0.1103 - val_acc: 0.6000\n",
            "Epoch 201/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1430 - acc: 0.7278 - val_loss: 0.1117 - val_acc: 0.6000\n",
            "Epoch 202/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1428 - acc: 0.7278 - val_loss: 0.1111 - val_acc: 0.6000\n",
            "Epoch 203/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.1428 - acc: 0.7278 - val_loss: 0.1123 - val_acc: 0.6000\n",
            "Epoch 204/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1424 - acc: 0.7222 - val_loss: 0.1096 - val_acc: 0.6000\n",
            "Epoch 205/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1418 - acc: 0.7278 - val_loss: 0.1100 - val_acc: 0.6000\n",
            "Epoch 206/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.1419 - acc: 0.7444 - val_loss: 0.1096 - val_acc: 0.6000\n",
            "Epoch 207/800\n",
            "180/180 [==============================] - 0s 486us/step - loss: 0.1413 - acc: 0.7278 - val_loss: 0.1088 - val_acc: 0.6000\n",
            "Epoch 208/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1411 - acc: 0.7278 - val_loss: 0.1096 - val_acc: 0.6000\n",
            "Epoch 209/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1411 - acc: 0.7167 - val_loss: 0.1085 - val_acc: 0.6000\n",
            "Epoch 210/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1404 - acc: 0.7389 - val_loss: 0.1086 - val_acc: 0.6000\n",
            "Epoch 211/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1400 - acc: 0.7333 - val_loss: 0.1090 - val_acc: 0.6000\n",
            "Epoch 212/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1399 - acc: 0.7278 - val_loss: 0.1097 - val_acc: 0.5500\n",
            "Epoch 213/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1399 - acc: 0.7278 - val_loss: 0.1086 - val_acc: 0.6000\n",
            "Epoch 214/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1395 - acc: 0.7278 - val_loss: 0.1087 - val_acc: 0.6500\n",
            "Epoch 215/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1389 - acc: 0.7278 - val_loss: 0.1088 - val_acc: 0.6500\n",
            "Epoch 216/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1388 - acc: 0.7278 - val_loss: 0.1068 - val_acc: 0.6500\n",
            "Epoch 217/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1386 - acc: 0.7333 - val_loss: 0.1082 - val_acc: 0.6000\n",
            "Epoch 218/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1385 - acc: 0.7222 - val_loss: 0.1066 - val_acc: 0.6500\n",
            "Epoch 219/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1378 - acc: 0.7278 - val_loss: 0.1069 - val_acc: 0.6000\n",
            "Epoch 220/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1377 - acc: 0.7278 - val_loss: 0.1054 - val_acc: 0.6000\n",
            "Epoch 221/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1373 - acc: 0.7167 - val_loss: 0.1075 - val_acc: 0.6000\n",
            "Epoch 222/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1374 - acc: 0.7389 - val_loss: 0.1066 - val_acc: 0.6500\n",
            "Epoch 223/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1369 - acc: 0.7278 - val_loss: 0.1059 - val_acc: 0.6000\n",
            "Epoch 224/800\n",
            "180/180 [==============================] - 0s 420us/step - loss: 0.1371 - acc: 0.7333 - val_loss: 0.1059 - val_acc: 0.6500\n",
            "Epoch 225/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1365 - acc: 0.7444 - val_loss: 0.1052 - val_acc: 0.6500\n",
            "Epoch 226/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1360 - acc: 0.7500 - val_loss: 0.1052 - val_acc: 0.6500\n",
            "Epoch 227/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1357 - acc: 0.7278 - val_loss: 0.1048 - val_acc: 0.6500\n",
            "Epoch 228/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1357 - acc: 0.7444 - val_loss: 0.1040 - val_acc: 0.6500\n",
            "Epoch 229/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1354 - acc: 0.7500 - val_loss: 0.1056 - val_acc: 0.6500\n",
            "Epoch 230/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1356 - acc: 0.7500 - val_loss: 0.1047 - val_acc: 0.6500\n",
            "Epoch 231/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1349 - acc: 0.7444 - val_loss: 0.1054 - val_acc: 0.6000\n",
            "Epoch 232/800\n",
            "180/180 [==============================] - 0s 415us/step - loss: 0.1351 - acc: 0.7444 - val_loss: 0.1037 - val_acc: 0.6000\n",
            "Epoch 233/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1347 - acc: 0.7500 - val_loss: 0.1041 - val_acc: 0.6000\n",
            "Epoch 234/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1344 - acc: 0.7500 - val_loss: 0.1046 - val_acc: 0.6500\n",
            "Epoch 235/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1337 - acc: 0.7500 - val_loss: 0.1038 - val_acc: 0.6000\n",
            "Epoch 236/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1344 - acc: 0.7333 - val_loss: 0.1036 - val_acc: 0.6000\n",
            "Epoch 237/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1335 - acc: 0.7500 - val_loss: 0.1036 - val_acc: 0.6500\n",
            "Epoch 238/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.1334 - acc: 0.7500 - val_loss: 0.1045 - val_acc: 0.6500\n",
            "Epoch 239/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1333 - acc: 0.7444 - val_loss: 0.1032 - val_acc: 0.6500\n",
            "Epoch 240/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.1330 - acc: 0.7500 - val_loss: 0.1032 - val_acc: 0.6500\n",
            "Epoch 241/800\n",
            "180/180 [==============================] - 0s 430us/step - loss: 0.1333 - acc: 0.7333 - val_loss: 0.1023 - val_acc: 0.6500\n",
            "Epoch 242/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1328 - acc: 0.7500 - val_loss: 0.1029 - val_acc: 0.6500\n",
            "Epoch 243/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1327 - acc: 0.7444 - val_loss: 0.1017 - val_acc: 0.6500\n",
            "Epoch 244/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1319 - acc: 0.7500 - val_loss: 0.1035 - val_acc: 0.5500\n",
            "Epoch 245/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1332 - acc: 0.7333 - val_loss: 0.1020 - val_acc: 0.6500\n",
            "Epoch 246/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.1319 - acc: 0.7444 - val_loss: 0.1049 - val_acc: 0.6500\n",
            "Epoch 247/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1322 - acc: 0.7389 - val_loss: 0.1020 - val_acc: 0.6500\n",
            "Epoch 248/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1313 - acc: 0.7556 - val_loss: 0.1015 - val_acc: 0.6500\n",
            "Epoch 249/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1313 - acc: 0.7500 - val_loss: 0.1011 - val_acc: 0.6500\n",
            "Epoch 250/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1312 - acc: 0.7556 - val_loss: 0.1004 - val_acc: 0.6500\n",
            "Epoch 251/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1310 - acc: 0.7556 - val_loss: 0.1017 - val_acc: 0.6500\n",
            "Epoch 252/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1307 - acc: 0.7556 - val_loss: 0.1028 - val_acc: 0.6500\n",
            "Epoch 253/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1307 - acc: 0.7556 - val_loss: 0.1013 - val_acc: 0.6000\n",
            "Epoch 254/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.1303 - acc: 0.7444 - val_loss: 0.0999 - val_acc: 0.7000\n",
            "Epoch 255/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.1304 - acc: 0.7500 - val_loss: 0.1012 - val_acc: 0.6500\n",
            "Epoch 256/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1301 - acc: 0.7556 - val_loss: 0.1013 - val_acc: 0.7000\n",
            "Epoch 257/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1298 - acc: 0.7444 - val_loss: 0.0994 - val_acc: 0.7000\n",
            "Epoch 258/800\n",
            "180/180 [==============================] - 0s 484us/step - loss: 0.1299 - acc: 0.7611 - val_loss: 0.1015 - val_acc: 0.7000\n",
            "Epoch 259/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1295 - acc: 0.7556 - val_loss: 0.1029 - val_acc: 0.6000\n",
            "Epoch 260/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1297 - acc: 0.7611 - val_loss: 0.0998 - val_acc: 0.7000\n",
            "Epoch 261/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1290 - acc: 0.7611 - val_loss: 0.0997 - val_acc: 0.7000\n",
            "Epoch 262/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1291 - acc: 0.7444 - val_loss: 0.1002 - val_acc: 0.7000\n",
            "Epoch 263/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.1290 - acc: 0.7611 - val_loss: 0.1009 - val_acc: 0.7000\n",
            "Epoch 264/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1291 - acc: 0.7500 - val_loss: 0.1011 - val_acc: 0.7000\n",
            "Epoch 265/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1289 - acc: 0.7611 - val_loss: 0.0997 - val_acc: 0.6500\n",
            "Epoch 266/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1283 - acc: 0.7500 - val_loss: 0.0977 - val_acc: 0.8000\n",
            "Epoch 267/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1284 - acc: 0.7611 - val_loss: 0.0993 - val_acc: 0.7500\n",
            "Epoch 268/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1280 - acc: 0.7444 - val_loss: 0.0982 - val_acc: 0.7500\n",
            "Epoch 269/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.1279 - acc: 0.7667 - val_loss: 0.1005 - val_acc: 0.7000\n",
            "Epoch 270/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1280 - acc: 0.7500 - val_loss: 0.0988 - val_acc: 0.7500\n",
            "Epoch 271/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1276 - acc: 0.7556 - val_loss: 0.0990 - val_acc: 0.7000\n",
            "Epoch 272/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1277 - acc: 0.7556 - val_loss: 0.0987 - val_acc: 0.7500\n",
            "Epoch 273/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1272 - acc: 0.7611 - val_loss: 0.0998 - val_acc: 0.7000\n",
            "Epoch 274/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1269 - acc: 0.7611 - val_loss: 0.0980 - val_acc: 0.7500\n",
            "Epoch 275/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1273 - acc: 0.7611 - val_loss: 0.0983 - val_acc: 0.7500\n",
            "Epoch 276/800\n",
            "180/180 [==============================] - 0s 481us/step - loss: 0.1267 - acc: 0.7556 - val_loss: 0.0976 - val_acc: 0.7500\n",
            "Epoch 277/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1267 - acc: 0.7667 - val_loss: 0.0972 - val_acc: 0.7500\n",
            "Epoch 278/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1267 - acc: 0.7556 - val_loss: 0.0998 - val_acc: 0.7500\n",
            "Epoch 279/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1268 - acc: 0.7556 - val_loss: 0.0982 - val_acc: 0.7000\n",
            "Epoch 280/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1266 - acc: 0.7611 - val_loss: 0.0975 - val_acc: 0.7500\n",
            "Epoch 281/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.1260 - acc: 0.7556 - val_loss: 0.0987 - val_acc: 0.7500\n",
            "Epoch 282/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1260 - acc: 0.7722 - val_loss: 0.1006 - val_acc: 0.7500\n",
            "Epoch 283/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1263 - acc: 0.7611 - val_loss: 0.0992 - val_acc: 0.7000\n",
            "Epoch 284/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1262 - acc: 0.7556 - val_loss: 0.0969 - val_acc: 0.7500\n",
            "Epoch 285/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.1260 - acc: 0.7500 - val_loss: 0.0995 - val_acc: 0.7500\n",
            "Epoch 286/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1257 - acc: 0.7556 - val_loss: 0.0969 - val_acc: 0.7500\n",
            "Epoch 287/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1257 - acc: 0.7556 - val_loss: 0.0970 - val_acc: 0.7500\n",
            "Epoch 288/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1252 - acc: 0.7722 - val_loss: 0.0965 - val_acc: 0.7500\n",
            "Epoch 289/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1251 - acc: 0.7500 - val_loss: 0.0956 - val_acc: 0.8000\n",
            "Epoch 290/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.1248 - acc: 0.7667 - val_loss: 0.0961 - val_acc: 0.7500\n",
            "Epoch 291/800\n",
            "180/180 [==============================] - 0s 340us/step - loss: 0.1249 - acc: 0.7500 - val_loss: 0.0959 - val_acc: 0.7500\n",
            "Epoch 292/800\n",
            "180/180 [==============================] - 0s 333us/step - loss: 0.1249 - acc: 0.7722 - val_loss: 0.0964 - val_acc: 0.7000\n",
            "Epoch 293/800\n",
            "180/180 [==============================] - 0s 488us/step - loss: 0.1246 - acc: 0.7667 - val_loss: 0.0962 - val_acc: 0.7500\n",
            "Epoch 294/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1245 - acc: 0.7667 - val_loss: 0.0955 - val_acc: 0.7500\n",
            "Epoch 295/800\n",
            "180/180 [==============================] - 0s 331us/step - loss: 0.1246 - acc: 0.7611 - val_loss: 0.0953 - val_acc: 0.8000\n",
            "Epoch 296/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1243 - acc: 0.7722 - val_loss: 0.0976 - val_acc: 0.8000\n",
            "Epoch 297/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1246 - acc: 0.7722 - val_loss: 0.0961 - val_acc: 0.7500\n",
            "Epoch 298/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1239 - acc: 0.7722 - val_loss: 0.0952 - val_acc: 0.8000\n",
            "Epoch 299/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1238 - acc: 0.7778 - val_loss: 0.0977 - val_acc: 0.7500\n",
            "Epoch 300/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1245 - acc: 0.7722 - val_loss: 0.0961 - val_acc: 0.8000\n",
            "Epoch 301/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1238 - acc: 0.7833 - val_loss: 0.0958 - val_acc: 0.8000\n",
            "Epoch 302/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1239 - acc: 0.7500 - val_loss: 0.0954 - val_acc: 0.7500\n",
            "Epoch 303/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1237 - acc: 0.7667 - val_loss: 0.0979 - val_acc: 0.8000\n",
            "Epoch 304/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1234 - acc: 0.7722 - val_loss: 0.0940 - val_acc: 0.8000\n",
            "Epoch 305/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1238 - acc: 0.7722 - val_loss: 0.0956 - val_acc: 0.8000\n",
            "Epoch 306/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1230 - acc: 0.7722 - val_loss: 0.0960 - val_acc: 0.7000\n",
            "Epoch 307/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1232 - acc: 0.7722 - val_loss: 0.0955 - val_acc: 0.8000\n",
            "Epoch 308/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1231 - acc: 0.7667 - val_loss: 0.0946 - val_acc: 0.8000\n",
            "Epoch 309/800\n",
            "180/180 [==============================] - 0s 338us/step - loss: 0.1232 - acc: 0.7667 - val_loss: 0.0958 - val_acc: 0.7500\n",
            "Epoch 310/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1228 - acc: 0.7722 - val_loss: 0.0947 - val_acc: 0.7500\n",
            "Epoch 311/800\n",
            "180/180 [==============================] - 0s 432us/step - loss: 0.1228 - acc: 0.7889 - val_loss: 0.0946 - val_acc: 0.8500\n",
            "Epoch 312/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1225 - acc: 0.7667 - val_loss: 0.0939 - val_acc: 0.8000\n",
            "Epoch 313/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1227 - acc: 0.7833 - val_loss: 0.0943 - val_acc: 0.8000\n",
            "Epoch 314/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1224 - acc: 0.7889 - val_loss: 0.0938 - val_acc: 0.8500\n",
            "Epoch 315/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1221 - acc: 0.7778 - val_loss: 0.0966 - val_acc: 0.7500\n",
            "Epoch 316/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1222 - acc: 0.7722 - val_loss: 0.0934 - val_acc: 0.8000\n",
            "Epoch 317/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1224 - acc: 0.7833 - val_loss: 0.0938 - val_acc: 0.8000\n",
            "Epoch 318/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1218 - acc: 0.7778 - val_loss: 0.0932 - val_acc: 0.8000\n",
            "Epoch 319/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1214 - acc: 0.7778 - val_loss: 0.0959 - val_acc: 0.8000\n",
            "Epoch 320/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1220 - acc: 0.7611 - val_loss: 0.0941 - val_acc: 0.8000\n",
            "Epoch 321/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1216 - acc: 0.7833 - val_loss: 0.0946 - val_acc: 0.8000\n",
            "Epoch 322/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1218 - acc: 0.7889 - val_loss: 0.0946 - val_acc: 0.7500\n",
            "Epoch 323/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1215 - acc: 0.7778 - val_loss: 0.0947 - val_acc: 0.8000\n",
            "Epoch 324/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1216 - acc: 0.7667 - val_loss: 0.0926 - val_acc: 0.7500\n",
            "Epoch 325/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1215 - acc: 0.7778 - val_loss: 0.0937 - val_acc: 0.8000\n",
            "Epoch 326/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.1212 - acc: 0.7944 - val_loss: 0.0933 - val_acc: 0.8000\n",
            "Epoch 327/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1217 - acc: 0.7722 - val_loss: 0.0939 - val_acc: 0.7500\n",
            "Epoch 328/800\n",
            "180/180 [==============================] - 0s 481us/step - loss: 0.1210 - acc: 0.7889 - val_loss: 0.0955 - val_acc: 0.8000\n",
            "Epoch 329/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1209 - acc: 0.7889 - val_loss: 0.0947 - val_acc: 0.7500\n",
            "Epoch 330/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1207 - acc: 0.7833 - val_loss: 0.0939 - val_acc: 0.7500\n",
            "Epoch 331/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1214 - acc: 0.7778 - val_loss: 0.0930 - val_acc: 0.8500\n",
            "Epoch 332/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1208 - acc: 0.7833 - val_loss: 0.0930 - val_acc: 0.8500\n",
            "Epoch 333/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1206 - acc: 0.7722 - val_loss: 0.0940 - val_acc: 0.8000\n",
            "Epoch 334/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1205 - acc: 0.7778 - val_loss: 0.0928 - val_acc: 0.8000\n",
            "Epoch 335/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1201 - acc: 0.7833 - val_loss: 0.0930 - val_acc: 0.8000\n",
            "Epoch 336/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.1203 - acc: 0.7889 - val_loss: 0.0943 - val_acc: 0.8500\n",
            "Epoch 337/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1204 - acc: 0.7778 - val_loss: 0.0950 - val_acc: 0.8000\n",
            "Epoch 338/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1201 - acc: 0.8056 - val_loss: 0.0932 - val_acc: 0.8500\n",
            "Epoch 339/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1203 - acc: 0.7889 - val_loss: 0.0930 - val_acc: 0.7500\n",
            "Epoch 340/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1199 - acc: 0.7944 - val_loss: 0.0913 - val_acc: 0.8500\n",
            "Epoch 341/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1196 - acc: 0.8000 - val_loss: 0.0929 - val_acc: 0.8500\n",
            "Epoch 342/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1198 - acc: 0.7778 - val_loss: 0.0940 - val_acc: 0.8500\n",
            "Epoch 343/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1198 - acc: 0.7889 - val_loss: 0.0914 - val_acc: 0.8500\n",
            "Epoch 344/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1197 - acc: 0.7722 - val_loss: 0.0923 - val_acc: 0.8500\n",
            "Epoch 345/800\n",
            "180/180 [==============================] - 0s 394us/step - loss: 0.1198 - acc: 0.7778 - val_loss: 0.0916 - val_acc: 0.8000\n",
            "Epoch 346/800\n",
            "180/180 [==============================] - 0s 399us/step - loss: 0.1194 - acc: 0.7833 - val_loss: 0.0919 - val_acc: 0.8000\n",
            "Epoch 347/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1193 - acc: 0.7944 - val_loss: 0.0913 - val_acc: 0.8000\n",
            "Epoch 348/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.1194 - acc: 0.7778 - val_loss: 0.0904 - val_acc: 0.8000\n",
            "Epoch 349/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1190 - acc: 0.7722 - val_loss: 0.0923 - val_acc: 0.8500\n",
            "Epoch 350/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1190 - acc: 0.7833 - val_loss: 0.0931 - val_acc: 0.8500\n",
            "Epoch 351/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1190 - acc: 0.7889 - val_loss: 0.0906 - val_acc: 0.8000\n",
            "Epoch 352/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1188 - acc: 0.7833 - val_loss: 0.0924 - val_acc: 0.7500\n",
            "Epoch 353/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1190 - acc: 0.7778 - val_loss: 0.0918 - val_acc: 0.8000\n",
            "Epoch 354/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1188 - acc: 0.7889 - val_loss: 0.0921 - val_acc: 0.7500\n",
            "Epoch 355/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1191 - acc: 0.7833 - val_loss: 0.0913 - val_acc: 0.8500\n",
            "Epoch 356/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1186 - acc: 0.7944 - val_loss: 0.0918 - val_acc: 0.8500\n",
            "Epoch 357/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1183 - acc: 0.7833 - val_loss: 0.0946 - val_acc: 0.7000\n",
            "Epoch 358/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1187 - acc: 0.7889 - val_loss: 0.0907 - val_acc: 0.8500\n",
            "Epoch 359/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1182 - acc: 0.7944 - val_loss: 0.0930 - val_acc: 0.8000\n",
            "Epoch 360/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1186 - acc: 0.7944 - val_loss: 0.0918 - val_acc: 0.8000\n",
            "Epoch 361/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1178 - acc: 0.8000 - val_loss: 0.0924 - val_acc: 0.8500\n",
            "Epoch 362/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1184 - acc: 0.8000 - val_loss: 0.0912 - val_acc: 0.8000\n",
            "Epoch 363/800\n",
            "180/180 [==============================] - 0s 488us/step - loss: 0.1180 - acc: 0.7944 - val_loss: 0.0913 - val_acc: 0.8500\n",
            "Epoch 364/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1179 - acc: 0.7833 - val_loss: 0.0914 - val_acc: 0.8500\n",
            "Epoch 365/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1180 - acc: 0.7889 - val_loss: 0.0904 - val_acc: 0.8500\n",
            "Epoch 366/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1178 - acc: 0.7944 - val_loss: 0.0908 - val_acc: 0.8500\n",
            "Epoch 367/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.1175 - acc: 0.7889 - val_loss: 0.0909 - val_acc: 0.8500\n",
            "Epoch 368/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1178 - acc: 0.7944 - val_loss: 0.0914 - val_acc: 0.8000\n",
            "Epoch 369/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1178 - acc: 0.7944 - val_loss: 0.0906 - val_acc: 0.8500\n",
            "Epoch 370/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1174 - acc: 0.7889 - val_loss: 0.0904 - val_acc: 0.8500\n",
            "Epoch 371/800\n",
            "180/180 [==============================] - 0s 336us/step - loss: 0.1171 - acc: 0.8111 - val_loss: 0.0909 - val_acc: 0.8000\n",
            "Epoch 372/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1180 - acc: 0.7889 - val_loss: 0.0897 - val_acc: 0.8000\n",
            "Epoch 373/800\n",
            "180/180 [==============================] - 0s 395us/step - loss: 0.1178 - acc: 0.8056 - val_loss: 0.0900 - val_acc: 0.8500\n",
            "Epoch 374/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1180 - acc: 0.7778 - val_loss: 0.0906 - val_acc: 0.8000\n",
            "Epoch 375/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.1178 - acc: 0.8000 - val_loss: 0.0917 - val_acc: 0.8500\n",
            "Epoch 376/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1171 - acc: 0.7889 - val_loss: 0.0914 - val_acc: 0.7500\n",
            "Epoch 377/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1174 - acc: 0.8000 - val_loss: 0.0908 - val_acc: 0.8500\n",
            "Epoch 378/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1177 - acc: 0.7889 - val_loss: 0.0902 - val_acc: 0.8000\n",
            "Epoch 379/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1167 - acc: 0.8000 - val_loss: 0.0905 - val_acc: 0.8000\n",
            "Epoch 380/800\n",
            "180/180 [==============================] - 0s 411us/step - loss: 0.1171 - acc: 0.8222 - val_loss: 0.0908 - val_acc: 0.8000\n",
            "Epoch 381/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.1167 - acc: 0.7944 - val_loss: 0.0904 - val_acc: 0.7500\n",
            "Epoch 382/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1167 - acc: 0.7944 - val_loss: 0.0888 - val_acc: 0.8000\n",
            "Epoch 383/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.1168 - acc: 0.8111 - val_loss: 0.0895 - val_acc: 0.8000\n",
            "Epoch 384/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1166 - acc: 0.8167 - val_loss: 0.0894 - val_acc: 0.8000\n",
            "Epoch 385/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1168 - acc: 0.7944 - val_loss: 0.0896 - val_acc: 0.8500\n",
            "Epoch 386/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1168 - acc: 0.8111 - val_loss: 0.0900 - val_acc: 0.8500\n",
            "Epoch 387/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1166 - acc: 0.8222 - val_loss: 0.0930 - val_acc: 0.7500\n",
            "Epoch 388/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1165 - acc: 0.7778 - val_loss: 0.0897 - val_acc: 0.8500\n",
            "Epoch 389/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1164 - acc: 0.8056 - val_loss: 0.0940 - val_acc: 0.7500\n",
            "Epoch 390/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1169 - acc: 0.8111 - val_loss: 0.0919 - val_acc: 0.8000\n",
            "Epoch 391/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1168 - acc: 0.7889 - val_loss: 0.0889 - val_acc: 0.8500\n",
            "Epoch 392/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.1165 - acc: 0.8000 - val_loss: 0.0876 - val_acc: 0.8000\n",
            "Epoch 393/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1162 - acc: 0.8056 - val_loss: 0.0915 - val_acc: 0.8000\n",
            "Epoch 394/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1160 - acc: 0.8056 - val_loss: 0.0915 - val_acc: 0.8500\n",
            "Epoch 395/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1163 - acc: 0.8000 - val_loss: 0.0892 - val_acc: 0.8000\n",
            "Epoch 396/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1158 - acc: 0.8056 - val_loss: 0.0911 - val_acc: 0.8500\n",
            "Epoch 397/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1160 - acc: 0.7944 - val_loss: 0.0894 - val_acc: 0.8500\n",
            "Epoch 398/800\n",
            "180/180 [==============================] - 0s 483us/step - loss: 0.1159 - acc: 0.7944 - val_loss: 0.0916 - val_acc: 0.8500\n",
            "Epoch 399/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1161 - acc: 0.8000 - val_loss: 0.0910 - val_acc: 0.8000\n",
            "Epoch 400/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1162 - acc: 0.8222 - val_loss: 0.0909 - val_acc: 0.8000\n",
            "Epoch 401/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1158 - acc: 0.8111 - val_loss: 0.0885 - val_acc: 0.8500\n",
            "Epoch 402/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1154 - acc: 0.8222 - val_loss: 0.0903 - val_acc: 0.8000\n",
            "Epoch 403/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1156 - acc: 0.7944 - val_loss: 0.0913 - val_acc: 0.8500\n",
            "Epoch 404/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1158 - acc: 0.8111 - val_loss: 0.0893 - val_acc: 0.8000\n",
            "Epoch 405/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1158 - acc: 0.8167 - val_loss: 0.0911 - val_acc: 0.8500\n",
            "Epoch 406/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1156 - acc: 0.8056 - val_loss: 0.0902 - val_acc: 0.7500\n",
            "Epoch 407/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1153 - acc: 0.8056 - val_loss: 0.0888 - val_acc: 0.8500\n",
            "Epoch 408/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1154 - acc: 0.8000 - val_loss: 0.0910 - val_acc: 0.8500\n",
            "Epoch 409/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1154 - acc: 0.8056 - val_loss: 0.0893 - val_acc: 0.7500\n",
            "Epoch 410/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1151 - acc: 0.8000 - val_loss: 0.0899 - val_acc: 0.8000\n",
            "Epoch 411/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1151 - acc: 0.8056 - val_loss: 0.0905 - val_acc: 0.8500\n",
            "Epoch 412/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1148 - acc: 0.8056 - val_loss: 0.0899 - val_acc: 0.8000\n",
            "Epoch 413/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1158 - acc: 0.8056 - val_loss: 0.0889 - val_acc: 0.8500\n",
            "Epoch 414/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1152 - acc: 0.7944 - val_loss: 0.0879 - val_acc: 0.8000\n",
            "Epoch 415/800\n",
            "180/180 [==============================] - 0s 489us/step - loss: 0.1148 - acc: 0.7944 - val_loss: 0.0882 - val_acc: 0.8500\n",
            "Epoch 416/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1152 - acc: 0.8222 - val_loss: 0.0879 - val_acc: 0.8500\n",
            "Epoch 417/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1152 - acc: 0.8167 - val_loss: 0.0892 - val_acc: 0.8000\n",
            "Epoch 418/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1154 - acc: 0.8000 - val_loss: 0.0890 - val_acc: 0.8500\n",
            "Epoch 419/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1146 - acc: 0.8056 - val_loss: 0.0875 - val_acc: 0.9000\n",
            "Epoch 420/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1146 - acc: 0.8111 - val_loss: 0.0895 - val_acc: 0.8500\n",
            "Epoch 421/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1147 - acc: 0.8056 - val_loss: 0.0912 - val_acc: 0.9000\n",
            "Epoch 422/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1143 - acc: 0.8056 - val_loss: 0.0890 - val_acc: 0.9000\n",
            "Epoch 423/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1156 - acc: 0.8333 - val_loss: 0.0889 - val_acc: 0.8500\n",
            "Epoch 424/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1145 - acc: 0.8222 - val_loss: 0.0884 - val_acc: 0.8000\n",
            "Epoch 425/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1143 - acc: 0.8278 - val_loss: 0.0880 - val_acc: 0.8000\n",
            "Epoch 426/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1142 - acc: 0.8278 - val_loss: 0.0881 - val_acc: 0.9000\n",
            "Epoch 427/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1147 - acc: 0.8167 - val_loss: 0.0890 - val_acc: 0.8000\n",
            "Epoch 428/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1145 - acc: 0.8278 - val_loss: 0.0875 - val_acc: 0.7500\n",
            "Epoch 429/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1144 - acc: 0.8222 - val_loss: 0.0893 - val_acc: 0.8500\n",
            "Epoch 430/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1145 - acc: 0.7944 - val_loss: 0.0884 - val_acc: 0.8500\n",
            "Epoch 431/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1145 - acc: 0.8167 - val_loss: 0.0891 - val_acc: 0.8000\n",
            "Epoch 432/800\n",
            "180/180 [==============================] - 0s 426us/step - loss: 0.1144 - acc: 0.7944 - val_loss: 0.0875 - val_acc: 0.7500\n",
            "Epoch 433/800\n",
            "180/180 [==============================] - 0s 417us/step - loss: 0.1142 - acc: 0.8111 - val_loss: 0.0881 - val_acc: 0.8000\n",
            "Epoch 434/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1148 - acc: 0.8167 - val_loss: 0.0894 - val_acc: 0.9000\n",
            "Epoch 435/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1141 - acc: 0.8167 - val_loss: 0.0900 - val_acc: 0.8000\n",
            "Epoch 436/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1146 - acc: 0.8167 - val_loss: 0.0905 - val_acc: 0.9000\n",
            "Epoch 437/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1146 - acc: 0.8167 - val_loss: 0.0881 - val_acc: 0.8500\n",
            "Epoch 438/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.1138 - acc: 0.8056 - val_loss: 0.0880 - val_acc: 0.8500\n",
            "Epoch 439/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1140 - acc: 0.8111 - val_loss: 0.0869 - val_acc: 0.8500\n",
            "Epoch 440/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1139 - acc: 0.8389 - val_loss: 0.0876 - val_acc: 0.8500\n",
            "Epoch 441/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1136 - acc: 0.7889 - val_loss: 0.0878 - val_acc: 0.8500\n",
            "Epoch 442/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.1140 - acc: 0.8111 - val_loss: 0.0903 - val_acc: 0.8500\n",
            "Epoch 443/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1143 - acc: 0.8111 - val_loss: 0.0881 - val_acc: 0.9000\n",
            "Epoch 444/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1138 - acc: 0.8389 - val_loss: 0.0880 - val_acc: 0.9000\n",
            "Epoch 445/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1143 - acc: 0.8111 - val_loss: 0.0899 - val_acc: 0.9000\n",
            "Epoch 446/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1134 - acc: 0.8278 - val_loss: 0.0888 - val_acc: 0.9000\n",
            "Epoch 447/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1139 - acc: 0.8167 - val_loss: 0.0874 - val_acc: 0.8500\n",
            "Epoch 448/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1135 - acc: 0.8389 - val_loss: 0.0923 - val_acc: 0.8500\n",
            "Epoch 449/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1142 - acc: 0.8222 - val_loss: 0.0907 - val_acc: 0.8000\n",
            "Epoch 450/800\n",
            "180/180 [==============================] - 0s 490us/step - loss: 0.1139 - acc: 0.8111 - val_loss: 0.0873 - val_acc: 0.9000\n",
            "Epoch 451/800\n",
            "180/180 [==============================] - 0s 436us/step - loss: 0.1133 - acc: 0.8222 - val_loss: 0.0897 - val_acc: 0.8500\n",
            "Epoch 452/800\n",
            "180/180 [==============================] - 0s 337us/step - loss: 0.1140 - acc: 0.8222 - val_loss: 0.0891 - val_acc: 0.9000\n",
            "Epoch 453/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1134 - acc: 0.8167 - val_loss: 0.0897 - val_acc: 0.9000\n",
            "Epoch 454/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1134 - acc: 0.8111 - val_loss: 0.0890 - val_acc: 0.9000\n",
            "Epoch 455/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1132 - acc: 0.8278 - val_loss: 0.0867 - val_acc: 0.9000\n",
            "Epoch 456/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1131 - acc: 0.8389 - val_loss: 0.0874 - val_acc: 0.8500\n",
            "Epoch 457/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1132 - acc: 0.8111 - val_loss: 0.0881 - val_acc: 0.8500\n",
            "Epoch 458/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1131 - acc: 0.8167 - val_loss: 0.0888 - val_acc: 0.8500\n",
            "Epoch 459/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1130 - acc: 0.8222 - val_loss: 0.0870 - val_acc: 0.8500\n",
            "Epoch 460/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1134 - acc: 0.8222 - val_loss: 0.0871 - val_acc: 0.8500\n",
            "Epoch 461/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1133 - acc: 0.8333 - val_loss: 0.0873 - val_acc: 0.9000\n",
            "Epoch 462/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1138 - acc: 0.8333 - val_loss: 0.0899 - val_acc: 0.8500\n",
            "Epoch 463/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1133 - acc: 0.8444 - val_loss: 0.0881 - val_acc: 0.8500\n",
            "Epoch 464/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1132 - acc: 0.8167 - val_loss: 0.0882 - val_acc: 0.7500\n",
            "Epoch 465/800\n",
            "180/180 [==============================] - 0s 380us/step - loss: 0.1140 - acc: 0.8222 - val_loss: 0.0871 - val_acc: 0.9000\n",
            "Epoch 466/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1136 - acc: 0.8278 - val_loss: 0.0878 - val_acc: 0.8500\n",
            "Epoch 467/800\n",
            "180/180 [==============================] - 0s 476us/step - loss: 0.1130 - acc: 0.8278 - val_loss: 0.0885 - val_acc: 0.8500\n",
            "Epoch 468/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1130 - acc: 0.8167 - val_loss: 0.0875 - val_acc: 0.9000\n",
            "Epoch 469/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1131 - acc: 0.8222 - val_loss: 0.0872 - val_acc: 0.9000\n",
            "Epoch 470/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1130 - acc: 0.8444 - val_loss: 0.0893 - val_acc: 0.8000\n",
            "Epoch 471/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.1126 - acc: 0.8278 - val_loss: 0.0854 - val_acc: 0.8500\n",
            "Epoch 472/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1128 - acc: 0.8333 - val_loss: 0.0866 - val_acc: 0.9000\n",
            "Epoch 473/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1129 - acc: 0.8333 - val_loss: 0.0866 - val_acc: 0.8500\n",
            "Epoch 474/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1130 - acc: 0.8333 - val_loss: 0.0860 - val_acc: 0.8500\n",
            "Epoch 475/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1125 - acc: 0.8444 - val_loss: 0.0858 - val_acc: 0.8500\n",
            "Epoch 476/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1127 - acc: 0.8556 - val_loss: 0.0879 - val_acc: 0.8500\n",
            "Epoch 477/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1131 - acc: 0.8556 - val_loss: 0.0883 - val_acc: 0.9000\n",
            "Epoch 478/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.1128 - acc: 0.8389 - val_loss: 0.0873 - val_acc: 0.8500\n",
            "Epoch 479/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1126 - acc: 0.8444 - val_loss: 0.0888 - val_acc: 0.9500\n",
            "Epoch 480/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.1128 - acc: 0.8389 - val_loss: 0.0868 - val_acc: 0.8500\n",
            "Epoch 481/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1125 - acc: 0.8500 - val_loss: 0.0854 - val_acc: 0.8500\n",
            "Epoch 482/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1124 - acc: 0.8500 - val_loss: 0.0868 - val_acc: 0.8500\n",
            "Epoch 483/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1128 - acc: 0.8611 - val_loss: 0.0884 - val_acc: 0.9000\n",
            "Epoch 484/800\n",
            "180/180 [==============================] - 0s 462us/step - loss: 0.1123 - acc: 0.8222 - val_loss: 0.0875 - val_acc: 0.8500\n",
            "Epoch 485/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1124 - acc: 0.8500 - val_loss: 0.0868 - val_acc: 0.8000\n",
            "Epoch 486/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1122 - acc: 0.8389 - val_loss: 0.0860 - val_acc: 0.8500\n",
            "Epoch 487/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.1121 - acc: 0.8500 - val_loss: 0.0873 - val_acc: 0.8500\n",
            "Epoch 488/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1121 - acc: 0.8444 - val_loss: 0.0880 - val_acc: 0.8500\n",
            "Epoch 489/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1124 - acc: 0.8556 - val_loss: 0.0871 - val_acc: 0.9000\n",
            "Epoch 490/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1124 - acc: 0.8389 - val_loss: 0.0863 - val_acc: 0.8000\n",
            "Epoch 491/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1119 - acc: 0.8389 - val_loss: 0.0865 - val_acc: 0.8500\n",
            "Epoch 492/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1122 - acc: 0.8222 - val_loss: 0.0858 - val_acc: 0.8500\n",
            "Epoch 493/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1119 - acc: 0.8611 - val_loss: 0.0872 - val_acc: 0.9000\n",
            "Epoch 494/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1120 - acc: 0.8167 - val_loss: 0.0862 - val_acc: 0.8000\n",
            "Epoch 495/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1116 - acc: 0.8333 - val_loss: 0.0861 - val_acc: 0.8500\n",
            "Epoch 496/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1119 - acc: 0.8444 - val_loss: 0.0892 - val_acc: 0.8500\n",
            "Epoch 497/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1117 - acc: 0.8333 - val_loss: 0.0867 - val_acc: 0.8500\n",
            "Epoch 498/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1118 - acc: 0.8611 - val_loss: 0.0882 - val_acc: 0.8500\n",
            "Epoch 499/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1122 - acc: 0.8556 - val_loss: 0.0877 - val_acc: 0.9000\n",
            "Epoch 500/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1119 - acc: 0.8444 - val_loss: 0.0864 - val_acc: 0.8500\n",
            "Epoch 501/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1118 - acc: 0.8444 - val_loss: 0.0866 - val_acc: 0.8500\n",
            "Epoch 502/800\n",
            "180/180 [==============================] - 0s 451us/step - loss: 0.1121 - acc: 0.8389 - val_loss: 0.0877 - val_acc: 0.8000\n",
            "Epoch 503/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1117 - acc: 0.8333 - val_loss: 0.0858 - val_acc: 0.8500\n",
            "Epoch 504/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1120 - acc: 0.8667 - val_loss: 0.0859 - val_acc: 0.8000\n",
            "Epoch 505/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1114 - acc: 0.8444 - val_loss: 0.0866 - val_acc: 0.8500\n",
            "Epoch 506/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1120 - acc: 0.8278 - val_loss: 0.0869 - val_acc: 0.8500\n",
            "Epoch 507/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1118 - acc: 0.8611 - val_loss: 0.0873 - val_acc: 0.8500\n",
            "Epoch 508/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1123 - acc: 0.8333 - val_loss: 0.0882 - val_acc: 0.9500\n",
            "Epoch 509/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1125 - acc: 0.8444 - val_loss: 0.0866 - val_acc: 0.8000\n",
            "Epoch 510/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1114 - acc: 0.8556 - val_loss: 0.0868 - val_acc: 0.8000\n",
            "Epoch 511/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1115 - acc: 0.8444 - val_loss: 0.0858 - val_acc: 0.9000\n",
            "Epoch 512/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1117 - acc: 0.8611 - val_loss: 0.0869 - val_acc: 0.8500\n",
            "Epoch 513/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1116 - acc: 0.8611 - val_loss: 0.0876 - val_acc: 0.9500\n",
            "Epoch 514/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1114 - acc: 0.8500 - val_loss: 0.0901 - val_acc: 0.8500\n",
            "Epoch 515/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.1119 - acc: 0.8500 - val_loss: 0.0860 - val_acc: 0.8500\n",
            "Epoch 516/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1115 - acc: 0.8500 - val_loss: 0.0849 - val_acc: 0.9000\n",
            "Epoch 517/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1116 - acc: 0.8611 - val_loss: 0.0868 - val_acc: 0.9000\n",
            "Epoch 518/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1118 - acc: 0.8611 - val_loss: 0.0871 - val_acc: 0.9000\n",
            "Epoch 519/800\n",
            "180/180 [==============================] - 0s 402us/step - loss: 0.1113 - acc: 0.8500 - val_loss: 0.0864 - val_acc: 0.9000\n",
            "Epoch 520/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1115 - acc: 0.8222 - val_loss: 0.0851 - val_acc: 0.9000\n",
            "Epoch 521/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1116 - acc: 0.8389 - val_loss: 0.0846 - val_acc: 0.9000\n",
            "Epoch 522/800\n",
            "180/180 [==============================] - 0s 334us/step - loss: 0.1116 - acc: 0.8611 - val_loss: 0.0878 - val_acc: 0.9000\n",
            "Epoch 523/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1116 - acc: 0.8722 - val_loss: 0.0856 - val_acc: 0.8500\n",
            "Epoch 524/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1115 - acc: 0.8611 - val_loss: 0.0880 - val_acc: 0.9000\n",
            "Epoch 525/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1114 - acc: 0.8500 - val_loss: 0.0867 - val_acc: 0.9000\n",
            "Epoch 526/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1108 - acc: 0.8556 - val_loss: 0.0877 - val_acc: 0.9000\n",
            "Epoch 527/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1113 - acc: 0.8667 - val_loss: 0.0886 - val_acc: 0.8000\n",
            "Epoch 528/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1112 - acc: 0.8500 - val_loss: 0.0843 - val_acc: 0.8000\n",
            "Epoch 529/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.1113 - acc: 0.8556 - val_loss: 0.0862 - val_acc: 0.8500\n",
            "Epoch 530/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1110 - acc: 0.8500 - val_loss: 0.0870 - val_acc: 0.9000\n",
            "Epoch 531/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.0864 - val_acc: 0.9000\n",
            "Epoch 532/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1114 - acc: 0.8611 - val_loss: 0.0881 - val_acc: 0.8500\n",
            "Epoch 533/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1111 - acc: 0.8667 - val_loss: 0.0876 - val_acc: 0.9000\n",
            "Epoch 534/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1107 - acc: 0.8611 - val_loss: 0.0866 - val_acc: 0.8000\n",
            "Epoch 535/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1111 - acc: 0.8500 - val_loss: 0.0863 - val_acc: 0.8500\n",
            "Epoch 536/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1112 - acc: 0.8611 - val_loss: 0.0876 - val_acc: 0.8500\n",
            "Epoch 537/800\n",
            "180/180 [==============================] - 0s 485us/step - loss: 0.1111 - acc: 0.8722 - val_loss: 0.0859 - val_acc: 0.9000\n",
            "Epoch 538/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.1109 - acc: 0.8778 - val_loss: 0.0853 - val_acc: 0.8500\n",
            "Epoch 539/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1109 - acc: 0.8833 - val_loss: 0.0885 - val_acc: 0.9000\n",
            "Epoch 540/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1109 - acc: 0.8611 - val_loss: 0.0880 - val_acc: 0.8500\n",
            "Epoch 541/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1120 - acc: 0.8611 - val_loss: 0.0847 - val_acc: 0.8000\n",
            "Epoch 542/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1113 - acc: 0.8500 - val_loss: 0.0882 - val_acc: 0.9000\n",
            "Epoch 543/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.1109 - acc: 0.8500 - val_loss: 0.0863 - val_acc: 0.8000\n",
            "Epoch 544/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1114 - acc: 0.8722 - val_loss: 0.0883 - val_acc: 0.8500\n",
            "Epoch 545/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1106 - acc: 0.8556 - val_loss: 0.0863 - val_acc: 0.8000\n",
            "Epoch 546/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1107 - acc: 0.8611 - val_loss: 0.0866 - val_acc: 0.8500\n",
            "Epoch 547/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1107 - acc: 0.8667 - val_loss: 0.0864 - val_acc: 0.8500\n",
            "Epoch 548/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1113 - acc: 0.8667 - val_loss: 0.0847 - val_acc: 0.8000\n",
            "Epoch 549/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1109 - acc: 0.8444 - val_loss: 0.0897 - val_acc: 0.9000\n",
            "Epoch 550/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1108 - acc: 0.8667 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 551/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1108 - acc: 0.8556 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 552/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1104 - acc: 0.8667 - val_loss: 0.0860 - val_acc: 0.9500\n",
            "Epoch 553/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.1110 - acc: 0.8722 - val_loss: 0.0860 - val_acc: 0.8500\n",
            "Epoch 554/800\n",
            "180/180 [==============================] - 0s 520us/step - loss: 0.1107 - acc: 0.8667 - val_loss: 0.0855 - val_acc: 0.8500\n",
            "Epoch 555/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1109 - acc: 0.8778 - val_loss: 0.0836 - val_acc: 0.8500\n",
            "Epoch 556/800\n",
            "180/180 [==============================] - 0s 346us/step - loss: 0.1108 - acc: 0.8667 - val_loss: 0.0850 - val_acc: 0.8500\n",
            "Epoch 557/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1111 - acc: 0.8611 - val_loss: 0.0886 - val_acc: 0.8500\n",
            "Epoch 558/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1113 - acc: 0.8778 - val_loss: 0.0874 - val_acc: 0.8500\n",
            "Epoch 559/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1110 - acc: 0.8556 - val_loss: 0.0855 - val_acc: 0.8500\n",
            "Epoch 560/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1103 - acc: 0.8611 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 561/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1105 - acc: 0.8833 - val_loss: 0.0861 - val_acc: 0.9000\n",
            "Epoch 562/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.1104 - acc: 0.8833 - val_loss: 0.0868 - val_acc: 0.8500\n",
            "Epoch 563/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.1105 - acc: 0.8722 - val_loss: 0.0864 - val_acc: 0.8000\n",
            "Epoch 564/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1108 - acc: 0.8667 - val_loss: 0.0854 - val_acc: 0.8500\n",
            "Epoch 565/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1105 - acc: 0.8667 - val_loss: 0.0853 - val_acc: 0.8500\n",
            "Epoch 566/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.1101 - acc: 0.8556 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 567/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1102 - acc: 0.8556 - val_loss: 0.0851 - val_acc: 0.8500\n",
            "Epoch 568/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1101 - acc: 0.8722 - val_loss: 0.0878 - val_acc: 0.8500\n",
            "Epoch 569/800\n",
            "180/180 [==============================] - 0s 386us/step - loss: 0.1108 - acc: 0.8667 - val_loss: 0.0849 - val_acc: 0.8500\n",
            "Epoch 570/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1104 - acc: 0.8778 - val_loss: 0.0870 - val_acc: 0.8500\n",
            "Epoch 571/800\n",
            "180/180 [==============================] - 0s 396us/step - loss: 0.1106 - acc: 0.8722 - val_loss: 0.0870 - val_acc: 0.9000\n",
            "Epoch 572/800\n",
            "180/180 [==============================] - 0s 404us/step - loss: 0.1110 - acc: 0.8833 - val_loss: 0.0851 - val_acc: 0.9000\n",
            "Epoch 573/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1106 - acc: 0.8444 - val_loss: 0.0852 - val_acc: 0.9000\n",
            "Epoch 574/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1110 - acc: 0.8611 - val_loss: 0.0855 - val_acc: 0.8500\n",
            "Epoch 575/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1103 - acc: 0.8611 - val_loss: 0.0858 - val_acc: 0.9000\n",
            "Epoch 576/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1109 - acc: 0.8667 - val_loss: 0.0851 - val_acc: 0.8500\n",
            "Epoch 577/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1100 - acc: 0.8611 - val_loss: 0.0875 - val_acc: 0.9000\n",
            "Epoch 578/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.1105 - acc: 0.8722 - val_loss: 0.0857 - val_acc: 0.8500\n",
            "Epoch 579/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1103 - acc: 0.8667 - val_loss: 0.0834 - val_acc: 0.8500\n",
            "Epoch 580/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1101 - acc: 0.8722 - val_loss: 0.0848 - val_acc: 0.8500\n",
            "Epoch 581/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1100 - acc: 0.8611 - val_loss: 0.0854 - val_acc: 0.8000\n",
            "Epoch 582/800\n",
            "180/180 [==============================] - 0s 377us/step - loss: 0.1103 - acc: 0.8778 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 583/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1101 - acc: 0.8722 - val_loss: 0.0869 - val_acc: 0.8500\n",
            "Epoch 584/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1105 - acc: 0.8722 - val_loss: 0.0847 - val_acc: 0.9000\n",
            "Epoch 585/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1102 - acc: 0.8722 - val_loss: 0.0862 - val_acc: 0.9000\n",
            "Epoch 586/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1107 - acc: 0.8833 - val_loss: 0.0855 - val_acc: 0.9000\n",
            "Epoch 587/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1101 - acc: 0.8833 - val_loss: 0.0863 - val_acc: 0.8500\n",
            "Epoch 588/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1098 - acc: 0.8722 - val_loss: 0.0846 - val_acc: 0.8500\n",
            "Epoch 589/800\n",
            "180/180 [==============================] - 0s 481us/step - loss: 0.1102 - acc: 0.8833 - val_loss: 0.0864 - val_acc: 0.8500\n",
            "Epoch 590/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1107 - acc: 0.8556 - val_loss: 0.0862 - val_acc: 0.8500\n",
            "Epoch 591/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1103 - acc: 0.8889 - val_loss: 0.0895 - val_acc: 0.9000\n",
            "Epoch 592/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1113 - acc: 0.8556 - val_loss: 0.0855 - val_acc: 0.9000\n",
            "Epoch 593/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1102 - acc: 0.9000 - val_loss: 0.0838 - val_acc: 0.8000\n",
            "Epoch 594/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1097 - acc: 0.9000 - val_loss: 0.0849 - val_acc: 0.9000\n",
            "Epoch 595/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1097 - acc: 0.8722 - val_loss: 0.0863 - val_acc: 0.9000\n",
            "Epoch 596/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1101 - acc: 0.8722 - val_loss: 0.0848 - val_acc: 0.9000\n",
            "Epoch 597/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1097 - acc: 0.8889 - val_loss: 0.0867 - val_acc: 0.8500\n",
            "Epoch 598/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1096 - acc: 0.8722 - val_loss: 0.0852 - val_acc: 0.8500\n",
            "Epoch 599/800\n",
            "180/180 [==============================] - 0s 394us/step - loss: 0.1099 - acc: 0.8833 - val_loss: 0.0858 - val_acc: 0.9000\n",
            "Epoch 600/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1101 - acc: 0.8778 - val_loss: 0.0846 - val_acc: 0.9000\n",
            "Epoch 601/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1096 - acc: 0.8667 - val_loss: 0.0834 - val_acc: 0.8000\n",
            "Epoch 602/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1095 - acc: 0.8722 - val_loss: 0.0843 - val_acc: 0.9000\n",
            "Epoch 603/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1101 - acc: 0.9000 - val_loss: 0.0835 - val_acc: 0.8500\n",
            "Epoch 604/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.1097 - acc: 0.8833 - val_loss: 0.0857 - val_acc: 0.8500\n",
            "Epoch 605/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1104 - acc: 0.8722 - val_loss: 0.0837 - val_acc: 0.8500\n",
            "Epoch 606/800\n",
            "180/180 [==============================] - 0s 383us/step - loss: 0.1096 - acc: 0.8944 - val_loss: 0.0843 - val_acc: 0.8000\n",
            "Epoch 607/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1098 - acc: 0.8722 - val_loss: 0.0844 - val_acc: 0.8500\n",
            "Epoch 608/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.1095 - acc: 0.8722 - val_loss: 0.0872 - val_acc: 0.8000\n",
            "Epoch 609/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1095 - acc: 0.8778 - val_loss: 0.0879 - val_acc: 0.8500\n",
            "Epoch 610/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1102 - acc: 0.8667 - val_loss: 0.0848 - val_acc: 0.9000\n",
            "Epoch 611/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1096 - acc: 0.8667 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 612/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1102 - acc: 0.8778 - val_loss: 0.0848 - val_acc: 0.9000\n",
            "Epoch 613/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1099 - acc: 0.8833 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 614/800\n",
            "180/180 [==============================] - 0s 330us/step - loss: 0.1104 - acc: 0.8667 - val_loss: 0.0837 - val_acc: 0.8000\n",
            "Epoch 615/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1101 - acc: 0.8722 - val_loss: 0.0840 - val_acc: 0.9000\n",
            "Epoch 616/800\n",
            "180/180 [==============================] - 0s 391us/step - loss: 0.1094 - acc: 0.8833 - val_loss: 0.0907 - val_acc: 0.8500\n",
            "Epoch 617/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1103 - acc: 0.8833 - val_loss: 0.0864 - val_acc: 0.8500\n",
            "Epoch 618/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1095 - acc: 0.8722 - val_loss: 0.0855 - val_acc: 0.9000\n",
            "Epoch 619/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1094 - acc: 0.8778 - val_loss: 0.0861 - val_acc: 0.9000\n",
            "Epoch 620/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1093 - acc: 0.8889 - val_loss: 0.0842 - val_acc: 0.8000\n",
            "Epoch 621/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1094 - acc: 0.8833 - val_loss: 0.0844 - val_acc: 0.9000\n",
            "Epoch 622/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1090 - acc: 0.8833 - val_loss: 0.0839 - val_acc: 0.9500\n",
            "Epoch 623/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1092 - acc: 0.8833 - val_loss: 0.0862 - val_acc: 0.9000\n",
            "Epoch 624/800\n",
            "180/180 [==============================] - 0s 488us/step - loss: 0.1093 - acc: 0.8500 - val_loss: 0.0866 - val_acc: 0.8500\n",
            "Epoch 625/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1103 - acc: 0.8722 - val_loss: 0.0850 - val_acc: 0.8500\n",
            "Epoch 626/800\n",
            "180/180 [==============================] - 0s 390us/step - loss: 0.1095 - acc: 0.8833 - val_loss: 0.0847 - val_acc: 0.9000\n",
            "Epoch 627/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1093 - acc: 0.8889 - val_loss: 0.0848 - val_acc: 0.8500\n",
            "Epoch 628/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1097 - acc: 0.8889 - val_loss: 0.0848 - val_acc: 0.8500\n",
            "Epoch 629/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1092 - acc: 0.8944 - val_loss: 0.0843 - val_acc: 0.8500\n",
            "Epoch 630/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1093 - acc: 0.8833 - val_loss: 0.0842 - val_acc: 0.9000\n",
            "Epoch 631/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1093 - acc: 0.9000 - val_loss: 0.0845 - val_acc: 0.8000\n",
            "Epoch 632/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1100 - acc: 0.9056 - val_loss: 0.0847 - val_acc: 0.9000\n",
            "Epoch 633/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1091 - acc: 0.8500 - val_loss: 0.0848 - val_acc: 0.9000\n",
            "Epoch 634/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1095 - acc: 0.8611 - val_loss: 0.0847 - val_acc: 0.8000\n",
            "Epoch 635/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1096 - acc: 0.8778 - val_loss: 0.0895 - val_acc: 0.9500\n",
            "Epoch 636/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1094 - acc: 0.9000 - val_loss: 0.0876 - val_acc: 0.9000\n",
            "Epoch 637/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1098 - acc: 0.8833 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 638/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1093 - acc: 0.8833 - val_loss: 0.0858 - val_acc: 0.9000\n",
            "Epoch 639/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1095 - acc: 0.8833 - val_loss: 0.0839 - val_acc: 0.8500\n",
            "Epoch 640/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1090 - acc: 0.8889 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 641/800\n",
            "180/180 [==============================] - 0s 463us/step - loss: 0.1092 - acc: 0.9000 - val_loss: 0.0835 - val_acc: 0.8500\n",
            "Epoch 642/800\n",
            "180/180 [==============================] - 0s 388us/step - loss: 0.1088 - acc: 0.8889 - val_loss: 0.0846 - val_acc: 0.9000\n",
            "Epoch 643/800\n",
            "180/180 [==============================] - 0s 374us/step - loss: 0.1088 - acc: 0.8722 - val_loss: 0.0870 - val_acc: 0.9000\n",
            "Epoch 644/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1100 - acc: 0.8889 - val_loss: 0.0834 - val_acc: 0.8500\n",
            "Epoch 645/800\n",
            "180/180 [==============================] - 0s 345us/step - loss: 0.1089 - acc: 0.8778 - val_loss: 0.0850 - val_acc: 0.9000\n",
            "Epoch 646/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1090 - acc: 0.8833 - val_loss: 0.0873 - val_acc: 0.8500\n",
            "Epoch 647/800\n",
            "180/180 [==============================] - 0s 384us/step - loss: 0.1094 - acc: 0.8500 - val_loss: 0.0864 - val_acc: 0.9500\n",
            "Epoch 648/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1091 - acc: 0.8833 - val_loss: 0.0852 - val_acc: 0.9500\n",
            "Epoch 649/800\n",
            "180/180 [==============================] - 0s 392us/step - loss: 0.1092 - acc: 0.8944 - val_loss: 0.0850 - val_acc: 0.8500\n",
            "Epoch 650/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1095 - acc: 0.8556 - val_loss: 0.0848 - val_acc: 0.9000\n",
            "Epoch 651/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1090 - acc: 0.8833 - val_loss: 0.0861 - val_acc: 0.9000\n",
            "Epoch 652/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1099 - acc: 0.8667 - val_loss: 0.0850 - val_acc: 0.9500\n",
            "Epoch 653/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1090 - acc: 0.8833 - val_loss: 0.0836 - val_acc: 0.8000\n",
            "Epoch 654/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1089 - acc: 0.8944 - val_loss: 0.0837 - val_acc: 0.8000\n",
            "Epoch 655/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1091 - acc: 0.8944 - val_loss: 0.0845 - val_acc: 0.9000\n",
            "Epoch 656/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1086 - acc: 0.8833 - val_loss: 0.0880 - val_acc: 0.9000\n",
            "Epoch 657/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1105 - acc: 0.9000 - val_loss: 0.0853 - val_acc: 0.8000\n",
            "Epoch 658/800\n",
            "180/180 [==============================] - 0s 412us/step - loss: 0.1094 - acc: 0.8833 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 659/800\n",
            "180/180 [==============================] - 0s 420us/step - loss: 0.1089 - acc: 0.9000 - val_loss: 0.0866 - val_acc: 0.9000\n",
            "Epoch 660/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.1094 - acc: 0.8833 - val_loss: 0.0881 - val_acc: 0.9500\n",
            "Epoch 661/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1090 - acc: 0.9000 - val_loss: 0.0848 - val_acc: 0.8500\n",
            "Epoch 662/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1093 - acc: 0.8389 - val_loss: 0.0842 - val_acc: 0.9500\n",
            "Epoch 663/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1088 - acc: 0.8889 - val_loss: 0.0841 - val_acc: 0.8500\n",
            "Epoch 664/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1095 - acc: 0.8833 - val_loss: 0.0847 - val_acc: 0.9000\n",
            "Epoch 665/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1087 - acc: 0.8667 - val_loss: 0.0833 - val_acc: 0.9000\n",
            "Epoch 666/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1088 - acc: 0.8833 - val_loss: 0.0901 - val_acc: 0.9000\n",
            "Epoch 667/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1092 - acc: 0.8889 - val_loss: 0.0849 - val_acc: 0.9500\n",
            "Epoch 668/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1086 - acc: 0.8611 - val_loss: 0.0836 - val_acc: 0.8500\n",
            "Epoch 669/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1087 - acc: 0.8833 - val_loss: 0.0836 - val_acc: 0.9000\n",
            "Epoch 670/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1089 - acc: 0.8889 - val_loss: 0.0848 - val_acc: 0.9000\n",
            "Epoch 671/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1093 - acc: 0.8722 - val_loss: 0.0836 - val_acc: 0.8500\n",
            "Epoch 672/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1089 - acc: 0.8778 - val_loss: 0.0833 - val_acc: 0.8500\n",
            "Epoch 673/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1087 - acc: 0.8944 - val_loss: 0.0855 - val_acc: 0.8500\n",
            "Epoch 674/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1088 - acc: 0.8889 - val_loss: 0.0850 - val_acc: 0.9000\n",
            "Epoch 675/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.1095 - acc: 0.8722 - val_loss: 0.0855 - val_acc: 0.9000\n",
            "Epoch 676/800\n",
            "180/180 [==============================] - 0s 434us/step - loss: 0.1085 - acc: 0.8889 - val_loss: 0.0843 - val_acc: 0.9000\n",
            "Epoch 677/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.1087 - acc: 0.8833 - val_loss: 0.0840 - val_acc: 0.9000\n",
            "Epoch 678/800\n",
            "180/180 [==============================] - 0s 348us/step - loss: 0.1087 - acc: 0.8722 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 679/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1089 - acc: 0.8833 - val_loss: 0.0836 - val_acc: 0.9000\n",
            "Epoch 680/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1088 - acc: 0.8778 - val_loss: 0.0857 - val_acc: 0.8500\n",
            "Epoch 681/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1086 - acc: 0.8889 - val_loss: 0.0859 - val_acc: 0.9000\n",
            "Epoch 682/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1097 - acc: 0.8889 - val_loss: 0.0856 - val_acc: 0.9000\n",
            "Epoch 683/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1090 - acc: 0.8778 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 684/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1089 - acc: 0.8889 - val_loss: 0.0838 - val_acc: 0.8500\n",
            "Epoch 685/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1085 - acc: 0.9000 - val_loss: 0.0830 - val_acc: 0.9000\n",
            "Epoch 686/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1083 - acc: 0.8944 - val_loss: 0.0832 - val_acc: 0.9000\n",
            "Epoch 687/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1083 - acc: 0.8889 - val_loss: 0.0834 - val_acc: 0.9000\n",
            "Epoch 688/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1086 - acc: 0.8889 - val_loss: 0.0847 - val_acc: 0.9000\n",
            "Epoch 689/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1082 - acc: 0.8778 - val_loss: 0.0838 - val_acc: 0.8500\n",
            "Epoch 690/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1097 - acc: 0.8944 - val_loss: 0.0896 - val_acc: 0.9000\n",
            "Epoch 691/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1089 - acc: 0.8778 - val_loss: 0.0839 - val_acc: 0.9000\n",
            "Epoch 692/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1083 - acc: 0.9056 - val_loss: 0.0878 - val_acc: 0.9000\n",
            "Epoch 693/800\n",
            "180/180 [==============================] - 0s 397us/step - loss: 0.1088 - acc: 0.9000 - val_loss: 0.0853 - val_acc: 0.8500\n",
            "Epoch 694/800\n",
            "180/180 [==============================] - 0s 417us/step - loss: 0.1098 - acc: 0.8778 - val_loss: 0.0846 - val_acc: 0.9000\n",
            "Epoch 695/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1086 - acc: 0.8833 - val_loss: 0.0853 - val_acc: 0.9000\n",
            "Epoch 696/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1091 - acc: 0.8833 - val_loss: 0.0837 - val_acc: 0.9000\n",
            "Epoch 697/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1083 - acc: 0.8944 - val_loss: 0.0830 - val_acc: 0.8500\n",
            "Epoch 698/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1087 - acc: 0.8889 - val_loss: 0.0850 - val_acc: 0.9000\n",
            "Epoch 699/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1082 - acc: 0.8889 - val_loss: 0.0845 - val_acc: 0.9000\n",
            "Epoch 700/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1083 - acc: 0.8944 - val_loss: 0.0834 - val_acc: 0.9000\n",
            "Epoch 701/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1083 - acc: 0.9000 - val_loss: 0.0845 - val_acc: 0.8500\n",
            "Epoch 702/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1085 - acc: 0.8944 - val_loss: 0.0837 - val_acc: 0.9000\n",
            "Epoch 703/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1085 - acc: 0.8722 - val_loss: 0.0852 - val_acc: 0.9000\n",
            "Epoch 704/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1084 - acc: 0.8778 - val_loss: 0.0846 - val_acc: 0.9000\n",
            "Epoch 705/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1081 - acc: 0.9056 - val_loss: 0.0846 - val_acc: 0.9000\n",
            "Epoch 706/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1082 - acc: 0.9111 - val_loss: 0.0834 - val_acc: 0.8500\n",
            "Epoch 707/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1084 - acc: 0.8833 - val_loss: 0.0839 - val_acc: 0.9000\n",
            "Epoch 708/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1086 - acc: 0.9056 - val_loss: 0.0860 - val_acc: 0.9000\n",
            "Epoch 709/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1083 - acc: 0.8889 - val_loss: 0.0868 - val_acc: 0.8500\n",
            "Epoch 710/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.1093 - acc: 0.8722 - val_loss: 0.0838 - val_acc: 0.9000\n",
            "Epoch 711/800\n",
            "180/180 [==============================] - 0s 458us/step - loss: 0.1082 - acc: 0.8944 - val_loss: 0.0828 - val_acc: 0.9000\n",
            "Epoch 712/800\n",
            "180/180 [==============================] - 0s 333us/step - loss: 0.1082 - acc: 0.8944 - val_loss: 0.0839 - val_acc: 0.8500\n",
            "Epoch 713/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1082 - acc: 0.8667 - val_loss: 0.0853 - val_acc: 0.9000\n",
            "Epoch 714/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1083 - acc: 0.8833 - val_loss: 0.0847 - val_acc: 0.9000\n",
            "Epoch 715/800\n",
            "180/180 [==============================] - 0s 344us/step - loss: 0.1082 - acc: 0.9056 - val_loss: 0.0842 - val_acc: 0.9000\n",
            "Epoch 716/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1083 - acc: 0.9056 - val_loss: 0.0835 - val_acc: 0.9000\n",
            "Epoch 717/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1082 - acc: 0.8944 - val_loss: 0.0836 - val_acc: 0.9000\n",
            "Epoch 718/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1086 - acc: 0.8778 - val_loss: 0.0869 - val_acc: 0.9000\n",
            "Epoch 719/800\n",
            "180/180 [==============================] - 0s 363us/step - loss: 0.1087 - acc: 0.8778 - val_loss: 0.0844 - val_acc: 0.9000\n",
            "Epoch 720/800\n",
            "180/180 [==============================] - 0s 352us/step - loss: 0.1084 - acc: 0.8944 - val_loss: 0.0844 - val_acc: 0.9000\n",
            "Epoch 721/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1087 - acc: 0.8889 - val_loss: 0.0834 - val_acc: 0.9500\n",
            "Epoch 722/800\n",
            "180/180 [==============================] - 0s 376us/step - loss: 0.1083 - acc: 0.8833 - val_loss: 0.0848 - val_acc: 0.9000\n",
            "Epoch 723/800\n",
            "180/180 [==============================] - 0s 369us/step - loss: 0.1083 - acc: 0.8833 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 724/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1081 - acc: 0.8778 - val_loss: 0.0839 - val_acc: 0.8500\n",
            "Epoch 725/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.1083 - acc: 0.8722 - val_loss: 0.0863 - val_acc: 0.9500\n",
            "Epoch 726/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1090 - acc: 0.9056 - val_loss: 0.0836 - val_acc: 0.9000\n",
            "Epoch 727/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1082 - acc: 0.8889 - val_loss: 0.0834 - val_acc: 0.9000\n",
            "Epoch 728/800\n",
            "180/180 [==============================] - 0s 488us/step - loss: 0.1080 - acc: 0.9000 - val_loss: 0.0841 - val_acc: 0.8500\n",
            "Epoch 729/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1083 - acc: 0.8778 - val_loss: 0.0844 - val_acc: 0.9000\n",
            "Epoch 730/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1081 - acc: 0.8833 - val_loss: 0.0836 - val_acc: 0.9000\n",
            "Epoch 731/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1081 - acc: 0.8889 - val_loss: 0.0855 - val_acc: 0.9000\n",
            "Epoch 732/800\n",
            "180/180 [==============================] - 0s 361us/step - loss: 0.1081 - acc: 0.8889 - val_loss: 0.0834 - val_acc: 0.9000\n",
            "Epoch 733/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1081 - acc: 0.8889 - val_loss: 0.0847 - val_acc: 0.8500\n",
            "Epoch 734/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1086 - acc: 0.8722 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 735/800\n",
            "180/180 [==============================] - 0s 357us/step - loss: 0.1079 - acc: 0.8944 - val_loss: 0.0839 - val_acc: 0.9000\n",
            "Epoch 736/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1078 - acc: 0.8889 - val_loss: 0.0830 - val_acc: 0.9000\n",
            "Epoch 737/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1084 - acc: 0.8889 - val_loss: 0.0842 - val_acc: 0.9000\n",
            "Epoch 738/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1086 - acc: 0.8833 - val_loss: 0.0829 - val_acc: 0.8500\n",
            "Epoch 739/800\n",
            "180/180 [==============================] - 0s 341us/step - loss: 0.1080 - acc: 0.8944 - val_loss: 0.0852 - val_acc: 0.8500\n",
            "Epoch 740/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1084 - acc: 0.8833 - val_loss: 0.0826 - val_acc: 0.9000\n",
            "Epoch 741/800\n",
            "180/180 [==============================] - 0s 385us/step - loss: 0.1081 - acc: 0.8778 - val_loss: 0.0826 - val_acc: 0.9000\n",
            "Epoch 742/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1084 - acc: 0.8944 - val_loss: 0.0832 - val_acc: 0.8500\n",
            "Epoch 743/800\n",
            "180/180 [==============================] - 0s 375us/step - loss: 0.1080 - acc: 0.8944 - val_loss: 0.0842 - val_acc: 0.8500\n",
            "Epoch 744/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1079 - acc: 0.9056 - val_loss: 0.0834 - val_acc: 0.9000\n",
            "Epoch 745/800\n",
            "180/180 [==============================] - 0s 389us/step - loss: 0.1076 - acc: 0.9000 - val_loss: 0.0851 - val_acc: 0.8500\n",
            "Epoch 746/800\n",
            "180/180 [==============================] - 0s 393us/step - loss: 0.1080 - acc: 0.8889 - val_loss: 0.0831 - val_acc: 0.9000\n",
            "Epoch 747/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1079 - acc: 0.9000 - val_loss: 0.0832 - val_acc: 0.8500\n",
            "Epoch 748/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1080 - acc: 0.8889 - val_loss: 0.0839 - val_acc: 0.9000\n",
            "Epoch 749/800\n",
            "180/180 [==============================] - 0s 381us/step - loss: 0.1087 - acc: 0.8833 - val_loss: 0.0843 - val_acc: 0.8500\n",
            "Epoch 750/800\n",
            "180/180 [==============================] - 0s 395us/step - loss: 0.1082 - acc: 0.8889 - val_loss: 0.0838 - val_acc: 0.9000\n",
            "Epoch 751/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1078 - acc: 0.8833 - val_loss: 0.0838 - val_acc: 0.9000\n",
            "Epoch 752/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1084 - acc: 0.8778 - val_loss: 0.0839 - val_acc: 0.9000\n",
            "Epoch 753/800\n",
            "180/180 [==============================] - 0s 370us/step - loss: 0.1079 - acc: 0.8722 - val_loss: 0.0861 - val_acc: 0.8500\n",
            "Epoch 754/800\n",
            "180/180 [==============================] - 0s 378us/step - loss: 0.1086 - acc: 0.8889 - val_loss: 0.0839 - val_acc: 0.8500\n",
            "Epoch 755/800\n",
            "180/180 [==============================] - 0s 360us/step - loss: 0.1079 - acc: 0.8889 - val_loss: 0.0838 - val_acc: 0.9000\n",
            "Epoch 756/800\n",
            "180/180 [==============================] - 0s 368us/step - loss: 0.1082 - acc: 0.9111 - val_loss: 0.0856 - val_acc: 0.9000\n",
            "Epoch 757/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.1079 - acc: 0.8833 - val_loss: 0.0833 - val_acc: 0.9000\n",
            "Epoch 758/800\n",
            "180/180 [==============================] - 0s 367us/step - loss: 0.1081 - acc: 0.9000 - val_loss: 0.0827 - val_acc: 0.9000\n",
            "Epoch 759/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1080 - acc: 0.8944 - val_loss: 0.0838 - val_acc: 0.9500\n",
            "Epoch 760/800\n",
            "180/180 [==============================] - 0s 387us/step - loss: 0.1080 - acc: 0.8944 - val_loss: 0.0855 - val_acc: 0.9000\n",
            "Epoch 761/800\n",
            "180/180 [==============================] - 0s 351us/step - loss: 0.1085 - acc: 0.8722 - val_loss: 0.0834 - val_acc: 0.9000\n",
            "Epoch 762/800\n",
            "180/180 [==============================] - 0s 359us/step - loss: 0.1079 - acc: 0.9000 - val_loss: 0.0830 - val_acc: 0.9000\n",
            "Epoch 763/800\n",
            "180/180 [==============================] - 0s 504us/step - loss: 0.1079 - acc: 0.8944 - val_loss: 0.0853 - val_acc: 0.9000\n",
            "Epoch 764/800\n",
            "180/180 [==============================] - 0s 366us/step - loss: 0.1081 - acc: 0.8833 - val_loss: 0.0840 - val_acc: 0.9000\n",
            "Epoch 765/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1077 - acc: 0.8944 - val_loss: 0.0847 - val_acc: 0.8500\n",
            "Epoch 766/800\n",
            "180/180 [==============================] - 0s 392us/step - loss: 0.1084 - acc: 0.8944 - val_loss: 0.0835 - val_acc: 0.9000\n",
            "Epoch 767/800\n",
            "180/180 [==============================] - 0s 379us/step - loss: 0.1076 - acc: 0.8944 - val_loss: 0.0863 - val_acc: 0.9000\n",
            "Epoch 768/800\n",
            "180/180 [==============================] - 0s 373us/step - loss: 0.1077 - acc: 0.9000 - val_loss: 0.0847 - val_acc: 0.9000\n",
            "Epoch 769/800\n",
            "180/180 [==============================] - 0s 343us/step - loss: 0.1079 - acc: 0.9000 - val_loss: 0.0835 - val_acc: 0.9000\n",
            "Epoch 770/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1087 - acc: 0.8944 - val_loss: 0.0837 - val_acc: 0.9000\n",
            "Epoch 771/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1076 - acc: 0.8778 - val_loss: 0.0868 - val_acc: 0.9000\n",
            "Epoch 772/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1086 - acc: 0.8778 - val_loss: 0.0842 - val_acc: 0.9000\n",
            "Epoch 773/800\n",
            "180/180 [==============================] - 0s 338us/step - loss: 0.1077 - acc: 0.8722 - val_loss: 0.0835 - val_acc: 0.9000\n",
            "Epoch 774/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1080 - acc: 0.8944 - val_loss: 0.0845 - val_acc: 0.9000\n",
            "Epoch 775/800\n",
            "180/180 [==============================] - 0s 356us/step - loss: 0.1077 - acc: 0.8833 - val_loss: 0.0845 - val_acc: 0.9000\n",
            "Epoch 776/800\n",
            "180/180 [==============================] - 0s 338us/step - loss: 0.1074 - acc: 0.8944 - val_loss: 0.0833 - val_acc: 0.8500\n",
            "Epoch 777/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1076 - acc: 0.8944 - val_loss: 0.0823 - val_acc: 0.8500\n",
            "Epoch 778/800\n",
            "180/180 [==============================] - 0s 389us/step - loss: 0.1075 - acc: 0.8889 - val_loss: 0.0851 - val_acc: 0.9000\n",
            "Epoch 779/800\n",
            "180/180 [==============================] - 0s 382us/step - loss: 0.1077 - acc: 0.9056 - val_loss: 0.0839 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00779: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 780/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1074 - acc: 0.8889 - val_loss: 0.0823 - val_acc: 0.8500\n",
            "Epoch 781/800\n",
            "180/180 [==============================] - 0s 364us/step - loss: 0.1069 - acc: 0.8944 - val_loss: 0.0826 - val_acc: 0.9000\n",
            "Epoch 782/800\n",
            "180/180 [==============================] - 0s 355us/step - loss: 0.1070 - acc: 0.8889 - val_loss: 0.0827 - val_acc: 0.9000\n",
            "Epoch 783/800\n",
            "180/180 [==============================] - 0s 362us/step - loss: 0.1070 - acc: 0.8889 - val_loss: 0.0827 - val_acc: 0.9000\n",
            "Epoch 784/800\n",
            "180/180 [==============================] - 0s 365us/step - loss: 0.1070 - acc: 0.8889 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 785/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1069 - acc: 0.8944 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 786/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1069 - acc: 0.8889 - val_loss: 0.0826 - val_acc: 0.9000\n",
            "Epoch 787/800\n",
            "180/180 [==============================] - 0s 350us/step - loss: 0.1070 - acc: 0.8944 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 788/800\n",
            "180/180 [==============================] - 0s 339us/step - loss: 0.1070 - acc: 0.9000 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 789/800\n",
            "180/180 [==============================] - 0s 464us/step - loss: 0.1069 - acc: 0.8889 - val_loss: 0.0824 - val_acc: 0.9000\n",
            "Epoch 790/800\n",
            "180/180 [==============================] - 0s 354us/step - loss: 0.1070 - acc: 0.8944 - val_loss: 0.0825 - val_acc: 0.8500\n",
            "Epoch 791/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1070 - acc: 0.8944 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 792/800\n",
            "180/180 [==============================] - 0s 338us/step - loss: 0.1069 - acc: 0.9000 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 793/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1069 - acc: 0.9000 - val_loss: 0.0824 - val_acc: 0.9000\n",
            "Epoch 794/800\n",
            "180/180 [==============================] - 0s 371us/step - loss: 0.1070 - acc: 0.8944 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 795/800\n",
            "180/180 [==============================] - 0s 353us/step - loss: 0.1070 - acc: 0.8889 - val_loss: 0.0824 - val_acc: 0.9000\n",
            "Epoch 796/800\n",
            "180/180 [==============================] - 0s 347us/step - loss: 0.1070 - acc: 0.9000 - val_loss: 0.0824 - val_acc: 0.9000\n",
            "Epoch 797/800\n",
            "180/180 [==============================] - 0s 342us/step - loss: 0.1069 - acc: 0.8944 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 798/800\n",
            "180/180 [==============================] - 0s 372us/step - loss: 0.1070 - acc: 0.8944 - val_loss: 0.0825 - val_acc: 0.9000\n",
            "Epoch 799/800\n",
            "180/180 [==============================] - 0s 358us/step - loss: 0.1070 - acc: 0.8889 - val_loss: 0.0824 - val_acc: 0.9000\n",
            "Epoch 800/800\n",
            "180/180 [==============================] - 0s 349us/step - loss: 0.1069 - acc: 0.9000 - val_loss: 0.0824 - val_acc: 0.9000\n",
            "210/210 [==============================] - 0s 130us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[test_loss, test_acc]'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[5.602794224875314, 0.276190476332392]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "f-RQZlxV2GaH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}